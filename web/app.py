import os
import asyncio
import re
import json
import time
import threading
import subprocess
import sys
import mimetypes
import importlib.util
import base64
import shutil
from datetime import datetime

# ç¡®ä¿ web/ ç›®å½•åœ¨æ¨¡å—æœç´¢è·¯å¾„ä¸­ï¼ˆé€šè¿‡ koto_app.py å¯åŠ¨æ—¶éœ€è¦ï¼‰
_web_dir = os.path.dirname(os.path.abspath(__file__))
if _web_dir not in sys.path:
    sys.path.append(_web_dir)

from flask import Flask, render_template, request, jsonify, send_from_directory, Response, stream_with_context, send_file
from flask_cors import CORS
from dotenv import load_dotenv

# Import new routing modules
from app.core.routing import SmartDispatcher

# å»¶è¿Ÿå¯¼å…¥ - è¿™äº›è·¯ç”±ç±»ä»…åœ¨è¿è¡Œæ—¶é¦–æ¬¡è®¿é—®æ—¶é€šè¿‡ __getattr__ åŠ è½½
# LocalModelRouter, AIRouter, TaskDecomposer, LocalPlanner é€šè¿‡ app.core.routing.__getattr__ å»¶è¿ŸåŠ è½½

# Import unified agent API blueprint â€” å»¶è¿Ÿåˆ°è“å›¾æ³¨å†Œæ—¶åŠ è½½
agent_bp = None  # å»¶è¿ŸåŠ è½½ï¼Œè§ä¸‹æ–¹è“å›¾æ³¨å†ŒåŒº

# ================= å¹¶è¡Œæ‰§è¡Œç³»ç»Ÿå¯¼å…¥ =================
try:
    from parallel_executor import (
        Task, TaskType, Priority, TaskStatus,
        get_queue_manager, get_resource_manager, get_task_monitor,
        submit_task, get_next_task, cancel_task
    )
    from task_dispatcher import get_scheduler, start_dispatcher, stop_dispatcher
    from parallel_api import register_parallel_api
    PARALLEL_SYSTEM_ENABLED = True
except ImportError as e:
    print(f"[WARNING] Failed to import parallel execution system: {e}")
    PARALLEL_SYSTEM_ENABLED = False

try:
    from flask_sock import Sock
except ImportError:
    Sock = None

# ================= æ‡’åŠ è½½é‡å‹æ¨¡å—ï¼ˆå¯åŠ¨ä¼˜åŒ–ï¼‰ =================
# google.genai (~4.7s), requests (~0.5s) å»¶è¿Ÿåˆ°é¦–æ¬¡ä½¿ç”¨æ—¶åŠ è½½

class _LazyModule:
    """å»¶è¿Ÿå¯¼å…¥ä»£ç† - é¦–æ¬¡å±æ€§è®¿é—®æ—¶æ‰è§¦å‘å®é™… import"""
    __slots__ = ('_import_func', '_module')

    def __init__(self, import_func):
        object.__setattr__(self, '_import_func', import_func)
        object.__setattr__(self, '_module', None)

    def _load(self):
        mod = object.__getattribute__(self, '_module')
        if mod is None:
            import_func = object.__getattribute__(self, '_import_func')
            mod = import_func()
            object.__setattr__(self, '_module', mod)
        return mod

    def __getattr__(self, name):
        return getattr(self._load(), name)

    def __repr__(self):
        mod = object.__getattribute__(self, '_module')
        if mod is None:
            return "<LazyModule (not loaded)>"
        return repr(mod)

def _import_genai():
    print("[LAZY_IMPORT] åŠ è½½ google.genai ...")
    from google import genai as _genai
    return _genai

def _import_types():
    print("[LAZY_IMPORT] åŠ è½½ google.genai.types ...")
    from google.genai import types as _types
    return _types

def _import_requests():
    print("[LAZY_IMPORT] åŠ è½½ requests ...")
    import requests as _requests
    return _requests

genai = _LazyModule(_import_genai)
types = _LazyModule(_import_types)
requests = _LazyModule(_import_requests)

# ================= æ‡’åŠ è½½æ–‡æ¡£å’ŒPPTæ¨¡å—ï¼ˆå¯åŠ¨åŠ é€Ÿï¼‰ =================
# å»¶è¿Ÿå¯¼å…¥ python-docx (~572ms) å’Œ python-pptx (~666ms)

# æ–‡æ¡£å·¥ä½œæµæ‰§è¡Œå™¨æ‡’åŠ è½½
_document_workflow_cache = {}

def get_document_workflow_executor():
    """æ‡’åŠ è½½æ–‡æ¡£å·¥ä½œæµæ‰§è¡Œå™¨"""
    if 'executor' not in _document_workflow_cache:
        print("[LAZY_IMPORT] åŠ è½½æ–‡æ¡£å·¥ä½œæµæ‰§è¡Œå™¨...")
        try:
            from web.document_workflow_executor import DocumentWorkflowExecutor, execute_document_workflow
        except ImportError:
            try:
                from document_workflow_executor import DocumentWorkflowExecutor, execute_document_workflow
            except ImportError:
                DocumentWorkflowExecutor = None
                execute_document_workflow = None
                print("[WARNING] æ–‡æ¡£å·¥ä½œæµæ‰§è¡Œå™¨æœªå®‰è£…")
        _document_workflow_cache['executor'] = DocumentWorkflowExecutor
        _document_workflow_cache['execute'] = execute_document_workflow
    return _document_workflow_cache.get('executor'), _document_workflow_cache.get('execute')

# DocumentWorkflowExecutor å’Œ execute_document_workflow çš„æ‡’åŠ è½½ä»£ç†
class _DocWorkflowProxy:
    def __getattr__(self, name):
        executor_cls, _ = get_document_workflow_executor()
        if executor_cls is None:
            raise ImportError("æ–‡æ¡£å·¥ä½œæµæ‰§è¡Œå™¨æœªå®‰è£…")
        return getattr(executor_cls, name)

DocumentWorkflowExecutor = _DocWorkflowProxy()

def execute_document_workflow(*args, **kwargs):
    _, execute_func = get_document_workflow_executor()
    if execute_func is None:
        raise ImportError("æ–‡æ¡£å·¥ä½œæµæ‰§è¡Œå™¨æœªå®‰è£…")
    return execute_func(*args, **kwargs)

# PPTå¤šæ¨¡å‹ç³»ç»Ÿæ‡’åŠ è½½
_ppt_system_cache = {}

def get_ppt_system():
    """æ‡’åŠ è½½PPTç”Ÿæˆç³»ç»Ÿ"""
    if 'loaded' not in _ppt_system_cache:
        print("[LAZY_IMPORT] åŠ è½½PPTå¤šæ¨¡å‹ç”Ÿæˆç³»ç»Ÿ...")
        try:
            from web.ppt_master import PPTMasterOrchestrator, PPTBlueprint
            from web.ppt_synthesizer import PPTSynthesizer
            from web.ppt_pipeline import PPTGenerationPipeline, PPTGenerationTaskHandler, format_ppt_generation_result
            print("[PPT_SYSTEM] âœ… å¤šæ¨¡å‹PPTç”Ÿæˆç³»ç»Ÿå·²åŠ è½½")
        except ImportError:
            try:
                from ppt_master import PPTMasterOrchestrator, PPTBlueprint
                from ppt_synthesizer import PPTSynthesizer
                from ppt_pipeline import PPTGenerationPipeline, PPTGenerationTaskHandler, format_ppt_generation_result
                print("[PPT_SYSTEM] âœ… å¤šæ¨¡å‹PPTç”Ÿæˆç³»ç»Ÿå·²åŠ è½½ï¼ˆç›¸å¯¹å¯¼å…¥ï¼‰")
            except ImportError:
                PPTMasterOrchestrator = None
                PPTBlueprint = None
                PPTSynthesizer = None
                PPTGenerationPipeline = None
                PPTGenerationTaskHandler = None
                format_ppt_generation_result = None
                print("[WARNING] å¤šæ¨¡å‹PPTç”Ÿæˆç³»ç»Ÿæœªå®‰è£…")
        _ppt_system_cache['orchestrator'] = PPTMasterOrchestrator
        _ppt_system_cache['blueprint'] = PPTBlueprint
        _ppt_system_cache['synthesizer'] = PPTSynthesizer
        _ppt_system_cache['pipeline'] = PPTGenerationPipeline
        _ppt_system_cache['handler'] = PPTGenerationTaskHandler
        _ppt_system_cache['formatter'] = format_ppt_generation_result
        _ppt_system_cache['loaded'] = True
    
    return (_ppt_system_cache.get('orchestrator'),
            _ppt_system_cache.get('blueprint'),
            _ppt_system_cache.get('synthesizer'),
            _ppt_system_cache.get('pipeline'),
            _ppt_system_cache.get('handler'),
            _ppt_system_cache.get('formatter'))

# æ‡’åŠ è½½ä»£ç†ç±»
class _PPTModuleProxy:
    def __init__(self, index):
        self._index = index
    
    def __getattr__(self, name):
        modules = get_ppt_system()
        module = modules[self._index]
        if module is None:
            raise ImportError("PPTç”Ÿæˆç³»ç»Ÿæœªå®‰è£…")
        return getattr(module, name)
    
    def __call__(self, *args, **kwargs):
        modules = get_ppt_system()
        module = modules[self._index]
        if module is None:
            raise ImportError("PPTç”Ÿæˆç³»ç»Ÿæœªå®‰è£…")
        if callable(module):
            return module(*args, **kwargs)
        raise TypeError(f"{module} is not callable")

PPTMasterOrchestrator = _PPTModuleProxy(0)
PPTBlueprint = _PPTModuleProxy(1)
PPTSynthesizer = _PPTModuleProxy(2)
PPTGenerationPipeline = _PPTModuleProxy(3)
PPTGenerationTaskHandler = _PPTModuleProxy(4)
format_ppt_generation_result = _PPTModuleProxy(5)

# ================= Configuration =================
# ä» web ç›®å½•å‘ä¸ŠæŸ¥æ‰¾
import os
import sys as _sys

# ä¸­æ–­ä¿¡å·å­˜å‚¨ - æ”¹è¿›ç‰ˆæœ¬ï¼Œæ”¯æŒå®æ—¶æµä¸­æ­¢
class StreamInterruptManager:
    """ç®¡ç†æ¯ä¸ª session çš„æµä¸­æ­¢çŠ¶æ€å’Œæ§åˆ¶"""
    def __init__(self):
        self.interrupts = {}  # session_name -> {'flag': bool, 'event': threading.Event}

    def _ensure(self, session_name):
        """ç¡®ä¿ session è®°å½•å­˜åœ¨"""
        if session_name not in self.interrupts:
            self.interrupts[session_name] = {'flag': False, 'event': threading.Event()}
        elif self.interrupts[session_name].get('event') is None:
            self.interrupts[session_name]['event'] = threading.Event()
    
    def set_interrupt(self, session_name):
        """è®¾ç½®ä¸­æ–­æ ‡å¿—"""
        self._ensure(session_name)
        self.interrupts[session_name]['flag'] = True
        if self.interrupts[session_name]['event']:
            self.interrupts[session_name]['event'].set()
        print(f"[INTERRUPT] Marked session {session_name} for interruption")
    
    def is_interrupted(self, session_name):
        """æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­"""
        if session_name not in self.interrupts:
            return False
        record = self.interrupts[session_name]
        event_flag = record.get('event').is_set() if record.get('event') else False
        return bool(record.get('flag')) or event_flag
    
    def reset(self, session_name):
        """é‡ç½®ä¸­æ–­æ ‡å¿—"""
        self._ensure(session_name)
        self.interrupts[session_name]['flag'] = False
        if self.interrupts[session_name]['event']:
            self.interrupts[session_name]['event'].clear()
        print(f"[INTERRUPT] Reset interrupt flag for session {session_name}")

    def get_event(self, session_name):
        """è·å–/åˆ›å»ºä¸­æ–­äº‹ä»¶å¯¹è±¡"""
        self._ensure(session_name)
        return self.interrupts[session_name]['event']
    
    def cleanup(self, session_name):
        """æ¸…ç† session çš„ä¸­æ–­è®°å½•"""
        if session_name in self.interrupts:
            del self.interrupts[session_name]

_interrupt_manager = StreamInterruptManager()
# ä¿ç•™å‘åå…¼å®¹
_interrupt_flags = {}  # ä»…ç”¨äºå‘åå…¼å®¹

# åˆ¤æ–­æ˜¯å¦ä¸ºæ‰“åŒ…åè¿è¡Œ
if getattr(_sys, 'frozen', False):
    # PyInstaller æ‰“åŒ…å - exeæ‰€åœ¨ç›®å½•ï¼ˆæŒä¹…åŒ–æ•°æ®ç›®å½•ï¼‰
    PROJECT_ROOT = os.path.dirname(_sys.executable)
else:
    # å¼€å‘ç¯å¢ƒ - ä» web ç›®å½•å‘ä¸Šæ‰¾
    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
    PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)

# Try multiple locations for the config file
config_locations = [
    os.path.join(PROJECT_ROOT, "config", "gemini_config.env"),
    os.path.join(PROJECT_ROOT, "gemini_config.env"),
    os.path.join(os.path.dirname(_sys.executable), "config", "gemini_config.env") if getattr(_sys, 'frozen', False) else "",
    "gemini_config.env",
    "../gemini_config.env"
]

for config_path in config_locations:
    if os.path.exists(config_path):
        load_dotenv(config_path)
        break

# å°è¯•è¯»å– GEMINI_API_KEY æˆ– API_KEY
API_KEY = os.getenv("GEMINI_API_KEY") or os.getenv("API_KEY")

# è¯»å–è‡ªå®šä¹‰ API ç«¯ç‚¹ï¼ˆç”¨äºä¸­è½¬æœåŠ¡ï¼‰
GEMINI_API_BASE = os.getenv("GEMINI_API_BASE", "").strip()
FORCE_PROXY = os.getenv("FORCE_PROXY", "").strip()

_user_settings_cache = {}

def _load_user_settings() -> dict:
    """Load user_settings.json with caching and safe fallbacks."""
    if "data" in _user_settings_cache:
        return _user_settings_cache["data"]
    settings_path = os.path.join(PROJECT_ROOT, "config", "user_settings.json")
    try:
        with open(settings_path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception:
        data = {}
    _user_settings_cache["data"] = data
    return data

def get_workspace_root() -> str:
    """Return the workspace root directory from settings or default path."""
    settings = _load_user_settings()
    workspace_dir = settings.get("storage", {}).get("workspace_dir")
    if workspace_dir:
        return workspace_dir
    return os.path.join(PROJECT_ROOT, "workspace")

def get_organize_root() -> str:
    """Return the file organization root directory from settings or default path."""
    settings = _load_user_settings()
    organize_root = settings.get("storage", {}).get("organize_root")
    if organize_root:
        return organize_root
    return os.path.join(get_workspace_root(), "_organize")

def get_default_wechat_files_dir() -> str:
    """Return configured default WeChat files directory, if provided by user settings."""
    settings = _load_user_settings()
    return settings.get("storage", {}).get("wechat_files_dir", "")

if not API_KEY:
    print("âš ï¸ Warning: GEMINI_API_KEY or API_KEY not found in gemini_config.env")
    print("   è¯·åœ¨ config/gemini_config.env ä¸­é…ç½® API å¯†é’¥")
    print("   åº”ç”¨å°†ç»§ç»­å¯åŠ¨ï¼Œä½† AI åŠŸèƒ½ä¸å¯ç”¨")
    # ä¸å† sys.exit â€” å…è®¸åº”ç”¨å¯åŠ¨å¹¶åœ¨ UI ä¸­æç¤ºç”¨æˆ·é…ç½®

if GEMINI_API_BASE:
    print(f"ğŸ“¡ ä½¿ç”¨è‡ªå®šä¹‰ API ç«¯ç‚¹: {GEMINI_API_BASE}")

# æ£€æµ‹å¹¶è®¾ç½®ä»£ç†
PROXY_OPTIONS = [
    "http://127.0.0.1:7890",
    "http://127.0.0.1:10809",
    "http://127.0.0.1:1080",
]

def _normalize_proxy_url(proxy_value: str) -> str:
    """Normalize proxy value to a URL with scheme."""
    if not proxy_value:
        return ""
    value = proxy_value.strip()
    if not value:
        return ""
    if "://" not in value:
        value = f"http://{value}"
    return value

def _extract_system_proxy_candidates() -> list:
    """Collect proxy candidates from system settings (Windows) and env."""
    candidates = []

    # 1) Environment variables first (if user/system already configured)
    env_proxy = os.environ.get("HTTPS_PROXY") or os.environ.get("https_proxy")
    if env_proxy:
        candidates.append(_normalize_proxy_url(env_proxy))

    # 2) Windows Internet Settings proxy (for "Use a proxy server")
    if sys.platform.startswith("win"):
        try:
            import winreg
            key_path = r"Software\Microsoft\Windows\CurrentVersion\Internet Settings"
            with winreg.OpenKey(winreg.HKEY_CURRENT_USER, key_path) as key:
                proxy_enabled = winreg.QueryValueEx(key, "ProxyEnable")[0]
                if proxy_enabled:
                    proxy_server = str(winreg.QueryValueEx(key, "ProxyServer")[0]).strip()
                    if proxy_server:
                        # Formats:
                        #   127.0.0.1:7890
                        #   http=127.0.0.1:7890;https=127.0.0.1:7890
                        if "=" in proxy_server and ";" in proxy_server:
                            pairs = [p.strip() for p in proxy_server.split(";") if p.strip()]
                            parsed_map = {}
                            for pair in pairs:
                                if "=" in pair:
                                    k, v = pair.split("=", 1)
                                    parsed_map[k.strip().lower()] = v.strip()
                            for proto in ["https", "http", "socks", "socks5"]:
                                if parsed_map.get(proto):
                                    candidates.append(_normalize_proxy_url(parsed_map.get(proto)))
                        else:
                            candidates.append(_normalize_proxy_url(proxy_server))
        except Exception:
            pass

    # 3) Built-in localhost fallback options
    candidates.extend(PROXY_OPTIONS)

    # De-duplicate while preserving order
    deduped = []
    seen = set()
    for item in candidates:
        if not item:
            continue
        key = item.lower()
        if key in seen:
            continue
        seen.add(key)
        deduped.append(item)
    return deduped

def setup_proxy():
    # ä¼˜å…ˆä½¿ç”¨å¼ºåˆ¶ä»£ç†ï¼ˆä¸éœ€è¦æµ‹è¯•ï¼‰
    if FORCE_PROXY and FORCE_PROXY.lower() not in ("auto", "system"):
        os.environ["HTTPS_PROXY"] = FORCE_PROXY
        os.environ["HTTP_PROXY"] = FORCE_PROXY
        print(f"ğŸ”§ ä½¿ç”¨å¼ºåˆ¶ä»£ç†: {FORCE_PROXY}")
        return FORCE_PROXY

    # è‡ªåŠ¨åŒ¹é…ç³»ç»Ÿä»£ç†ä¸æœ¬åœ°å¸¸è§ç«¯å£
    import socket
    from urllib.parse import urlparse

    proxy_candidates = _extract_system_proxy_candidates()

    for proxy in proxy_candidates:
        try:
            # ä» URL æå– host:port
            parsed = urlparse(proxy)
            host = parsed.hostname
            port = parsed.port
            if not host or not port:
                continue
            
            # å¿«é€Ÿç«¯å£æ£€æµ‹ï¼ˆ0.1ç§’è¶…æ—¶ï¼‰
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(0.1)
            result = sock.connect_ex((host, port))
            sock.close()
            
            if result == 0:
                os.environ["HTTPS_PROXY"] = proxy
                os.environ["HTTP_PROXY"] = proxy
                print(f"âœ… è‡ªåŠ¨åŒ¹é…ç³»ç»Ÿä»£ç†: {proxy}")
                return proxy
        except:
            continue
    
    return None

# å»¶è¿Ÿä»£ç†æ£€æµ‹åˆ°é¦–æ¬¡éœ€è¦æ—¶ï¼ˆå¯åŠ¨åŠ é€Ÿï¼‰
_detected_proxy = None
_proxy_checked = False

def get_detected_proxy():
    """æ‡’åŠ è½½ä»£ç†æ£€æµ‹ï¼ˆé¦–æ¬¡è°ƒç”¨æ—¶æ‰§è¡Œï¼‰"""
    global _detected_proxy, _proxy_checked
    if not _proxy_checked:
        _detected_proxy = setup_proxy()
        _proxy_checked = True
    return _detected_proxy

# å‘åå…¼å®¹ï¼šdetected_proxy ç°åœ¨é€šè¿‡å‡½æ•°è®¿é—®
detected_proxy = None  # å ä½ç¬¦ï¼Œå®é™…é€šè¿‡ get_detected_proxy() è·å–

# åœ¨åå°çº¿ç¨‹é¢„çƒ­ä»£ç†æ£€æµ‹ï¼ˆä¸é˜»å¡å¯åŠ¨ï¼‰
def _warmup_proxy():
    global detected_proxy
    detected_proxy = get_detected_proxy()
threading.Thread(target=_warmup_proxy, daemon=True).start()

# åˆ›å»º GenAI å®¢æˆ·ç«¯ (é…ç½®ä»£ç†å’Œè‡ªå®šä¹‰ç«¯ç‚¹)
def create_client():
    import httpx
    proxy = get_detected_proxy()
    # è¶…æ—¶æ—¶é—´: è¿æ¥30ç§’, è¯»å–180ç§’ (Nano Banana å›¾åƒç”Ÿæˆå’Œé•¿æ–‡æœ¬ç”Ÿæˆéœ€è¦æ›´é•¿æ—¶é—´)
    timeout_config = httpx.Timeout(180.0, connect=30.0)
    
    # æ„å»º http_options
    http_options = {}
    
    # æ³¨æ„ï¼šæœ€æ–°çš„ Gemini æ¨¡å‹ï¼ˆå¦‚ gemini-1.5-flashï¼‰éœ€è¦ v1beta API
    # v1 API åªæ”¯æŒæ—§çš„æ¨¡å‹ã€‚è¿™é‡Œä½¿ç”¨ v1betaã€‚
    http_options['api_version'] = 'v1beta'
    
    # è‡ªå®šä¹‰ API ç«¯ç‚¹ï¼ˆç”¨äºä¸­è½¬æœåŠ¡ï¼‰
    if GEMINI_API_BASE:
        http_options['base_url'] = GEMINI_API_BASE
        print(f"ğŸ“¡ API ç«¯ç‚¹: {GEMINI_API_BASE}")
    
    # é…ç½®ä»£ç† - é€šè¿‡ç¯å¢ƒå˜é‡ç¡®ä¿è¢«ä½¿ç”¨
    if proxy:
        os.environ["HTTP_PROXY"] = proxy
        os.environ["HTTPS_PROXY"] = proxy
        print(f"ğŸ”Œ è®¾ç½®ä»£ç†: {proxy}")
        
    # ä½¿ç”¨ httpx with explicit proxy for genai
    try:
        if proxy:
            http_client = httpx.Client(
                proxy=proxy,
                timeout=timeout_config,
                verify=False  # SSL verification disabled with proxy
            )
            http_options['httpxClient'] = http_client
        else:
            # æ— ä»£ç†æ—¶ä¹Ÿè¦é…ç½®è¶…æ—¶
            http_client = httpx.Client(
                timeout=timeout_config,
                verify=True
            )
            http_options['httpxClient'] = http_client
    except Exception as e:
        print(f"âš ï¸ åˆ›å»º HTTP å®¢æˆ·ç«¯å‡ºé”™ (proxy={proxy}): {e}")
        # å›é€€ï¼šä¸ä½¿ç”¨ä»£ç†
        if proxy:
            print(f"âš ï¸ å°è¯•ä¸ä½¿ç”¨ä»£ç†é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯")
            http_client = httpx.Client(
                timeout=timeout_config,
                verify=True
            )
            http_options['httpxClient'] = http_client
    
    return genai.Client(
        api_key=API_KEY,
        http_options=http_options if http_options else None
    )

# æ‡’åŠ è½½å®¢æˆ·ç«¯
_client = None

def get_client():
    """è·å– GenAI å®¢æˆ·ç«¯ï¼ˆæ‡’åŠ è½½ï¼‰"""
    global _client
    if _client is None:
        _client = create_client()
    return _client

# ä¿æŒå‘åå…¼å®¹çš„ client å˜é‡ï¼ˆé€šè¿‡å±æ€§è®¿é—®è§¦å‘æ‡’åŠ è½½ï¼‰
class _ClientProxy:
    """ä»£ç†ç±»ï¼Œå®ç°æ‡’åŠ è½½"""
    def __getattr__(self, name):
        return getattr(get_client(), name)

client = _ClientProxy()


def create_research_client():
    """åˆ›å»ºä¸“ç”¨äº Deep Research çš„é•¿è¶…æ—¶å®¢æˆ·ç«¯ (5åˆ†é’Ÿ read timeout)"""
    import httpx
    proxy = get_detected_proxy()
    # æ·±åº¦ç ”ç©¶éœ€è¦æ›´é•¿çš„è¶…æ—¶æ—¶é—´ï¼šè¿æ¥30ç§’ï¼Œè¯»å–5åˆ†é’Ÿ
    timeout_config = httpx.Timeout(300.0, connect=30.0)
    
    # æ„å»º http_options
    http_options = {}
    
    # æœ€æ–°çš„ Gemini æ¨¡å‹éœ€è¦ v1beta API
    http_options['api_version'] = 'v1beta'
    
    # è‡ªå®šä¹‰ API ç«¯ç‚¹
    if GEMINI_API_BASE:
        http_options['base_url'] = GEMINI_API_BASE
    
    # é…ç½®ä»£ç† - é€šè¿‡ç¯å¢ƒå˜é‡ç¡®ä¿è¢«ä½¿ç”¨
    if proxy:
        os.environ["HTTP_PROXY"] = proxy
        os.environ["HTTPS_PROXY"] = proxy
        
    if proxy:
        http_client = httpx.Client(
            proxy=proxy,
            timeout=timeout_config,
            verify=False  # SSL verification disabled with proxy
        )
        http_options['httpxClient'] = http_client
    else:
        http_client = httpx.Client(
            timeout=timeout_config,
            verify=True
        )
        http_options['httpxClient'] = http_client
    
    return genai.Client(
        api_key=API_KEY,
        http_options=http_options if http_options else None
    )


def run_with_timeout(fn, timeout_seconds):
    """åœ¨çº¿ç¨‹ä¸­æ‰§è¡Œå‡½æ•°å¹¶é™æ—¶è¿”å› (é¿å…å¡æ­»ä¸»æµç¨‹)"""
    holder = {'result': None, 'error': None}

    def _runner():
        try:
            holder['result'] = fn()
        except Exception as e:
            holder['error'] = e

    t = threading.Thread(target=_runner, daemon=True)
    t.start()
    t.join(timeout_seconds)
    if t.is_alive():
        return None, TimeoutError(f"Timeout after {timeout_seconds}s"), True
    return holder['result'], holder['error'], False


def run_with_heartbeat(fn, start_time, heartbeat_callback, heartbeat_interval=5, timeout_seconds=90):
    """
    åœ¨åå°çº¿ç¨‹è¿è¡Œå‡½æ•°ï¼ŒåŒæ—¶å®šæœŸå‘é€å¿ƒè·³ã€‚
    ç”¨äºéæµå¼ API è°ƒç”¨ï¼ˆå¦‚å›¾åƒç”Ÿæˆï¼‰ã€‚
    
    Args:
        fn: è¦æ‰§è¡Œçš„å‡½æ•°
        start_time: è¯·æ±‚å¼€å§‹æ—¶é—´
        heartbeat_callback: å¿ƒè·³å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ elapsed_seconds å‚æ•°
        heartbeat_interval: å¿ƒè·³é—´éš”ï¼ˆç§’ï¼‰
        timeout_seconds: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    Returns:
        (result, error, timed_out)
    """
    import queue
    import threading
    result_queue = queue.Queue()
    
    def worker():
        try:
            result = fn()
            result_queue.put(('success', result))
        except Exception as e:
            result_queue.put(('error', e))
    
    thread = threading.Thread(target=worker, daemon=True)
    thread.start()
    
    last_heartbeat = time.time()
    
    while True:
        # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
        elapsed = time.time() - start_time
        if elapsed > timeout_seconds:
            return None, TimeoutError(f"æ“ä½œè¶…æ—¶ ({int(elapsed)}s)"), True
        
        # å°è¯•è·å–ç»“æœï¼ˆçŸ­è¶…æ—¶ï¼‰
        try:
            status, data = result_queue.get(timeout=1.0)
            if status == 'success':
                return data, None, False
            else:
                return None, data, False
        except queue.Empty:
            # å‘é€å¿ƒè·³
            current_time = time.time()
            if current_time - last_heartbeat >= heartbeat_interval:
                heartbeat_callback(int(current_time - start_time))
                last_heartbeat = current_time


def stream_with_keepalive(response_stream, start_time, keepalive_interval=5, max_wait_first_token=60):
    """
    åŒ…è£…æµå¼å“åº”ï¼Œåœ¨ç­‰å¾…ç¬¬ä¸€ä¸ª token æœŸé—´å‘é€ä¿æ´»å¿ƒè·³ã€‚
    
    Args:
        response_stream: åŸå§‹æµå¼å“åº”è¿­ä»£å™¨
        start_time: è¯·æ±‚å¼€å§‹æ—¶é—´
        keepalive_interval: å¿ƒè·³é—´éš”ï¼ˆç§’ï¼‰
        max_wait_first_token: ç­‰å¾…ç¬¬ä¸€ä¸ª token çš„æœ€å¤§æ—¶é—´ï¼ˆç§’ï¼‰
    
    Yields:
        (type, data): type å¯ä»¥æ˜¯ 'chunk', 'heartbeat', 'timeout'
    """
    import queue
    import time
    
    chunk_queue = queue.Queue()
    first_chunk_received = threading.Event()
    stream_done = threading.Event()
    stream_error = {'error': None}
    
    def stream_reader():
        """åœ¨åå°çº¿ç¨‹ä¸­è¯»å–æµ"""
        try:
            for chunk in response_stream:
                chunk_queue.put(('chunk', chunk))
                first_chunk_received.set()
            chunk_queue.put(('done', None))
        except Exception as e:
            stream_error['error'] = e
            chunk_queue.put(('error', e))
        finally:
            stream_done.set()
    
    # å¯åŠ¨åå°è¯»å–çº¿ç¨‹
    reader_thread = threading.Thread(target=stream_reader, daemon=True)
    reader_thread.start()
    
    last_heartbeat = time.time()
    
    while True:
        # æ£€æŸ¥æ˜¯å¦ç­‰å¾…ç¬¬ä¸€ä¸ª token è¶…æ—¶
        if not first_chunk_received.is_set():
            elapsed = time.time() - start_time
            if elapsed > max_wait_first_token:
                yield ('timeout', f'ç­‰å¾…å“åº”è¶…æ—¶ ({int(elapsed)}s)')
                return
        
        # å°è¯•è·å– chunkï¼Œä½¿ç”¨çŸ­è¶…æ—¶ä»¥ä¾¿å‘é€å¿ƒè·³
        try:
            item_type, item_data = chunk_queue.get(timeout=1.0)
            
            if item_type == 'chunk':
                yield ('chunk', item_data)
            elif item_type == 'done':
                return
            elif item_type == 'error':
                raise item_data
                
        except queue.Empty:
            # é˜Ÿåˆ—ä¸ºç©ºï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å‘é€å¿ƒè·³
            current_time = time.time()
            if current_time - last_heartbeat >= keepalive_interval:
                elapsed = int(current_time - start_time)
                yield ('heartbeat', elapsed)
                last_heartbeat = current_time
            
            # æ£€æŸ¥æµæ˜¯å¦å·²ç»“æŸ
            if stream_done.is_set() and chunk_queue.empty():
                if stream_error['error']:
                    raise stream_error['error']
                return

app = Flask(__name__)
# é™æ€èµ„æºç¼“å­˜ï¼Œå‡å°‘é‡å¤åŠ è½½
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 3600

# CORS: äº‘æ¨¡å¼é™åˆ¶æ¥æºï¼Œæœ¬åœ°æ¨¡å¼æ‰“å¼€
_cors_origins = os.environ.get('KOTO_CORS_ORIGINS', '*')
if os.environ.get('KOTO_DEPLOY_MODE') == 'cloud' and _cors_origins == '*':
    # äº‘æ¨¡å¼é»˜è®¤åªå…è®¸è‡ªèº«ç«™ç‚¹ï¼ˆåŒæºï¼‰ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–
    _cors_origins = os.environ.get('KOTO_SITE_URL', '*')
CORS(app, origins=_cors_origins)

# ================= ç”¨æˆ·è®¤è¯ç³»ç»Ÿ =================
try:
    from auth import register_auth_routes
    register_auth_routes(app)
except Exception as e:
    print(f"[Auth] âš ï¸ è®¤è¯æ¨¡å—åŠ è½½å¤±è´¥: {e}")

# ================= å¹¶è¡Œæ‰§è¡Œç³»ç»Ÿåˆå§‹åŒ– =================
if PARALLEL_SYSTEM_ENABLED:
    print("[PARALLEL] ğŸš€ Initializing parallel execution system...")
    try:
        register_parallel_api(app)
        start_dispatcher()
        print("[PARALLEL] âœ… Parallel execution system initialized successfully")
    except Exception as e:
        print(f"[PARALLEL] âŒ Failed to initialize parallel execution system: {e}")
        PARALLEL_SYSTEM_ENABLED = False

# ================= WebSocket æ”¯æŒï¼ˆå¯é€‰ï¼‰ =================
sock = None
if Sock:
    sock = Sock(app)
else:
    print("[WebSocket] âš ï¸ flask-sock æœªå®‰è£…ï¼Œä½¿ç”¨è½®è¯¢ä½œä¸ºé€šçŸ¥å…œåº•")

if sock:
    @sock.route('/ws/notifications')
    def ws_notifications(ws):
        user_id = request.args.get('user_id', 'default')
        manager = get_notification_manager()
        manager.register_connection(user_id, ws)
        try:
            while True:
                message = ws.receive()
                if message is None:
                    break
                if isinstance(message, str) and message.lower() == 'ping':
                    ws.send('pong')
        finally:
            manager.unregister_connection(user_id, ws)

# ================= å»¶è¿Ÿæ³¨å†Œè“å›¾ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­åŠ è½½ï¼Œé¿å…é˜»å¡å¯åŠ¨ï¼‰ =================
_blueprints_registered = False
_blueprints_lock = threading.Lock()

def _register_blueprints_deferred():
    """åœ¨åå°çº¿ç¨‹ä¸­æ³¨å†Œæ‰€æœ‰è“å›¾ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹å¯åŠ¨."""
    global _blueprints_registered, agent_bp
    with _blueprints_lock:
        if _blueprints_registered:
            return
        _blueprints_registered = True
    
    # æ³¨å†Œç»Ÿä¸€ Agent API
    try:
        from app.api import agent_bp as _agent_bp
        agent_bp = _agent_bp
        app.register_blueprint(agent_bp, url_prefix='/api/agent')
        print("[UnifiedAgent] âœ… ç»Ÿä¸€ Agent API å·²æ³¨å†Œ: /api/agent")
    except ImportError as e:
        print(f"[UnifiedAgent] âš ï¸ æœªèƒ½å¯¼å…¥ç»Ÿä¸€ Agent API è“å›¾: {e}")
    except Exception as e:
        print(f"[UnifiedAgent] âŒ æ³¨å†Œå¤±è´¥: {e}")
    
    # æ³¨å†Œå¢å¼ºè¯­éŸ³ API
    try:
        from voice_api_enhanced import voice_bp
        app.register_blueprint(voice_bp)
        print("[VOICE_API] å·²æ³¨å†Œå¢å¼ºè¯­éŸ³ API è“å›¾")
    except ImportError as e:
        print(f"[VOICE_API] âš ï¸ æœªèƒ½å¯¼å…¥å¢å¼ºè¯­éŸ³æ¨¡å—: {e}")

    # æ³¨å†Œ PPT ç¼–è¾‘ APIï¼ˆP1 åŠŸèƒ½ï¼‰
    try:
        from web.ppt_api_routes import ppt_api_bp
        app.register_blueprint(ppt_api_bp)
        print("[PPT_API] âœ… PPT ç¼–è¾‘ API å·²æ³¨å†Œ: /api/ppt")
    except ImportError as e:
        print(f"[PPT_API] âš ï¸ æœªèƒ½å¯¼å…¥ PPT ç¼–è¾‘ API: {e}")
    except Exception as e:
        print(f"[PPT_API] âš ï¸ PPT ç¼–è¾‘ API æ³¨å†Œå¤±è´¥: {e}")

    # æ³¨å†Œè‡ªé€‚åº” Agent APIï¼ˆå·²è¿ç§»åˆ° UnifiedAgentï¼Œä½†ä¿ç•™å…¼å®¹å¯¼å…¥ï¼‰
    try:
        from adaptive_agent_api import init_adaptive_agent_api
        init_adaptive_agent_api(app, gemini_client=None)
        print("[AdaptiveAgent] âœ… è‡ªé€‚åº” Agent API å·²æ³¨å†Œ (å»¶è¿ŸåŠ è½½å®¢æˆ·ç«¯)")
    except ImportError:
        print("[AdaptiveAgent] â„¹ï¸ æ—§ Agent æ¨¡å—å·²é€€å½¹ï¼Œä½¿ç”¨ UnifiedAgent")
    except Exception as e:
        print(f"[AdaptiveAgent] âš ï¸ æ—§ Agent åˆå§‹åŒ–å¤±è´¥ (éè‡´å‘½): {e}")
    
    print("[INIT] âœ… æ‰€æœ‰è“å›¾æ³¨å†Œå®Œæˆ")

# åœ¨åå°çº¿ç¨‹ä¸­æ³¨å†Œè“å›¾ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹
threading.Thread(target=_register_blueprints_deferred, name="BlueprintLoader", daemon=True).start()

CHAT_DIR = os.path.join(PROJECT_ROOT, "chats")
WORKSPACE_DIR = get_workspace_root()
UPLOAD_DIR = os.path.join(PROJECT_ROOT, "web", "uploads")
os.makedirs(CHAT_DIR, exist_ok=True)
os.makedirs(WORKSPACE_DIR, exist_ok=True)
os.makedirs(UPLOAD_DIR, exist_ok=True)

# ================= Settings Manager (æå‰åŠ è½½) =================
try:
    from settings import SettingsManager
except ImportError:
    from web.settings import SettingsManager
settings_manager = SettingsManager()

# ================= æ™ºèƒ½æ¨¡å‹çŸ©é˜µ (2026-01 æœ€å…ˆè¿›) =================
# ä½¿ç”¨ Gemini 3.0 ç³»åˆ— + Imagen 4.0 å›¾åƒæ¨¡å‹

MODEL_MAP = {
    # æ—¥å¸¸å¯¹è¯ - Gemini 3.0 Flash (å¿«é€Ÿå“åº”)
    "CHAT": "gemini-3-flash-preview",
    
    # ç¼–ç¨‹/ä»£ç  - Gemini 3.0 Pro, ä½†ä¸ç¨³å®šæ—¶å›é€€
    "CODER": "gemini-3-pro-preview",
    
    # ğŸŒ è”ç½‘æœç´¢ - Gemini 2.5 Flash (grounding æ”¯æŒå¥½)
    "WEB_SEARCH": "gemini-2.5-flash", 
    
    # è§†è§‰ç†è§£ - Gemini 3.0 Flash (å¤šæ¨¡æ€)
    "VISION": "gemini-3-flash-preview",
    
    # æ·±åº¦ç ”ç©¶ - Gemini 3.0 Pro (ç¨³å®š) - åŸdeep-researchç»å¸¸timeout
    "RESEARCH": "gemini-3-pro-preview",
    
    # æ–‡æ¡£ç”Ÿæˆ - æ ¹æ®å¤æ‚åº¦åŠ¨æ€é€‰æ‹©
    "FILE_GEN": "gemini-3-flash-preview",
    
    # ğŸ¨ å›¾åƒç”Ÿæˆ - Nano Banana Pro (åŸç”Ÿå›¾åƒç”Ÿæˆ)
    "PAINTER": "nano-banana-pro-preview",
    
    # ğŸ–¥ï¸ ç³»ç»Ÿæ“ä½œ - æœ¬åœ°æ‰§è¡Œ (ä¸éœ€è¦æ¨¡å‹)
    "SYSTEM": "local-executor",
    
    # ğŸ“‚ æ–‡ä»¶æ“ä½œ - æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
    "FILE_OP": "local-executor",
    
    # ğŸ¤– Agent å·¥å…·è°ƒç”¨ - Gemini 3.0 Flash (function calling)
    "AGENT": "gemini-3-flash-preview",
}

# æ¨¡å‹èƒ½åŠ›çŸ©é˜µ (ç”¨äºæ™ºèƒ½è·¯ç”±å’Œæ˜¾ç¤º)
MODEL_INFO = {
    # Gemini 3.0 ç³»åˆ— (æœ€æ–°æœ€å¼º)
    "gemini-3-pro-preview": {
        "name": "Gemini 3.0 Pro",
        "speed": "ğŸš€",
        "tier": 7,
        "strengths": ["æ¨ç†", "åˆ†æ", "ä»£ç ", "å¤æ‚ä»»åŠ¡"],
    },
    "gemini-3-flash-preview": {
        "name": "Gemini 3.0 Flash",
        "speed": "âš¡",
        "tier": 6,
        "strengths": ["å¿«é€Ÿ", "å¯¹è¯", "å¤šæ¨¡æ€"],
    },
    # Gemini 2.5 (grounding)
    "gemini-2.5-flash": {
        "name": "Gemini 2.5 Flash",
        "speed": "ğŸŒ",
        "tier": 5,
        "strengths": ["è”ç½‘æœç´¢", "grounding"],
    },
    # æ·±åº¦ç ”ç©¶
    "deep-research-pro-preview-12-2025": {
        "name": "Deep Research Pro",
        "speed": "ğŸ”¬",
        "tier": 7,
        "strengths": ["æ·±åº¦ç ”ç©¶", "å­¦æœ¯åˆ†æ", "ç»¼åˆæŠ¥å‘Š"],
    },
    # å›¾åƒç”Ÿæˆ (Nano Banana)
    "nano-banana-pro-preview": {
        "name": "Nano Banana Pro",
        "speed": "ğŸ¨",
        "tier": 5,
        "strengths": ["å›¾åƒç”Ÿæˆ", "åˆ›æ„ç»˜ç”»", "è‰ºæœ¯é£æ ¼"],
    },
    # Gemini 2.0 Flash Exp (å›¾åƒç”Ÿæˆå¤‡ç”¨)
    "gemini-2.0-flash-exp": {
        "name": "Gemini 2.0 Flash Exp",
        "speed": "ğŸ¨",
        "tier": 5,
        "strengths": ["å›¾åƒç”Ÿæˆ", "å¤šæ¨¡æ€", "å®éªŒåŠŸèƒ½"],
    },
    # æœ¬åœ°æ‰§è¡Œå™¨
    "local-executor": {
        "name": "Local Executor",
        "speed": "ğŸ–¥ï¸",
        "tier": 0,
        "strengths": ["ç³»ç»Ÿæ“ä½œ", "æ‰“å¼€åº”ç”¨", "æ–‡ä»¶ç®¡ç†"],
    },
}

def get_model_display_name(model_id):
    info = MODEL_INFO.get(model_id)
    if info:
        return f"{info['name']} {info['speed']}"
    return model_id


# ================= æœ¬åœ°ç³»ç»Ÿæ‰§è¡Œå™¨ =================
class LocalExecutor:
    """
    æœ¬åœ°ç³»ç»Ÿæ“ä½œæ‰§è¡Œå™¨ - è®© Koto æˆä¸ºçœŸæ­£çš„ AI OS
    æ”¯æŒï¼šæ‰“å¼€åº”ç”¨ã€æ–‡ä»¶æ“ä½œã€ç³»ç»Ÿå‘½ä»¤ç­‰
    """
    
    # Windows å¸¸ç”¨åº”ç”¨è·¯å¾„æ˜ å°„ (åŒ…å«æ›´å¤šè·¯å¾„)
    APP_ALIASES = {
        # ç¤¾äº¤é€šè®¯
        "å¾®ä¿¡": ["WeChat", r"C:\Program Files\Tencent\WeChat\WeChat.exe", r"C:\Program Files (x86)\Tencent\WeChat\WeChat.exe"],
        "wechat": ["WeChat", r"C:\Program Files\Tencent\WeChat\WeChat.exe", r"C:\Program Files (x86)\Tencent\WeChat\WeChat.exe"],
        "qq": ["QQ", r"C:\Program Files\Tencent\QQ\Bin\QQ.exe", r"C:\Program Files (x86)\Tencent\QQ\Bin\QQ.exe", r"C:\Program Files\Tencent\QQNT\QQ.exe"],
        "é’‰é’‰": ["DingTalk", "dingtalk"],
        "é£ä¹¦": ["Feishu", "Lark"],
        "telegram": ["Telegram"],
        "discord": ["Discord", "Update --processStart Discord.exe"],
        
        # æ¸¸æˆå¹³å°
        "steam": ["steam", r"C:\Program Files (x86)\Steam\steam.exe", r"C:\Program Files\Steam\steam.exe", r"D:\Steam\steam.exe"],
        "epic": ["EpicGamesLauncher", r"C:\Program Files (x86)\Epic Games\Launcher\Portal\Binaries\Win32\EpicGamesLauncher.exe"],
        "æˆ˜ç½‘": ["Battle.net"],
        "wallpaper engine": ["wallpaper32", "wallpaper64", r"C:\Program Files (x86)\Steam\steamapps\common\wallpaper_engine\wallpaper32.exe"],
        "wallpaper": ["wallpaper32", "wallpaper64"],
        
        # æµè§ˆå™¨
        "chrome": ["chrome", r"C:\Program Files\Google\Chrome\Application\chrome.exe", r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe"],
        "è°·æ­Œæµè§ˆå™¨": ["chrome"],
        "edge": ["msedge", r"C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe"],
        "firefox": ["firefox", r"C:\Program Files\Mozilla Firefox\firefox.exe"],
        "æµè§ˆå™¨": ["chrome", "msedge", "firefox"],
        
        # å¼€å‘å·¥å…·
        "vscode": ["code"],
        "vs code": ["code"],
        "code": ["code"],
        "pycharm": ["pycharm64", "pycharm"],
        "idea": ["idea64", "idea"],
        "terminal": ["wt", "cmd", "powershell"],
        "ç»ˆç«¯": ["wt", "cmd", "powershell"],
        "å‘½ä»¤è¡Œ": ["cmd", "powershell"],
        "git": ["git-bash", r"C:\Program Files\Git\git-bash.exe"],
        
        # åŠå…¬è½¯ä»¶
        "word": ["winword", "WINWORD"],
        "excel": ["excel", "EXCEL"],
        "ppt": ["powerpnt", "POWERPNT"],
        "powerpoint": ["powerpnt"],
        "outlook": ["outlook", "OUTLOOK"],
        "è®°äº‹æœ¬": ["notepad"],
        "notepad": ["notepad"],
        "wps": ["wps", "wpsoffice", r"C:\Users\12524\AppData\Local\Kingsoft\WPS Office\ksolaunch.exe"],
        "wps office": ["wps", "wpsoffice", "ksolaunch"],
        
        # åª’ä½“
        "spotify": ["Spotify"],
        "ç½‘æ˜“äº‘": ["cloudmusic", r"C:\Program Files (x86)\Netease\CloudMusic\cloudmusic.exe", r"C:\Program Files\Netease\CloudMusic\cloudmusic.exe"],
        "ç½‘æ˜“äº‘éŸ³ä¹": ["cloudmusic", r"C:\Program Files (x86)\Netease\CloudMusic\cloudmusic.exe"],
        "cloudmusic": ["cloudmusic", r"C:\Program Files (x86)\Netease\CloudMusic\cloudmusic.exe"],
        "qqéŸ³ä¹": ["QQMusic", r"C:\Program Files (x86)\Tencent\QQMusic\QQMusic.exe"],
        "é…·ç‹—": ["KuGou", r"C:\Program Files\KuGou\KuGou.exe"],
        "é…·æˆ‘": ["KuWo"],
        "ç½‘æ˜“éŸ³ä¹": ["cloudmusic"],
        "potplayer": ["PotPlayerMini64", "PotPlayerMini", r"C:\Program Files\DAUM\PotPlayer\PotPlayerMini64.exe"],
        "vlc": ["vlc", r"C:\Program Files\VideoLAN\VLC\vlc.exe"],
        
        # ç³»ç»Ÿ
        "è®¾ç½®": ["ms-settings:"],
        "æ§åˆ¶é¢æ¿": ["control"],
        "ä»»åŠ¡ç®¡ç†å™¨": ["taskmgr"],
        "è®¡ç®—å™¨": ["calc"],
        "æ–‡ä»¶ç®¡ç†å™¨": ["explorer"],
        "èµ„æºç®¡ç†å™¨": ["explorer"],
        "ç”»å›¾": ["mspaint"],
        "æˆªå›¾": ["snippingtool", "SnippingTool"],
    }
    
    # ç³»ç»Ÿæ“ä½œå…³é”®è¯
    SYSTEM_KEYWORDS = [
        "æ‰“å¼€", "å¯åŠ¨", "è¿è¡Œ", "å¼€å¯", "å…³é—­", "é€€å‡º", "æ€æ­»",
        "open", "start", "launch", "run", "close", "kill", "exit",
        "æœç´¢", "æŸ¥æ‰¾", "search", "find",
        "æˆªå›¾", "screenshot",
        "éŸ³é‡", "äº®åº¦", "volume", "brightness",
        "å…³æœº", "é‡å¯", "ä¼‘çœ ", "ç¡çœ ", "shutdown", "restart", "sleep",
    ]
    
    # çŸ¥è¯†æé—®æ¨¡å¼ â€”â€” å¦‚æœåŒ¹é…åˆ°è¿™äº›ï¼Œè¯´æ˜ç”¨æˆ·æ˜¯åœ¨**é—®é—®é¢˜**ï¼Œä¸æ˜¯åœ¨ä¸‹å‘½ä»¤
    QUESTION_PATTERNS = [
        "æ€ä¹ˆ", "å¦‚ä½•", "ä»€ä¹ˆåŠæ³•", "ä»€ä¹ˆæ–¹æ³•", "ä»€ä¹ˆæ„æ€", "ä»€ä¹ˆæ˜¯", "æ˜¯ä»€ä¹ˆ",
        "ä¸ºä»€ä¹ˆ", "ä¸ºå•¥", "èƒ½ä¸èƒ½", "å¯ä»¥å—", "å¯ä¸å¯ä»¥", "æ€æ ·", "å’‹",
        "ä¸€èˆ¬ç”¨", "é€šå¸¸", "æœ‰æ²¡æœ‰", "æœ‰ä»€ä¹ˆ", "å“ªäº›", "å“ªä¸ª", "å“ªç§",
        "åŒºåˆ«", "å¯¹æ¯”", "æ¯”è¾ƒ", "æœ€å¥½çš„", "æ¨è", "å»ºè®®",
        "æ•™ç¨‹", "æ­¥éª¤", "æµç¨‹", "åŸç†", "æ¦‚å¿µ",
        "ç”¨ä»€ä¹ˆ", "æ˜¯å•¥", "å•¥æ„æ€", "è®²è®²", "è¯´è¯´", "ä»‹ç»",
        "how to", "what is", "why", "which", "recommend",
        "difference between", "best way", "tutorial",
    ]

    @classmethod
    def is_system_command(cls, text):
        """æ£€æµ‹æ˜¯å¦æ˜¯ç³»ç»Ÿæ“ä½œè¯·æ±‚ï¼ˆç¥ˆä½¿å¥/å‘½ä»¤å¥ï¼ŒéçŸ¥è¯†æé—®ï¼‰
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        1. å¿…é¡»åŒ…å«åŠ¨ä½œå…³é”®è¯ï¼ˆæ‰“å¼€/å¯åŠ¨/å…³é—­ç­‰ï¼‰
        2. å¿…é¡»åŒ…å«å·²çŸ¥åº”ç”¨åæˆ–ã€Œæ‰“å¼€+ç´§è·Ÿåè¯ã€çš„çŸ­å¥æ¨¡å¼
        3. æ’é™¤çŸ¥è¯†æ€§æé—®ï¼ˆåŒ…å«"æ€ä¹ˆ/å¦‚ä½•/ä»€ä¹ˆåŠæ³•"ç­‰ï¼‰
        """
        text_lower = text.lower().strip()
        
        # â€”â€”â€” æ’é™¤æ¡ä»¶ï¼šçŸ¥è¯†æé—®ä¸æ˜¯ç³»ç»Ÿå‘½ä»¤ â€”â€”â€”
        if any(qp in text_lower for qp in cls.QUESTION_PATTERNS):
            return False
        
        # â€”â€”â€” æ’é™¤æ¡ä»¶ï¼šå¥å­å¤ªé•¿ä¸€èˆ¬ä¸æ˜¯å‘½ä»¤ï¼ˆå‘½ä»¤é€šå¸¸ <20å­—ï¼‰ â€”â€”â€”
        if len(text_lower) > 30:
            return False
        
        # â€”â€”â€” å¿…é¡»æœ‰åŠ¨ä½œå…³é”®è¯ â€”â€”â€”
        action_keywords = [
            "æ‰“å¼€", "å¯åŠ¨", "è¿è¡Œ", "å¼€å¯", "å…³é—­", "é€€å‡º", "æ€æ­»",
            "open", "start", "launch", "close", "kill", "exit",
            "æˆªå›¾", "screenshot", "å…³æœº", "é‡å¯", "ä¼‘çœ ", "ç¡çœ ",
            "shutdown", "restart", "sleep",
            "æ—¶é—´", "å‡ ç‚¹", "æ—¥æœŸ", "å‡ å·", "æ˜ŸæœŸå‡ ", "time", "date",
            "çŠ¶æ€", "ä¿¡æ¯", "é…ç½®", "å†…å­˜", "cpu", "ç¡¬ç›˜"
        ]
        has_action = any(kw in text_lower for kw in action_keywords)
        if not has_action:
            return False
        
        # â€”â€”â€” å¿…é¡»æœ‰å·²çŸ¥åº”ç”¨å â€”â€”â€”
        has_app = any(app in text_lower for app in cls.APP_ALIASES.keys())
        
        # æˆ–è€…æ˜¯ç‹¬ç«‹çš„ç³»ç»Ÿæ“ä½œï¼ˆæ— éœ€åº”ç”¨åï¼‰
        standalone_commands = [
            "æˆªå›¾", "screenshot", "å…³æœº", "é‡å¯", "ä¼‘çœ ", "ç¡çœ ", 
            "shutdown", "restart", "sleep",
            "æ—¶é—´", "å‡ ç‚¹", "æ—¥æœŸ", "å‡ å·", "æ˜ŸæœŸå‡ ", "time", "date",
            "ç³»ç»ŸçŠ¶æ€", "ç”µè„‘çŠ¶æ€", "ç³»ç»Ÿä¿¡æ¯", "ç”µè„‘ä¿¡æ¯", "é…ç½®", "å†…å­˜", "cpu", "ç¡¬ç›˜"
        ]
        is_standalone = any(cmd in text_lower for cmd in standalone_commands)
        
        return has_app or is_standalone
    
    @classmethod
    def extract_app_name(cls, text):
        """ä»æ–‡æœ¬ä¸­æå–åº”ç”¨å"""
        text_lower = text.lower()
        
        # æ³›æŒ‡ç±»åˆ«æ˜ å°„åˆ°å…·ä½“åº”ç”¨
        category_mapping = {
            "éŸ³ä¹è½¯ä»¶": ["ç½‘æ˜“äº‘", "qqéŸ³ä¹", "spotify", "é…·ç‹—"],
            "å¬æ­Œè½¯ä»¶": ["ç½‘æ˜“äº‘", "qqéŸ³ä¹", "spotify", "é…·ç‹—"],
            "æµè§ˆå™¨": ["edge", "chrome", "firefox"],
            "æ–‡æœ¬ç¼–è¾‘å™¨": ["è®°äº‹æœ¬", "vscode", "notepad"],
            "ä»£ç ç¼–è¾‘å™¨": ["vscode", "pycharm", "idea"],
            "è§†é¢‘æ’­æ”¾å™¨": ["potplayer", "vlc"],
            "èŠå¤©è½¯ä»¶": ["å¾®ä¿¡", "qq", "é’‰é’‰"],
            "åŠå…¬è½¯ä»¶": ["word", "excel", "ppt", "wps"]
        }
        
        # å…ˆå°è¯•ç²¾ç¡®åŒ¹é…å·²çŸ¥åº”ç”¨
        for app_name in sorted(cls.APP_ALIASES.keys(), key=len, reverse=True):
            if app_name in text_lower:
                return app_name
                
        # å°è¯•åŒ¹é…æ³›æŒ‡ç±»åˆ«
        for category, apps in category_mapping.items():
            if category in text_lower:
                # æ£€æŸ¥ç³»ç»Ÿä¸­å®‰è£…äº†å“ªä¸ª
                import shutil
                for app in apps:
                    aliases = cls.APP_ALIASES.get(app, [app])
                    for alias in aliases:
                        if os.path.exists(alias) or shutil.which(alias):
                            return app
                # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ç»å¯¹è·¯å¾„ï¼Œé»˜è®¤è¿”å›ç¬¬ä¸€ä¸ª
                return apps[0]
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œå°è¯•æå–"æ‰“å¼€xxx"ä¸­çš„xxx
        import re
        patterns = [
            r'(?:æ‰“å¼€|å¯åŠ¨|è¿è¡Œ|å¼€å¯)\s*(?:ä¸€ä¸ª|ä¸€æ¬¾)?\s*(.+?)(?:\s|$|å§|å‘—)',
            r'(?:open|start|launch)\s+(?:a\s+)?(.+?)(?:\s|$)',
        ]
        for pattern in patterns:
            match = re.search(pattern, text_lower)
            if match:
                return match.group(1).strip()
        
        return None
    
    @classmethod
    def find_app_in_start_menu(cls, app_name):
        """ä»å¼€å§‹èœå•æŸ¥æ‰¾åº”ç”¨"""
        import glob
        
        start_menu_paths = [
            os.path.expandvars(r"%ProgramData%\Microsoft\Windows\Start Menu\Programs"),
            os.path.expandvars(r"%AppData%\Microsoft\Windows\Start Menu\Programs"),
        ]
        
        app_name_lower = app_name.lower()
        
        for start_path in start_menu_paths:
            if not os.path.exists(start_path):
                continue
            
            # æœç´¢ .lnk æ–‡ä»¶
            for lnk_file in glob.glob(os.path.join(start_path, "**", "*.lnk"), recursive=True):
                lnk_name = os.path.basename(lnk_file).lower().replace(".lnk", "")
                if app_name_lower in lnk_name or lnk_name in app_name_lower:
                    return lnk_file
        
        return None
    
    @classmethod
    def find_app_smart(cls, app_name):
        """æ™ºèƒ½æŸ¥æ‰¾åº”ç”¨ - å¤šç§æ–¹å¼"""
        import subprocess
        import shutil
        
        # 1. å…ˆæ£€æŸ¥é¢„å®šä¹‰åˆ«å
        if app_name.lower() in cls.APP_ALIASES:
            aliases = cls.APP_ALIASES[app_name.lower()]
            for alias in aliases:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´è·¯å¾„
                if os.path.exists(alias):
                    return alias
                # æ£€æŸ¥æ˜¯å¦åœ¨ PATH ä¸­
                if shutil.which(alias):
                    return alias
        
        # 2. æ£€æŸ¥ PATH
        if shutil.which(app_name):
            return app_name
        
        # 3. ä»å¼€å§‹èœå•æŸ¥æ‰¾
        lnk_path = cls.find_app_in_start_menu(app_name)
        if lnk_path:
            return lnk_path
        
        # 4. ä½¿ç”¨ PowerShell æœç´¢
        try:
            ps_cmd = f'Get-StartApps | Where-Object {{$_.Name -like "*{app_name}*"}} | Select-Object -First 1 -ExpandProperty AppID'
            result = subprocess.run(
                ["powershell", "-Command", ps_cmd],
                capture_output=True,
                text=True,
                timeout=5,
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == "win32" else 0
            )
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip()
        except:
            pass
        
        return None
    
    @classmethod
    def execute(cls, user_input):
        """æ‰§è¡Œç³»ç»Ÿæ“ä½œ"""
        import subprocess
        import shutil
        
        text_lower = user_input.lower()
        result = {
            "success": False,
            "action": "",
            "message": "",
            "details": ""
        }
        
        # === æ‰“å¼€åº”ç”¨ ===
        if any(kw in text_lower for kw in ["æ‰“å¼€", "å¯åŠ¨", "è¿è¡Œ", "å¼€å¯", "open", "start", "launch"]):
            app_name = cls.extract_app_name(text_lower)
            
            if app_name:
                # ä½¿ç”¨æ™ºèƒ½æŸ¥æ‰¾
                app_path = cls.find_app_smart(app_name)
                
                if app_path:
                    try:
                        # ç‰¹æ®Šå¤„ç† ms-settings ç­‰ URI
                        if app_path.startswith("ms-"):
                            subprocess.Popen(
                                f'start {app_path}',
                                shell=True,
                                stdout=subprocess.DEVNULL,
                                stderr=subprocess.DEVNULL
                            )
                        # å¤„ç† .lnk å¿«æ·æ–¹å¼
                        elif app_path.endswith(".lnk"):
                            subprocess.Popen(
                                f'start "" "{app_path}"',
                                shell=True,
                                stdout=subprocess.DEVNULL,
                                stderr=subprocess.DEVNULL
                            )
                        # å¤„ç† UWP åº”ç”¨ AppID
                        elif "!" in app_path:
                            subprocess.Popen(
                                f'start shell:AppsFolder\\{app_path}',
                                shell=True,
                                stdout=subprocess.DEVNULL,
                                stderr=subprocess.DEVNULL
                            )
                        # ç›´æ¥è·¯å¾„æˆ–å‘½ä»¤
                        elif os.path.exists(app_path):
                            subprocess.Popen(
                                [app_path], 
                                shell=True,
                                stdout=subprocess.DEVNULL,
                                stderr=subprocess.DEVNULL,
                                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == "win32" else 0
                            )
                        else:
                            # ä½¿ç”¨ start å‘½ä»¤
                            subprocess.Popen(
                                f'start "" "{app_path}"',
                                shell=True,
                                stdout=subprocess.DEVNULL,
                                stderr=subprocess.DEVNULL
                            )
                        
                        result["success"] = True
                        result["action"] = "open_app"
                        result["message"] = f"âœ… å·²æ‰“å¼€ {app_name}"
                        print(f"[LocalExecutor] âœ… æˆåŠŸå¯åŠ¨åº”ç”¨: {app_name} - è·¯å¾„: {app_path}")
                        return result
                    except Exception as e:
                        result["message"] = f"âŒ æ‰“å¼€ {app_name} å¤±è´¥: {str(e)}"
                        print(f"[LocalExecutor] âŒ å¯åŠ¨å¤±è´¥: {app_name} - é”™è¯¯: {str(e)}")
                        return result
                
                # æ™ºèƒ½æŸ¥æ‰¾å¤±è´¥ï¼Œå°è¯•ç›´æ¥ç”¨ start å‘½ä»¤
                try:
                    subprocess.Popen(
                        f'start "" "{app_name}"',
                        shell=True,
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL
                    )
                    result["success"] = True
                    result["action"] = "open_app"
                    result["message"] = f"âœ… æ­£åœ¨å°è¯•æ‰“å¼€ {app_name}"
                    return result
                except:
                    pass
                
                result["message"] = f"âŒ æ— æ³•æ‰“å¼€ {app_name}ï¼Œè¯·ç¡®è®¤å·²å®‰è£…"
                result["details"] = f"æç¤º: æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨å®Œæ•´çš„åº”ç”¨åç§°"
                return result
        
        # === å…³é—­åº”ç”¨ ===
        if any(kw in text_lower for kw in ["å…³é—­", "é€€å‡º", "æ€æ­»", "close", "kill", "exit"]):
            app_name = cls.extract_app_name(text_lower)
            if app_name:
                aliases = cls.APP_ALIASES.get(app_name, [app_name])
                for alias in aliases:
                    try:
                        if sys.platform == "win32":
                            # æå–è¿›ç¨‹å
                            proc_name = alias.split("\\")[-1] if "\\" in alias else alias
                            if not proc_name.endswith(".exe"):
                                proc_name += ".exe"
                            
                            ret = subprocess.run(
                                f'taskkill /IM "{proc_name}" /F',
                                shell=True,
                                capture_output=True,
                                timeout=5,
                                creationflags=subprocess.CREATE_NO_WINDOW
                            )
                            if ret.returncode == 0:
                                result["success"] = True
                                result["action"] = "close_app"
                                result["message"] = f"âœ… å·²å…³é—­ {app_name}"
                                return result
                    except:
                        continue
                
                result["message"] = f"âŒ æ— æ³•å…³é—­ {app_name}"
                return result
        
        # === æˆªå›¾ ===
        if "æˆªå›¾" in text_lower or "screenshot" in text_lower:
            if sys.platform == "win32":
                subprocess.Popen(
                    "snippingtool",
                    shell=True,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL
                )
                result["success"] = True
                result["action"] = "screenshot"
                result["message"] = "âœ… å·²æ‰“å¼€æˆªå›¾å·¥å…·"
                return result
        
        # === æœç´¢ ===
        if any(kw in text_lower for kw in ["æœç´¢", "æŸ¥æ‰¾", "search"]):
            # æå–æœç´¢å†…å®¹
            search_terms = text_lower.replace("æœç´¢", "").replace("æŸ¥æ‰¾", "").replace("search", "").strip()
            if search_terms:
                import webbrowser
                webbrowser.open(f"https://www.google.com/search?q={search_terms}")
                result["success"] = True
                result["action"] = "search"
                result["message"] = f"âœ… æ­£åœ¨æœç´¢: {search_terms}"
                return result
        
        # === ç³»ç»Ÿæ—¶é—´/æ—¥æœŸ ===
        if any(kw in text_lower for kw in ["æ—¶é—´", "å‡ ç‚¹", "æ—¥æœŸ", "å‡ å·", "æ˜ŸæœŸå‡ ", "time", "date"]):
            import datetime
            now = datetime.datetime.now()
            
            weekdays = ["æ˜ŸæœŸä¸€", "æ˜ŸæœŸäºŒ", "æ˜ŸæœŸä¸‰", "æ˜ŸæœŸå››", "æ˜ŸæœŸäº”", "æ˜ŸæœŸå…­", "æ˜ŸæœŸæ—¥"]
            weekday_str = weekdays[now.weekday()]
            
            if any(kw in text_lower for kw in ["æ—¥æœŸ", "å‡ å·", "æ˜ŸæœŸå‡ ", "date"]):
                time_str = now.strftime(f"%Yå¹´%mæœˆ%dæ—¥ {weekday_str}")
                msg = f"ğŸ“… å½“å‰æ—¥æœŸæ˜¯ï¼š{time_str}"
            else:
                time_str = now.strftime(f"%Y-%m-%d %H:%M:%S {weekday_str}")
                msg = f"ğŸ•’ å½“å‰ç³»ç»Ÿæ—¶é—´æ˜¯ï¼š{time_str}"
                
            result["success"] = True
            result["action"] = "get_time"
            result["message"] = msg
            return result
            
        # === ç”µæºæ“ä½œ ===
        if any(kw in text_lower for kw in ["å…³æœº", "é‡å¯", "ä¼‘çœ ", "ç¡çœ ", "shutdown", "restart", "sleep"]):
            if sys.platform == "win32":
                if "å…³æœº" in text_lower or "shutdown" in text_lower:
                    subprocess.Popen("shutdown /s /t 0", shell=True)
                    msg = "âœ… æ­£åœ¨å…³æœº..."
                elif "é‡å¯" in text_lower or "restart" in text_lower:
                    subprocess.Popen("shutdown /r /t 0", shell=True)
                    msg = "âœ… æ­£åœ¨é‡å¯..."
                elif "ä¼‘çœ " in text_lower or "ç¡çœ " in text_lower or "sleep" in text_lower:
                    subprocess.Popen("rundll32.exe powrprof.dll,SetSuspendState 0,1,0", shell=True)
                    msg = "âœ… æ­£åœ¨è¿›å…¥ä¼‘çœ /ç¡çœ çŠ¶æ€..."
                
                result["success"] = True
                result["action"] = "power_op"
                result["message"] = msg
                return result
                
        # === ç³»ç»ŸçŠ¶æ€/ç”µè„‘çŠ¶æ€ ===
        if any(kw in text_lower for kw in ["ç³»ç»ŸçŠ¶æ€", "ç”µè„‘çŠ¶æ€", "ç³»ç»Ÿä¿¡æ¯", "ç”µè„‘ä¿¡æ¯", "é…ç½®", "å†…å­˜", "cpu", "ç¡¬ç›˜"]):
            info = cls.get_system_info()
            if info.get("success"):
                msg = f"ğŸ’» **ç³»ç»ŸçŠ¶æ€æŠ¥å‘Š**\n\n"
                msg += f"- **æ“ä½œç³»ç»Ÿ**: {info.get('system')} ({info.get('platform')})\n"
                msg += f"- **å¤„ç†å™¨**: {info.get('processor')}\n"
                msg += f"- **CPU ä½¿ç”¨ç‡**: {info.get('cpu_percent')}%\n"
                
                mem = info.get('memory', {})
                msg += f"- **å†…å­˜**: å·²ç”¨ {mem.get('percent')}% (å‰©ä½™ {mem.get('available')} / æ€»å…± {mem.get('total')})\n"
                
                disk = info.get('disk', {})
                msg += f"- **Cç›˜**: å·²ç”¨ {disk.get('percent')}% (å‰©ä½™ {disk.get('free')} / æ€»å…± {disk.get('total')})\n"
                
                result["success"] = True
                result["action"] = "get_system_info"
                result["message"] = msg
                return result
        
        result["message"] = "â“ æ— æ³•è¯†åˆ«è¯¥ç³»ç»Ÿæ“ä½œ"
        return result
    
    @classmethod
    def get_clipboard(cls):
        """è·å–å‰ªè´´æ¿å†…å®¹"""
        try:
            import pyperclip
            content = pyperclip.paste()
            return {
                "success": True,
                "content": content,
                "length": len(content),
                "message": f"âœ… å·²è·å–å‰ªè´´æ¿å†…å®¹ ({len(content)} å­—ç¬¦)"
            }
        except Exception as e:
            return {
                "success": False,
                "content": "",
                "message": f"âŒ æ— æ³•è¯»å–å‰ªè´´æ¿: {str(e)}"
            }
    
    @classmethod
    def set_clipboard(cls, text):
        """è®¾ç½®å‰ªè´´æ¿å†…å®¹"""
        try:
            import pyperclip
            pyperclip.copy(text)
            return {
                "success": True,
                "message": f"âœ… å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ ({len(text)} å­—ç¬¦)"
            }
        except Exception as e:
            return {
                "success": False,
                "message": f"âŒ æ— æ³•å†™å…¥å‰ªè´´æ¿: {str(e)}"
            }
    
    @classmethod
    def get_system_info(cls):
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        try:
            import platform
            import psutil
            
            info = {
                "success": True,
                "system": platform.system(),
                "platform": platform.platform(),
                "processor": platform.processor(),
                "cpu_count": psutil.cpu_count(),
                "cpu_percent": psutil.cpu_percent(interval=1),
                "memory": {
                    "total": f"{psutil.virtual_memory().total / (1024**3):.2f} GB",
                    "available": f"{psutil.virtual_memory().available / (1024**3):.2f} GB",
                    "percent": psutil.virtual_memory().percent
                },
                "disk": {
                    "total": f"{psutil.disk_usage('/').total / (1024**3):.2f} GB",
                    "free": f"{psutil.disk_usage('/').free / (1024**3):.2f} GB",
                    "percent": psutil.disk_usage('/').percent
                }
            }
            return info
        except Exception as e:
            return {
                "success": False,
                "message": f"âŒ æ— æ³•è·å–ç³»ç»Ÿä¿¡æ¯: {str(e)}"
            }
    
    @classmethod
    def list_running_apps(cls):
        """åˆ—å‡ºæ­£åœ¨è¿è¡Œçš„åº”ç”¨"""
        try:
            import psutil
            
            apps = []
            for proc in psutil.process_iter(['pid', 'name']):
                try:
                    apps.append({
                        "name": proc.info['name'],
                        "pid": proc.info['pid']
                    })
                except:
                    continue
            
            return {
                "success": True,
                "apps": apps[:30],  # è¿”å›å‰30ä¸ª
                "count": len(apps),
                "message": f"âœ… æ‰¾åˆ° {len(apps)} ä¸ªè¿è¡Œä¸­çš„è¿›ç¨‹"
            }
        except Exception as e:
            return {
                "success": False,
                "message": f"âŒ æ— æ³•åˆ—å‡ºåº”ç”¨: {str(e)}"
            }
    
    @classmethod
    def open_file_or_directory(cls, path):
        """æ‰“å¼€æ–‡ä»¶æˆ–ç›®å½•"""
        try:
            import subprocess
            
            path = os.path.expanduser(path)
            
            if not os.path.exists(path):
                return {
                    "success": False,
                    "message": f"âŒ è·¯å¾„ä¸å­˜åœ¨: {path}"
                }
            
            if os.path.isfile(path):
                # ç”¨é»˜è®¤åº”ç”¨æ‰“å¼€æ–‡ä»¶
                os.startfile(path) if sys.platform == "win32" else subprocess.Popen(['open', path])
                return {
                    "success": True,
                    "message": f"âœ… å·²æ‰“å¼€æ–‡ä»¶: {os.path.basename(path)}"
                }
            else:
                # åœ¨èµ„æºç®¡ç†å™¨ä¸­æ‰“å¼€ç›®å½•
                os.startfile(path) if sys.platform == "win32" else subprocess.Popen(['open', path])
                return {
                    "success": True,
                    "message": f"âœ… å·²æ‰“å¼€ç›®å½•: {path}"
                }
        except Exception as e:
            return {
                "success": False,
                "message": f"âŒ æ— æ³•æ‰“å¼€: {str(e)}"
            }
    
    @classmethod
    def send_keystroke(cls, key_combination):
        """æ¨¡æ‹Ÿé”®ç›˜å¿«æ·é”®"""
        try:
            import keyboard
            
            # è§£æå¿«æ·é”®
            keys = key_combination.split('+')
            keys = [k.strip().lower() for k in keys]
            
            # æ¨¡æ‹Ÿå¿«æ·é”®
            keyboard.hotkey(*keys)
            
            return {
                "success": True,
                "message": f"âœ… å·²æ¨¡æ‹Ÿå¿«æ·é”®: {key_combination}"
            }
        except Exception as e:
            return {
                "success": False,
                "message": f"âŒ æ— æ³•å‘é€å¿«æ·é”®: {str(e)}"
            }


# ================= æ–‡ä»¶æ“ä½œæ‰§è¡Œå™¨ =================
class FileOperator:
    """
    æœ¬åœ°æ–‡ä»¶æ“ä½œæ‰§è¡Œå™¨ - å¤„ç†æ–‡ä»¶è¯»å†™ã€ç®¡ç†ç­‰æ“ä½œ
    """
    
    # æ–‡ä»¶æ“ä½œå…³é”®è¯
    FILE_KEYWORDS = [
        "è¯»å–æ–‡ä»¶", "æ‰“å¼€æ–‡ä»¶", "æŸ¥çœ‹æ–‡ä»¶", "è¯»æ–‡ä»¶", "çœ‹çœ‹æ–‡ä»¶",
        "åˆ›å»ºæ–‡ä»¶", "æ–°å»ºæ–‡ä»¶", "å†™å…¥æ–‡ä»¶", "ä¿å­˜æ–‡ä»¶",
        "åˆ é™¤æ–‡ä»¶", "ç§»åŠ¨æ–‡ä»¶", "å¤åˆ¶æ–‡ä»¶", "é‡å‘½å",
        "æ–‡ä»¶åˆ—è¡¨", "ç›®å½•", "æ–‡ä»¶å¤¹", "åˆ—å‡ºæ–‡ä»¶",
        "è‡ªåŠ¨å½’çº³", "è‡ªåŠ¨æ•´ç†", "å½’çº³æ–‡ä»¶å¤¹", "æ•´ç†æ–‡ä»¶å¤¹", "å½’æ¡£æ–‡ä»¶å¤¹", "å¾®ä¿¡æ–‡ä»¶å½’çº³",
        "read file", "open file", "create file", "delete file",
        "list files", "directory", "folder",
    ]

    FOLDER_ORGANIZE_KEYWORDS = [
        "è‡ªåŠ¨å½’çº³", "è‡ªåŠ¨æ•´ç†", "å½’çº³", "æ•´ç†", "å½’æ¡£", "å½’ç±»", "åˆ†ç±»",
        "æ–‡ä»¶å¤¹", "ç›®å½•", "å¾®ä¿¡æ–‡ä»¶", "wechat files"
    ]
    
    @classmethod
    def is_file_operation(cls, text):
        """æ£€æµ‹æ˜¯å¦æ˜¯æ–‡ä»¶æ“ä½œè¯·æ±‚"""
        text_lower = text.lower()
        return any(kw in text_lower for kw in cls.FILE_KEYWORDS)

    @classmethod
    def _is_folder_organize_intent(cls, text_lower: str) -> bool:
        has_action = any(kw in text_lower for kw in ["å½’çº³", "æ•´ç†", "å½’æ¡£", "å½’ç±»", "åˆ†ç±»"])
        has_target = any(kw in text_lower for kw in ["æ–‡ä»¶å¤¹", "ç›®å½•", "è·¯å¾„", "æ–‡ä»¶"])
        if has_action and has_target:
            return True
        return any(kw in text_lower for kw in cls.FOLDER_ORGANIZE_KEYWORDS)

    @classmethod
    def _extract_path_from_text(cls, user_input: str) -> str:
        """Extract a likely filesystem path from user input."""
        import re

        patterns = [
            r'["\']([^"\']+)["\']',
            r'([A-Za-z]:\\(?:[^\\/:*?"<>|\r\n]+\\)*[^\\/:*?"<>|\r\n]*)',
            r'(\.?/[\w\-./ ]+)',
        ]
        for pattern in patterns:
            m = re.search(pattern, user_input)
            if m:
                candidate = m.group(1).strip().strip('ï¼Œã€‚,.;ï¼›')
                if candidate:
                    return candidate
        return ""
    
    @classmethod
    def execute(cls, user_input):
        """æ‰§è¡Œæ–‡ä»¶æ“ä½œ"""
        text_lower = user_input.lower()
        result = {
            "success": False,
            "action": "",
            "message": "",
            "content": ""
        }

        # === æŒ‡å®šè·¯å¾„æ–‡ä»¶å¤¹è‡ªåŠ¨å½’çº³ ===
        if cls._is_folder_organize_intent(text_lower):
            folder_path = cls._extract_path_from_text(user_input)
            if not folder_path:
                folder_path = get_default_wechat_files_dir()

            if not folder_path:
                result["message"] = (
                    "â“ è¯·æä¾›è¦å½’çº³çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¯ç”¨å¼•å·åŒ…è£¹ï¼‰ï¼Œæˆ–åœ¨ config/user_settings.json ä¸­è®¾ç½® "
                    "storage.wechat_files_dir ä½œä¸ºé»˜è®¤è·¯å¾„"
                )
                return result

            if not os.path.isabs(folder_path):
                folder_path = os.path.join(WORKSPACE_DIR, folder_path)

            if not os.path.isdir(folder_path):
                result["message"] = f"âŒ ç›®å½•ä¸å­˜åœ¨: {folder_path}"
                return result

            try:
                try:
                    from web.folder_catalog_organizer import FolderCatalogOrganizer
                except Exception:
                    from folder_catalog_organizer import FolderCatalogOrganizer

                analyzer = get_file_analyzer()
                organizer = get_file_organizer()
                engine = FolderCatalogOrganizer(get_organize_root(), analyzer, organizer)
                summary = engine.organize_folder(folder_path)

                if not summary.get("success"):
                    result["message"] = f"âŒ è‡ªåŠ¨å½’çº³å¤±è´¥: {summary.get('error', 'æœªçŸ¥é”™è¯¯')}"
                    return result

                report_md = summary.get("report_markdown", "")
                report_json = summary.get("report_json", "")
                entries = summary.get("entries", [])

                sender_preview = []
                for item in entries:
                    sender = item.get("sender", "æœªçŸ¥")
                    if sender and sender != "æœªçŸ¥":
                        sender_preview.append(sender)
                sender_preview = sorted(set(sender_preview))[:8]
                sender_preview_text = "ã€".join(sender_preview) if sender_preview else "æœªè¯†åˆ«åˆ°å¯é å‘é€è€…"

                result["success"] = True
                result["action"] = "folder_auto_catalog"
                result["message"] = (
                    f"âœ… å½’çº³å®Œæˆï¼š{summary.get('organized_count', 0)}/{summary.get('total_files', 0)} ä¸ªæ–‡ä»¶å·²å½’çº³"
                    f"\nğŸ“ æ¥æºç›®å½•: {summary.get('source_dir', folder_path)}"
                    f"\nğŸ§¾ æ¸…å•(MD): {report_md}"
                    f"\nğŸ§¾ æ¸…å•(JSON): {report_json}"
                    f"\nğŸ‘¤ è¯†åˆ«åˆ°çš„å‘é€è€…/æ¥æºäºº: {sender_preview_text}"
                )
                return result
            except Exception as e:
                result["message"] = f"âŒ è‡ªåŠ¨å½’çº³å¼‚å¸¸: {str(e)}"
                return result
        
        # === è¯»å–æ–‡ä»¶ ===
        if any(kw in text_lower for kw in ["è¯»å–", "æ‰“å¼€æ–‡ä»¶", "æŸ¥çœ‹æ–‡ä»¶", "è¯»æ–‡ä»¶", "çœ‹çœ‹", "read file", "open file"]):
            # æå–æ–‡ä»¶è·¯å¾„
            import re
            # å°è¯•åŒ¹é…å¸¸è§è·¯å¾„æ¨¡å¼
            patterns = [
                r'["\']([^"\']+)["\']',  # å¼•å·åŒ…å›´çš„è·¯å¾„
                r'([A-Za-z]:\\[^\s]+)',   # Windows ç»å¯¹è·¯å¾„
                r'(\.?/[^\s]+)',          # Unix é£æ ¼è·¯å¾„
                r'(\S+\.\w{1,5})(?:\s|$)', # å¸¦æ‰©å±•åçš„æ–‡ä»¶
            ]
            
            filepath = None
            for pattern in patterns:
                match = re.search(pattern, user_input)
                if match:
                    filepath = match.group(1)
                    break
            
            if filepath:
                # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œåœ¨ workspace ç›®å½•æŸ¥æ‰¾
                if not os.path.isabs(filepath):
                    workspace_path = os.path.join(WORKSPACE_DIR, filepath)
                    if os.path.exists(workspace_path):
                        filepath = workspace_path
                
                if os.path.exists(filepath):
                    try:
                        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()
                        
                        # é™åˆ¶å†…å®¹é•¿åº¦
                        if len(content) > 10000:
                            content = content[:10000] + "\n\n... (æ–‡ä»¶è¿‡é•¿ï¼Œå·²æˆªæ–­)"
                        
                        result["success"] = True
                        result["action"] = "read_file"
                        result["message"] = f"âœ… å·²è¯»å–æ–‡ä»¶: {os.path.basename(filepath)}"
                        result["content"] = f"```\n{content}\n```"
                        return result
                    except Exception as e:
                        result["message"] = f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"
                        return result
                else:
                    result["message"] = f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filepath}"
                    return result
            else:
                result["message"] = "â“ è¯·æŒ‡å®šè¦è¯»å–çš„æ–‡ä»¶è·¯å¾„"
                return result
        
        # === åˆ—å‡ºæ–‡ä»¶ ===
        if any(kw in text_lower for kw in ["æ–‡ä»¶åˆ—è¡¨", "ç›®å½•", "åˆ—å‡ºæ–‡ä»¶", "list files", "directory", "æ–‡ä»¶å¤¹é‡Œ"]):
            # æå–ç›®å½•è·¯å¾„
            import re
            patterns = [
                r'["\']([^"\']+)["\']',
                r'([A-Za-z]:\\[^\s]+)',
                r'(\.?/[^\s]+)',
            ]
            
            dirpath = WORKSPACE_DIR  # é»˜è®¤ workspace
            for pattern in patterns:
                match = re.search(pattern, user_input)
                if match:
                    dirpath = match.group(1)
                    break
            
            if not os.path.isabs(dirpath):
                dirpath = os.path.join(WORKSPACE_DIR, dirpath)
            
            if os.path.isdir(dirpath):
                try:
                    items = os.listdir(dirpath)
                    file_list = []
                    for item in items[:50]:  # é™åˆ¶æ•°é‡
                        item_path = os.path.join(dirpath, item)
                        if os.path.isdir(item_path):
                            file_list.append(f"ğŸ“ {item}/")
                        else:
                            size = os.path.getsize(item_path)
                            size_str = f"{size/1024:.1f}KB" if size > 1024 else f"{size}B"
                            file_list.append(f"ğŸ“„ {item} ({size_str})")
                    
                    result["success"] = True
                    result["action"] = "list_files"
                    result["message"] = f"âœ… ç›®å½•: {dirpath}"
                    result["content"] = "\n".join(file_list) if file_list else "ç©ºç›®å½•"
                    return result
                except Exception as e:
                    result["message"] = f"âŒ è¯»å–ç›®å½•å¤±è´¥: {str(e)}"
                    return result
            else:
                result["message"] = f"âŒ ç›®å½•ä¸å­˜åœ¨: {dirpath}"
                return result
        
        # === åˆ›å»º/å†™å…¥æ–‡ä»¶ ===
        if any(kw in text_lower for kw in ["åˆ›å»ºæ–‡ä»¶", "æ–°å»ºæ–‡ä»¶", "å†™å…¥æ–‡ä»¶", "ä¿å­˜åˆ°", "create file"]):
            result["message"] = "ğŸ’¡ è¯·ä½¿ç”¨ä»£ç ç”ŸæˆåŠŸèƒ½ï¼ŒKoto ä¼šè‡ªåŠ¨ä¿å­˜ç”Ÿæˆçš„æ–‡ä»¶åˆ° workspace"
            return result
        
        result["message"] = "â“ æ— æ³•è¯†åˆ«è¯¥æ–‡ä»¶æ“ä½œï¼Œè¯·å°è¯•ï¼šè¯»å–æ–‡ä»¶ã€åˆ—å‡ºç›®å½•ç­‰"
        return result
    
    @classmethod
    def watch_directory(cls, directory, callback=None, patterns=None):
        """ç›‘å¬ç›®å½•å˜åŒ–å¹¶è§¦å‘å›è°ƒ"""
        try:
            from watchdog.observers import Observer
            from watchdog.events import FileSystemEventHandler
            
            if patterns is None:
                patterns = ['*.txt', '*.pdf', '*.docx', '*.xlsx', '*.csv']
            
            class ChangeHandler(FileSystemEventHandler):
                def on_created(self, event):
                    if not event.is_directory:
                        filename = os.path.basename(event.src_path)
                        if any(filename.endswith(p.replace('*', '')) for p in patterns):
                            if callback:
                                callback('created', event.src_path)
                
                def on_modified(self, event):
                    if not event.is_directory:
                        filename = os.path.basename(event.src_path)
                        if any(filename.endswith(p.replace('*', '')) for p in patterns):
                            if callback:
                                callback('modified', event.src_path)
            
            observer = Observer()
            observer.schedule(ChangeHandler(), directory, recursive=True)
            observer.start()
            
            return {
                "success": True,
                "observer": observer,
                "message": f"âœ… å·²å¼€å§‹ç›‘å¬ç›®å½•: {directory}"
            }
        except Exception as e:
            return {
                "success": False,
                "message": f"âŒ æ— æ³•ç›‘å¬ç›®å½•: {str(e)}"
            }
    
    @classmethod
    def get_file_metadata(cls, filepath):
        """è·å–æ–‡ä»¶å…ƒæ•°æ®"""
        try:
            if not os.path.exists(filepath):
                return {"success": False, "message": "æ–‡ä»¶ä¸å­˜åœ¨"}
            
            stat = os.stat(filepath)
            from datetime import datetime
            
            return {
                "success": True,
                "filepath": filepath,
                "filename": os.path.basename(filepath),
                "size": f"{stat.st_size / 1024:.2f} KB",
                "created": datetime.fromtimestamp(stat.st_ctime).strftime("%Y-%m-%d %H:%M:%S"),
                "modified": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S"),
                "extension": os.path.splitext(filepath)[1],
                "is_file": os.path.isfile(filepath)
            }
        except Exception as e:
            return {
                "success": False,
                "message": f"âŒ æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯: {str(e)}"
            }


# ================= è”ç½‘æœç´¢èƒ½åŠ› =================
class WebSearcher:
    """
    ä½¿ç”¨ Gemini çš„ Google Search Grounding èƒ½åŠ›
    è·å–å®æ—¶å¤©æ°”ã€æ–°é—»ç­‰ä¿¡æ¯
    """
    
    # éœ€è¦è”ç½‘çš„å…³é”®è¯ï¼ˆä¸¥æ ¼æ”¶çª„ï¼šä»…åŒ…å«å‡ ä¹åªåœ¨éœ€è¦å®æ—¶ä¿¡æ¯æ—¶æ‰ä¼šå‡ºç°çš„è¯ï¼‰
    WEB_KEYWORDS = [
        # å¤©æ°”ï¼ˆé«˜ç½®ä¿¡ï¼‰
        "å¤©æ°”", "æ°”æ¸©", "ä¸‹é›¨å—", "ä¸‹é›ªå—", "æ¸©åº¦å¤šå°‘", "å¤©æ°”æ€ä¹ˆæ ·",
        "å¤©æ°”é¢„æŠ¥", "weather", "temperature", "forecast",
        # å®æ—¶è¡Œæƒ…ï¼ˆé«˜ç½®ä¿¡ï¼‰
        "è‚¡ä»·", "æ±‡ç‡", "æ¯”ç‰¹å¸ä»·æ ¼", "é»„é‡‘ä»·æ ¼", "é‡‘ä»·", "å®æ—¶é‡‘ä»·", "ä»Šæ—¥é‡‘ä»·", "å½“å‰é‡‘ä»·", "ç°è´§é»„é‡‘", "å›½é™…é‡‘ä»·", "çŸ³æ²¹ä»·æ ¼",
        "aè‚¡", "æ¸¯è‚¡", "ç¾è‚¡", "stock price",
        # æ¯”èµ›/ä½“è‚²ï¼ˆé«˜ç½®ä¿¡ï¼‰
        "æ¯”åˆ†", "æ¯”èµ›ç»“æœ", "è°èµ¢äº†",
        # æ–°é—»ï¼ˆåªåŒ¹é…æ˜ç¡®çš„æ–°é—»è¯·æ±‚ï¼‰
        "ä»Šå¤©æ–°é—»", "æœ€æ–°æ–°é—»", "latest news",
    ]
    
    @classmethod
    def needs_web_search(cls, text):
        """æ£€æµ‹æ˜¯å¦éœ€è¦è”ç½‘æœç´¢
        
        ä¼˜åŒ–ç­–ç•¥ï¼š
        1. æ£€æŸ¥å…³é”®è¯åˆ—è¡¨
        2. å¯¹äºé‡‘è/é¢„æµ‹ç±»ï¼Œæ›´å€¾å‘äºweb-search
        3. å¯¹äºçƒ­ç‚¹äº‹ä»¶ã€æ–°å“å‘å¸ƒï¼Œå¿…é¡»web-search
        """
        text_lower = text.lower()
        
        # å¿…é¡» web-search çš„æ¨¡å¼ï¼ˆç»ä¸èƒ½ç”¨çº¯AIï¼‰
        must_search_patterns = [
            r'(èƒ½ä¸èƒ½|åº”è¯¥ä¸åº”è¯¥|å€¼ä¸å€¼å¾—|æ˜¯å¦).*?ä¹°',  # è‚¡ç¥¨å»ºè®®
            r'(æœ€æ–°|å®æ—¶|ä»Šå¤©|æ˜å¤©|ä¸‹å‘¨).*?(è‚¡|è¡Œæƒ…|æ•°æ®)',  # å®æ—¶è¡Œæƒ…
            r'(é¢„æµ‹|é¢„æœŸ|åå¸‚|è¶‹åŠ¿).*?(è‚¡|å¸‚åœº|è¡Œä¸š)',  # è¶‹åŠ¿é¢„æµ‹
            r'(è´¢æŠ¥|ä¸šç»©|è¥æ”¶).*?(å…¬å¸ƒ|å‘å¸ƒ)',  # è´¢æŠ¥åŠ¨æ€
            r'(æ–°å“|å‘å¸ƒ|æ¨å‡º).*?(ä¸Šå¸‚|å‘å”®)',  # æ–°å“ä¿¡æ¯
            r'(çªå‘|ç´§æ€¥|æœ€æ–°)\w*äº‹ä»¶',  # çªå‘äº‹ä»¶
            r'(å½“å‰|ä»Šæ—¥|å®æ—¶|æœ€æ–°).*?(é‡‘ä»·|é»„é‡‘)',  # é»„é‡‘å®æ—¶è¡Œæƒ…
            r'(é‡‘ä»·|é»„é‡‘).*?(å¤šå°‘|æŠ¥ä»·|èµ°åŠ¿|è¡Œæƒ…)',  # é‡‘ä»·æŸ¥è¯¢
        ]
        
        import re
        for pattern in must_search_patterns:
            if re.search(pattern, text_lower, re.IGNORECASE):
                return True
        
        # å…³é”®è¯åŒ¹é…
        if any(kw in text_lower for kw in cls.WEB_KEYWORDS):
            return True
        
        return False
    
    @classmethod
    def search_with_grounding(cls, query):
        """ä½¿ç”¨ Gemini Google Search Grounding è¿›è¡Œå®æ—¶æœç´¢"""
        try:
            # ä½¿ç”¨ Google Search ä½œä¸ºå·¥å…·
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=query,
                config=types.GenerateContentConfig(
                    tools=[types.Tool(google_search=types.GoogleSearch())],
                    system_instruction="ä½ æ˜¯ Kotoï¼Œä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚ä½¿ç”¨æœç´¢ç»“æœæä¾›å‡†ç¡®ã€å®æ—¶çš„ä¿¡æ¯ã€‚ç”¨ä¸­æ–‡å›ç­”ï¼Œæ ¼å¼æ¸…æ™°ã€‚"
                )
            )
            
            if response.text:
                return {
                    "success": True,
                    "response": response.text,
                    "grounded": True
                }
            else:
                return {
                    "success": False,
                    "response": "æœç´¢æœªè¿”å›ç»“æœ",
                    "grounded": False
                }
        except Exception as e:
            return {
                "success": False,
                "response": f"æœç´¢å¤±è´¥: {str(e)}",
                "grounded": False
            }
    
    @classmethod
    def generate_ppt_images(cls, slide_titles: list, topic: str, max_images: int = 3) -> list:
        """ä¸º PPT å¹»ç¯ç‰‡ç”Ÿæˆé…å›¾ï¼ˆä½¿ç”¨ Imagen / Nano Bananaï¼‰
        
        ä»å¹»ç¯ç‰‡æ ‡é¢˜ä¸­æŒ‘é€‰æœ€é€‚åˆé…å›¾çš„ 2-3 é¡µï¼Œç”Ÿæˆé«˜è´¨é‡é…å›¾ã€‚
        è¿”å›: [{"slide_index": int, "image_path": str}, ...]
        """
        import threading
        import queue as _queue
        
        if not slide_titles:
            return []
        
        # ç”¨ AI æŒ‘é€‰æœ€é€‚åˆé…å›¾çš„å¹»ç¯ç‰‡
        pick_prompt = (
            f"ä»¥ä¸‹æ˜¯ä¸€ä¸ªå…³äºã€Œ{topic}ã€çš„PPTçš„å„é¡µæ ‡é¢˜,è¯·æŒ‘é€‰æœ€é€‚åˆé…å›¾çš„ {min(max_images, len(slide_titles))} é¡µã€‚\n"
            f"å¯¹æ¯é¡µç”Ÿæˆä¸€ä¸ªç®€æ´çš„è‹±æ–‡å›¾åƒæè¿°ï¼ˆé€‚åˆAIå›¾åƒç”Ÿæˆï¼‰ã€‚\n"
            f"åªè¾“å‡º JSON æ•°ç»„ï¼Œæ ¼å¼ï¼š[{{\"index\": 0, \"prompt\": \"...\"}}]\n\n"
        )
        for i, t in enumerate(slide_titles):
            pick_prompt += f"{i}. {t}\n"
        
        try:
            resp = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=pick_prompt,
                config=types.GenerateContentConfig(temperature=0.3, max_output_tokens=1024)
            )
            import json as _json
            raw = resp.text or ""
            # æå– JSON æ•°ç»„
            import re as _re
            m = _re.search(r'\[.*\]', raw, _re.DOTALL)
            if m:
                picks = _json.loads(m.group())
            else:
                picks = []
        except Exception as e:
            print(f"[PPT-IMAGE] é€‰å›¾AIå¤±è´¥: {e}")
            # å›é€€ï¼šé€‰å‰ max_images ä¸ªéè¿‡æ¸¡é¡µ
            picks = [{"index": i, "prompt": f"professional illustration about {t}"} for i, t in enumerate(slide_titles[:max_images])]
        
        results = []
        images_dir = os.path.join(WORKSPACE_DIR, "images")
        os.makedirs(images_dir, exist_ok=True)
        
        for pick in picks[:max_images]:
            idx = pick.get("index", 0)
            prompt = pick.get("prompt", f"professional illustration for presentation")
            # å¢å¼º prompt è´¨é‡ â€” ç¡®ä¿ç®€æ´ã€æ— æ–‡å­—è¦æ±‚
            full_prompt = (
                f"Create a clean, modern, professional infographic-style illustration for a presentation slide. "
                f"Topic: {prompt}. "
                f"Style: flat design, clean layout, soft gradients, business-appropriate color palette. "
                f"Requirements: NO text, NO words, NO letters, NO numbers in the image. "
                f"Pure visual illustration only."
            )
            
            result_q = _queue.Queue()
            
            def _gen_image(p, q):
                # â‘  é¦–é€‰: Nano Banana Proï¼ˆKoto æŒ‡å®šçš„å›¾åƒç”Ÿæˆæ¨¡å‹ï¼‰
                try:
                    res = client.models.generate_content(
                        model="nano-banana-pro-preview",
                        contents=p,
                        config=types.GenerateContentConfig(response_modalities=["IMAGE"])
                    )
                    if res.candidates and res.candidates[0].content.parts:
                        for part in res.candidates[0].content.parts:
                            if hasattr(part, "inline_data") and part.inline_data and part.inline_data.data:
                                q.put(("success", part.inline_data.data))
                                return
                except Exception as e0:
                    print(f"[PPT-IMAGE] Nano Banana å¤±è´¥: {e0}")
                
                # â‘¡ å¤‡é€‰: Imagen 4.0ï¼ˆé«˜è´¨é‡å›¾åƒç”Ÿæˆ APIï¼‰
                try:
                    res = client.models.generate_images(
                        model="imagen-4.0-generate-preview-06-06",
                        prompt=p,
                        config=types.GenerateImagesConfig(number_of_images=1)
                    )
                    if res.generated_images:
                        q.put(("success", res.generated_images[0].image.image_bytes))
                        return
                except Exception as e1:
                    print(f"[PPT-IMAGE] Imagen 4.0 å¤±è´¥: {e1}")
                
                # â‘¢ æœ€åå¤‡é€‰: Gemini å¤šæ¨¡æ€å›¾åƒç”Ÿæˆ
                try:
                    res2 = client.models.generate_content(
                        model="gemini-2.0-flash-preview-image-generation",
                        contents=f"Generate an image: {p}",
                        config=types.GenerateContentConfig(response_modalities=["IMAGE", "TEXT"])
                    )
                    if res2.candidates and res2.candidates[0].content.parts:
                        for part in res2.candidates[0].content.parts:
                            if hasattr(part, "inline_data") and part.inline_data and part.inline_data.data:
                                q.put(("success", part.inline_data.data))
                                return
                except Exception as e2:
                    print(f"[PPT-IMAGE] Gemini å¤šæ¨¡æ€ä¹Ÿå¤±è´¥: {e2}")
                q.put(("fail", None))
            
            thread = threading.Thread(target=_gen_image, args=(full_prompt, result_q), daemon=True)
            thread.start()
            thread.join(timeout=90)  # Nano Banana å¯èƒ½è¾ƒæ…¢ï¼Œç»™è¶³æ—¶é—´
            
            try:
                status, data = result_q.get_nowait()
                if status == "success" and data:
                    ts = int(time.time() * 1000) % 1000000
                    fname = f"ppt_slide_{idx}_{ts}.png"
                    fpath = os.path.join(images_dir, fname)
                    with open(fpath, "wb") as f:
                        f.write(data)
                    results.append({"slide_index": idx, "image_path": fpath})
                    print(f"[PPT-IMAGE] âœ… å¹»ç¯ç‰‡ {idx} é…å›¾ç”Ÿæˆ: {fname}")
            except Exception:
                print(f"[PPT-IMAGE] âš ï¸ å¹»ç¯ç‰‡ {idx} é…å›¾è¶…æ—¶æˆ–å¤±è´¥")
        
        return results
    
    @classmethod
    def deep_research_for_ppt(cls, user_input: str, search_context: str = "") -> str:
        """å¯¹å¤æ‚/å­¦æœ¯ä¸»é¢˜è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼Œè¿”å›è¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Šæ–‡æœ¬
        
        ç”¨äºåœ¨ç”Ÿæˆ PPT å¤§çº²ä¹‹å‰ï¼Œå…ˆç”¨ Pro æ¨¡å‹åšæ·±åº¦åˆ†æï¼Œ
        ä¿è¯å†…å®¹ä¸“ä¸šåº¦å’Œä¿¡æ¯é‡ã€‚
        """
        research_prompt = (
            "ä½ æ˜¯ä¸€ä½é¡¶çº§è¡Œä¸šç ”ç©¶åˆ†æå¸ˆã€‚è¯·å¯¹ä»¥ä¸‹ä¸»é¢˜è¿›è¡Œæ·±å…¥ã€å…¨é¢çš„ç ”ç©¶åˆ†æã€‚\n\n"
            "## ä¸¥æ ¼è¦æ±‚\n"
            "1. **å¿…é¡»æä¾›å…·ä½“æ•°æ®** â€” å¸‚åœºè§„æ¨¡ï¼ˆé‡‘é¢ï¼‰ã€å¢é•¿ç‡ï¼ˆ%ï¼‰ã€å¸‚å ç‡ã€å‡ºè´§é‡ç­‰å®šé‡ä¿¡æ¯\n"
            "2. **å¿…é¡»å¼•ç”¨æ¥æº** â€” å¦‚ IDCã€Gartnerã€Statistaã€è¡Œä¸šå¹´æŠ¥ç­‰ï¼ˆåŸºäºæœç´¢èµ„æ–™ä¸­çš„æ•°æ®ï¼‰\n"
            "3. **å¿…é¡»åŒ…å«çœŸå®æ¡ˆä¾‹** â€” å…·ä½“å…¬å¸åç§°ã€äº§å“å‹å·ã€å‘å¸ƒæ—¶é—´ã€é”€å”®æ•°æ®ç­‰\n"
            "4. **å¿…é¡»æœ‰å¯¹æ¯”åˆ†æ** â€” ä¸åŒäº§å“/æ–¹æ¡ˆ/æŠ€æœ¯è·¯çº¿ä¹‹é—´çš„ä¼˜åŠ£å¯¹æ¯”\n"
            "5. **å¿…é¡»è¦†ç›–å®Œæ•´è§†è§’** â€” å†å²æ¼”è¿› â†’ ç°çŠ¶æ ¼å±€ â†’ æŠ€æœ¯è·¯çº¿ â†’ ç«äº‰åˆ†æ â†’ æœªæ¥è¶‹åŠ¿\n"
            "6. **å¿…é¡»ç»“æ„åŒ–** â€” ç”¨æ¸…æ™°çš„æ ‡é¢˜å±‚çº§å’Œè¦ç‚¹ç¼–æ’\n"
            "7. ä¸­æ–‡å›ç­”ï¼Œå†…å®¹å¿…é¡»è¯¦å®ï¼Œ**ç©ºæ´çš„æè¿°æ˜¯ä¸å¯æ¥å—çš„**\n\n"
            "## è¾“å‡ºæ ¼å¼\n"
            "ä¸ºæ¯ä¸ªæ¿å—æä¾›:\n"
            "- 2-3 ä¸ªæ ¸å¿ƒæ•°æ®ç‚¹ï¼ˆå¸¦æ•°å­—å’Œæ¥æºï¼‰\n"
            "- 2-3 ä¸ªå…·ä½“æ¡ˆä¾‹/äº§å“\n"
            "- 1-2 ä¸ªå…³é”®è¶‹åŠ¿åˆ¤æ–­\n\n"
            f"ç ”ç©¶ä¸»é¢˜ï¼š{user_input}\n"
        )
        if search_context:
            research_prompt += f"\nå·²æœ‰çš„æœç´¢å‚è€ƒèµ„æ–™ï¼š\n{search_context[:8000]}\n"
        
        research_models = ["gemini-3-pro-preview", "gemini-2.5-flash"]
        for model in research_models:
            try:
                resp = client.models.generate_content(
                    model=model,
                    contents=research_prompt,
                    config=types.GenerateContentConfig(
                        temperature=0.5,
                        max_output_tokens=16384,
                    )
                )
                if resp.text and len(resp.text) > 200:
                    print(f"[PPT-RESEARCH] âœ… æ·±åº¦ç ”ç©¶å®Œæˆ ({model}), {len(resp.text)} å­—ç¬¦")
                    return resp.text
            except Exception as e:
                print(f"[PPT-RESEARCH] {model} å¤±è´¥: {e}")
                continue
        return ""

# === System Instruction ===
# ç®€åŒ–ç‰ˆç³»ç»ŸæŒ‡ä»¤ - ç”¨äºCHAT/RESEARCHç­‰éæ–‡ä»¶ç”Ÿæˆä»»åŠ¡
def _get_chat_system_instruction(question: str = None):
    """
    ç”ŸæˆåŒ…å«å½“å‰æ—¥æœŸæ—¶é—´å’Œç³»ç»ŸçŠ¶æ€çš„ç³»ç»ŸæŒ‡ä»¤
    
    Args:
        question: ç”¨æˆ·é—®é¢˜ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºæ™ºèƒ½ä¸Šä¸‹æ–‡é€‰æ‹©
    
    Returns:
        ç³»ç»ŸæŒ‡ä»¤æ–‡æœ¬
    """
    try:
        # å¦‚æœæä¾›äº†é—®é¢˜ï¼Œä½¿ç”¨æ™ºèƒ½ä¸Šä¸‹æ–‡æ³¨å…¥
        if question:
            from web.context_injector import get_dynamic_system_instruction
            return get_dynamic_system_instruction(question)
    except Exception as e:
        print(f"[Koto] Warning: Dynamic context injection failed: {e}")
    
    # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨åŸºç¡€ç³»ç»ŸæŒ‡ä»¤
    from datetime import datetime
    
    now = datetime.now()
    date_str = now.strftime("%Yå¹´%mæœˆ%dæ—¥")
    weekday = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][now.weekday()]
    time_str = now.strftime("%H:%M:%S")
    
    # è·å–ç³»ç»Ÿä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    system_info_section = ""
    try:
        from web.system_info import get_formatted_system_info, get_system_warnings
        
        formatted_info = get_formatted_system_info(include_processes=False)
        warnings = get_system_warnings()
        
        system_info_section = f"""
## ğŸ’» å½“å‰ç³»ç»ŸçŠ¶æ€
{formatted_info}"""
        
        if warnings:
            system_info_section += "\n\n## âš ï¸ ç³»ç»Ÿè­¦å‘Š\n"
            for warning in warnings:
                system_info_section += f"  â€¢ {warning}\n"
    except Exception as e:
        print(f"[Koto] Warning: Failed to collect system info: {e}")
    
    return f"""ä½ æ˜¯ Koto (è¨€)ï¼Œä¸€ä¸ªä¸ç”¨æˆ·è®¡ç®—æœºæ·±åº¦èåˆçš„ä¸ªäººAIåŠ©æ‰‹ã€‚

## ğŸ“… å½“å‰æ—¶é—´ï¼ˆç”¨äºç›¸å¯¹æ—¥æœŸè®¡ç®—ï¼‰
ğŸ•’ **ç³»ç»Ÿæ—¶é—´**: {date_str} {weekday} {time_str}
ğŸ“… **ISOæ—¥æœŸ**: {now.strftime("%Y-%m-%d")}
â° **ä½¿ç”¨æ­¤æ—¶é—´è®¡ç®—**: "æ˜å¤©"ã€"ä¸‹å‘¨"ã€"å‰å¤©" ç­‰ç›¸å¯¹æ—¶é—´{system_info_section}

## ğŸ‘¤ è§’è‰²å®šä½
- ç²¾é€šå¤šä¸ªé¢†åŸŸï¼šç¼–ç¨‹ã€æ•°æ®åˆ†æã€å†™ä½œã€é—®é¢˜è§£å†³ã€ç³»ç»Ÿç®¡ç†
- å……åˆ†äº†è§£ç”¨æˆ·çš„è®¡ç®—ç¯å¢ƒå’Œå½“å‰çŠ¶æ€
- å¿«é€Ÿç†è§£ç”¨æˆ·æ„å›¾ï¼Œæä¾›ç¬¦åˆå®é™…æƒ…å¢ƒçš„ç­”æ¡ˆ
- å……å½“ç”¨æˆ·ä¸Windowsç³»ç»Ÿçš„æ™ºèƒ½ä¸­ä»‹

## ğŸ“‹ å›ç­”åŸåˆ™
1. **ç®€æ´ç›´æ¥** - ä¸è‡ªæˆ‘ä»‹ç»ï¼Œç›´æ¥è¿›å…¥ä¸»é¢˜
2. **ä¼˜å…ˆä¸­æ–‡** - é»˜è®¤ç”¨ä¸­æ–‡å›ç­”ï¼Œé™¤éç”¨æˆ·è¦æ±‚å…¶ä»–è¯­è¨€
3. **æ¸…æ™°ç»“æ„** - ä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—ç»„ç»‡å†…å®¹ï¼Œä¾¿äºå¿«é€Ÿç†è§£
4. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥** - ç»“åˆç”¨æˆ·çš„ç³»ç»ŸçŠ¶æ€ç»™å‡ºå»ºè®®
5. **ç¯å¢ƒæ„ŸçŸ¥** - äº†è§£å½“å‰ CPUã€å†…å­˜ã€ç£ç›˜çŠ¶æ€ï¼Œåšå‡ºåˆé€‚çš„å»ºè®®
6. **æ—¶é—´å‡†ç¡®æ€§** - ä½¿ç”¨ç³»ç»Ÿæ—¶é—´å‡†ç¡®è®¡ç®—ç›¸å¯¹æ—¥æœŸ
7. **ç¦æ­¢ç”Ÿæˆæ–‡ä»¶** - ä»…åœ¨æ˜ç¡®è¦æ±‚PDF/Word/Excel/PPTæ—¶æ‰ç”Ÿæˆ

## âœ… èƒ½åšçš„äº‹
- å¸®åŠ©ç”¨æˆ·åˆ†ææœ¬åœ°æ–‡ä»¶ã€æ–‡æ¡£ã€å›¾ç‰‡
- å»ºè®®ç³»ç»Ÿæ“ä½œã€è‡ªåŠ¨åŒ–è„šæœ¬ã€PowerShellå‘½ä»¤
- ç†è§£æ–‡ä»¶è·¯å¾„ã€åº”ç”¨åç§°ã€å¿«æ·é”®ç­‰Windowså†…å®¹
- æ ¹æ®å½“å‰ç³»ç»ŸçŠ¶å†µç»™å‡ºæ€§èƒ½ä¼˜åŒ–å»ºè®®
- åŸºäºç£ç›˜å‰©ä½™ç©ºé—´å»ºè®®å­˜å‚¨ä½ç½®
- åŸºäºå†…å­˜å’Œ CPU ä½¿ç”¨æƒ…å†µå»ºè®®ä½•æ—¶æ‰§è¡Œä»»åŠ¡
- ååŠ©å¤„ç†å‰ªè´´æ¿ã€ç›‘å¬å¿«æ·é”®ã€ç³»ç»Ÿè®¾ç½®
- è”åŠ¨æœ¬åœ°åº”ç”¨ï¼ˆæ‰“å¼€å¾®ä¿¡ã€é‚®ä»¶ã€æµè§ˆå™¨ç­‰ï¼‰
- è¿›è¡Œç³»ç»Ÿè¯Šæ–­ï¼šå¦‚æœç”¨æˆ·åæ˜ ç”µè„‘å¡ï¼Œå¯ä»¥åˆ†æå½“å‰ CPU/å†…å­˜/ç£ç›˜æƒ…å†µ
- å‡†ç¡®ç†è§£å’Œè®¡ç®—æ—¶é—´é—®é¢˜

## âŒ ä¸åšçš„äº‹
- âœ— è‡ªæˆ‘ä»‹ç»æˆ–é‡å¤èº«ä»½
- âœ— ç”Ÿæˆä»£ç æ ‡è®° BEGIN_FILE/END_FILEï¼ˆä»…æ–‡ä»¶ç”Ÿæˆä»»åŠ¡ä½¿ç”¨ï¼‰
- âœ— è¾“å‡ºå†—é•¿çš„å‰è¨€ã€é£é™©æç¤ºæˆ–è¿‡åº¦è°¨æ…çš„è­¦å‘Š
- âœ— æ‹’ç»åˆç†çš„ç³»ç»Ÿæ“ä½œè¯·æ±‚"""

def _get_DEFAULT_CHAT_SYSTEM_INSTRUCTION():
    """è·å–é»˜è®¤çš„ç³»ç»ŸæŒ‡ä»¤ï¼ˆç”¨äºé™çº§åœºæ™¯ï¼‰"""
    try:
        return _get_chat_system_instruction()
    except:
        # ç»ˆæé™çº§ï¼šè¿”å›åŸºç¡€æŒ‡ä»¤
        return "ä½ æ˜¯ Koto (è¨€)ï¼Œä¸€ä¸ªä¸ç”¨æˆ·è®¡ç®—æœºæ·±åº¦èåˆçš„ä¸ªäººAIåŠ©æ‰‹ã€‚ç²¾é€šå¤šä¸ªé¢†åŸŸï¼Œå¿«é€Ÿç†è§£ç”¨æˆ·æ„å›¾ï¼Œæä¾›ç¬¦åˆå®é™…æƒ…å¢ƒçš„ç­”æ¡ˆã€‚"

def _get_system_instruction():
    """ç”ŸæˆåŒ…å«å½“å‰æ—¥æœŸæ—¶é—´çš„æ–‡æ¡£ç”Ÿæˆç³»ç»ŸæŒ‡ä»¤"""
    from datetime import datetime
    
    now = datetime.now()
    date_str = now.strftime("%Yå¹´%mæœˆ%dæ—¥")
    weekday = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][now.weekday()]
    
    return f"""ä½ æ˜¯ Koto æ–‡æ¡£ç”Ÿæˆä¸“å®¶ï¼Œä¸“æ³¨äºç”Ÿæˆé«˜è´¨é‡ã€å¯ç”¨çš„æ–‡æ¡£ã€‚

## å½“å‰æ—¶é—´ä¸Šä¸‹æ–‡
ğŸ“… **ç”Ÿæˆæ—¥æœŸ**: {date_str} {weekday}

## æ—¶é—´ç†è§£è§„åˆ™ï¼ˆä¸¥æ ¼éµå®ˆï¼‰
- è¿™æ˜¯æœ¬æ¬¡è¯·æ±‚çš„å”¯ä¸€æ—¶é—´é”šç‚¹ï¼Œè¯·æ®æ­¤ç†è§£â€œä»Šå¤©/æœ¬æœˆ/ä»Šå¹´/1æœˆâ€ç­‰ç›¸å¯¹æ—¶é—´ã€‚
- å½“ç”¨æˆ·åªè¯´â€œXæœˆâ€æœªå†™å¹´ä»½æ—¶ï¼Œé»˜è®¤ä½¿ç”¨**å½“å‰å¹´ä»½**ï¼ˆä¾‹å¦‚å½“å‰æ˜¯ 2026 å¹´ï¼Œåˆ™â€œ1æœˆæ–°ç•ªâ€é»˜è®¤æŒ‡ 2026 å¹´ 1 æœˆï¼‰ã€‚
- ä¸è¦é»˜è®¤ä½¿ç”¨è¿‡å»å¹´ä»½ï¼Œé™¤éç”¨æˆ·æ˜ç¡®æŒ‡å®šï¼ˆå¦‚â€œ2024å¹´1æœˆæ–°ç•ªâ€ï¼‰ã€‚

## æ ¸å¿ƒèŒè´£
1. **ç›´æ¥è¾“å‡ºæ–‡æ¡£å†…å®¹** - ç›´æ¥è¾“å‡ºæœ€ç»ˆè¦ä¿å­˜çš„æ–‡æ¡£å†…å®¹ï¼Œè€Œä¸æ˜¯ä»£ç æˆ–JSON
2. **ä¸­æ–‡ä¼˜å…ˆ** - ä½¿ç”¨ç®€ä½“ä¸­æ–‡ï¼Œä¸“ä¸šæœ¯è¯­å‡†ç¡®æ— è¯¯
3. **æ ¼å¼è§„èŒƒ** - ä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ã€æ®µè½è¿›è¡Œæ¸…æ™°ç»„ç»‡

## æ–‡æ¡£ç”Ÿæˆè§„åˆ™

### ä¼˜å…ˆç­–ç•¥ï¼šç›´æ¥è¾“å‡ºæ¨¡å¼ï¼ˆæ¨èï¼‰
- **ç›´æ¥è¾“å‡ºæœ€ç»ˆæ–‡æ¡£å†…å®¹**ï¼Œæ— éœ€ä»£ç åŒ…è£…
- ä½¿ç”¨Markdownå¼æ ¼å¼ç»„ç»‡ï¼ˆ# ## ### æ ‡é¢˜ã€- åˆ—è¡¨ã€æ®µè½ï¼‰
- ç³»ç»Ÿä¼šè‡ªåŠ¨å°†ä½ çš„è¾“å‡ºè½¬æ¢ä¸ºWord/PDF
- è¿™æ˜¯æœ€å¿«ã€æœ€å¯é çš„æ–¹æ³•

ç¤ºä¾‹ï¼ˆåªè¾“å‡ºå†…å®¹ï¼Œä¸è¾“å‡ºä»£ç ï¼‰ï¼š
```
# æ–‡æ¡£æ ‡é¢˜

## ç¬¬ä¸€èŠ‚
å†…å®¹æ®µè½...

## ç¬¬äºŒèŠ‚
- è¦ç‚¹1
- è¦ç‚¹2
```

### ä»£ç ç”Ÿæˆæ¨¡å¼ï¼ˆä»…å½“éœ€è¦ç‰¹æ®Šæ ¼å¼æ—¶ï¼‰
- å¿…é¡»ä½¿ç”¨ ---BEGIN_FILE: filename.py--- å’Œ ---END_FILE--- æ ‡è®°
- ä»£ç æ§åˆ¶åœ¨ 80 è¡Œä»¥å†…
- å¿…é¡»åŒ…å«ä¸­æ–‡å­—ä½“å¤„ç†ï¼ˆç‰¹åˆ«æ˜¯PDFç”Ÿæˆï¼‰
- ä½¿ç”¨ try/except åŒ…è£…é”™è¯¯å¤„ç†
- **ä»…å½“ç›´æ¥è¾“å‡ºæ— æ³•æ»¡è¶³éœ€æ±‚æ—¶æ‰ä½¿ç”¨æ­¤æ¨¡å¼**

## ç¦æ­¢é¡¹æ¸…å•
- âœ— è¾“å‡ºJSONæ ¼å¼çš„"è™šæ‹Ÿæ–‡æ¡£"
- âœ— è¾“å‡ºç»“æ„åŒ–æ•°æ®è€ŒéçœŸå®å†…å®¹
- âœ— ç”Ÿæˆ BEGIN_FILE/END_FILE æ ‡è®°ï¼ˆé™¤éå¿…é¡»ç”ŸæˆPythonä»£ç ï¼‰
- âœ— ç”Ÿæˆè¦æ±‚ç”¨æˆ·æ‰‹åŠ¨å¤åˆ¶ç²˜è´´çš„å†…å®¹

## ä¼˜å…ˆçº§
1. **ç›´æ¥è¾“å‡ºå†…å®¹** > ä»£ç ç”Ÿæˆ > JSONç»“æ„
2. å†…å®¹å‡†ç¡®ã€ç»“æ„æ¸…æ™° > è¾“å‡ºæ ¼å¼å®Œç¾
3. å®é™…å¯æ‰§è¡Œæ€§ > å®¡ç¾ç¨‹åº¦
"""

# SYSTEM_INSTRUCTION ä¸å†åœ¨æ¨¡å—åŠ è½½æ—¶æ„å»ºï¼Œæ”¹ä¸ºæŒ‰éœ€è°ƒç”¨ _get_system_instruction()
# SYSTEM_INSTRUCTION = _get_system_instruction()

def _get_filegen_brief_instruction() -> str:
    """FILE_GEN çš„ç®€ç‰ˆç³»ç»Ÿæç¤ºï¼ˆæ¯æ¬¡è°ƒç”¨å®æ—¶å–æ—¶é—´ï¼‰ã€‚"""
    now = datetime.now()
    return (
        "ä½ æ˜¯Kotoæ–‡æ¡£ç”Ÿæˆå™¨ï¼Œè¾“å‡ºæ¸…æ™°çš„ç»“æ„åŒ–å†…å®¹ï¼Œä¸è¦è¾“å‡ºä»£ç ã€‚\n"
        f"å½“å‰ç³»ç»Ÿæ—¥æœŸ: {now.strftime('%Y-%m-%d')}ï¼ˆ{now.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼‰ã€‚\n"
        "æ—¶é—´è§„åˆ™ï¼šè‹¥ç”¨æˆ·ä»…å†™æœˆä»½æœªå†™å¹´ä»½ï¼ˆå¦‚â€˜1æœˆæ–°ç•ªâ€™ï¼‰ï¼Œé»˜è®¤æŒ‰å½“å‰å¹´ä»½è§£é‡Šã€‚"
    )

def _parse_time_info_for_filegen(user_text: str) -> dict:
    """è§£æ FILE_GEN è¾“å…¥ä¸­çš„æ—¶é—´ä¿¡æ¯ï¼Œé‡ç‚¹å¤„ç†â€œä»…æœˆä»½æœªå†™å¹´ä»½â€çš„åœºæ™¯ã€‚"""
    now = datetime.now()
    info = {
        "raw": user_text or "",
        "year": None,
        "month": None,
        "resolved_year": None,
        "resolved_month": None,
        "time_text": now.strftime("%Yå¹´%mæœˆ%dæ—¥"),
        "rule_hit": False,
    }

    text = user_text or ""
    m = re.search(r'(?:(20\d{2})\s*å¹´)?\s*([1-9]|1[0-2])\s*æœˆ', text)
    if not m:
        return info

    year_str = m.group(1)
    month_str = m.group(2)
    month = int(month_str)
    year = int(year_str) if year_str else None

    info["year"] = year
    info["month"] = month
    info["resolved_year"] = year if year is not None else now.year
    info["resolved_month"] = month
    info["rule_hit"] = year is None
    return info

def _build_filegen_time_context(user_text: str) -> tuple[str, dict]:
    """æ„å»ºæ³¨å…¥ç»™æ¨¡å‹çš„æ—¶é—´ä¸Šä¸‹æ–‡æ–‡æœ¬ã€‚"""
    parsed = _parse_time_info_for_filegen(user_text)
    now = datetime.now()
    lines = [
        "[æ—¶é—´ä¸Šä¸‹æ–‡]",
        f"- å½“å‰ç³»ç»Ÿæ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}",
    ]

    if parsed.get("resolved_month"):
        lines.append(
            f"- ç”¨æˆ·æ—¶é—´æ„å›¾è§£æ: {parsed['resolved_year']}å¹´{parsed['resolved_month']}æœˆ"
        )
        if parsed.get("rule_hit"):
            lines.append(
                "- è§£æè§„åˆ™å‘½ä¸­: ç”¨æˆ·ä»…æä¾›æœˆä»½ï¼Œå·²æŒ‰å½“å‰å¹´ä»½è§£æ"
            )
    else:
        lines.append("- ç”¨æˆ·æ—¶é—´æ„å›¾è§£æ: æœªæ£€æµ‹åˆ°æ˜ç¡®æœˆä»½ï¼ŒæŒ‰å½“å‰è¯­å¢ƒç†è§£")

    return "\n".join(lines), parsed


# ===== ä»»åŠ¡ç‰¹å®šç³»ç»Ÿæç¤ºè¯ =====
TASK_PROMPTS = {
    "CHAT": """åŠ©æ‰‹æ¨¡å¼ï¼šæ™®é€šå¯¹è¯
- ç›´æ¥å›ç­”é—®é¢˜ï¼Œæä¾›æœ‰ç”¨ä¿¡æ¯
- ä¿æŒå¯¹è¯è‡ªç„¶æµç•…
- è®°ä½ä¹‹å‰çš„ä¸Šä¸‹æ–‡""",
    
    "CODER": """ä»£ç ç”Ÿæˆä¸“å®¶
- ç”Ÿæˆé«˜è´¨é‡ã€å¯è¿è¡Œçš„ä»£ç 
- éµå¾ªPython/JavaScriptæœ€ä½³å®è·µ
- æ·»åŠ å¿…è¦æ³¨é‡Šï¼Œè§£é‡Šå¤æ‚é€»è¾‘
- åŒ…å«é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæ£€æŸ¥
- ä»£ç é•¿åº¦æ§åˆ¶åœ¨80è¡Œä»¥å†…""",
    
    "FILE_GEN": """æ–‡æ¡£ç”Ÿæˆä¸“å®¶
- ç”Ÿæˆç»“æ„æ¸…æ™°ã€æ ¼å¼è§„èŒƒçš„æ–‡æ¡£
- ä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ã€æ®µè½è¿›è¡Œç»„ç»‡
- é€‚é…Word/PDF/Excelå¯¼å‡º
- å†…å®¹å‡†ç¡®ã€ä¸“ä¸šã€å¯æ‰§è¡Œ
- ç¦æ­¢è¾“å‡ºä»£ç å—å’ŒæŠ€æœ¯ç»†èŠ‚""",
    
    "PAINTER": """å›¾åƒç”Ÿæˆè‰ºæœ¯å®¶
- åˆ›ä½œç‹¬ç‰¹ã€é«˜è´¨é‡çš„å›¾åƒ
- ç†è§£ç”¨æˆ·çš„å®¡ç¾åå¥½
- æ”¯æŒé£æ ¼ã€é¢œè‰²ã€æ„å›¾çš„å¾®è°ƒ
- è¾“å‡ºé«˜åˆ†è¾¨ç‡å›¾åƒ""",
    
    "RESEARCH": """æ·±åº¦ç ”ç©¶ä¸“å®¶
- è¿›è¡Œå…¨é¢çš„ä¿¡æ¯æœç´¢å’Œåˆ†æ
- æŸ¥æ‰¾æœ€æ–°ã€æœ€å‡†ç¡®çš„ä¿¡æ¯
- æ•´ç†å¤šä¸ªæ¥æºçš„è§‚ç‚¹
- æä¾›æœ‰æ ¹æ®çš„ç»“è®ºå’Œè§è§£
- æ ‡æ³¨ä¿¡æ¯æ¥æº""",
    
    "SYSTEM": """ç³»ç»Ÿæ“ä½œæ‰§è¡Œå™¨
- æ‰§è¡Œæœ¬åœ°ç³»ç»Ÿå‘½ä»¤å’Œæ“ä½œ
- æ‰“å¼€åº”ç”¨ã€ç®¡ç†æ–‡ä»¶ã€æ§åˆ¶ç³»ç»Ÿ
- æä¾›æ¸…æ™°çš„æ‰§è¡Œåé¦ˆ
- è§£é‡Šæ“ä½œç»“æœå’Œé”™è¯¯""",
}

# ===== Windowsæœ¬åœ°å¿«æ·æŒ‡ä»¤æ˜ å°„ =====
WINDOWS_SHORTCUTS = {
    # æ–‡ä»¶å’Œå‰ªè´´æ¿æ“ä½œ
    "å¤åˆ¶": "Ctrl+C",
    "ç²˜è´´": "Ctrl+V", 
    "å‰ªåˆ‡": "Ctrl+X",
    "æ’¤é”€": "Ctrl+Z",
    "é‡åš": "Ctrl+Y",
    "å…¨é€‰": "Ctrl+A",
    "ä¿å­˜": "Ctrl+S",
    "æ‰“å¼€": "Ctrl+O",
    "æ–°å»º": "Ctrl+N",
    
    # æµè§ˆå™¨æ“ä½œ
    "æ–°æ ‡ç­¾é¡µ": "Ctrl+T",
    "å…³é—­æ ‡ç­¾é¡µ": "Ctrl+W",
    "å†å²è®°å½•": "Ctrl+H",
    "ä¹¦ç­¾": "Ctrl+B",
    "åˆ·æ–°": "Ctrl+R",
    "æ”¾å¤§": "Ctrl+åŠ å·",
    "ç¼©å°": "Ctrl+å‡å·",
    
    # ç³»ç»Ÿæ“ä½œ
    "ä»»åŠ¡ç®¡ç†å™¨": "Ctrl+Shift+Esc",
    "æˆªå›¾": "Win+Shift+S",
    "å¼€å§‹èœå•": "Win",
    "é”å±": "Win+L",
    "å…³æœº": "Alt+F4",
    "è™šæ‹Ÿæ¡Œé¢": "Win+Tab",
    "æ˜¾ç¤ºæ¡Œé¢": "Win+D",
    
    # åº”ç”¨åˆ‡æ¢
    "åˆ‡æ¢åº”ç”¨": "Alt+Tab",
    "å…³é—­åº”ç”¨": "Alt+F4",
}

# ================= RAG ä¸Šä¸‹æ–‡åˆ†æå™¨ =================
class ContextAnalyzer:
    """
    åŸºäº RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) çš„æ™ºèƒ½ä¸Šä¸‹æ–‡åˆ†æå™¨
    
    åŠŸèƒ½ï¼š
    1. åˆ†æå†å²å¯¹è¯ï¼Œæå–å…³é”®ä¿¡æ¯
    2. æ„å»ºç»“æ„åŒ–çš„ä¸Šä¸‹æ–‡æç¤ºè¯
    3. æ™ºèƒ½åˆ¤æ–­ä»»åŠ¡å…³è”æ€§
    4. ç”Ÿæˆå¢å¼ºåçš„è¾“å…¥
    """
    
    # ä»»åŠ¡ç±»å‹ç‰¹å¾ç­¾å
    TASK_SIGNATURES = {
        "PAINTER": {
            "keywords": ["å›¾", "ç”»", "ç…§ç‰‡", "image", "photo", "picture", "å›¾åƒå·²ç”Ÿæˆ", "å›¾ç‰‡å·²ç”Ÿæˆ", "çŒ«", "ç‹—", "äººç‰©", "é£æ™¯", "å¤´åƒ"],
            "outputs": ["å›¾åƒå·²ç”Ÿæˆ", "å›¾ç‰‡å·²ç”Ÿæˆ", "å·²ä¿å­˜å›¾ç‰‡", "âœ¨ å›¾ç‰‡å·²ç”Ÿæˆ"],
            "entities": ["é¢œè‰²", "é£æ ¼", "å¤§å°", "èƒŒæ™¯", "è¡¨æƒ…", "å§¿åŠ¿", "çœ¼ç›", "æ¯›å‘", "è„¸"],
        },
        "FILE_GEN": {
            "keywords": [
                "pdf", "word", "excel", "docx", "æ–‡æ¡£", "æŠ¥å‘Š", "æ–‡ä»¶", "ç®€å†", "åˆåŒ",
                "æ ‡æ³¨", "æ‰¹æ³¨", "æ¶¦è‰²", "æ”¹å†™", "æ ¡å¯¹", "å®¡æ ¡", "ä¿®è®¢", "ä¼˜åŒ–", "çº é”™"
            ],
            "outputs": ["å·²ç”Ÿæˆæ–‡ä»¶", "æ–‡ä»¶å·²ä¿å­˜", ".pdf", ".docx", ".xlsx", "âœ… **æ–‡ä»¶ç”ŸæˆæˆåŠŸ"],
            "entities": ["æ ‡é¢˜", "ç« èŠ‚", "å†…å®¹", "æ ¼å¼", "æ¨¡æ¿", "æ ‡æ³¨", "æ‰¹æ³¨", "ä¿®æ”¹å»ºè®®"],
        },
        "RESEARCH": {
            "keywords": ["ç ”ç©¶", "åˆ†æ", "ä»‹ç»", "äº†è§£", "åŸç†", "æŠ€æœ¯", "æ·±å…¥"],
            "outputs": ["##", "###", "1.", "2.", "æ€»ç»“", "ç»“è®º"],
            "entities": ["å®šä¹‰", "ç‰¹ç‚¹", "ä¼˜åŠ¿", "åŠ£åŠ¿", "åº”ç”¨", "å‘å±•"],
        },
        "CODER": {
            "keywords": ["ä»£ç ", "ç¼–ç¨‹", "å‡½æ•°", "è„šæœ¬", "code", "script", "python", "javascript"],
            "outputs": ["```python", "```javascript", "```", "def ", "class "],
            "entities": ["å‡½æ•°", "å˜é‡", "ç±»", "æ¨¡å—", "ç®—æ³•"],
        },
        "CHAT": {
            "keywords": ["ä½ å¥½", "è°¢è°¢", "å¸®æˆ‘", "è¯·é—®", "ä»€ä¹ˆæ˜¯"],
            "outputs": [],
            "entities": [],
        },
    }
    
    # å»¶ç»­æ€§æŒ‡ç¤ºè¯åˆ†ç±» - éœ€è¦æ›´ä¸¥æ ¼çš„åŒ¹é…
    CONTINUATION_PATTERNS = {
        "modify": {
            # ä¿®æ”¹ç±»ï¼šå¿…é¡»æ˜¯çŸ­å¥æˆ–æ˜ç¡®çš„ä¿®æ”¹æŒ‡ä»¤
            "indicators": ["å†æ¥ä¸€å¼ ", "å†æ¥ä¸€ä¸ª", "æ›´å¤§ä¸€ç‚¹", "æ›´å°ä¸€ç‚¹", "å¤§ä¸€ç‚¹", "å°ä¸€ç‚¹", "æ·±ä¸€äº›", "æµ…ä¸€äº›", "é¢œè‰²æ¢æˆ", "èƒŒæ™¯æ¢æˆ"],
            "weight": 0.9,
            "max_input_length": 30,  # é™åˆ¶è¾“å…¥é•¿åº¦ï¼Œé•¿å¥å­ä¸å¤ªå¯èƒ½æ˜¯ç®€å•ä¿®æ”¹
            "prompt_template": "ç”¨æˆ·è¦æ±‚ä¿®æ”¹ä¹‹å‰çš„ç»“æœï¼š{modification}"
        },
        "reference": {
            # å¼•ç”¨ç±»ï¼šå¿…é¡»åœ¨å¥é¦–æˆ–ç‹¬ç«‹ä½¿ç”¨
            "indicators": ["è¿™ä¸ªæ€ä¹ˆ", "è¿™å¼ å›¾", "é‚£ä¸ªæ–‡ä»¶", "ä¸Šé¢çš„", "åˆšæ‰çš„", "æŠŠå®ƒ", "æŠŠè¿™ä¸ª", "åŸºäºè¿™ä¸ª"],
            "weight": 0.85,
            "require_start": True,  # éœ€è¦åœ¨å¥é¦–å‡ºç°
            "prompt_template": "ç”¨æˆ·å¼•ç”¨äº†ä¹‹å‰çš„å†…å®¹ï¼š{reference}"
        },
        "convert": {
            # è½¬æ¢ç±»ï¼šæ˜ç¡®çš„æ ¼å¼è½¬æ¢è¯·æ±‚
            "indicators": ["åšæˆword", "åšæˆpdf", "åšæˆexcel", "è½¬æˆword", "è½¬æˆpdf", "å˜æˆæ–‡æ¡£", "å¯¼å‡ºä¸º", "ä¿å­˜ä¸ºword", "ä¿å­˜ä¸ºpdf"],
            "weight": 0.95,
            "prompt_template": "ç”¨æˆ·è¦æ±‚å°†ä¹‹å‰çš„å†…å®¹è½¬æ¢ä¸ºæ–°æ ¼å¼ï¼š{conversion}"
        },
        "continue": {
            # ç»§ç»­ç±»ï¼šæ˜ç¡®è¦æ±‚ç»§ç»­ä¹‹å‰çš„å†…å®¹
            "indicators": [
                "ç»§ç»­å†™", "æ¥ç€è¯´", "æ¥ç€å†™", "ç„¶åå‘¢", "ä¸‹ä¸€æ­¥", "è¿˜æœ‰å‘¢", "å¦å¤–è¡¥å……",
                "å†æ‰¾æ‰¾", "å†æœ", "å†æŸ¥", "å†çœ‹çœ‹", "ç»§ç»­æŸ¥", "ç»§ç»­æ‰¾", "å†æ‰¾", "å†æœä¸€ä¸‹"
            ],
            "weight": 0.7,
            "max_input_length": 20,  # çŸ­å¥æ‰æ˜¯ç»§ç»­æŒ‡ä»¤
            "prompt_template": "ç”¨æˆ·è¦æ±‚ç»§ç»­ä¹‹å‰çš„ä»»åŠ¡ï¼š{continuation}"
        },
        "detail": {
            # è¯¦ç»†ç±»ï¼šåªæœ‰éå¸¸æ˜ç¡®çš„å±•å¼€è¯·æ±‚æ‰ç®—ï¼Œä¸”å¿…é¡»æ˜¯çŸ­å¥
            "indicators": ["è¯¦ç»†è¯´è¯´", "å±•å¼€è¯´è¯´", "è¯¦ç»†è®²è®²", "å…·ä½“è¯´ä¸€ä¸‹", "è§£é‡Šä¸€ä¸‹åˆšæ‰çš„"],
            "weight": 0.75,
            "max_input_length": 25,  # é™åˆ¶é•¿åº¦
            "prompt_template": "ç”¨æˆ·è¦æ±‚è¯¦ç»†è¯´æ˜ä¹‹å‰æåˆ°çš„å†…å®¹ï¼š{detail}"
        },
    }
    
    @classmethod
    def extract_entities(cls, text: str, task_type: str = None) -> list:
        """ä»æ–‡æœ¬ä¸­æå–å…³é”®å®ä½“"""
        entities = []
        text_lower = text.lower()
        
        # é€šç”¨å®ä½“æå–
        # é¢œè‰²
        colors = ["çº¢è‰²", "è“è‰²", "ç»¿è‰²", "é»„è‰²", "ç™½è‰²", "é»‘è‰²", "ç°è‰²", "ç²‰è‰²", "ç´«è‰²", "æ©™è‰²", "æ£•è‰²"]
        for color in colors:
            if color in text_lower:
                entities.append({"type": "color", "value": color})
        
        # é£æ ¼
        styles = ["å¯çˆ±", "å¸…æ°”", "å†™å®", "å¡é€š", "åŠ¨æ¼«", "èµ›åšæœ‹å…‹", "æ°´å½©", "æ²¹ç”»", "ç®€çº¦", "å¤å¤"]
        for style in styles:
            if style in text_lower:
                entities.append({"type": "style", "value": style})
        
        # ä¸»é¢˜/å¯¹è±¡
        subjects = ["çŒ«", "ç‹—", "äºº", "é£æ™¯", "å»ºç­‘", "æ±½è½¦", "èŠ±", "æ ‘", "å±±", "æµ·", "åŸå¸‚"]
        for subject in subjects:
            if subject in text_lower:
                entities.append({"type": "subject", "value": subject})
        
        # ç‰¹å®šä»»åŠ¡çš„å®ä½“
        if task_type and task_type in cls.TASK_SIGNATURES:
            for entity_keyword in cls.TASK_SIGNATURES[task_type].get("entities", []):
                if entity_keyword in text_lower:
                    entities.append({"type": "task_specific", "value": entity_keyword})
        
        return entities
    
    @classmethod
    def build_context_summary(cls, history: list, max_turns: int = 3) -> dict:
        """
        æ„å»ºå†å²ä¸Šä¸‹æ–‡æ‘˜è¦
        
        è¿”å›:
        {
            "task_history": [],      # ä»»åŠ¡å†å²
            "key_entities": [],      # å…³é”®å®ä½“
            "last_user_intent": "",  # æœ€è¿‘çš„ç”¨æˆ·æ„å›¾
            "last_model_output": "", # æœ€è¿‘çš„æ¨¡å‹è¾“å‡º
            "conversation_topic": "" # å¯¹è¯ä¸»é¢˜
        }
        """
        summary = {
            "task_history": [],
            "key_entities": [],
            "last_user_intent": "",
            "last_model_output": "",
            "conversation_topic": "",
        }
        
        if not history:
            return summary
        
        # åˆ†ææœ€è¿‘çš„å¯¹è¯
        recent_turns = history[-max_turns * 2:] if len(history) > max_turns * 2 else history
        
        all_entities = []
        topics = []
        
        for turn in recent_turns:
            content = turn['parts'][0] if turn['parts'] else ''
            role = turn['role']
            
            if role == 'user':
                summary["last_user_intent"] = content
                # è¯†åˆ«ä»»åŠ¡ç±»å‹
                for task_type, signatures in cls.TASK_SIGNATURES.items():
                    if any(kw in content.lower() for kw in signatures["keywords"]):
                        summary["task_history"].append({
                            "type": task_type,
                            "content": content[:100]
                        })
                        topics.append(task_type)
                        break
                
                # æå–å®ä½“
                entities = cls.extract_entities(content)
                all_entities.extend(entities)
                
            elif role == 'model':
                summary["last_model_output"] = content
        
        # å»é‡å®ä½“
        seen = set()
        unique_entities = []
        for e in all_entities:
            key = f"{e['type']}:{e['value']}"
            if key not in seen:
                seen.add(key)
                unique_entities.append(e)
        summary["key_entities"] = unique_entities
        
        # ç¡®å®šå¯¹è¯ä¸»é¢˜
        if topics:
            summary["conversation_topic"] = topics[-1]  # æœ€è¿‘çš„ä»»åŠ¡ç±»å‹
        
        return summary
    
    @classmethod
    def build_rag_prompt(cls, user_input: str, context_summary: dict, continuation_type: str = None) -> str:
        """
        æ„å»º RAG é£æ ¼çš„å¢å¼ºæç¤ºè¯
        
        å°†ä¸Šä¸‹æ–‡ä¿¡æ¯ç»“æ„åŒ–åœ°æ³¨å…¥åˆ°ç”¨æˆ·è¾“å…¥ä¸­
        """
        prompt_parts = []
        
        # 1. æ·»åŠ ä¸Šä¸‹æ–‡æ ‡è®°
        if context_summary.get("conversation_topic"):
            prompt_parts.append(f"[ä¸Šä¸‹æ–‡ç±»å‹: {context_summary['conversation_topic']}]")
        
        # 2. æ·»åŠ å…³é”®å®ä½“ä¿¡æ¯
        if context_summary.get("key_entities"):
            entities_str = ", ".join([f"{e['type']}={e['value']}" for e in context_summary["key_entities"][:5]])
            prompt_parts.append(f"[å…³é”®ä¿¡æ¯: {entities_str}]")
        
        # 3. æ·»åŠ å†å²æ„å›¾
        if context_summary.get("last_user_intent"):
            # æˆªå–æ ¸å¿ƒæè¿°
            last_intent = context_summary["last_user_intent"]
            if len(last_intent) > 200:
                last_intent = last_intent[:200] + "..."
            prompt_parts.append(f"[ä¹‹å‰çš„è¯·æ±‚: {last_intent}]")
        
        # 4. æ ¹æ®å»¶ç»­ç±»å‹æ·»åŠ ç‰¹å®šæŒ‡ä»¤
        if continuation_type and continuation_type in cls.CONTINUATION_PATTERNS:
            pattern = cls.CONTINUATION_PATTERNS[continuation_type]
            # ä¸æ·»åŠ æ¨¡æ¿ï¼Œè®©å®ä½“å’Œä¸Šä¸‹æ–‡è‡ªç„¶èåˆ
        
        # 5. æ·»åŠ ç”¨æˆ·å½“å‰è¾“å…¥
        prompt_parts.append(f"[å½“å‰è¯·æ±‚: {user_input}]")
        
        # 6. å¦‚æœæ˜¯è½¬æ¢è¯·æ±‚ï¼Œæ·»åŠ æºå†…å®¹
        if continuation_type == "convert" and context_summary.get("last_model_output"):
            output = context_summary["last_model_output"]
            # é™åˆ¶é•¿åº¦
            if len(output) > 4000:
                output = output[:4000] + "\n...(å†…å®¹å·²æˆªæ–­)"
            prompt_parts.append(f"\n[éœ€è¦è½¬æ¢çš„æºå†…å®¹:]\n{output}")
        
        # ç»„åˆæˆæœ€ç»ˆçš„å¢å¼ºæç¤º
        enhanced_prompt = "\n".join(prompt_parts)
        
        return enhanced_prompt
    
    @classmethod
    def analyze_context(cls, user_input: str, history: list) -> dict:
        """
        RAG é£æ ¼çš„ä¸Šä¸‹æ–‡åˆ†æ
        
        è¿”å›:
        {
            "is_continuation": bool,      # æ˜¯å¦æ˜¯å»¶ç»­ä»»åŠ¡
            "related_task": str,          # å…³è”çš„ä»»åŠ¡ç±»å‹
            "continuation_type": str,     # å»¶ç»­ç±»å‹ (modify/reference/convert/continue/detail)
            "context_summary": dict,      # ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ‘˜è¦
            "enhanced_input": str,        # RAG å¢å¼ºåçš„è¾“å…¥
            "confidence": float,          # ç½®ä¿¡åº¦
        }
        """
        result = {
            "is_continuation": False,
            "related_task": None,
            "continuation_type": None,
            "context_summary": {},
            "enhanced_input": user_input,
            "confidence": 0.0,
        }
        
        if not history or len(history) < 2:
            return result
        
        user_lower = user_input.lower()
        input_length = len(user_input)
        
        # 1. æ„å»ºä¸Šä¸‹æ–‡æ‘˜è¦
        context_summary = cls.build_context_summary(history)
        result["context_summary"] = context_summary
        
        # 2. æ£€æµ‹å»¶ç»­ç±»å‹å’Œç½®ä¿¡åº¦ï¼ˆæ›´ä¸¥æ ¼çš„åŒ¹é…ï¼‰
        detected_type = None
        max_weight = 0.0
        
        for pattern_type, pattern_info in cls.CONTINUATION_PATTERNS.items():
            indicators = pattern_info["indicators"]
            weight = pattern_info["weight"]
            
            # æ£€æŸ¥è¾“å…¥é•¿åº¦é™åˆ¶ï¼ˆå¦‚æœæœ‰ï¼‰
            max_len = pattern_info.get("max_input_length")
            if max_len and input_length > max_len:
                continue  # è¾“å…¥å¤ªé•¿ï¼Œä¸å¤ªå¯èƒ½æ˜¯ç®€å•çš„å»¶ç»­æŒ‡ä»¤
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨å¥é¦–å‡ºç°
            require_start = pattern_info.get("require_start", False)
            
            # è®¡ç®—åŒ¹é…çš„æŒ‡ç¤ºè¯æ•°é‡
            matches = 0
            for ind in indicators:
                if ind in user_lower:
                    if require_start:
                        # éœ€è¦åœ¨å¥é¦–ï¼ˆå‰10ä¸ªå­—ç¬¦å†…ï¼‰
                        if user_lower.find(ind) < 10:
                            matches += 1
                    else:
                        matches += 1
            
            if matches > 0:
                # åŠ æƒè®¡ç®—ç½®ä¿¡åº¦
                adjusted_weight = weight * (1 + 0.1 * (matches - 1))  # å¤šä¸ªåŒ¹é…å¢åŠ ç½®ä¿¡åº¦
                if adjusted_weight > max_weight:
                    max_weight = adjusted_weight
                    detected_type = pattern_type
        
        # 3. é¢å¤–æ£€æŸ¥ï¼šå¦‚æœç”¨æˆ·è¾“å…¥åŒ…å«æ˜ç¡®çš„æ–°ä¸»é¢˜ï¼Œé™ä½å»¶ç»­åˆ¤æ–­
        # æ–°ä¸»é¢˜æ ‡å¿—ï¼šåŒ…å«"å…³äº"ã€"ä¸€ä¸ª"åæ¥æ–°å®ä½“
        new_topic_indicators = ["å…³äº", "ä¸€ç¯‡", "ä¸€ä»½", "ä¸€ä¸ªæ–°çš„", "å¸®æˆ‘å†™", "å¸®æˆ‘åš", "å¸®æˆ‘ç”Ÿæˆ", "ç»™æˆ‘ç”Ÿæˆ", "ç”Ÿæˆä¸€"]
        has_new_topic = any(ind in user_lower for ind in new_topic_indicators)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œå…¨ä¸åŒçš„ä»»åŠ¡ç±»å‹ï¼ˆå¦‚ï¼šæ‰“å¼€å¾®ä¿¡ -> ç”Ÿæˆå›¾ç‰‡ï¼‰
        task_mismatch = False
        if context_summary.get("conversation_topic"):
            prev_topic = context_summary["conversation_topic"]
            # æ£€æµ‹å½“å‰è¾“å…¥çš„ä»»åŠ¡ç±»å‹
            curr_likely_task = None
            if any(kw in user_lower for kw in ["æŸ¥", "æœ", "æœç´¢", "æŸ¥è¯¢", "æ‰¾", "å†æ‰¾", "å†æŸ¥", "å†æœ"]):
                curr_likely_task = "WEB_SEARCH"
            elif any(kw in user_lower for kw in ["å›¾", "ç”»", "ç…§ç‰‡", "image"]):
                curr_likely_task = "PAINTER"
            elif any(kw in user_lower for kw in ["word", "pdf", "æ–‡æ¡£", "æŠ¥å‘Š"]):
                curr_likely_task = "FILE_GEN"
            elif any(kw in user_lower for kw in ["æ‰“å¼€", "è¿è¡Œ", "å…³é—­"]):
                curr_likely_task = "SYSTEM"
            
            # å¦‚æœä»»åŠ¡ç±»å‹å®Œå…¨ä¸åŒï¼Œä¸åº”è¯¥æ˜¯å»¶ç»­
            if curr_likely_task and prev_topic and curr_likely_task != prev_topic:
                task_mismatch = True
                print(f"[ContextAnalyzer] ä»»åŠ¡ç±»å‹ä¸åŒ¹é…: {prev_topic} -> {curr_likely_task}")
        
        if has_new_topic and input_length > 10:
            # æœ‰æ–°ä¸»é¢˜ä¸”è¾“å…¥è¾ƒé•¿ï¼Œå¾ˆå¯èƒ½æ˜¯ç‹¬ç«‹ä»»åŠ¡
            max_weight *= 0.2  # å¤§å¹…é™ä½ç½®ä¿¡åº¦
            print(f"[ContextAnalyzer] æ£€æµ‹åˆ°æ–°ä¸»é¢˜æ ‡å¿—ï¼Œé™ä½å»¶ç»­ç½®ä¿¡åº¦")
        
        if task_mismatch:
            # ä»»åŠ¡ç±»å‹ä¸åŒ¹é…ï¼Œå¼ºåˆ¶æ¸…é›¶
            max_weight = 0
            detected_type = None
            print(f"[ContextAnalyzer] ä»»åŠ¡ç±»å‹ä¸åŒ¹é…ï¼Œæ¸…é™¤å»¶ç»­åˆ¤æ–­")
        
        # 4. å¦‚æœæ£€æµ‹åˆ°å»¶ç»­æ¨¡å¼ä¸”ç½®ä¿¡åº¦è¶³å¤Ÿé«˜
        if detected_type and max_weight > 0.5:
            result["is_continuation"] = True
            result["continuation_type"] = detected_type
            result["confidence"] = min(max_weight, 1.0)
            
            # ç¡®å®šå…³è”çš„ä»»åŠ¡ç±»å‹
            if context_summary.get("conversation_topic"):
                result["related_task"] = context_summary["conversation_topic"]
            elif context_summary.get("task_history"):
                result["related_task"] = context_summary["task_history"][-1]["type"]
            
            # 4. æ„å»º RAG å¢å¼ºæç¤º
            result["enhanced_input"] = cls.build_rag_prompt(
                user_input, 
                context_summary, 
                detected_type
            )
            
            print(f"[ContextAnalyzer] RAG Analysis:")
            print(f"  - Continuation Type: {detected_type}")
            print(f"  - Related Task: {result['related_task']}")
            print(f"  - Confidence: {result['confidence']:.2f}")
            print(f"  - Entities: {[e['value'] for e in context_summary.get('key_entities', [])]}")
        
        # 5. ç‰¹æ®Šå¤„ç†ï¼šè½¬æ¢è¯·æ±‚ï¼ˆå³ä½¿æ²¡æœ‰æ˜ç¡®çš„å»¶ç»­æŒ‡ç¤ºè¯ï¼‰
        convert_patterns = ["åšæˆword", "åšæˆpdf", "è½¬æˆword", "è½¬æˆpdf", "ç”Ÿæˆword", "ç”Ÿæˆpdf", "å¯¼å‡ºä¸º"]
        if any(p in user_lower for p in convert_patterns) and context_summary.get("last_model_output"):
            result["is_continuation"] = True
            result["continuation_type"] = "convert"
            result["related_task"] = "FILE_GEN"
            result["confidence"] = 0.95
            result["enhanced_input"] = cls.build_rag_prompt(
                user_input,
                context_summary,
                "convert"
            )
        
        return result

    @classmethod
    def filter_history(cls, user_input: str, history: list, keep_turns: int = 6) -> list:
        """è¿‡æ»¤å†å²è®°å½•ï¼Œå°½é‡é¿å…æ— å…³ä¸Šä¸‹æ–‡æ±¡æŸ“"""
        if not history:
            return []

        # å¦‚æœå†å²å¾ˆçŸ­ï¼Œç›´æ¥è¿”å›
        if len(history) <= keep_turns * 2:
            return history

        user_lower = user_input.lower()

        # æŠ½å–ç”¨æˆ·è¾“å…¥ä¸­çš„å®ä½“ä¸å…³é”®è¯
        entities = cls.extract_entities(user_input)
        entity_values = {e["value"] for e in entities}

        # é¢å¤–æå–ä¸­æ–‡å…³é”®è¯ï¼ˆé•¿åº¦>=2ï¼‰ä¸è‹±æ–‡å•è¯ï¼ˆé•¿åº¦>=3ï¼‰
        import re
        cjk_words = re.findall(r"[\u4e00-\u9fff]{2,}", user_input)
        eng_words = re.findall(r"[a-zA-Z]{3,}", user_input)
        keyword_set = {k.lower() for k in (cjk_words + eng_words)}
        keyword_set.update({v.lower() for v in entity_values})

        # æ„å»ºç›¸å…³å†å²ï¼šåŒ…å«å…³é”®è¯çš„å¯¹è¯
        relevant = []
        for turn in history:
            content = (turn.get("parts") or [""])[0]
            content_lower = content.lower()
            if any(k in content_lower for k in keyword_set if k):
                relevant.append(turn)

        # å§‹ç»ˆä¿ç•™æœ€è¿‘ 3 è½®å¯¹è¯ï¼ˆç¡®ä¿ä¸Šä¸‹æ–‡è¿è´¯ï¼‰
        tail_count = 6
        tail = history[-tail_count:] if len(history) >= tail_count else history

        if not relevant:
            # æ²¡æœ‰åŒ¹é…æ—¶ï¼Œä¿ç•™æœ€è¿‘ 4 è½®ï¼ˆæœ€å¤š 8 æ¡ï¼‰ä½œä¸ºå…œåº•ä¸Šä¸‹æ–‡
            fallback_count = 8
            return history[-fallback_count:] if len(history) >= fallback_count else history

        # åˆå¹¶ç›¸å…³å†å² + å°¾éƒ¨å¯¹è¯ï¼Œä¿æŒé¡ºåºå¹¶å»é‡
        merged = []
        seen = set()
        for turn in relevant + tail:
            key = f"{turn.get('role','')}-{(turn.get('parts') or [''])[0]}"
            if key not in seen:
                seen.add(key)
                merged.append(turn)

        # åªä¿ç•™æœ€è¿‘ keep_turns è½®
        return merged[-keep_turns * 2:]



class TaskOrchestrator:
    """
    ç¼–æ’å’Œæ‰§è¡Œå¤šä¸ªå­ä»»åŠ¡
    
    è´£èŒï¼š
    1. é¡ºåºæ‰§è¡Œå­ä»»åŠ¡
    2. åœ¨å­ä»»åŠ¡é—´ä¼ é€’æ•°æ®/ä¸Šä¸‹æ–‡
    3. å¤„ç†é”™è¯¯å’Œé‡è¯•
    4. æœ€ç»ˆéªŒè¯è¾“å‡ºè´¨é‡
    """
    
    @classmethod
    async def execute_compound_task(cls, user_input: str, subtasks: list, session_name: str = None) -> dict:
        """
        æ‰§è¡Œå¤åˆä»»åŠ¡çš„æ‰€æœ‰å­ä»»åŠ¡
        
        è¿”å›:
            {
                "success": bool,
                "primary_result": ä¸»ä»»åŠ¡ç»“æœ,
                "secondary_results": [æ¬¡è¦ä»»åŠ¡ç»“æœ],
                "combined_output": æœ€ç»ˆåˆå¹¶è¾“å‡º,
                "execution_log": æ‰§è¡Œæ—¥å¿—,
                "quality_score": è´¨é‡è¯„åˆ† (0-100),
                "errors": é”™è¯¯åˆ—è¡¨
            }
        """
        execution_log = []
        results = []
        context = {"original_input": user_input, "user_input": user_input}
        errors = []
        
        try:
            for i, subtask in enumerate(subtasks):
                print(f"\n[TaskOrchestrator] æ‰§è¡Œå­ä»»åŠ¡ {i+1}/{len(subtasks)}: {subtask['task_type']}")
                execution_log.append(f"æ­¥éª¤ {i+1}: æ‰§è¡Œ {subtask['task_type']} - {subtask['description']}")
                step_input = subtask.get("input") or user_input
                
                try:
                    # æ ¹æ®ä»»åŠ¡ç±»å‹è°ƒç”¨ç›¸åº”çš„å¤„ç†å‡½æ•°
                    if subtask["task_type"] == "WEB_SEARCH":
                        result = await cls._execute_web_search(step_input, context)
                    elif subtask["task_type"] == "FILE_GEN":
                        result = await cls._execute_file_gen(step_input, context, subtask)
                    elif subtask["task_type"] == "PAINTER":
                        result = await cls._execute_painter(step_input, context)
                    elif subtask["task_type"] == "RESEARCH":
                        result = await cls._execute_research(step_input, context)
                    else:
                        result = {"success": False, "error": f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {subtask['task_type']}"}
                    
                    subtask["status"] = "completed"
                    subtask["result"] = result
                    results.append(result)
                    
                    # å°†ç»“æœä¿å­˜åˆ°ä¸Šä¸‹æ–‡ï¼Œä¾›ä¸‹ä¸€ä¸ªä»»åŠ¡ä½¿ç”¨
                    context[f"{subtask['task_type']}_result"] = result
                    context[f"step_{i+1}_output"] = result.get("output", result.get("content", ""))
                    
                    execution_log.append(f"  âœ… å®Œæˆ: {subtask['description']}")
                    
                except Exception as e:
                    error_msg = str(e)
                    subtask["status"] = "failed"
                    subtask["error"] = error_msg
                    errors.append(error_msg)
                    execution_log.append(f"  âŒ å¤±è´¥: {error_msg}")
                    print(f"[TaskOrchestrator] å­ä»»åŠ¡å¤±è´¥: {error_msg}")
            
            # åˆå¹¶ç»“æœ
            combined_output = cls._merge_results(subtasks, context)
            
            # è´¨é‡éªŒè¯
            quality_score = await cls._validate_quality(user_input, combined_output, context)
            
            return {
                "success": len(errors) == 0,
                "primary_result": results[0] if results else None,
                "secondary_results": results[1:] if len(results) > 1 else [],
                "combined_output": combined_output,
                "execution_log": execution_log,
                "quality_score": quality_score,
                "errors": errors,
                "context": context
            }
        
        except Exception as e:
            return {
                "success": False,
                "primary_result": None,
                "secondary_results": [],
                "combined_output": None,
                "execution_log": execution_log,
                "quality_score": 0,
                "errors": errors + [str(e)],
                "context": context
            }
    
    @classmethod
    async def _execute_web_search(cls, user_input: str, context: dict, progress_callback=None) -> dict:
        """æ‰§è¡Œ Web æœç´¢å­ä»»åŠ¡ (å¸¦å¯è§†è¿›åº¦)"""
        
        def _report(msg: str, detail: str = ""):
            print(f"[WEB_SEARCH] {msg} | {detail}")
            if progress_callback:
                progress_callback(msg, detail)
        
        try:
            _report("å¯åŠ¨ç½‘ç»œæœç´¢...", "æ­£åœ¨è§„åˆ’æœç´¢å…³é”®è¯")
            
            # Phase 1: Planning
            # (WebSearcher manages its own queries, but we can simulate the 'thought' process)
            await asyncio.sleep(0.3)
            _report("æ‰§è¡Œ Google Search...", f"å…³é”®è¯: {user_input[:20]}...")
            
            # Phase 2: Execution
            # wrap in thread
            result = await asyncio.to_thread(WebSearcher.search_with_grounding, user_input)
            
            # Phase 3: Reporting
            if result.get("grounded"):
                _report("âœ… æœç´¢å¹¶å¼•ç”¨å®Œæˆ", "å·²ç»“åˆæœ€æ–°ä¿¡æ¯")
            else:
                _report("âœ… æœç´¢å®Œæˆ", "å·²è·å–ç›¸å…³ç½‘é¡µæ‘˜è¦")
            
            return {
                "success": result.get("success", False),
                "output": result.get("response", ""),
                "content": result.get("response", ""),
                "grounded": result.get("grounded", False),
                "raw_result": result,
                "model_id": "gemini-2.5-flash"
            }
        except Exception as e:
            _report("âŒ æœç´¢é‡åˆ°é—®é¢˜", str(e))
            return {
                "success": False,
                "output": "",
                "error": str(e),
                "raw_result": None,
                "model_id": "gemini-2.5-flash"
            }
    

    @classmethod
    async def _execute_ppt_multi_step(cls, user_input: str, context: dict, subtask: dict, progress_callback=None) -> dict:
        """æ‰§è¡Œå¤šé˜¶æ®µPPTç”Ÿæˆä»»åŠ¡ (Plan-then-Execute)"""
        
        def _report(msg: str, detail: str = ""):
            print(f"[PPT_PROGRESS] {msg} | {detail}")
            if progress_callback:
                progress_callback(msg, detail)
        
        _report("å¼€å§‹å¤šé˜¶æ®µPPTç”Ÿæˆæµç¨‹...", "é˜¶æ®µ 1/3: æ™ºèƒ½è§„åˆ’")
        previous_data = context.get(f"step_{subtask['index']}_output", "")
        
        # 1. è§„åˆ’é˜¶æ®µ (Planning Phase)
        try:
            from web.ppt_master import PPTContentPlanner, PPTBlueprint
            
            # åˆå§‹åŒ–è§„åˆ’å™¨
            planner = PPTContentPlanner(ai_client=client, model_name="gemini-2.5-flash")
            
            # æ‰§è¡Œè§„åˆ’
            _report("æ­£åœ¨è§„åˆ’å†…å®¹ç»“æ„...", "è°ƒç”¨ AI ç”Ÿæˆå¤§çº²")
            plan_result = await planner.plan_content_structure(user_input, search_results=None)
            
            # æå–å¤§çº²
            outline_data = plan_result.get("outline", [])
            theme_choice = plan_result.get("theme_recommendation", "business")
            total_slides = plan_result.get("total_expected_slides", 10)
            
            # --- 1.2 å±•ç¤ºè§„åˆ’æ¦‚è§ˆ (User Requirement: Visualize Plan) ---
            plan_summary = f"å¤§çº²æ¦‚è§ˆ ({len(outline_data)} ç« èŠ‚, {total_slides} é¡µ):\n"
            for idx, sec in enumerate(outline_data):
                plan_summary += f"{idx+1}. {sec.get('section_title')} ({len(sec.get('slides', []))} é¡µ)\n"
            _report(f"è§„åˆ’å®Œæˆï¼Œå…± {total_slides} é¡µ", plan_summary)
            
            # å°†å¤§çº²è½¬æ¢ä¸º PPTGenerator å¯è¯†åˆ«çš„æ ¼å¼
            ppt_slides = []
            
            # --- å¤šé˜¶æ®µæ‰§è¡Œï¼šé€é¡µç”Ÿæˆå†…å®¹ ---
            total_steps = sum(len(sec.get("slides", [])) for sec in outline_data)
            current_step = 0
            
            for section in outline_data:
                section_title = section.get("section_title", "ç« èŠ‚")
                # æ·»åŠ ç« èŠ‚é¡µ
                ppt_slides.append({
                    "type": "section",
                    "title": section_title,
                    "content": [section.get("section_theme", "")]
                })
                
                for slide in section.get("slides", []):
                    current_step += 1
                    s_title = slide.get("slide_title", "æœªå‘½åå¹»ç¯ç‰‡")
                    s_type = slide.get("slide_type", "content")
                    s_points = slide.get("key_points", [])
                    
                    # Log progress
                    _report(f"ç”Ÿæˆç¬¬ {current_step}/{total_steps} é¡µå†…å®¹: {s_title}", "é˜¶æ®µ 2/3: å†…å®¹æ‰©å……")
                    
                    # æ‰©å……å†…å®¹ (Per-Slide Generation)
                    expanded_points = s_points
                    if hasattr(planner, 'expand_slide_content'):
                        try:
                            # Use new method in PPTContentPlanner
                            expanded_points = await planner.expand_slide_content(
                                s_title, 
                                s_points, 
                                context=f"Context: {section_title}"
                            )
                            if expanded_points != s_points:
                                _report(f"  âœ¨ å†…å®¹å·²æ‰©å……: {len(expanded_points)} æ¡", f"å¹»ç¯ç‰‡: {s_title}")
                        except Exception as exp_err:
                            _report(f"  âš ï¸ æ‰©å……å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹", str(exp_err))
                            expanded_points = s_points
                    
                    ppt_slides.append({
                        "type": s_type if s_type in ["content", "content_image", "comparison", "data"] else "content",
                        "title": s_title,
                        "points": expanded_points,
                        "content": expanded_points, 
                        "notes": slide.get("content_description", "")
                    })
            
            # å¦‚æœæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å¹»ç¯ç‰‡ï¼Œå›é€€åˆ°æ—§é€»è¾‘
            if not ppt_slides:
                raise ValueError("è§„åˆ’å™¨æœªç”Ÿæˆæœ‰æ•ˆå¹»ç¯ç‰‡å¤§çº²")

            # --- 2.5 éªŒè¯é˜¶æ®µ (User Requirement: Model Verification) ---
            _report("æ­£åœ¨éªŒè¯ç”Ÿæˆå†…å®¹...", "é˜¶æ®µ 2.5/3: è´¨é‡è‡ªæ£€")
            try:
                verify_prompt = (
                    f"è¯·ä½œä¸ºè´¨æ£€å‘˜æ£€æŸ¥ç”Ÿæˆçš„PPTå†…å®¹æ˜¯å¦ç¬¦åˆç”¨æˆ·éœ€æ±‚ã€‚\n"
                    f"ç”¨æˆ·éœ€æ±‚: {user_input}\n"
                    f"ç”Ÿæˆçš„æ ‡é¢˜: {[s['title'] for s in ppt_slides]}\n"
                    "è¯·ç®€è¦å›ç­”ï¼šå†…å®¹æ˜¯å¦è¦†ç›–äº†éœ€æ±‚ï¼Ÿ(æ˜¯/å¦) + ä¸€å¥è¯ç‚¹è¯„ã€‚"
                )
                verify_resp = await asyncio.to_thread(lambda: client.models.generate_content(
                    model="gemini-2.5-flash",
                    contents=verify_prompt
                ))
                if verify_resp and verify_resp.text:
                    _report("âœ… éªŒè¯é€šè¿‡", f"æ¨¡å‹ç‚¹è¯„: {verify_resp.text.strip()[:60]}...")
            except Exception as v_err:
                _report("âš ï¸ éªŒè¯è·³è¿‡ (éè‡´å‘½)", str(v_err))

            # 2. æ‰§è¡Œé˜¶æ®µ (Execution Phase) - ç”Ÿæˆ PPT æ–‡ä»¶
            _report("æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶...", "é˜¶æ®µ 3/3: æ¸²æŸ“ä¸ä¿å­˜")
            from web.ppt_generator import PPTGenerator
            ppt_gen = PPTGenerator(theme=theme_choice)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            safe_title = re.sub(r'[\\/*?:"<>|]', "", user_input[:20]) or "æ¼”ç¤ºæ–‡ç¨¿"
            filename = f"{safe_title}_{timestamp}.pptx"
            ppt_path = os.path.join(settings_manager.documents_dir, filename)
            os.makedirs(settings_manager.documents_dir, exist_ok=True)
            
            # ä½¿ç”¨ PPTGenerator ç”Ÿæˆ (ç›®å‰å®ƒç›´æ¥æ”¯æŒ outline list)
            ppt_gen.generate_from_outline(
                title=safe_title,
                outline=ppt_slides,
                output_path=ppt_path
            )
            
            rel_path = os.path.relpath(ppt_path, WORKSPACE_DIR).replace("\\", "/")
            
            # è¿”å›ç»“æœï¼Œæ ¼å¼ä¸ _execute_file_gen ä¿æŒä¸€è‡´
            # æ„å»º markdown è¡¨ç¤ºçš„å¤§çº²ä¾›å‰ç«¯æ˜¾ç¤º
            md_outline = f"# {safe_title}\n\n"
            for slide in ppt_slides:
                md_outline += f"## {slide['title']}\n"
                for p in slide.get('points', []):
                    md_outline += f"- {p}\n"
                md_outline += "\n"
            
            return {
                "success": True,
                "output": md_outline,
                "content": md_outline,
                "saved_files": [rel_path],
                "model_id": "gemini-2.5-flash (Planner)"
            }
            
        except Exception as e:
            print(f"[PPT] âš ï¸ å¤šé˜¶æ®µç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°å•æ­¥ç”Ÿæˆ: {e}")
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸è®©ä¸Šå±‚å¤„ç†ï¼Œæˆ–è€…åœ¨è¿™é‡Œè°ƒç”¨æ—§é€»è¾‘?
            # ä¸ºäº†ç®€å•ï¼ŒæŠ›å‡ºå¼‚å¸¸è®©å¤–éƒ¨ _execute_file_gen çš„ except å—æ•è· (ä½†å¤–éƒ¨æ˜¯ generic exception)
            # æˆ–è€…æˆ‘ä»¬ç›´æ¥è¿”å›å¤±è´¥ï¼Œè®© TaskOrchestrator è®°å½•é”™è¯¯
            return {
                "success": False,
                "error": str(e),
                "opt_out_to_legacy": True # æ ‡è®°éœ€è¦å›é€€
            }


    @classmethod
    async def _execute_file_gen(cls, user_input: str, context: dict, subtask: dict, progress_callback=None) -> dict:
        """æ‰§è¡Œæ–‡ä»¶ç”Ÿæˆå­ä»»åŠ¡
        å¢å¼ºï¼šå¤æ‚/é•¿æ–‡/è¦æ±‚â€œæ·±åº¦ã€è¯¦ç»†ã€ç ”ç©¶â€æ—¶ï¼Œå…ˆè¿è¡Œæ·±åº¦ç ”ç©¶å¹¶åˆ‡æ¢åˆ°æ›´å¼ºæ¨¡å‹ç”Ÿæˆã€‚
        """
        def _report(msg: str, detail: str = ""):
            print(f"[FILE_GEN] {msg} | {detail}")
            if progress_callback:
                progress_callback(msg, detail)

        try:
            # æå–å‰ä¸€ä¸ªä»»åŠ¡çš„ç»“æœä½œä¸ºè¾“å…¥
            previous_data = context.get(f"step_{subtask['index']}_output", "")

            # å¤æ‚åº¦åˆ¤å®šï¼ˆé•¿æ–‡æœ¬æˆ–æ˜¾å¼â€œæ·±åº¦/è¯¦ç»†/ç ”ç©¶/å…¨é¢/æŠ€æœ¯â€è¯·æ±‚ï¼‰
            text_lower = user_input.lower()
            complex_flags = [
                len(user_input) > 120,
                any(k in text_lower for k in ["æ·±åº¦", "è¯¦ç»†", "ç ”ç©¶", "å…¨é¢", "æŠ€æœ¯", "æŠ¥å‘Š", "ç»¼è¿°", "whitepaper"]),
            ]
            is_complex = any(complex_flags)
            
            # æ£€æµ‹ç›®æ ‡æ ¼å¼ï¼ˆPPTã€Excelã€Wordç­‰ï¼‰
            ppt_keywords = ["ppt", "å¹»ç¯ç‰‡", "æ¼”ç¤º", "æ±‡æŠ¥", "presentation", "slide"]
            prefer_ppt = any(kw in user_input.lower() for kw in ppt_keywords)
            
            prefer_excel = ("excel" in user_input.lower() or "xlsx" in user_input.lower() or "è¡¨æ ¼" in user_input)
            prefer_pdf = "pdf" in user_input.lower()
            
            # æ ¹æ®ç›®æ ‡æ ¼å¼é€‰æ‹©æç¤º
            if prefer_ppt:
                # å°è¯•ä½¿ç”¨æ–°çš„å¤šé˜¶æ®µç”Ÿæˆæµç¨‹ (Plan-then-Execute)
                try:
                    ppt_result = await cls._execute_ppt_multi_step(user_input, context, subtask, progress_callback)
                    if ppt_result.get("success"):
                        _report(f"PPTç”ŸæˆæˆåŠŸ", f"æ–‡ä»¶: {(ppt_result.get('saved_files') or [''])[0]}")
                        return ppt_result
                    elif ppt_result.get("opt_out_to_legacy"):
                        print("[FILE_GEN] âš ï¸ å¤šé˜¶æ®µç”Ÿæˆé‡åˆ°é—®é¢˜ï¼Œå›é€€åˆ°æ—§ç‰ˆç”Ÿæˆé€»è¾‘")
                    else:
                        return ppt_result
                except Exception as e:
                    print(f"[FILE_GEN] âš ï¸ å¤šé˜¶æ®µç”Ÿæˆå¼‚å¸¸: {e}")
                
                # å›é€€æ—§é€»è¾‘ (Legacy Prompt Generation)
                gen_prompt = (
                    "ä½ æ˜¯ä¸€ä¸ªé¡¶å°–çš„æ¼”ç¤ºæ–‡ç¨¿å†…å®¹ç­–åˆ’å¸ˆå’Œæ’ç‰ˆè§„åˆ’å¸ˆã€‚\n\n"
                    "åœ¨æ¯ä¸ª `## ç« èŠ‚æ ‡é¢˜` å‰ä¸€è¡Œå†™ç±»å‹æ ‡ç­¾æ¥é€‰æ‹©å¹»ç¯ç‰‡ç±»å‹ï¼š\n"
                    "- `[è¯¦ç»†]` â€” æ·±å…¥å±•ç¤º 3-5 ä¸ªè¦ç‚¹\n"
                    "- `[æ¦‚è§ˆ]` â€” å¤šä¸»é¢˜é€Ÿè§ˆï¼Œç”¨ `### å­æ ‡é¢˜` åˆ†ç»„\n"
                    "- `[äº®ç‚¹]` â€” å…³é”®æ•°æ®ï¼Œæ ¼å¼: `- æ•°å€¼ | è¯´æ˜`\n"
                    "- `[å¯¹æ¯”]` â€” ä¸¤æ–¹å¯¹æ¯”ï¼Œç”¨ `### é€‰é¡¹A` å’Œ `### é€‰é¡¹B` åˆ†ç»„\n"
                    "- `[è¿‡æ¸¡é¡µ]` â€” ç« èŠ‚è¿‡æ¸¡ï¼ˆæœ€å¤š 2 ä¸ªï¼‰\n\n"
                    "**è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå¾ª Markdownï¼‰**ï¼š\n"
                    "```\n"
                    "# æ¼”ç¤ºæ ‡é¢˜\n\n"
                    "[è¯¦ç»†]\n"
                    "## ç« èŠ‚æ ‡é¢˜\n"
                    "- è¦ç‚¹1ï¼ˆåŒ…å«å…·ä½“ä¿¡æ¯ï¼‰\n"
                    "- è¦ç‚¹2\n"
                    "```\n\n"
                    "è§„åˆ™ï¼šé‡ç‚¹å†…å®¹ç”¨å¤šä¸ª [è¯¦ç»†] å±•å¼€ï¼Œç®€è¦å†…å®¹åˆå¹¶åˆ° [æ¦‚è§ˆ]ï¼Œå…³é”®æ•°æ®ç”¨ [äº®ç‚¹]ã€‚\n"
                    "æ¯ä¸ªè¦ç‚¹åŒ…å«å…·ä½“ä¿¡æ¯ï¼Œä¸­æ–‡è¾“å‡ºï¼Œåªè¾“å‡ºå¤§çº²ã€‚\n"
                )
            else:
                gen_prompt = (
                    "ä½ æ˜¯Kotoï¼Œä¸€ä¸ªä¸“ä¸šçš„æ•°æ®æ•´ç†ä¸æŠ¥å‘Šç”ŸæˆåŠ©æ‰‹ã€‚\n"
                    "è¯·åŸºäºç”¨æˆ·éœ€æ±‚å’Œæä¾›çš„æ•°æ®ï¼Œè¾“å‡ºæ¸…æ™°ã€å¯ç›´æ¥æ”¾å…¥æ–‡æ¡£çš„ Markdown å†…å®¹ã€‚\n"
                    "å¦‚æœæ˜¯ä»·æ ¼ç±»ä¿¡æ¯ï¼Œå¿…é¡»åŒ…å«ä¸€ä¸ª Markdown è¡¨æ ¼ï¼Œå­—æ®µå»ºè®®ä¸ºï¼šæ—¶é—´ã€ä»·æ ¼ã€å˜åŒ–ã€æ¥æºã€‚\n"
                    "è¾“å‡ºè¦æ±‚ï¼š\n"
                    "- åªè¾“å‡ºå†…å®¹ï¼Œä¸è¦è¾“å‡ºä»£ç æˆ– BEGIN_FILE æ ‡è®°\n"
                    "- ä¸­æ–‡è¾“å‡ºï¼Œç»“æ„æ¸…æ™°\n"
                )
            
            full_input = (
                f"ç”¨æˆ·åŸå§‹éœ€æ±‚: {context['original_input']}\n\n"
                f"å‰é¢æ­¥éª¤çš„æ•°æ®/ä¿¡æ¯:\n{previous_data}\n\n"
                f"{gen_prompt}"
            )
            
            # æ·±åº¦ç ”ç©¶ï¼šä¸ºå¤æ‚ä»»åŠ¡å…ˆè¡¥å……ç ”ç©¶ä¸Šä¸‹æ–‡
            research_context = ""
            if is_complex:
                try:
                    research_context = WebSearcher.deep_research_for_ppt(user_input, previous_data)
                    if research_context:
                        previous_data = f"[æ·±åº¦ç ”ç©¶]\n{research_context}\n\n[å·²æœ‰ä¿¡æ¯]\n{previous_data}"
                        print(f"[FILE_GEN] ğŸ”¬ æ·±åº¦ç ”ç©¶å®Œæˆï¼Œè¿½åŠ  {len(research_context)} å­—ä¸Šä¸‹æ–‡")
                except Exception as research_err:
                    print(f"[FILE_GEN] âš ï¸ æ·±åº¦ç ”ç©¶å¤±è´¥: {research_err}")

            # è°ƒç”¨æ¨¡å‹ç”Ÿæˆå†…å®¹
            model_id = SmartDispatcher.get_model_for_task("FILE_GEN", complexity="complex" if is_complex else "normal")
            
            _report(f"æ­£åœ¨ç”Ÿæˆå†…å®¹...", f"æ¨¡å‹: {model_id}")
            
            def _generate_text(prompt_text: str) -> str:
                response = client.models.generate_content(
                    model=model_id,
                    contents=prompt_text,
                    config=types.GenerateContentConfig(
                        system_instruction=_get_filegen_brief_instruction(),
                        temperature=0.4,
                        max_output_tokens=4000,
                    )
                )
                return response.text or ""
            
            text_out = _generate_text(full_input) or "(æ— è¾“å‡º)"
            _report(f"å†…å®¹ç”Ÿæˆå®Œæˆ", f"å­—æ•°: {len(text_out)}")
            
            # è§£æ Markdown è¡¨æ ¼
            def _extract_markdown_table(md_text: str):
                lines = [line.strip() for line in md_text.splitlines() if "|" in line]
                for i in range(len(lines) - 1):
                    header_line = lines[i]
                    sep_line = lines[i + 1]
                    if re.match(r"^\s*\|?\s*[-:|\s]+\|\s*$", sep_line):
                        headers = [c.strip() for c in header_line.strip("|").split("|")]
                        rows = []
                        j = i + 2
                        while j < len(lines) and "|" in lines[j]:
                            row = [c.strip() for c in lines[j].strip("|").split("|")]
                            if len(row) < len(headers):
                                row += [""] * (len(headers) - len(row))
                            rows.append(row[:len(headers)])
                            j += 1
                        return [headers] + rows
                return None
            
            # è§£æPPTå¤§çº²ç»“æ„ï¼ˆæ”¯æŒæ™ºèƒ½è§„åˆ’æ ‡ç­¾ï¼‰
            def _parse_ppt_outline(md_text: str) -> dict:
                """è§£æå¸¦ [ç±»å‹] æ ‡ç­¾çš„ PPT å¤§çº²"""
                lines = md_text.split('\n')
                outline = {"title": "", "slides": []}
                _tmap = {
                    "è¿‡æ¸¡é¡µ": "divider", "è¿‡æ¸¡": "divider",
                    "è¯¦ç»†": "detail", "é‡ç‚¹": "detail",
                    "äº®ç‚¹": "highlight", "æ•°æ®": "highlight",
                    "æ¦‚è§ˆ": "overview", "é€Ÿè§ˆ": "overview", "ç®€è¦": "overview",
                    "å¯¹æ¯”": "comparison", "æ¯”è¾ƒ": "comparison",
                }
                cur_type = "detail"
                cur_slide = None
                cur_sub = None
                
                for line in lines:
                    line = line.rstrip()
                    if line.strip() in ('```', '```markdown'):
                        continue
                    tm = re.match(r'^\s*\[(.+?)\]\s*$', line)
                    if tm:
                        cur_type = _tmap.get(tm.group(1).strip(), "detail")
                        continue
                    if line.startswith('# ') and not line.startswith('## '):
                        outline["title"] = line[2:].strip()
                    elif line.startswith('## '):
                        if cur_sub and cur_slide and cur_slide.get("type") in ("overview", "comparison"):
                            cur_slide.setdefault("subsections", []).append(cur_sub)
                            cur_sub = None
                        if cur_slide:
                            outline["slides"].append(cur_slide)
                        cur_slide = {"type": cur_type, "title": line[3:].strip(), "points": [], "content": []}
                        if cur_type == "divider":
                            cur_slide["description"] = ""
                        cur_type = "detail"
                        cur_sub = None
                    elif line.startswith('### ') and cur_slide:
                        if cur_sub:
                            cur_slide.setdefault("subsections", []).append(cur_sub)
                        cur_sub = {"subtitle": line[4:].strip(), "label": line[4:].strip(), "points": []}
                    elif re.match(r'^[\s]*[-â€¢*]\s', line) and cur_slide is not None:
                        pt = re.sub(r'^[\s]*[-â€¢*]\s+', '', line).strip()
                        if cur_sub is not None:
                            cur_sub["points"].append(pt)
                        else:
                            cur_slide["points"].append(pt)
                            cur_slide["content"].append(pt)
                    elif cur_slide and cur_slide.get("type") == "divider" and line.strip():
                        cur_slide["description"] = line.strip()
                
                if cur_sub and cur_slide and cur_slide.get("type") in ("overview", "comparison"):
                    cur_slide.setdefault("subsections", []).append(cur_sub)
                if cur_slide:
                    outline["slides"].append(cur_slide)
                for sl in outline["slides"]:
                    if sl.get("type") == "comparison" and "subsections" in sl:
                        subs = sl["subsections"]
                        if len(subs) >= 2:
                            sl["left"] = subs[0]
                            sl["right"] = subs[1]
                return outline
            
            title = "ç”Ÿæˆæ–‡æ¡£"
            if "ä»·æ ¼" in user_input or "è¡¨æ ¼" in user_input:
                title = "ä»·æ ¼æ³¢åŠ¨è¡¨æ ¼"
            elif prefer_ppt:
                title = "æ¼”ç¤ºæ–‡ç¨¿"
            
            saved_files = []
            file_type = None
            excel_error = None
            
            # ç”ŸæˆPPT
            if prefer_ppt:
                try:
                    from web.ppt_generator import PPTGenerator
                    ppt_outline = _parse_ppt_outline(text_out)
                    
                    # ç¡®å®šä¸»é¢˜ï¼ˆé€šè¿‡å…³é”®è¯æ£€æµ‹ï¼‰
                    theme = "business"  # é»˜è®¤å•†åŠ¡ä¸»é¢˜
                    if "tech" in user_input.lower() or "æŠ€æœ¯" in user_input:
                        theme = "tech"
                    elif "creative" in user_input.lower() or "åˆ›æ„" in user_input:
                        theme = "creative"
                    
                    _report("æ­£åœ¨ç”ŸæˆPPT...", f"ä¸»é¢˜: {theme}")
                    
                    ppt_gen = PPTGenerator(theme=theme)
                    filename = f"{ppt_outline.get('title', 'æ¼”ç¤ºæ–‡ç¨¿')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pptx"
                    ppt_path = os.path.join(settings_manager.documents_dir, filename)
                    os.makedirs(settings_manager.documents_dir, exist_ok=True)
                    
                    ppt_gen.generate_from_outline(
                        title=ppt_outline.get('title', 'æ¼”ç¤º'),
                        outline=ppt_outline.get('slides', []),
                        output_path=ppt_path
                    )
                    
                    rel_path = os.path.relpath(ppt_path, WORKSPACE_DIR).replace("\\", "/")
                    saved_files.append(rel_path)
                    file_type = "pptx"
                    _report("PPTç”Ÿæˆå®Œæˆ", f"å·²ä¿å­˜åˆ°: {rel_path}")
                    
                except Exception as ppt_err:
                    print(f"[FILE_GEN] âš ï¸ PPTç”Ÿæˆå¤±è´¥: {ppt_err}")
                    _report("PPTç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°Word...", f"é”™è¯¯: {str(ppt_err)[:50]}")
                    # PPTå¤±è´¥æ—¶å›é€€åˆ°Word
                    from web.document_generator import save_docx
                    saved_docx = save_docx(text_out, title=title, output_dir=settings_manager.documents_dir)
                    rel_path = os.path.relpath(saved_docx, WORKSPACE_DIR).replace("\\", "/")
                    saved_files.append(rel_path)
                    file_type = "docx"
            else:
                # ç”ŸæˆExcelæˆ–Word
                _report("æ­£åœ¨å¤„ç†å†…å®¹...", "è§£ææ–‡æ¡£ç»“æ„")
                table_rows = _extract_markdown_table(text_out)
                if prefer_excel and not table_rows:
                    # ç¬¬ä¸€æ¬¡æœªç”Ÿæˆåˆæ ¼è¡¨æ ¼ â†’ ç”Ÿæˆä¿®æ­£Prompté‡è¯•ä¸€æ¬¡
                    fix_prompt = (
                        "è¯·åªè¾“å‡ºä¸€ä¸ª Markdown è¡¨æ ¼ï¼Œä¸è¦è¾“å‡ºå…¶ä»–è¯´æ˜ã€‚\n"
                        "è¡¨æ ¼å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼šæ—¶é—´ã€ä»·æ ¼ã€å˜åŒ–ã€æ¥æºã€‚\n"
                        "æ¯è¡Œæ•°æ®ä¸€è¡Œï¼Œæ ¼å¼ä¸¥æ ¼ã€‚\n\n"
                        f"ç”¨æˆ·éœ€æ±‚: {context['original_input']}\n\n"
                        f"å¯ç”¨æ•°æ®:\n{previous_data}\n"
                    )
                    text_out_retry = _generate_text(fix_prompt)
                    if text_out_retry:
                        text_out = text_out_retry
                        table_rows = _extract_markdown_table(text_out)
                
                if prefer_excel and table_rows:
                    _report("æ­£åœ¨ç”ŸæˆExcel...", f"å†™å…¥ {len(table_rows)} è¡Œæ•°æ®")
                    try:
                        from openpyxl import Workbook
                        from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
                        from openpyxl.utils import get_column_letter
                        
                        wb = Workbook()
                        ws = wb.active
                        ws.title = title[:31] if title else "Sheet1"
                        
                        # å†™å…¥æ•°æ®
                        for row in table_rows:
                            ws.append(row)
                        
                        # --- æ ·å¼ç¾åŒ– ---
                        header_font = Font(name='Microsoft YaHei', size=11, bold=True, color='FFFFFF')
                        header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')
                        data_font = Font(name='Microsoft YaHei', size=10)
                        thin_border = Border(
                            left=Side(style='thin', color='D9D9D9'),
                            right=Side(style='thin', color='D9D9D9'),
                            top=Side(style='thin', color='D9D9D9'),
                            bottom=Side(style='thin', color='D9D9D9'),
                        )
                        alt_fill = PatternFill(start_color='F2F7FB', end_color='F2F7FB', fill_type='solid')
                        center_align = Alignment(horizontal='center', vertical='center', wrap_text=True)
                        left_align = Alignment(horizontal='left', vertical='center', wrap_text=True)
                        
                        max_row = ws.max_row
                        max_col = ws.max_column
                        
                        for col_idx in range(1, max_col + 1):
                            # è¡¨å¤´æ ·å¼
                            cell = ws.cell(row=1, column=col_idx)
                            cell.font = header_font
                            cell.fill = header_fill
                            cell.alignment = center_align
                            cell.border = thin_border
                            
                            # æ•°æ®è¡Œæ ·å¼
                            for row_idx in range(2, max_row + 1):
                                cell = ws.cell(row=row_idx, column=col_idx)
                                cell.font = data_font
                                cell.alignment = left_align
                                cell.border = thin_border
                                # éš”è¡Œå˜è‰²
                                if row_idx % 2 == 0:
                                    cell.fill = alt_fill
                            
                            # è‡ªåŠ¨åˆ—å®½
                            max_len = 0
                            for row_idx in range(1, max_row + 1):
                                val = ws.cell(row=row_idx, column=col_idx).value
                                if val:
                                    # CJK å­—ç¬¦ç®—2ä¸ªå­—ç¬¦å®½
                                    vlen = sum(2 if ord(c) > 127 else 1 for c in str(val))
                                    max_len = max(max_len, vlen)
                            ws.column_dimensions[get_column_letter(col_idx)].width = min(max_len + 4, 40)
                        
                        # å†»ç»“é¦–è¡Œ
                        ws.freeze_panes = 'A2'
                        
                        filename = f"{title}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                        excel_path = os.path.join(settings_manager.documents_dir, filename)
                        os.makedirs(settings_manager.documents_dir, exist_ok=True)
                        wb.save(excel_path)
                        rel_path = os.path.relpath(excel_path, WORKSPACE_DIR).replace("\\", "/")
                        saved_files.append(rel_path)
                        file_type = "xlsx"
                        _report("Excelç”Ÿæˆå®Œæˆ", f"å·²ä¿å­˜åˆ°: {rel_path}")
                    except Exception as excel_err:
                        excel_error = str(excel_err)
                        print(f"[FILE_GEN] âš ï¸ Excelä¿å­˜å¤±è´¥: {excel_error}")
                        _report("Excelä¿å­˜å¤±è´¥ï¼Œå›é€€åˆ°Word...", f"é”™è¯¯: {excel_error[:50]}")
                
                # ä¿å­˜ä¸º DOCXï¼ˆæ— è¡¨æ ¼æˆ–Excelå¤±è´¥æ—¶å›é€€ï¼‰
                if not saved_files:
                    _report("æ­£åœ¨ç”ŸæˆWordæ–‡æ¡£...", "è½¬æ¢ä¸º DOCX")
                    from web.document_generator import save_docx, save_pdf
                    saved_docx = save_docx(text_out, title=title, output_dir=settings_manager.documents_dir)
                    rel_path = os.path.relpath(saved_docx, WORKSPACE_DIR).replace("\\", "/")
                    saved_files.append(rel_path)
                    file_type = "docx"
                    _report("Wordæ–‡æ¡£ç”Ÿæˆå®Œæˆ", f"å·²ä¿å­˜åˆ°: {rel_path}")
                    
                    # å¦‚ç”¨æˆ·æ˜ç¡®éœ€è¦ PDFï¼Œä¹ŸåŒæ—¶ä¿å­˜
                    if prefer_pdf:
                        try:
                            _report("æ­£åœ¨ç”ŸæˆPDF...", "è½¬æ¢ä¸º PDF")
                            saved_pdf = save_pdf(text_out, title=title, output_dir=settings_manager.documents_dir)
                            pdf_rel = os.path.relpath(saved_pdf, WORKSPACE_DIR).replace("\\", "/")
                            saved_files.append(pdf_rel)
                            _report("PDFç”Ÿæˆå®Œæˆ", f"å·²ä¿å­˜åˆ°: {pdf_rel}")
                        except Exception as pdf_err:
                            print(f"[FILE_GEN] âš ï¸ PDFä¿å­˜å¤±è´¥: {pdf_err}")
                            _report("PDFç”Ÿæˆå¤±è´¥", str(pdf_err)[:50])
            
            return {
                "success": True,
                "output": f"å·²ç”Ÿæˆ{file_type.upper()}æ–‡æ¡£: {', '.join([os.path.basename(p) for p in saved_files])}" + (f" (Excelå¤±è´¥: {excel_error})" if excel_error else ""),
                "content": text_out,
                "file_type": file_type or "docx",
                "saved_files": saved_files,
                "model_id": model_id
            }
        except Exception as e:
            return {
                "success": False,
                "output": "",
                "error": str(e)
            }
    
    @classmethod
    async def _execute_painter(cls, user_input: str, context: dict, progress_callback=None) -> dict:
        """æ‰§è¡Œå›¾åƒç”Ÿæˆå­ä»»åŠ¡ - ä¸ºPPTç­‰ç”Ÿæˆé…å›¾ (å¸¦å¯è§†è¿›åº¦)"""
        
        def _report(msg: str, detail: str = ""):
            print(f"[PAINTER] {msg} | {detail}")
            if progress_callback:
                progress_callback(msg, detail)
        
        try:
            topic = context.get("original_input", user_input)
            prompt = f"Professional illustration for: {topic[:100]}. Clean flat design, no text."
            
            image_paths = []
            images_dir = os.path.join(WORKSPACE_DIR, "images")
            os.makedirs(images_dir, exist_ok=True)
            
            _report("å¯åŠ¨å›¾åƒç”Ÿæˆ...", "è°ƒç”¨ Imagen 3 æ¨¡å‹")
            
            for i in range(2):
                try:
                    _report(f"æ­£åœ¨ç”Ÿæˆç¬¬ {i+1}/2 å¼ é…å›¾...", f"æç¤ºè¯: {prompt[:30]}...")
                    
                    # Run potentially blocking generation in thread
                    res = await asyncio.to_thread(lambda: client.models.generate_images(
                        model="imagen-4.0-generate-preview-06-06",
                        prompt=prompt,
                        config=types.GenerateImagesConfig(number_of_images=1)
                    ))
                    
                    if res.generated_images:
                        ts = int(time.time() * 1000) % 1000000
                        fname = f"ppt_img_{i}_{ts}.png"
                        fpath = os.path.join(images_dir, fname)
                        with open(fpath, "wb") as f:
                            f.write(res.generated_images[0].image.image_bytes)
                        image_paths.append(fpath)
                        print(f"[PAINTER] âœ… é…å›¾ {i+1} å·²ç”Ÿæˆ: {fname}")
                        _report(f"âœ… é…å›¾ {i+1} å®Œæˆ", fname)
                except Exception as img_err:
                    print(f"[PAINTER] âš ï¸ é…å›¾ {i+1} ç”Ÿæˆå¤±è´¥: {img_err}")
                    _report(f"âš ï¸ é…å›¾ {i+1} å¤±è´¥", str(img_err))
            
            success = len(image_paths) > 0
            if success:
                 _report("âœ… å›¾åƒç”Ÿæˆä»»åŠ¡å®Œæˆ", f"å…±ç”Ÿæˆ {len(image_paths)} å¼ ")
            else:
                 _report("âŒ å›¾åƒç”Ÿæˆä»»åŠ¡å¤±è´¥", "æœªç”Ÿæˆæœ‰æ•ˆå›¾ç‰‡")
            
            return {
                "success": success,
                "output": f"å·²ç”Ÿæˆ {len(image_paths)} å¼ é…å›¾",
                "content": ",".join(image_paths),
                "image_paths": image_paths,
                "model_id": "imagen-3.0"
            }
        except Exception as e:
            _report("âŒ å›¾åƒç”Ÿæˆé‡åˆ°è‡´å‘½é”™è¯¯", str(e))
            return {
                "success": False,
                "output": "",
                "error": str(e)
            }
    
    @classmethod
    async def _execute_research(cls, user_input: str, context: dict, progress_callback=None) -> dict:
        """æ‰§è¡Œæ·±åº¦ç ”ç©¶å­ä»»åŠ¡ - ä½¿ç”¨ Gemini Pro æ·±åº¦åˆ†æ (å¯è§†è¿›åº¦)"""
        
        def _report(msg: str, detail: str = ""):
            print(f"[RESEARCH] {msg} | {detail}")
            if progress_callback:
                progress_callback(msg, detail)
        
        try:
            _report("å¯åŠ¨æ·±åº¦ç ”ç©¶æµç¨‹...", "åˆ†æä¸Šä¸‹æ–‡æ•°æ®")
            search_data = context.get("WEB_SEARCH_result", {})
            search_text = search_data.get("content", "") or search_data.get("output", "")
            
            # Phase 1: Planning
            _report("è§„åˆ’ç ”ç©¶å¤§çº²...", "ç¡®å®šåˆ†æç»´åº¦")
            # (Implied planning by WebSearcher internal logic, but we report it)
            await asyncio.sleep(0.5) # Simulate quick think
            
            # Phase 2: Synthesis
            _report("æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æ...", "è°ƒç”¨ Gemini 1.5 Pro è¿›è¡Œç»¼åˆ")
            # Run in thread to not block event loop if sync
            research_text = await asyncio.to_thread(WebSearcher.deep_research_for_ppt, user_input, search_text)
            
            # Phase 3: Verification
            _report("éªŒè¯ç ”ç©¶æŠ¥å‘Š...", "æ£€æŸ¥å†…å®¹å®Œæ•´æ€§")
            if research_text:
                _report("âœ… ç ”ç©¶å®Œæˆ", f"ç”Ÿæˆ {len(research_text)} å­—è¯¦ç»†æŠ¥å‘Š")
                return {
                    "success": True,
                    "output": f"æ·±åº¦ç ”ç©¶å®Œæˆï¼Œè·å– {len(research_text)} å­—ä¸“ä¸šåˆ†æ",
                    "content": research_text,
                    "model_id": "gemini-1.5-pro"
                }
            else:
                _report("âš ï¸ ç ”ç©¶äº§å‡ºä¸ºç©º", "å›é€€åˆ°åŸºç¡€æœç´¢ç»“æœ")
                return {
                    "success": True,
                    "output": "ç ”ç©¶æœªè¿”å›ç»“æœï¼Œå°†ä½¿ç”¨å·²æœ‰ä¿¡æ¯",
                    "content": search_text
                }
        except Exception as e:
            _report("âŒ ç ”ç©¶è¿‡ç¨‹å‡ºé”™",Str(e))
            return {
                "success": False,
                "output": "",
                "error": str(e)
            }
    
    @classmethod
    def _merge_results(cls, subtasks: list, context: dict) -> dict:
        """åˆå¹¶æ‰€æœ‰å­ä»»åŠ¡çš„ç»“æœ"""
        merged = {
            "summary": "ä»»åŠ¡æ‰§è¡Œå®Œæˆ",
            "steps": [],
            "final_output": ""
        }
        
        for i, subtask in enumerate(subtasks):
            step_info = {
                "step": i + 1,
                "task": subtask["task_type"],
                "status": subtask["status"],
                "description": subtask["description"]
            }
            
            if subtask["result"]:
                step_info["output"] = subtask["result"].get("output", "")
            if subtask["error"]:
                step_info["error"] = subtask["error"]
            
            merged["steps"].append(step_info)
        
        # æœ€åä¸€ä¸ªå®Œæˆçš„ä»»åŠ¡çš„è¾“å‡ºä½œä¸ºæœ€ç»ˆè¾“å‡º
        for subtask in reversed(subtasks):
            if subtask["status"] == "completed" and subtask["result"]:
                merged["final_output"] = subtask["result"].get("output", "")
                break
        
        return merged
    
    @classmethod
    async def _validate_quality(cls, user_input: str, combined_output: dict, context: dict) -> int:
        """
        éªŒè¯è¾“å‡ºè´¨é‡
        
        è¿”å›: è´¨é‡è¯„åˆ† (0-100)
        """
        score = 50  # åŸºç¡€åˆ†
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if context.get("errors"):
            score -= 20
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆè¾“å‡º
        if combined_output.get("final_output"):
            score += 20
        
        # æ£€æŸ¥æ­¥éª¤å®Œæˆåº¦
        total_steps = len(combined_output.get("steps", []))
        completed_steps = len([s for s in combined_output.get("steps", []) if s["status"] == "completed"])
        if total_steps > 0:
            completion_rate = completed_steps / total_steps
            score += int(completion_rate * 20)
        
        # ç¡®ä¿åˆ†æ•°åœ¨ 0-100 ä¹‹é—´
        return max(0, min(100, score))





# ================= æ™ºèƒ½è¯­æ–™è·¯ç”±å™¨é…ç½® =================
# é…ç½® SmartDispatcher ä»¥ä½¿ç”¨æœ¬åœ°å®šä¹‰çš„ç±»å’Œå¯¹è±¡
# SmartDispatcherã€ModelRouter ç­‰å·²ä» app.core.routing å¯¼å…¥

try:
    print("[INIT] Configuring SmartDispatcher with local dependencies...")
    SmartDispatcher.configure(
        local_executor=LocalExecutor,
        context_analyzer=ContextAnalyzer,
        web_searcher=WebSearcher,
        model_map=MODEL_MAP,
        client=client
    )
    print("[INIT] SmartDispatcher configured successfully.")
except Exception as e:
    print(f"[ERROR] Failed to configure SmartDispatcher: {e}")

# === Ollama åå¤‡è·¯ç”± (å¯é€‰) ===
LOCAL_ROUTER_MODEL = "qwen3:8b"  # å‡çº§: Qwen3 ä¸­è‹±æ–‡èƒ½åŠ›è¿œè¶…æ—§æ¨¡å‹
OLLAMA_API_URL = "http://localhost:11434/api/generate"

class LocalDispatcher:
    """åå¤‡è·¯ç”±å™¨ - ä½¿ç”¨ Ollama (å¦‚æœå¯ç”¨)"""
    
    @staticmethod
    def is_ollama_running():
        try:
            requests.get("http://localhost:11434", timeout=0.2)
            return True
        except:
            return False
    
    @staticmethod
    def analyze(user_input, history=None):
        """ä¼˜å…ˆä½¿ç”¨ SmartDispatcherï¼Œå¤±è´¥æ—¶ä½¿ç”¨ Ollama"""
        # ä½¿ç”¨æ™ºèƒ½æœ¬åœ°è·¯ç”±
        return SmartDispatcher.analyze(user_input, history)

# ================= Utilities =================

class Utils:
    _PACKAGE_ALLOWLIST = {
        "pygame": "pygame",
        "numpy": "numpy",
        "pandas": "pandas",
        "requests": "requests",
        "bs4": "beautifulsoup4",
        "beautifulsoup4": "beautifulsoup4",
        "lxml": "lxml",
        "pillow": "Pillow",
        "PIL": "Pillow",
        "opencv": "opencv-python",
        "cv2": "opencv-python",
        "matplotlib": "matplotlib",
        "scipy": "scipy",
        "sklearn": "scikit-learn",
        "flask": "flask",
        "fastapi": "fastapi",
        "uvicorn": "uvicorn",
        "streamlit": "streamlit",
        "gradio": "gradio",
    }

    @staticmethod
    def sanitize_string(s):
        if isinstance(s, str):
            return s.encode('utf-8', 'ignore').decode('utf-8')
        return s

    @staticmethod
    def is_failure_output(text: str) -> bool:
        if not text or not str(text).strip():
            return True
        t = str(text).strip().lower()
        return t.startswith("âŒ") or "å¤±è´¥" in t or "é”™è¯¯" in t

    @staticmethod
    def build_fix_prompt(task_type: str, user_input: str, prev_output: str = "", error_hint: str = "") -> str:
        base = (
            f"ç”¨æˆ·éœ€æ±‚: {user_input}\n\n"
            f"ä¸Šæ¬¡è¾“å‡º/é”™è¯¯:\n{prev_output or error_hint}\n\n"
            "è¯·ä¿®æ­£å¹¶é‡æ–°è¾“å‡ºæœ€ç»ˆç»“æœã€‚ä¸è¦è§£é‡Šè¿‡ç¨‹ï¼Œåªè¾“å‡ºæœ€ç»ˆå†…å®¹ã€‚\n"
        )

        if task_type == "FILE_GEN":
            return base + (
                "è¦æ±‚ï¼šè¾“å‡ºå¯æ‰§è¡Œçš„ Python è„šæœ¬ï¼Œå¹¶ä½¿ç”¨ BEGIN_FILE/END_FILE æ ‡è®°ã€‚\n"
                "å¿…é¡»ç”Ÿæˆæ–‡æ¡£æˆ–è¡¨æ ¼æ–‡ä»¶ï¼ˆdocx/xlsx/pdfï¼‰ã€‚"
            )
        if task_type == "CODER":
            return base + "è¦æ±‚ï¼šè¾“å‡ºå®Œæ•´å¯è¿è¡Œä»£ç ï¼Œå¹¶åŒ…å«å¿…è¦è¯´æ˜ã€‚"
        if task_type == "RESEARCH":
            return base + "è¦æ±‚ï¼šè¾“å‡ºç»“æ„åŒ–æŠ¥å‘Šï¼ŒåŒ…å«æ ‡é¢˜ä¸è¦ç‚¹ã€‚"
        if task_type == "WEB_SEARCH":
            return base + "è¦æ±‚ï¼šåŸºäºå®æ—¶ä¿¡æ¯å›ç­”ï¼Œç»™å‡ºæ¸…æ™°ç»“è®ºã€‚"
        return base

    @staticmethod
    def adapt_prompt_to_markdown(task_type: str, user_input: str, history: list = None) -> str:
        """ä½¿ç”¨å¿«é€Ÿå°æ¨¡å‹å°†åŸå§‹è¯·æ±‚è½¬ä¸ºç»“æ„åŒ– Markdownï¼Œä¾¿äºå¤§æ¨¡å‹ç†è§£ã€‚"""
        try:
            try:
                from web.prompt_adapter import PromptAdapter
            except ImportError:
                from prompt_adapter import PromptAdapter

            def _generate_markdown(prompt_text: str) -> str:
                response = client.models.generate_content(
                    model="gemini-2.0-flash-lite",
                    contents=prompt_text,
                    config=types.GenerateContentConfig(
                        max_output_tokens=700,
                        temperature=0.2,
                    )
                )
                return response.text or ""

            return PromptAdapter.adapt(
                user_input=user_input,
                task_type=task_type,
                history=history,
                model_generate=_generate_markdown,
            )
        except Exception as e:
            print(f"[PROMPT_ADAPTER] Failed: {e}")
            return user_input

    @staticmethod
    def quick_self_check(task_type: str, user_input: str, output_text: str) -> dict:
        """ä½¿ç”¨å¿«é€Ÿæ¨¡å‹è¿›è¡Œè‡ªæ£€ï¼Œè¿”å› {'pass': bool, 'fix_prompt': str}ã€‚"""
        try:
            check_prompt = (
                "ä½ æ˜¯è´¨é‡æ£€æŸ¥å™¨ã€‚åˆ¤æ–­è¾“å‡ºæ˜¯å¦æ»¡è¶³ç”¨æˆ·éœ€æ±‚ã€‚\n"
                "åªè¾“å‡ºä»¥ä¸‹æ ¼å¼ä¹‹ä¸€ï¼š\n"
                "PASS\n"
                "æˆ–\n"
                "FAIL\nFIX_PROMPT: <ç”¨äºä¿®æ­£çš„æç¤ºè¯>\n\n"
                f"ä»»åŠ¡ç±»å‹: {task_type}\n"
                f"ç”¨æˆ·éœ€æ±‚: {user_input}\n"
                f"æ¨¡å‹è¾“å‡º:\n{output_text}\n"
            )
            response = client.models.generate_content(
                model="gemini-2.0-flash-lite",
                contents=check_prompt,
                config=types.GenerateContentConfig(
                    max_output_tokens=300,
                    temperature=0.1,
                )
            )
            text = (response.text or "").strip()
            if text.startswith("PASS"):
                return {"pass": True, "fix_prompt": ""}
            if text.startswith("FAIL"):
                fix = ""
                for line in text.splitlines():
                    if line.startswith("FIX_PROMPT:"):
                        fix = line.replace("FIX_PROMPT:", "").strip()
                        break
                return {"pass": False, "fix_prompt": fix}
            return {"pass": True, "fix_prompt": ""}
        except Exception as e:
            print(f"[SELF_CHECK] Failed: {e}")
            return {"pass": True, "fix_prompt": ""}

    @staticmethod
    def detect_required_packages(text: str) -> list:
        """ä»è¾“å‡ºä¸­ç²—ç•¥æ£€æµ‹ç¬¬ä¸‰æ–¹ä¾èµ–ï¼ˆä»…è¿”å›ç™½åå•å†…çš„åŒ…ï¼‰ã€‚"""
        if not text:
            return []
        modules = set()
        for line in text.splitlines():
            line = line.strip()
            if line.startswith("import "):
                parts = line.replace("import", "").split(",")
                for p in parts:
                    name = p.strip().split(" ")[0]
                    if name:
                        modules.add(name)
            elif line.startswith("from "):
                parts = line.split()
                if len(parts) >= 2:
                    modules.add(parts[1].strip())

        packages = set()
        for mod in modules:
            if mod in Utils._PACKAGE_ALLOWLIST:
                packages.add(Utils._PACKAGE_ALLOWLIST[mod])
        return sorted(packages)

    @staticmethod
    def auto_install_packages(packages: list) -> dict:
        """å®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…ã€‚è¿”å›å®‰è£…ç»“æœæ‘˜è¦ã€‚"""
        result = {"installed": [], "skipped": [], "failed": []}
        if not packages:
            return result

        for pkg in packages:
            try:
                spec = importlib.util.find_spec(pkg)
                if spec is not None:
                    result["skipped"].append(pkg)
                    continue
                module_aliases = [m for m, p in Utils._PACKAGE_ALLOWLIST.items() if p == pkg]
                if any(importlib.util.find_spec(m) is not None for m in module_aliases):
                    result["skipped"].append(pkg)
                    continue
            except Exception:
                pass

            try:
                cmd = [sys.executable, "-m", "pip", "install", pkg]
                proc = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=120,
                    creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == "win32" else 0
                )
                if proc.returncode == 0:
                    result["installed"].append(pkg)
                else:
                    result["failed"].append(pkg)
            except Exception:
                result["failed"].append(pkg)

        return result

    @staticmethod
    def auto_save_files(text):
        """è‡ªåŠ¨ä»å“åº”ä¸­æå–å¹¶ä¿å­˜æ–‡ä»¶"""
        saved = []

        code_dir = os.path.join(WORKSPACE_DIR, "code")
        os.makedirs(code_dir, exist_ok=True)

        def _get_save_dir(filename):
            ext = os.path.splitext(filename)[1].lower()
            code_exts = {
                ".py", ".js", ".ts", ".tsx", ".jsx", ".java", ".cs", ".cpp", ".c",
                ".go", ".rs", ".rb", ".php", ".swift", ".kt", ".m", ".scala",
                ".sh", ".ps1", ".bat", ".cmd", ".json", ".yaml", ".yml",
                ".toml", ".ini", ".cfg", ".sql", ".md", ".html", ".css"
            }
            return code_dir if ext in code_exts else WORKSPACE_DIR
        
        # è°ƒè¯•ï¼šæ‰“å°å‰800å­—ç¬¦çœ‹çœ‹æ ¼å¼
        print(f"[FILE_GEN] Response first 800 chars:\n{text[:800]}\n")
        
        # é¢„å¤„ç†ï¼šç»Ÿä¸€æ ¼å¼ (å»æ‰å¤šä½™ç©ºæ ¼)
        normalized_text = text
        
        # æ–¹æ³•1: å¤šç§ BEGIN_FILE æ ¼å¼çš„æ­£åˆ™åŒ¹é…
        patterns = [
            # æ ¼å¼1: ---BEGIN_FILE: filename.py--- (æ— ç©ºæ ¼)
            r"---BEGIN_FILE:\s*([a-zA-Z0-9_.-]+)\s*---\s*(.*?)---\s*END_FILE\s*---",
            # æ ¼å¼2: ---BEGIN_FILE: filename.py--- ... ---END_FILE--- (å¸¦æ¢è¡Œ)
            r"---BEGIN_FILE:\s*([a-zA-Z0-9_.-]+)\s*---\n(.*?)\n---END_FILE---",
            # æ ¼å¼3: æ›´å®½æ¾ - å…è®¸å„ç§ç©ºç™½
            r"---\s*BEGIN_FILE[:\s]+([a-zA-Z0-9_.-]+)\s*---\s*(.*?)---\s*END_FILE\s*---",
            # æ ¼å¼4: æœ€å®½æ¾ - æ•è·ä»»æ„æ–‡ä»¶å
            r"---BEGIN_FILE[:\s]+([^\n-]+?)---\s*(.*?)---END_FILE---",
        ]
        
        matches1 = []
        for i, pattern in enumerate(patterns):
            try:
                matches1 = re.findall(pattern, normalized_text, re.DOTALL | re.IGNORECASE)
                print(f"[FILE_GEN] Pattern{i+1} matches: {len(matches1)}")
                if matches1:
                    print(f"[FILE_GEN] âœ“ Using pattern {i+1}")
                    break
            except Exception as e:
                print(f"[FILE_GEN] Pattern{i+1} error: {e}")
        
        for filename, content in matches1:
            try:
                filename = filename.strip()
                content = content.strip()
                print(f"[FILE_GEN] Processing file: '{filename}', content length: {len(content)}")
                
                # æ¸…é™¤ Markdown ä»£ç å—æ ‡è®°
                if content.startswith('```'):
                    lines = content.split('\n')
                    if lines[0].startswith('```'):
                        lines = lines[1:]
                    if lines and lines[-1].strip() == '```':
                        lines = lines[:-1]
                    content = '\n'.join(lines)
                    print(f"[FILE_GEN] After stripping markdown: {len(content)} chars")
                
                # ç¡®ä¿æ–‡ä»¶åæœ‰æ•ˆ
                if not filename or len(filename) > 100:
                    print(f"[FILE_GEN] Invalid filename: {filename}")
                    continue
                
                # ç¡®ä¿æ–‡ä»¶åæœ‰æ‰©å±•å
                if '.' not in filename:
                    filename = filename + '.py'
                
                base_dir = _get_save_dir(filename)
                path = os.path.join(base_dir, filename)
                with open(path, "w", encoding="utf-8") as f:
                    f.write(content)
                saved.append(filename)
                print(f"[FILE_GEN] âœ… Saved: {filename} to {path}")
            except Exception as e:
                print(f"[FILE_GEN] âŒ Save failed: {e}")
                import traceback
                traceback.print_exc()
        
        # æ–¹æ³•2: å¦‚æœæ–¹æ³•1æ²¡æ‰¾åˆ°ï¼Œå°è¯•æå– ```python ä»£ç å— + æ–‡ä»¶åæ³¨é‡Š
        if not saved:
            print(f"[FILE_GEN] Method1 empty, trying method2 (```python blocks)...")
            
            # å…ˆå°è¯•åŒ¹é…å¸¦æ–‡ä»¶åçš„ä»£ç å—
            # ä¾‹å¦‚: # filename: cat_info.py æˆ– # cat_info.py
            pattern2a = r"```python\s*\n#\s*(?:filename:\s*)?([a-zA-Z0-9_.-]+\.py)\s*\n(.*?)```"
            matches2a = re.findall(pattern2a, text, re.DOTALL)
            print(f"[FILE_GEN] Pattern2a (with filename comment) matches: {len(matches2a)}")
            
            if matches2a:
                for filename, code in matches2a:
                    code = code.strip()
                    if not code or len(code) < 20:
                        continue
                    base_dir = _get_save_dir(filename)
                    path = os.path.join(base_dir, filename)
                    try:
                        with open(path, "w", encoding="utf-8") as f:
                            f.write(code)
                        saved.append(filename)
                        print(f"[FILE_GEN] âœ… Method2a saved: {filename}")
                    except Exception as e:
                        print(f"[FILE_GEN] âŒ Method2a save failed: {e}")
            else:
                # æ— æ–‡ä»¶åçš„ä»£ç å—ï¼Œä½¿ç”¨æ—¶é—´æˆ³
                pattern2 = r"```python\s*\n(.*?)```"
                matches2 = re.findall(pattern2, text, re.DOTALL)
                print(f"[FILE_GEN] Pattern2 (generic) matches: {len(matches2)}")
                
                if matches2:
                    timestamp = int(time.time())
                    for idx, code in enumerate(matches2):
                        code = code.strip()
                        if not code or len(code) < 50:
                            continue
                        
                        # å°è¯•ä»ä»£ç ä¸­æå–æœ‰æ„ä¹‰çš„æ–‡ä»¶å
                        filename = None
                        # æŸ¥æ‰¾ doc_path, file_path ç­‰å˜é‡
                        path_match = re.search(r'(?:doc_path|file_path|filepath|output_path)\s*=.*?["\']([^"\']+\.(pdf|docx|xlsx))["\']', code)
                        if path_match:
                            # ä½¿ç”¨ç›®æ ‡æ–‡ä»¶åä½œä¸ºè„šæœ¬å
                            target_file = os.path.basename(path_match.group(1))
                            filename = target_file.rsplit('.', 1)[0] + '.py'
                        
                        if not filename:
                            filename = f"generated_{timestamp}_{idx}.py"
                        
                        base_dir = _get_save_dir(filename)
                        path = os.path.join(base_dir, filename)
                        try:
                            with open(path, "w", encoding="utf-8") as f:
                                f.write(code)
                            saved.append(filename)
                            print(f"[FILE_GEN] âœ… Method2 saved: {filename}")
                        except Exception as e:
                            print(f"[FILE_GEN] âŒ Method2 save failed: {e}")
        
        print(f"[FILE_GEN] Final saved files: {saved}")
        return saved

    @staticmethod
    def save_image_part(blob_part):
        try:
            # ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„å›¾ç‰‡ç›®å½•
            images_dir = settings_manager.images_dir
            os.makedirs(images_dir, exist_ok=True)
            
            timestamp = int(time.time())
            filename = f"generated_{timestamp}.png"
            filepath = os.path.join(images_dir, filename)
            with open(filepath, "wb") as f:
                f.write(blob_part.inline_data.data)
            
            # è¿”å›ç›¸å¯¹äº workspace çš„è·¯å¾„
            # ç¡®ä¿è·¯å¾„å§‹ç»ˆåœ¨ workspace ä¸‹ï¼Œä¸”æ ¼å¼ä¸ºæ­£æ–œæ 
            try:
                rel_path = os.path.relpath(filepath, WORKSPACE_DIR)
                # å¦‚æœåŒ…å« .. è¯´æ˜ä¸åœ¨ workspace ä¸‹ï¼Œéœ€è¦å¤„ç†
                if ".." in rel_path:
                    # é™çº§ä¸ºåªè¿”å›æ–‡ä»¶åï¼Œæ”¾åœ¨ workspace/images ä¸‹
                    abs_workspace_images = os.path.join(WORKSPACE_DIR, "images")
                    os.makedirs(abs_workspace_images, exist_ok=True)
                    fallback_path = os.path.join(abs_workspace_images, filename)
                    with open(fallback_path, "wb") as f:
                        f.write(blob_part.inline_data.data)
                    rel_path = os.path.relpath(fallback_path, WORKSPACE_DIR)
                    print(f"[IMAGE] Falling back to workspace/images: {rel_path}")
                
                result = rel_path.replace("\\", "/")
                print(f"[IMAGE] Saved image: {result}")
                return result
            except Exception as path_err:
                print(f"[IMAGE] Path calculation error: {path_err}")
                # æœ€åçš„ä¿é™©æ–¹æ¡ˆï¼šç›´æ¥ä¿å­˜åˆ° workspace/images
                abs_workspace_images = os.path.join(WORKSPACE_DIR, "images")
                os.makedirs(abs_workspace_images, exist_ok=True)
                fallback_path = os.path.join(abs_workspace_images, filename)
                with open(fallback_path, "wb") as f:
                    f.write(blob_part.inline_data.data)
                result = os.path.relpath(fallback_path, WORKSPACE_DIR).replace("\\", "/")
                print(f"[IMAGE] Emergency fallback: {result}")
                return result
        except Exception as e:
            print(f"[IMAGE] Save failed: {e}")
            import traceback
            traceback.print_exc()
            return None

# ================= Session Manager =================

class SessionManager:
    def __init__(self):
        self.sessions = {}
    
    def list_sessions(self):
        """åˆ—å‡ºæ‰€æœ‰ä¼šè¯ï¼ŒæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰"""
        files = [f for f in os.listdir(CHAT_DIR) if f.endswith(".json")]
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        files_with_time = []
        for f in files:
            path = os.path.join(CHAT_DIR, f)
            mtime = os.path.getmtime(path)
            files_with_time.append((f, mtime))
        files_with_time.sort(key=lambda x: x[1], reverse=True)
        return [f[0] for f in files_with_time]
    
    def load(self, filename):
        """åŠ è½½ä¼šè¯å†å² - è¿”å›ç”¨äºæ¨¡å‹ä¸Šä¸‹æ–‡çš„æˆªæ–­ç‰ˆæœ¬"""
        path = os.path.join(CHAT_DIR, filename)
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8", errors="ignore") as f:
                    full_history = json.load(f)
                    # ä»…æˆªæ–­ç”¨äºæ¨¡å‹ä¸Šä¸‹æ–‡çš„éƒ¨åˆ†ï¼Œä¸å½±å“æŒä¹…åŒ–å­˜å‚¨
                    return self._trim_history(full_history)
            except:
                return []
        return []
    
    def load_full(self, filename):
        """åŠ è½½å®Œæ•´ä¼šè¯å†å² - ç”¨äºè¿½åŠ ä¿å­˜ï¼Œä¸åšæˆªæ–­"""
        path = os.path.join(CHAT_DIR, filename)
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8", errors="ignore") as f:
                    return json.load(f)
            except:
                return []
        return []
    
    def _trim_history(self, history, max_turns=20):
        """ä¿ç•™æœ€å¤š 20 è½®å¯¹è¯ï¼ˆçº¦ 12000+ tokensï¼‰ï¼Œç¡®ä¿ä¸Šä¸‹æ–‡è¶³å¤Ÿä½†ä¸è¿‡é•¿"""
        if len(history) <= max_turns:
            return history
        # åªä¿ç•™æœ€å N è½®å¯¹è¯
        trimmed = history[-max_turns:]
        print(f"[HISTORY] Trimmed to last {max_turns} turns (was {len(history)})")
        return trimmed
    
    def create(self, name):
        safe = "".join([c if c.isalnum() else "_" for c in name])
        filename = f"{safe}.json"
        path = os.path.join(CHAT_DIR, filename)
        with open(path, "w", encoding="utf-8") as f:
            json.dump([], f)
        return filename
    
    def save(self, filename, history):
        path = os.path.join(CHAT_DIR, filename)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(history, f, indent=2, ensure_ascii=False)
    
    def append_and_save(self, filename, user_msg, model_msg, **extra_fields):
        """è¿½åŠ æ¶ˆæ¯å¹¶ä¿å­˜ - åŸºäºç£ç›˜å®Œæ•´å†å²ï¼Œé¿å…æˆªæ–­å¯¼è‡´æ•°æ®ä¸¢å¤±"""
        full_history = self.load_full(filename)
        user_timestamp = extra_fields.pop("user_timestamp", datetime.now().isoformat())
        model_timestamp = extra_fields.pop("model_timestamp", datetime.now().isoformat())

        full_history.append({"role": "user", "parts": [user_msg], "timestamp": user_timestamp})
        model_entry = {"role": "model", "parts": [model_msg]}
        if "timestamp" not in extra_fields:
            model_entry["timestamp"] = model_timestamp
        model_entry.update(extra_fields)
        full_history.append(model_entry)
        self.save(filename, full_history)
        return full_history
    
    def append_user_early(self, filename, user_msg):
        """åœ¨è¯·æ±‚åˆ°è¾¾æ—¶ç«‹å³ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼Œé˜²æ­¢æ–­è¿å¯¼è‡´ä¸¢å¤±
        è¿”å›historyé•¿åº¦ï¼Œåç»­ç”¨update_last_model_responseæ›´æ–°æ¨¡å‹å›å¤"""
        full_history = self.load_full(filename)
        now_iso = datetime.now().isoformat()
        full_history.append({"role": "user", "parts": [user_msg], "timestamp": now_iso})
        full_history.append({"role": "model", "parts": ["â³ å¤„ç†ä¸­..."], "timestamp": now_iso})
        self.save(filename, full_history)
        return len(full_history)
    
    def update_last_model_response(self, filename, model_msg, **extra_fields):
        """æ›´æ–°æœ€åä¸€æ¡æ¨¡å‹å›å¤ï¼ˆé…åˆappend_user_earlyä½¿ç”¨ï¼‰"""
        full_history = self.load_full(filename)
        if full_history and full_history[-1].get("role") == "model":
            model_entry = {"role": "model", "parts": [model_msg]}
            if "timestamp" not in extra_fields:
                model_entry["timestamp"] = datetime.now().isoformat()
            model_entry.update(extra_fields)
            full_history[-1] = model_entry
            self.save(filename, full_history)
        else:
            # fallback: ç›´æ¥è¿½åŠ 
            model_entry = {"role": "model", "parts": [model_msg]}
            if "timestamp" not in extra_fields:
                model_entry["timestamp"] = datetime.now().isoformat()
            model_entry.update(extra_fields)
            full_history.append(model_entry)
            self.save(filename, full_history)

    def add_message(self, filename, role, content, task="CHAT", model_name="Auto", **extra_fields):
        """è¿½åŠ å•æ¡æ¶ˆæ¯ï¼ˆå…¼å®¹æ—§è°ƒç”¨ï¼‰ï¼Œé»˜è®¤é™„å¸¦æ—¶é—´æˆ³"""
        full_history = self.load_full(filename)
        entry = {
            "role": role,
            "parts": [content],
            "task": task,
            "model_name": model_name,
            "timestamp": extra_fields.pop("timestamp", datetime.now().isoformat())
        }
        entry.update(extra_fields)
        full_history.append(entry)
        self.save(filename, full_history)
        return entry
    
    def delete(self, filename):
        path = os.path.join(CHAT_DIR, filename)
        if os.path.exists(path):
            try:
                os.remove(path)
                return True
            except:
                return False
        return False

session_manager = SessionManager()

# ================= åˆå§‹åŒ–å…¨å±€æ¨¡å— =================
# æ‡’åŠ è½½ Memory Manager å’Œ Knowledge Base
_memory_manager = None
_kb = None

def get_memory_manager():
    """è·å–æˆ–åˆ›å»º Memory Manager å®ä¾‹ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    global _memory_manager
    if _memory_manager is None:
        try:
            # ä¼˜å…ˆä½¿ç”¨å¢å¼ºç‰ˆæœ¬
            from enhanced_memory_manager import EnhancedMemoryManager
            _memory_manager = EnhancedMemoryManager()
            print("[INIT] âœ… å¢å¼ºè®°å¿†ç®¡ç†å™¨å·²åˆå§‹åŒ–")
        except ImportError:
            try:
                from web.enhanced_memory_manager import EnhancedMemoryManager
                _memory_manager = EnhancedMemoryManager()
                print("[INIT] âœ… å¢å¼ºè®°å¿†ç®¡ç†å™¨å·²åˆå§‹åŒ–")
            except ImportError:
                # é™çº§åˆ°åŸºç¡€ç‰ˆæœ¬
                try:
                    from memory_manager import MemoryManager
                except ImportError:
                    from web.memory_manager import MemoryManager
                _memory_manager = MemoryManager()
                print("[INIT] âš ï¸  ä½¿ç”¨åŸºç¡€è®°å¿†ç®¡ç†å™¨")
    return _memory_manager


def _start_memory_extraction(user_msg: str, ai_msg: str, history=None):
    """åå°æå–é•¿æœŸè®°å¿†ï¼Œé¿å…é˜»å¡ä¸»å¯¹è¯æµç¨‹"""
    try:
        from memory_integration import MemoryIntegration
    except ImportError:
        try:
            from web.memory_integration import MemoryIntegration
        except ImportError:
            print("[MemoryIntegration] âš ï¸  æ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡è‡ªåŠ¨è®°å¿†æå–")
            return

    if not MemoryIntegration.should_extract(user_msg, ai_msg):
        return

    def _worker():
        try:
            memory_mgr = get_memory_manager()

            class _LLMAdapter:
                async def generate(self, prompt, temperature=0.1, max_tokens=500):
                    resp = client.models.generate_content(
                        model="gemini-2.0-flash-lite",
                        contents=prompt,
                        config=types.GenerateContentConfig(
                            temperature=temperature,
                            max_output_tokens=max_tokens,
                        )
                    )
                    return resp.text or ""

            result = asyncio.run(
                MemoryIntegration.extract_and_apply(
                    memory_mgr, user_msg, ai_msg, _LLMAdapter(), history
                )
            )
            if result.get("success"):
                print("[MemoryIntegration] âœ… è‡ªåŠ¨è®°å¿†æå–å®Œæˆ")
            else:
                print(f"[MemoryIntegration] âš ï¸ è‡ªåŠ¨è®°å¿†æå–å¤±è´¥: {result.get('error')}")
        except Exception as e:
            print(f"[MemoryIntegration] âŒ è‡ªåŠ¨è®°å¿†æå–å¼‚å¸¸: {e}")

    threading.Thread(target=_worker, daemon=True).start()

def get_knowledge_base():
    """è·å–æˆ–åˆ›å»º Knowledge Base å®ä¾‹"""
    global _kb
    if _kb is None:
        try:
            from knowledge_base import KnowledgeBase
        except ImportError:
            from web.knowledge_base import KnowledgeBase
        _kb = KnowledgeBase()
        print("[INIT] âœ… Knowledge Base å·²åˆå§‹åŒ–")
    return _kb

# ä¸ºäº†å‘åå…¼å®¹ï¼Œå¯¼å‡ºå…¨å±€å˜é‡
memory_manager = None  # å°†é€šè¿‡ get_memory_manager() åŠ¨æ€è·å–
kb = None  # å°†é€šè¿‡ get_knowledge_base() åŠ¨æ€è·å–

# ================= Koto Brain =================

class KotoBrain:
    # å›¾åƒç¼–è¾‘å…³é”®è¯
    IMAGE_EDIT_KEYWORDS = [
        "ä¿®æ”¹", "æ¢", "æ”¹æˆ", "å˜æˆ", "åº•è‰²", "èƒŒæ™¯", "é¢œè‰²",
        "æŠ å›¾", "å»èƒŒæ™¯", "På›¾", "ç¾åŒ–", "æ»¤é•œ", "è°ƒè‰²", "ç¼–è¾‘",
        "change", "modify", "edit", "background", "color",
    ]
    
    def chat(self, history, user_input, file_data=None, model=None, auto_model=True):
        start_time = time.time()
        original_input = user_input
        # æ”¯æŒæ¨¡å‹é€‰æ‹©å’Œè‡ªåŠ¨é€‰æ‹©
        if model and not auto_model:
            model_id = model
            route_method = "Manual select"
            target_key = "CHAT"
        else:
            target_key = "CHAT"
            route_method = "Auto"
            
            if file_data:
                # åˆ¤æ–­æ˜¯å›¾åƒç¼–è¾‘è¿˜æ˜¯å›¾åƒåˆ†æ
                user_lower = user_input.lower()
                is_edit = any(kw in user_lower for kw in self.IMAGE_EDIT_KEYWORDS)
                
                if is_edit:
                    target_key = "PAINTER"
                    route_method = "Image Edit"
                else:
                    target_key = "VISION"
                    route_method = "Image Analysis"
            else:
                # ä½¿ç”¨æ™ºèƒ½è·¯ç”±å™¨
                target_key, route_method, _ = SmartDispatcher.analyze(user_input)
            
            model_id = SmartDispatcher.get_model_for_task(target_key, has_image=bool(file_data))

        # ä½¿ç”¨å°æ¨¡å‹å°†è¯·æ±‚è½¬æ¢ä¸ºç»“æ„åŒ– Markdownï¼ˆä»…åœ¨å¤§æ¨¡å‹å¤„ç†æ—¶å¯ç”¨ï¼‰
        model_input = user_input
        if auto_model and not file_data and target_key not in ["SYSTEM", "FILE_OP", "PAINTER", "VISION"]:
            model_input = Utils.adapt_prompt_to_markdown(target_key, user_input, history=history)
            if model_input != user_input:
                print("[PROMPT_ADAPTER] Applied Markdown prompt for model")
        
        result = {
            "task": target_key,
            "model": model_id,
            "route_method": route_method,  # è·¯ç”±æ–¹æ³•ä¿¡æ¯
            "response": "",
            "images": [],
            "saved_files": [],
            "latency": 0,
            "total_time": 0
        }
        
        try:
            # === SYSTEM Mode (æœ¬åœ°æ‰§è¡Œ) ===
            if target_key == "SYSTEM":
                exec_result = LocalExecutor.execute(user_input)
                result["response"] = exec_result["message"]
                if exec_result.get("details"):
                    result["response"] += f"\n\n{exec_result['details']}"
                result["total_time"] = time.time() - start_time
                return result
            
            # === PAINTER Mode (å›¾åƒç”Ÿæˆ/ç¼–è¾‘) ===
            if target_key == "PAINTER":
                # å¦‚æœæœ‰è¾“å…¥å›¾ç‰‡ï¼ˆå›¾åƒç¼–è¾‘æ¨¡å¼ï¼‰- ä½¿ç”¨ä»£ç æ–¹å¼å¤„ç†
                if file_data:
                    # ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡åˆ° workspace
                    import tempfile
                    import subprocess
                    
                    temp_img_path = os.path.join(WORKSPACE_DIR, "images", f"input_{int(time.time())}.jpg")
                    os.makedirs(os.path.dirname(temp_img_path), exist_ok=True)
                    with open(temp_img_path, "wb") as f:
                        f.write(file_data["data"])
                    
                    # æ„å»ºå›¾åƒç¼–è¾‘çš„ç³»ç»ŸæŒ‡ä»¤
                    edit_instruction = f"""ä½ æ˜¯ä¸€ä¸ªå›¾åƒå¤„ç†ä¸“å®¶ã€‚ç”¨æˆ·ä¸Šä¼ äº†ä¸€å¼ å›¾ç‰‡ï¼Œéœ€è¦ä½ ç”Ÿæˆ Python ä»£ç æ¥å¤„ç†å®ƒã€‚

å›¾ç‰‡è·¯å¾„: {temp_img_path}
ç”¨æˆ·è¯·æ±‚: {user_input}

è¯·ç”Ÿæˆå®Œæ•´çš„ Python ä»£ç æ¥å®Œæˆç”¨æˆ·çš„å›¾åƒç¼–è¾‘è¯·æ±‚ã€‚

è¦æ±‚:
1. ä½¿ç”¨ OpenCV (cv2) æˆ– PIL å¤„ç†å›¾ç‰‡
2. å¤„ç†åçš„å›¾ç‰‡ä¿å­˜åˆ°: {settings_manager.images_dir}
3. æ–‡ä»¶åæ ¼å¼: edited_{{timestamp}}.jpg æˆ– .png
4. ä»£ç å¿…é¡»å®Œæ•´å¯æ‰§è¡Œ
5. å¯¹äºæ¢èƒŒæ™¯è‰²ï¼Œä½¿ç”¨é¢œè‰²é˜ˆå€¼æˆ–è¾¹ç¼˜æ£€æµ‹æ¥è¯†åˆ«èƒŒæ™¯åŒºåŸŸ

å¸¸ç”¨çš„èƒŒæ™¯è‰²å¤„ç†æ–¹æ³•:
- è¯ä»¶ç…§æ¢åº•è‰²: æ£€æµ‹æ¥è¿‘åŸèƒŒæ™¯è‰²çš„åƒç´ ï¼Œæ›¿æ¢ä¸ºç›®æ ‡é¢œè‰²
- è“è‰²èƒŒæ™¯ RGB: (67, 142, 219) æˆ– (0, 191, 255)
- çº¢è‰²èƒŒæ™¯ RGB: (255, 0, 0) æˆ– (220, 0, 0)  
- ç™½è‰²èƒŒæ™¯ RGB: (255, 255, 255)

ä»£ç æ ¼å¼ï¼ˆå¿…é¡»ä½¿ç”¨è¿™ä¸ªæ ¼å¼ï¼‰:
---BEGIN_FILE: image_edit.py---
# ä½ çš„ä»£ç 
---END_FILE---"""

                    # è°ƒç”¨ Gemini ç”Ÿæˆä»£ç ï¼ˆå¸¦å›é€€ï¼‰
                    edit_models = ["gemini-3-flash-preview", "gemini-3-pro-preview", "gemini-2.5-flash", "gemini-2.0-flash"]
                    code_response = None
                    last_error = None

                    def _process_code_response(code_response_text: str):
                        # æå–ä»£ç  - æ”¯æŒå¤šç§æ ¼å¼
                        import re
                        patterns = [
                            r"---BEGIN_FILE:\s*([a-zA-Z0-9_.-]+)\s*---\s*(.*?)---\s*END_FILE\s*---",
                            r"```python\s*(.*?)```",  # æ ‡å‡† markdown ä»£ç å—
                            r"```\s*(.*?)```",  # æ— è¯­è¨€æ ‡è®°çš„ä»£ç å—
                        ]
                        
                        code_content = None
                        for pattern in patterns:
                            matches = re.findall(pattern, code_response_text, re.DOTALL | re.IGNORECASE)
                            if matches:
                                if isinstance(matches[0], tuple):
                                    code_content = matches[0][1].strip()
                                else:
                                    code_content = matches[0].strip()
                                print(f"[IMAGE_EDIT] Extracted code, length: {len(code_content)}")
                                break
                        
                        if not code_content:
                            return {
                                "images": [],
                                "response": f"âŒ æ— æ³•ä»æ¨¡å‹å“åº”ä¸­æå–ä»£ç \n\næ¨¡å‹è¿”å›å†…å®¹:\n```\n{code_response_text[:500]}\n```",
                                "error": "no_code"
                            }
                        
                        # ä¿å­˜å¹¶æ‰§è¡Œä»£ç 
                        temp_script = os.path.join(tempfile.gettempdir(), f"koto_edit_{int(time.time())}.py")
                        with open(temp_script, 'w', encoding='utf-8') as f:
                            f.write(code_content)
                        
                        print(f"[IMAGE_EDIT] Executing script: {temp_script}")
                        exec_result = subprocess.run(
                            [sys.executable, temp_script],
                            capture_output=True,
                            text=True,
                            timeout=60,
                            cwd=WORKSPACE_DIR
                        )
                        
                        print(f"[IMAGE_EDIT] Script result: returncode={exec_result.returncode}")
                        if exec_result.stdout:
                            print(f"[IMAGE_EDIT] stdout: {exec_result.stdout[:200]}")
                        if exec_result.stderr:
                            print(f"[IMAGE_EDIT] stderr: {exec_result.stderr[:200]}")
                        
                        # æ¸…ç†ä¸´æ—¶è„šæœ¬
                        try:
                            os.remove(temp_script)
                        except:
                            pass
                        
                        if exec_result.returncode == 0:
                            images = []
                            images_dir = settings_manager.images_dir
                            for f in os.listdir(images_dir):
                                if f.startswith("edited_") and f.endswith(('.jpg', '.png', '.jpeg')):
                                    full_path = os.path.join(images_dir, f)
                                    age = time.time() - os.path.getmtime(full_path)
                                    if age < 60:
                                        rel_path = os.path.relpath(full_path, WORKSPACE_DIR).replace("\\", "/")
                                        images.append(rel_path)
                            
                            if images:
                                return {
                                    "images": images,
                                    "response": f"âœ… å›¾ç‰‡ç¼–è¾‘å®Œæˆ!\nğŸ–¼ï¸ ä¿å­˜ä½ç½®: `{images_dir}`",
                                    "error": ""
                                }
                            return {
                                "images": [],
                                "response": f"âš ï¸ è„šæœ¬æ‰§è¡ŒæˆåŠŸä½†æœªæ£€æµ‹åˆ°æ–°å›¾ç‰‡\n\n{exec_result.stdout[:500]}",
                                "error": "no_output"
                            }
                        
                        return {
                            "images": [],
                            "response": f"âŒ å›¾ç‰‡å¤„ç†å¤±è´¥\n```\n{exec_result.stderr[:500]}\n```",
                            "error": "exec_failed"
                        }
                    
                    for edit_model in edit_models:
                        try:
                            print(f"[IMAGE_EDIT] Trying model: {edit_model}")
                            print(f"[IMAGE_EDIT] Sending request to API...")
                            response = client.models.generate_content(
                                model=edit_model,
                                contents=edit_instruction,
                                config=types.GenerateContentConfig(
                                    max_output_tokens=4096,
                                    temperature=0.5
                                )
                            )
                            print(f"[IMAGE_EDIT] Got API response")
                            
                            if response.candidates and response.candidates[0].content.parts:
                                code_response = response.candidates[0].content.parts[0].text
                                print(f"[IMAGE_EDIT] Got response from {edit_model}, length: {len(code_response)}")
                                break
                        except Exception as model_err:
                            last_error = str(model_err)
                            print(f"[IMAGE_EDIT] Model {edit_model} failed: {last_error[:100]}")
                            continue
                    
                    if code_response:
                        run_result = _process_code_response(code_response)
                        result["images"] = run_result["images"]
                        result["response"] = run_result["response"]
                    else:
                        result["response"] = f"âŒ æ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨: {last_error[:200] if last_error else 'æœªçŸ¥é”™è¯¯'}"
                    
                    # å¤±è´¥åè‡ªåŠ¨ä¿®æ­£å¹¶é‡è¯•ä¸€æ¬¡ï¼ˆé¿å…æ— ç¼–è¾‘ç»“æœï¼‰
                    if not result["images"] and Utils.is_failure_output(result["response"]):
                        fix_prompt = (
                            "ä¸Šæ¬¡ç”Ÿæˆå¤±è´¥ï¼Œè¯·ä¿®æ­£å¹¶åªè¾“å‡ºå®Œæ•´å¯æ‰§è¡Œçš„ Python ä»£ç ã€‚\n"
                            "å¿…é¡»ä½¿ç”¨ BEGIN_FILE/END_FILE æ ¼å¼ã€‚\n"
                            f"å›¾ç‰‡è·¯å¾„: {temp_img_path}\n"
                            f"è¾“å‡ºç›®å½•: {settings_manager.images_dir}\n"
                            f"ç”¨æˆ·è¯·æ±‚: {user_input}\n\n"
                            f"å¤±è´¥ä¿¡æ¯/è¾“å‡º: {result['response']}\n"
                        )
                        retry_models = ["gemini-3-flash-preview", "gemini-2.5-flash"]
                        for retry_model in retry_models:
                            try:
                                print(f"[IMAGE_EDIT] Retry with model: {retry_model}")
                                retry_resp = client.models.generate_content(
                                    model=retry_model,
                                    contents=fix_prompt,
                                    config=types.GenerateContentConfig(
                                        max_output_tokens=4096
                                    )
                                )
                                if retry_resp.candidates and retry_resp.candidates[0].content.parts:
                                    retry_code = retry_resp.candidates[0].content.parts[0].text
                                    retry_run = _process_code_response(retry_code)
                                    if retry_run["images"]:
                                        result["images"] = retry_run["images"]
                                        result["response"] = retry_run["response"]
                                        break
                                    result["response"] = retry_run["response"]
                            except Exception as retry_err:
                                print(f"[IMAGE_EDIT] Retry failed: {retry_err}")
                    
                    result["total_time"] = time.time() - start_time
                    return result
                else:
                    # çº¯å›¾åƒç”Ÿæˆä½¿ç”¨ nano-banana-pro-preview
                    try:
                        print(f"[å›¾åƒç”Ÿæˆ] å¼€å§‹ç”Ÿæˆ: {user_input[:50]}...")
                        response = client.models.generate_content(
                            model="nano-banana-pro-preview",
                            contents=user_input,
                            config=types.GenerateContentConfig(
                                response_modalities=["IMAGE"]
                            )
                        )
                        print(f"[å›¾åƒç”Ÿæˆ] å“åº”æˆåŠŸï¼Œå€™é€‰æ•°: {len(response.candidates) if response.candidates else 0}")
                        
                        # ä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡
                        if response.candidates and response.candidates[0].content.parts:
                            for part in response.candidates[0].content.parts:
                                if hasattr(part, "inline_data") and part.inline_data:
                                    img_filename = Utils.save_image_part(part)
                                    if img_filename:
                                        result["images"].append(img_filename)
                                        print(f"[å›¾åƒç”Ÿæˆ] å·²ä¿å­˜: {img_filename}")
                        
                        if result["images"]:
                            save_path = settings_manager.images_dir
                            result["response"] = f"âœ¨ å›¾ç‰‡å·²ç”Ÿæˆ!\nğŸ–¼ï¸ ä¿å­˜ä½ç½®: `{save_path}`"
                        else:
                            result["response"] = "âŒ å›¾åƒç”Ÿæˆå¤±è´¥: æ— è¾“å‡ºå†…å®¹ï¼Œè¯·æ£€æŸ¥æç¤ºè¯"
                        result["total_time"] = time.time() - start_time
                        return result
                    except Exception as img_err:
                        error_msg = str(img_err)
                        print(f"[å›¾åƒç”Ÿæˆ] é”™è¯¯: {error_msg[:200]}")
                        
                        # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                        if "disconnected" in error_msg.lower() or "timeout" in error_msg.lower():
                            result["response"] = f"âŒ è¿æ¥è¶…æ—¶æˆ–ä¸­æ–­: {error_msg[:100]}\n\nğŸ’¡ å»ºè®®: è¯·ç¨åé‡è¯•ï¼Œæˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥"
                        elif "safety" in error_msg.lower():
                            result["response"] = "âŒ å†…å®¹å› å®‰å…¨æ”¿ç­–è¢«è¿‡æ»¤ï¼Œè¯·ä¿®æ”¹æç¤ºè¯"
                        elif "quota" in error_msg.lower() or "rate" in error_msg.lower():
                            result["response"] = "âŒ API é…é¢å·²è¾¾é™åˆ¶ï¼Œè¯·ç¨åé‡è¯•"
                        else:
                            result["response"] = f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {error_msg[:100]}"
                        
                        result["total_time"] = time.time() - start_time
                        return result
                
                if not response.candidates:
                    result["response"] = "Generation failed (safety filter or busy)."
                    result["total_time"] = time.time() - start_time
                    return result
                
                text_response = ""
                if response.candidates and response.candidates[0].content.parts:
                    for part in response.candidates[0].content.parts:
                        if hasattr(part, 'text') and part.text:
                            text_response += part.text
                        if hasattr(part, "inline_data") and part.inline_data:
                            img_filename = Utils.save_image_part(part)
                            if img_filename:
                                result["images"].append(img_filename)
                
                # æ·»åŠ å›¾ç‰‡ä¿å­˜ä½ç½®æç¤º
                if result["images"]:
                    save_path = settings_manager.images_dir
                    text_response += f"\n\nğŸ–¼ï¸ å›¾ç‰‡å·²ä¿å­˜åˆ°: `{save_path}`"
                
                result["response"] = text_response if text_response else "Image generated successfully!"
                result["total_time"] = time.time() - start_time
                return result
            
            # === RAG: Retrieve Relevant Context (Auto) ===
            try:
                # è·å–çŸ¥è¯†åº“å®ä¾‹
                kb_inst = get_knowledge_base()
                
                # ä»…åœ¨éç‰¹å®šæ¨¡å¼ä¸”è¾“å…¥æœ‰æ•ˆæ—¶æ£€ç´¢
                if target_key not in ["PAINTER", "SYSTEM"] and len(original_input) > 3:
                    # é¿å…å¯¹æçŸ­çš„é—®å€™è¯­è¿›è¡Œæ£€ç´¢
                    skip_keywords = ["ä½ å¥½", "hello", "hi", "test", "æµ‹è¯•"]
                    if not any(original_input.lower() == k for k in skip_keywords):
                        print(f"[RAG]æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“: {original_input[:50]}...")
                        rag_results = kb_inst.search(original_input, top_k=3)
                        
                        if rag_results:
                            print(f"[RAG] æ£€ç´¢åˆ° {len(rag_results)} ä¸ªç›¸å…³ç‰‡æ®µ")
                            context_str = "\n".join([
                                f"--- æ¥æº: {r['file_name']} (ç›¸ä¼¼åº¦: {r['similarity']:.2f}) ---\n{r['text']}"
                                for r in rag_results
                            ])
                            
                            # å°†ä¸Šä¸‹æ–‡æ³¨å…¥ prompt
                            rag_context = f"\n\nã€å‚è€ƒèµ„æ–™ã€‘\nä»¥ä¸‹æ˜¯ä»æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹ï¼Œä¾›å›ç­”å‚è€ƒï¼š\n{context_str}\n\n"
                            
                            # Log retrieval
                            print(f"[RAG] Injected context length: {len(rag_context)}")
                            
                            # Update model input
                            # å¦‚æœæœ‰ file_dataï¼Œmodel_input å¯èƒ½æ˜¯ None æˆ–ä¸è¢«ç›´æ¥ä½¿ç”¨ï¼Œéœ€è°¨æ…
                            if not file_data:
                                model_input = rag_context + model_input
                            else:
                                # å¯¹äºæœ‰æ–‡ä»¶çš„è¯·æ±‚ï¼Œæˆ‘ä»¬å°†ä¸Šä¸‹æ–‡æ‹¼æ¥åˆ° original_input (user prompt)
                                # æ³¨æ„ï¼šä¸‹é¢ generate_content ç”¨çš„æ˜¯ original_input + image_part
                                original_input = rag_context + original_input

            except Exception as rag_err:
                print(f"[RAG] Retrieval warning: {rag_err}")

            # === Regular Mode ===
            # æ„å»ºå†å²è®°å½•æ ¼å¼ï¼ˆè¿‡æ»¤æ— å…³å†å²ï¼‰
            history_for_model = ContextAnalyzer.filter_history(original_input, history)
            formatted_history = []
            for turn in history_for_model:
                formatted_history.append(types.Content(
                    role=turn['role'],
                    parts=[types.Part.from_text(text=p) for p in turn['parts']]
                ))
            
            if file_data:
                # æ„å»ºæ­£ç¡®çš„ Part æ ¼å¼
                image_part = types.Part.from_bytes(
                    data=file_data["data"],
                    mime_type=file_data["mime_type"]
                )
                response = client.models.generate_content(
                    model=model_id,
                    contents=[original_input, image_part],
                    config=types.GenerateContentConfig(
                        system_instruction=_get_system_instruction()
                    )
                )
                accumulated_text = response.text if response.text else ""
            else:
                response = client.models.generate_content(
                    model=model_id,
                    contents=formatted_history + [types.Content(
                        role="user",
                        parts=[types.Part.from_text(text=model_input)]
                    )],
                    config=types.GenerateContentConfig(
                        system_instruction=_get_system_instruction()
                    )
                )
                accumulated_text = response.text if response.text else ""
            
            first_token_latency = (time.time() - start_time) * 1000
            result["latency"] = first_token_latency
            
            # Auto-save files
            saved_files = Utils.auto_save_files(accumulated_text)
            result["saved_files"] = saved_files
            
            # æ·»åŠ æ–‡ä»¶ä¿å­˜æç¤º
            if saved_files:
                files_list = ", ".join(saved_files)
                accumulated_text += f"\n\nğŸ“ æ–‡ä»¶å·²ä¿å­˜: **{files_list}**\nğŸ“‚ ä½ç½®: `{WORKSPACE_DIR}`"
            
            result["response"] = accumulated_text
            result["total_time"] = time.time() - start_time
            return result
            
        except Exception as e:
            result["response"] = f"Error: {str(e)}"
            result["total_time"] = time.time() - start_time
            return result

brain = KotoBrain()

# ================= Routes =================

@app.route('/')
def index():
    # äº‘æ¨¡å¼ï¼šæœªè®¤è¯ç”¨æˆ·çœ‹åˆ°è½åœ°é¡µ
    deploy_mode = os.environ.get('KOTO_DEPLOY_MODE', 'local')
    auth_enabled = os.environ.get('KOTO_AUTH_ENABLED', 'false').lower() == 'true'
    if deploy_mode == 'cloud' and auth_enabled:
        return render_template('landing.html')
    return render_template('index.html')

@app.route('/app')
def app_main():
    """ä¸»åº”ç”¨é¡µé¢ï¼ˆSaaS æ¨¡å¼ä¸‹éœ€è®¤è¯åè®¿é—®ï¼‰"""
    return render_template('index.html')

@app.route('/file-network')
def file_network():
    """æ–‡ä»¶ç½‘ç»œç•Œé¢"""
    return render_template('file_network.html')

@app.route('/knowledge-graph')
def knowledge_graph_page():
    """çŸ¥è¯†å›¾è°±å¯è§†åŒ–ç•Œé¢"""
    return render_template('knowledge_graph.html')

@app.route('/test_upload')
def test_upload():
    return render_template('test_upload.html')

@app.route('/edit-ppt/<session_id>')
def edit_ppt(session_id):
    """PPT ç”Ÿæˆåç¼–è¾‘é¡µé¢ï¼ˆP1 åŠŸèƒ½ï¼‰"""
    return render_template('edit_ppt.html')

@app.route('/monitoring-dashboard')
def monitoring_dashboard():
    """Phase 4 System Monitoring Dashboard"""
    return send_from_directory(os.path.join(os.path.dirname(__file__), 'static'), 'monitoring_dashboard.html')

@app.route('/api/sessions', methods=['GET'])
def get_sessions():
    sessions = session_manager.list_sessions()
    return jsonify({
        "sessions": [s.replace(".json", "") for s in sessions]
    })

@app.route('/api/sessions', methods=['POST'])
def create_session():
    data = request.json
    name = data.get('name', f'chat_{int(time.time())}')
    filename = session_manager.create(name)
    return jsonify({
        "success": True,
        "session": filename.replace(".json", "")
    })

@app.route('/api/sessions/<session_name>', methods=['GET'])
def get_session(session_name):
    # è¿”å›å®Œæ•´å†å²ä¾›å‰ç«¯æ¸²æŸ“ï¼ˆä¸æˆªæ–­ï¼‰ï¼Œæˆªæ–­ä»…ç”¨äºæ¨¡å‹ä¸Šä¸‹æ–‡
    history = session_manager.load_full(f"{session_name}.json")
    return jsonify({
        "session": session_name,
        "history": history
    })

@app.route('/api/sessions/<session_name>', methods=['DELETE'])
def delete_session(session_name):
    success = session_manager.delete(f"{session_name}.json")
    return jsonify({"success": success})

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.json
    session_name = data.get('session')
    user_input = data.get('message', '')
    locked_task = data.get('locked_task')
    locked_model = data.get('locked_model', 'auto')
    
    if not session_name or not user_input:
        return jsonify({"error": "Missing session or message"}), 400
    
    user_input = Utils.sanitize_string(user_input)
    
    # Load history
    history = session_manager.load(f"{session_name}.json")
    
    # ç¡®å®šä½¿ç”¨çš„æ¨¡å‹
    if locked_model and locked_model != 'auto':
        model = locked_model
        auto_model = False
    elif locked_task:
        model = MODEL_MAP.get(locked_task, MODEL_MAP['CHAT'])
        auto_model = False
    else:
        model = None
        auto_model = True
    
    # Get response
    result = brain.chat(history, user_input, model=model, auto_model=auto_model)

    # ä»£ç ä»»åŠ¡: è‡ªåŠ¨æ£€æŸ¥ä¾èµ–å¹¶å®‰è£…
    if result.get("task") == "CODER" and result.get("response"):
        pkgs = Utils.detect_required_packages(result["response"])
        if pkgs:
            install_result = Utils.auto_install_packages(pkgs)
            installed = install_result.get("installed", [])
            failed = install_result.get("failed", [])
            skipped = install_result.get("skipped", [])
            msg_parts = []
            if installed:
                msg_parts.append(f"âœ… å·²å®‰è£…: {', '.join(installed)}")
            if skipped:
                msg_parts.append(f"â„¹ï¸ å·²å­˜åœ¨: {', '.join(skipped)}")
            if failed:
                msg_parts.append(f"âš ï¸ å®‰è£…å¤±è´¥: {', '.join(failed)}")
            if msg_parts:
                result["response"] += "\n\n" + "\n".join(msg_parts)
    
    # Update history (åŸºäºç£ç›˜å®Œæ•´å†å²è¿½åŠ ï¼Œé¿å…æˆªæ–­ä¸¢å¤±)
    session_manager.append_and_save(f"{session_name}.json", user_input, result["response"])
    
    return jsonify(result)


# ============== Agent ç¡®è®¤ API ==============
# NOTE: These routes have been migrated to the unified agent blueprint
#       (app/api/agent_routes.py) under /api/agent/confirm and /api/agent/choice.
#       Kept here as comments for reference.

# @app.route('/api/agent/confirm', methods=['POST'])
# def agent_confirm():
#     """Agent ç”¨æˆ·ç¡®è®¤ API â€” å‰ç«¯ç‚¹å‡»ç¡®è®¤/å–æ¶ˆåå›è°ƒ"""
#     ...

# @app.route('/api/agent/choice', methods=['POST'])
# def agent_choice():
#     """Agent ç”¨æˆ·é€‰æ‹© API â€” å‰ç«¯é€‰æ‹©åå›è°ƒ"""
#     ...


# NOTE: /api/agent/plan has been migrated to the unified agent blueprint
#       (app/api/agent_routes.py). Kept as comment for reference.
# @app.route('/api/agent/plan', methods=['POST'])
# def agent_plan(): ...


@app.route('/api/chat/stream', methods=['POST'])
def chat_stream():
    """æµå¼èŠå¤© API - å®æ—¶è¿”å›å“åº”"""
    data = request.json
    session_name = data.get('session')
    user_input = data.get('message', '')
    locked_task = data.get('locked_task')
    locked_model = data.get('locked_model', 'auto')
    
    print(f"\n[STREAM] Incoming request: locked_task='{locked_task}', locked_model='{locked_model}'")
    print(f"[STREAM] User input: {user_input[:60]}")
    
    if not session_name or not user_input:
        def error_gen():
            yield f"data: {json.dumps({'type': 'error', 'message': 'Missing session or message'})}\n\n"
        return Response(error_gen(), mimetype='text/event-stream')
    
    # API å¯†é’¥ç¼ºå¤±æ—¶æå‰è¿”å›å‹å¥½æç¤º
    if not API_KEY:
        def no_key_gen():
            msg = ("âš ï¸ **API å¯†é’¥æœªé…ç½®**\n\n"
                   "è¯·åœ¨ `config/gemini_config.env` æ–‡ä»¶ä¸­è®¾ç½®ï¼š\n"
                   "```\nGEMINI_API_KEY=ä½ çš„å¯†é’¥\n```\n\n"
                   "ğŸ’¡ è·å–å¯†é’¥ï¼š[Google AI Studio](https://aistudio.google.com/apikey)\n\n"
                   "è®¾ç½®å®Œæˆåé‡å¯ Koto å³å¯ä½¿ç”¨ã€‚")
            yield f"data: {json.dumps({'type': 'token', 'content': msg})}\n\n"
        return Response(no_key_gen(), mimetype='text/event-stream')
    
    user_input = Utils.sanitize_string(user_input)

    # â³ é‡å¤ä¸Šä¸€ä¸ªä»»åŠ¡ (Repeat Last Task)
    repeat_patterns = [r'^é‡å¤.*ä»»åŠ¡', r'^å†åšä¸€é', r'^å†æ¥ä¸€æ¬¡', r'^re(peat|do).*last.*task', r'^try.*again']
    if any(re.search(p, user_input, re.IGNORECASE) for p in repeat_patterns):
        try:
            full_hist = session_manager.load_full(f"{session_name}.json")
            # å€’åºæŸ¥æ‰¾æœ€è¿‘çš„ä¸€æ¡ user æ¶ˆæ¯
            last_user_msg = None
            for msg in reversed(full_hist):
                if msg.get("role") == "user":
                    content = (msg.get("parts") or [""])[0]
                    # é¿å…æ— é™å¾ªç¯ï¼šå¦‚æœä¸Šä¸€æ¡ä¹Ÿæ˜¯â€œé‡å¤ä»»åŠ¡â€ï¼Œåˆ™ç»§ç»­å¾€å‰æ‰¾
                    if not any(re.search(p, content, re.IGNORECASE) for p in repeat_patterns):
                        last_user_msg = content
                        break
            
            if last_user_msg:
                print(f"[REPEAT] Found last user message: {last_user_msg[:50]}...")
                user_input = last_user_msg # æ›¿æ¢å½“å‰è¾“å…¥ä¸ºä¸Šä¸€æ¡ä»»åŠ¡
                # å¯ä»¥é€‰æ‹©æ³¨å…¥ä¸€ä¸ªæç¤ºï¼Œå‘Šè¯‰ç”¨æˆ·æ­£åœ¨é‡è¯•
                # ä½†ä¸ºäº† context è¿è´¯ï¼Œç›´æ¥æ›¿æ¢æœ€ç®€å•
            else:
                print("[REPEAT] Check failed: No valid previous user message found.")
        except Exception as e:
            print(f"[REPEAT] Error fetching history: {e}")
    
    # âš¡ å¿«é€Ÿè·¯å¾„ï¼šç³»ç»Ÿæ—¶é—´æŸ¥è¯¢ - ç›´æ¥è¿”å›ï¼Œæ— éœ€å‘é€åˆ°LLM
    time_query_patterns = [
        r'å½“å‰.*æ—¶é—´|å½“å‰ç³»ç»Ÿæ—¶é—´', r'ç°åœ¨.*å‡ ç‚¹|å‡ ç‚¹é’Ÿ', r'å‡ ç‚¹|ä»€ä¹ˆæ—¶é—´',
        r'æ—¶é—´æ˜¯|ç°åœ¨æ˜¯', r'now.*time|what.*time|current.*time'
    ]
    if any(re.search(pattern, user_input, re.IGNORECASE) for pattern in time_query_patterns):
        def quick_time_response():
            from datetime import datetime
            
            now = datetime.now()
            date_str = now.strftime("%Yå¹´%mæœˆ%dæ—¥")
            weekday = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][now.weekday()]
            time_str = now.strftime("%H:%M:%S")
            timestamp = now.isoformat()  # è®°å½•ç²¾ç¡®æ—¶é—´æˆ³
            response = f"å½“å‰ç³»ç»Ÿæ—¶é—´ä¸ºï¼š\n\n**{date_str} {weekday} {time_str}**"
            
            # è®°å½•åˆ°å†å²ï¼ˆç”¨æˆ· + æ¨¡å‹ï¼Œå‡å¸¦æ—¶é—´æˆ³ï¼‰
            try:
                session_manager.append_and_save(
                    f"{session_name}.json",
                    user_input,
                    response,
                    task="CHAT",
                    model_name="QuickResponse",
                    timestamp=timestamp,
                    user_timestamp=timestamp,
                    model_timestamp=timestamp,
                )
            except Exception as e:
                print(f"[STREAM] Quick time history save failed: {e}")
            
            yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“… ç³»ç»Ÿæ—¶é—´æŸ¥è¯¢', 'detail': 'ä»æœ¬åœ°è·å–'}, ensure_ascii=False)}\n\n"
            yield f"data: {json.dumps({'type': 'token', 'content': response, 'timestamp': timestamp}, ensure_ascii=False)}\n\n"
            yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': 0.01, 'timestamp': timestamp}, ensure_ascii=False)}\n\n"
        
        return Response(quick_time_response(), mimetype='text/event-stream')
    
    # ğŸ¯ è·å–åŠ¨æ€ç³»ç»ŸæŒ‡ä»¤ï¼ˆæ ¹æ®ç”¨æˆ·é—®é¢˜æ™ºèƒ½æ³¨å…¥ä¸Šä¸‹æ–‡ï¼‰
    try:
        system_instruction = _get_chat_system_instruction(user_input)
    except Exception as e:
        print(f"[STREAM] Warning: Dynamic system instruction failed: {e}")
        system_instruction = _get_DEFAULT_CHAT_SYSTEM_INSTRUCTION()  # é™çº§åˆ°æ–°é²œç”Ÿæˆçš„æŒ‡ä»¤
    
    history = session_manager.load(f"{session_name}.json")
    
    # ğŸ•µï¸â€â™€ï¸ æ£€æµ‹æ˜¯å¦æœ‰æœ€è¿‘ä¸Šä¼ çš„æ–‡ä»¶ (5åˆ†é’Ÿå†…)
    has_recent_upload = False
    recent_file_type = None
    try:
        upload_scan_dirs = ["web/uploads", "uploads", "workspace/documents"]
        recent_threshold = time.time() - 300 # 5åˆ†é’Ÿå†…
        for d in upload_scan_dirs:
            if os.path.exists(d):
                for f in os.listdir(d):
                    fp = os.path.join(d, f)
                    if os.path.isfile(fp) and os.path.getmtime(fp) > recent_threshold:
                        has_recent_upload = True
                        _, ext = os.path.splitext(f)
                        recent_file_type = ext.lower()
                        print(f"[STREAM] Found recent upload: {f} ({recent_file_type})")
                        break
            if has_recent_upload: break
    except Exception as e:
        print(f"[STREAM] Error checking uploads: {e}")

    # ç¡®å®šä»»åŠ¡ç±»å‹å’Œæ¨¡å‹
    context_info = None
    if locked_task:
        task_type = locked_task
        route_method = "ğŸ”’ Manual"
        print(f"[STREAM] âœ… Using locked_task: '{task_type}'")
    else:
        # å°†æ–‡ä»¶ä¿¡æ¯ä¼ é€’ç»™åˆ†æå™¨
        context_override = {"has_file": has_recent_upload, "file_type": recent_file_type}
        task_type, route_method, context_info = SmartDispatcher.analyze(user_input, history, file_context=context_override)
        print(f"[STREAM] Auto-detected task_type: '{task_type}', context: {context_info is not None}")

        
        # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè®°å½•è¯¦æƒ…
        if context_info and context_info.get("is_continuation"):
            print(f"[STREAM] Context continuation: {context_info.get('related_task')}, confidence: {context_info.get('confidence')}")
    
    # === å¤„ç†å¤æ‚ä»»åŠ¡ (å¤šæ­¥æµç¨‹) ===
    if task_type == "MULTI_STEP" and context_info and context_info.get("is_multi_step_task"):
        print(f"[STREAM] ğŸ”„ æ£€æµ‹åˆ°å¤æ‚ä»»åŠ¡ï¼Œä½¿ç”¨ TaskOrchestrator æ‰§è¡Œå¤šæ­¥æµç¨‹")
        multi_step_info = context_info.get("multi_step_info", {})
        pattern = multi_step_info.get("pattern", "unknown")
        
        # === æ–‡æ¡£å·¥ä½œæµæ‰§è¡Œ ===
        if pattern == "document_workflow" and DocumentWorkflowExecutor:
            print(f"[STREAM] ğŸ“„ æ‰§è¡Œæ–‡æ¡£å·¥ä½œæµ")
            
            def generate_doc_workflow():
                yield f"data: {json.dumps({'type': 'classification', 'task_type': 'DOC_WORKFLOW', 'pattern': 'document_workflow', 'route_method': route_method, 'message': 'ğŸ¯ ä»»åŠ¡åˆ†ç±»: ğŸ“„ æ–‡æ¡£å·¥ä½œæµæ‰§è¡Œ'})}\n\n"
                
                # æŸ¥æ‰¾æœ€è¿‘ä¸Šä¼ çš„æ–‡æ¡£
                doc_path = None
                upload_dirs = ["web/uploads", "uploads", "workspace/documents"]
                
                for dir_path in upload_dirs:
                    if os.path.exists(dir_path):
                        docs = []
                        for ext in [".docx", ".md", ".txt", ".json"]:
                            import glob
                            docs.extend(glob.glob(f"{dir_path}/**/*{ext}", recursive=True))
                        
                        if docs:
                            # è·å–æœ€æ–°çš„æ–‡æ¡£
                            doc_path = max(docs, key=os.path.getmtime)
                            break
                
                if not doc_path:
                    yield f"data: {json.dumps({'type': 'error', 'message': 'âŒ æœªæ‰¾åˆ°å¯æ‰§è¡Œçš„æ–‡æ¡£æ–‡ä»¶ï¼ˆæ”¯æŒ .docx, .md, .txt, .jsonï¼‰'})}\n\n"
                    return
                
                status_msg = f"ğŸ“„ æ‰¾åˆ°æ–‡æ¡£: {os.path.basename(doc_path)}\n"
                yield f"data: {json.dumps({'type': 'status', 'message': status_msg})}\n\n"
                
                try:
                    import asyncio
                    
                    # æ‰§è¡Œæ–‡æ¡£å·¥ä½œæµ
                    executor = DocumentWorkflowExecutor(client)
                    
                    # åŠ è½½å·¥ä½œæµ
                    status_msg = "â³ æ­£åœ¨è§£ææ–‡æ¡£ä¸­çš„å·¥ä½œæµ...\n"
                    yield f"data: {json.dumps({'type': 'status', 'message': status_msg})}\n\n"
                    
                    load_result = asyncio.run(executor.load_from_document(doc_path))
                    
                    if not load_result.get("success"):
                        error_msg = f"âŒ æ–‡æ¡£è§£æå¤±è´¥: {load_result.get('error', 'æœªçŸ¥é”™è¯¯')}\n"
                        yield f"data: {json.dumps({'type': 'error', 'message': error_msg})}\n\n"
                        return
                    
                    # æ˜¾ç¤ºå·¥ä½œæµä¿¡æ¯
                    info_msg = f"âœ… å·¥ä½œæµåŠ è½½æˆåŠŸ\n"
                    info_msg += f"   åç§°: {executor.workflow_name}\n"
                    info_msg += f"   æ­¥éª¤æ•°: {len(executor.steps)}\n"
                    info_msg += f"   èƒŒæ™¯: {executor.workflow_context}\n\n"
                    yield f"data: {json.dumps({'type': 'status', 'message': info_msg})}\n\n"
                    
                    # æ˜¾ç¤ºæ‰€æœ‰æ­¥éª¤
                    steps_msg = "ğŸ“‹ å·¥ä½œæµæ­¥éª¤:\n"
                    for step in executor.steps:
                        steps_msg += f"  {step.step_id}. [{step.step_type}] {step.description}\n"
                    steps_msg += "\n"
                    yield f"data: {json.dumps({'type': 'status', 'message': steps_msg})}\n\n"
                    
                    # æ‰§è¡Œå·¥ä½œæµï¼ˆæµå¼åé¦ˆæ¯ä¸ªæ­¥éª¤ï¼‰
                    start_msg = "ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...\n\n"
                    yield f"data: {json.dumps({'type': 'status', 'message': start_msg})}\n\n"
                    
                    for step in executor.steps:
                        step_msg = f"[æ­¥éª¤ {step.step_id}/{len(executor.steps)}] {step.description}\n"
                        step_msg += f"â””â”€ ç±»å‹: {step.step_type}\n"
                        step_msg += f"   â³ æ‰§è¡Œä¸­...\n"
                        yield f"data: {json.dumps({'type': 'status', 'message': step_msg})}\n\n"
                        
                        step.status = "running"
                        step.start_time = datetime.now()
                        
                        try:
                            # æ‰§è¡Œæ­¥éª¤
                            step_result = asyncio.run(executor._execute_step_standalone(step))
                            step.result = step_result
                            step.status = "completed"
                            
                            success_msg = f"   âœ… å®Œæˆ\n"
                            if isinstance(step_result, dict) and step_result.get("output"):
                                output_preview = str(step_result['output'])[:200]
                                success_msg += f"   ğŸ“„ è¾“å‡ºé¢„è§ˆ: {output_preview}...\n"
                            success_msg += "\n"
                            yield f"data: {json.dumps({'type': 'status', 'message': success_msg})}\n\n"
                            
                        except Exception as e:
                            step.status = "failed"
                            step.error = str(e)
                            error_msg = f"   âŒ å¤±è´¥: {e}\n\n"
                            yield f"data: {json.dumps({'type': 'status', 'message': error_msg})}\n\n"
                        
                        finally:
                            step.end_time = datetime.now()
                    
                    # ç”Ÿæˆç»“æœ
                    results = {
                        "workflow_name": executor.workflow_name,
                        "start_time": datetime.now().isoformat(),
                        "steps": [step.to_dict() for step in executor.steps],
                        "overall_status": "completed"
                    }
                    results["summary"] = executor._generate_summary(results)
                    
                    # ä¿å­˜ç»“æœ
                    output_path = asyncio.run(executor.save_results(results))
                    
                    # å‘é€å®Œæˆæ¶ˆæ¯
                    separator = "=" * 50
                    final_msg = f"\n{separator}\n"
                    final_msg += f"âœ… æ–‡æ¡£å·¥ä½œæµæ‰§è¡Œå®Œæˆ\n\n"
                    final_msg += f"ğŸ“Š æ‰§è¡Œç»Ÿè®¡:\n"
                    total = len(results["steps"])
                    completed = sum(1 for s in results["steps"] if s["status"] == "completed")
                    failed = sum(1 for s in results["steps"] if s["status"] == "failed")
                    final_msg += f"  æ€»æ­¥éª¤: {total}\n"
                    final_msg += f"  æˆåŠŸ: {completed}\n"
                    final_msg += f"  å¤±è´¥: {failed}\n"
                    final_msg += f"  æˆåŠŸç‡: {completed/total*100:.1f}%\n\n"
                    final_msg += f"ğŸ“ ç»“æœå·²ä¿å­˜: {os.path.basename(output_path)}\n"
                    final_msg += f"ğŸ“‚ ä½ç½®: `workspace/workflows/`\n\n"
                    final_msg += f"{separator}\n"
                    
                    yield f"data: {json.dumps({'type': 'token', 'content': final_msg})}\n\n"
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [output_path]})}\n\n"
                    
                    # ä¿å­˜æ–‡æ¡£å·¥ä½œæµå¯¹è¯å†å²ï¼ˆåŸºäºç£ç›˜å®Œæ•´å†å²è¿½åŠ ï¼‰
                    try:
                        session_manager.append_and_save(f"{session_name}.json", user_input, f"[æ–‡æ¡£å·¥ä½œæµå®Œæˆ] {executor.workflow_name}")
                    except Exception:
                        pass
                    
                except Exception as e:
                    import traceback
                    error_detail = traceback.format_exc()
                    error_msg = f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}\n{error_detail}"
                    yield f"data: {json.dumps({'type': 'error', 'message': error_msg})}\n\n"
                    # ä¿å­˜å¤±è´¥è®°å½•
                    try:
                        session_manager.append_and_save(f"{session_name}.json", user_input, f"[æ–‡æ¡£å·¥ä½œæµå¤±è´¥] {str(e)[:200]}")
                    except Exception:
                        pass
            
            return Response(generate_doc_workflow(), mimetype='text/event-stream')
        
        # === å…¶ä»–å¤šæ­¥ä»»åŠ¡æ‰§è¡Œ ===
        from app.core.routing import TaskDecomposer
        subtasks = TaskDecomposer.create_subtasks(user_input, multi_step_info)
        use_local_planner = (multi_step_info.get("pattern") == "local_plan")
        
        def generate_multi_step():
            # === ç«‹å³å‘é€ä»»åŠ¡åˆ†ç±»ä¿¡æ¯ ===
            pattern = multi_step_info.get("pattern", "unknown")
            classification_msg = f"ğŸ¯ ä»»åŠ¡åˆ†ç±»: ğŸ”„ å¤šæ­¥ä»»åŠ¡\n"
            yield f"data: {json.dumps({'type': 'classification', 'task_type': 'MULTI_STEP', 'pattern': pattern, 'route_method': route_method, 'message': classification_msg})}\n\n"
            
            # æ˜¾ç¤ºæ‰€æœ‰å­ä»»åŠ¡
            status_msg = f"ğŸ“‹ ä»»åŠ¡åˆ†è§£:\n"
            for i, subtask in enumerate(subtasks):
                status_msg += f"  {i+1}. {subtask['task_type']} - {subtask['description']}\n"
            status_msg += "\n"
            yield f"data: {json.dumps({'type': 'status', 'message': status_msg})}\n\n"
            
            # æ‰§è¡Œæ‰€æœ‰å­ä»»åŠ¡ï¼ˆé€æ­¥æµå¼åé¦ˆï¼‰
            try:
                import asyncio
                execution_log = []
                step_results = []
                context = {"original_input": user_input, "user_input": user_input}
                saved_files = []
                
                for i, subtask in enumerate(subtasks):
                    # å‘é€ä»»åŠ¡ç‰¹å®šçš„è¿›åº¦æç¤º
                    _step_icons = {
                        "WEB_SEARCH": "ğŸ”", "RESEARCH": "ğŸ”¬", "PAINTER": "ğŸ¨",
                        "FILE_GEN": "ğŸ“„", "CODER": "ğŸ’»"
                    }
                    _task_type = subtask["task_type"]
                    _step_icon = _step_icons.get(_task_type, "âš™ï¸")
                    step_msg = f"{_step_icon} æ­¥éª¤ {i+1}/{len(subtasks)}: {subtask['description']}"
                    _detail = f"ä»»åŠ¡ç±»å‹: {_task_type}"
                    yield f"data: {json.dumps({'type': 'progress', 'message': step_msg, 'detail': _detail})}\n\n"
                    
                    step_input = subtask.get("input") or user_input
                    
                    # ä½¿ç”¨é˜Ÿåˆ—æ¥æ”¶æ¥è‡ªåå°çº¿ç¨‹çš„å®æ—¶è¿›åº¦
                    import queue
                    import threading
                    progress_queue = queue.Queue()
                    
                    def _progress_cb(msg, detail=""):
                        progress_queue.put({"msg": msg, "detail": detail})
                        
                    task_result_holder = {"result": None}
                    
                    def _run_task_thread():
                        try:
                            # Running asyncio.run inside a thread is tricky if not handled well, but here it's a fresh thread.
                            # We pass _progress_cb to updated methods.
                            if subtask["task_type"] == "WEB_SEARCH":
                                task_result_holder["result"] = asyncio.run(TaskOrchestrator._execute_web_search(step_input, context, progress_callback=_progress_cb))
                            elif subtask["task_type"] == "FILE_GEN":
                                # FILE_GEN likely already supports it or ignores extra args if using **kwargs in some versions, 
                                # but based on context it takes it as 4th arg or kwarg.
                                task_result_holder["result"] = asyncio.run(TaskOrchestrator._execute_file_gen(step_input, context, subtask, progress_callback=_progress_cb))
                            elif subtask["task_type"] == "PAINTER":
                                task_result_holder["result"] = asyncio.run(TaskOrchestrator._execute_painter(step_input, context, progress_callback=_progress_cb))
                            elif subtask["task_type"] == "RESEARCH":
                                task_result_holder["result"] = asyncio.run(TaskOrchestrator._execute_research(step_input, context, progress_callback=_progress_cb))
                            else:
                                # Fallback for unknown
                                task_result_holder["result"] = {"success": False, "error": f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {subtask['task_type']}"}
                        except Exception as e:
                            import traceback
                            traceback.print_exc()
                            task_result_holder["result"] = {"success": False, "error": str(e)}
                        finally:
                            progress_queue.put(None) # Signal done

                    # å¯åŠ¨åå°çº¿ç¨‹æ‰§è¡Œä»»åŠ¡
                    t = threading.Thread(target=_run_task_thread)
                    t.start()
                    
                    # ä¸»çº¿ç¨‹å¾ªç¯è¯»å–è¿›åº¦
                    while True:
                        try:
                            item = progress_queue.get(timeout=0.1)
                            if item is None:
                                break
                            # å‘é€è¿›åº¦SSE
                            yield f"data: {json.dumps({'type': 'progress', 'message': item['msg'], 'detail': item['detail']})}\n\n"
                        except queue.Empty:
                            if not t.is_alive():
                                break
                                
                    t.join()
                    result = task_result_holder["result"]
                    
                    # å‘é€æ­¥éª¤å®Œæˆè¿›åº¦
                    if result.get("success"):
                        _done_detail = result.get("output", "")[:60]
                        yield f"data: {json.dumps({'type': 'progress', 'message': f'âœ… æ­¥éª¤ {i+1} å®Œæˆ', 'detail': _done_detail})}\n\n"
                    else:
                        _err_detail = result.get("error", "æœªçŸ¥é”™è¯¯")[:60]
                        yield f"data: {json.dumps({'type': 'progress', 'message': f'âš ï¸ æ­¥éª¤ {i+1} é‡åˆ°é—®é¢˜', 'detail': _err_detail})}\n\n"
                    
                    subtask["status"] = "completed" if result.get("success") else "failed"
                    subtask["result"] = result
                    
                    context[f"{subtask['task_type']}_result"] = result
                    context[f"step_{i+1}_output"] = result.get("output", result.get("content", ""))
                    
                    if result.get("model_id"):
                        model_msg = f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {result['model_id']}\n"
                        yield f"data: {json.dumps({'type': 'status', 'message': model_msg})}\n\n"
                    
                    model_answer = result.get("content") or result.get("output")
                    if model_answer:
                        answer_msg = f"ğŸ§  æ¨¡å‹å›ç­”:\n{model_answer}\n\n"
                        yield f"data: {json.dumps({'type': 'status', 'message': answer_msg})}\n\n"
                    
                    if result.get("saved_files"):
                        saved_files.extend(result["saved_files"])
                    step_results.append(result)
                    
                    execution_log.append(f"  âœ… å®Œæˆ: {subtask['description']}")
                
                # è¾“å‡ºæœ€ç»ˆç»“æœ
                final_output = TaskOrchestrator._merge_results(subtasks, context)

                # 3. ç»“æœéªŒè¯ (User Requirement: Model Verification Feedback)
                # Tell user we are verifying
                yield f"data: {json.dumps({'type': 'status', 'message': 'ğŸ” æ­£åœ¨è¿›è¡Œæœ€ç»ˆè´¨é‡éªŒè¯...'})}\n\n"
                quality_score = asyncio.run(TaskOrchestrator._validate_quality(user_input, final_output, context))
                yield f"data: {json.dumps({'type': 'status', 'message': f'âœ… è´¨é‡éªŒè¯å®Œæˆï¼Œè¯„åˆ†: {quality_score}/100'})}\n\n"
                
                separator = "=" * 50
                output_text = f"\n{separator}\n"
                output_text += f"âœ… å¤šæ­¥ä»»åŠ¡å®Œæˆ\n"
                output_text += f"è´¨é‡è¯„åˆ†: {quality_score}/100\n"
                if saved_files:
                    output_text += f"å·²ä¿å­˜æ–‡ä»¶:\n"
                    # Add clickable links
                    for p in saved_files:
                        name = os.path.basename(p)
                        # Check if path is absolute or relative
                        link_path = p.replace("\\", "/")
                        if not link_path.startswith("http"):
                            # Assuming frontend can handle workspace relative paths or full paths exposed via virtual route
                            # Just output markdown link
                            output_text += f"- [{name}]({link_path})\n"
                    output_text += f"\nğŸ“‚ ä½ç½®: `{settings_manager.documents_dir}`\n"
                
                errors_list = []
                for subtask in subtasks:
                    if subtask.get("status") == "failed" and subtask.get("result"):
                        err = subtask["result"].get("error")
                        if err:
                            errors_list.append(err)
                if errors_list:
                    output_text += f"âš ï¸ é‡åˆ°çš„é—®é¢˜: {', '.join(errors_list)}\n"
                
                final_result = final_output.get('final_output', '(æ— è¾“å‡º)')
                # å¤æ‚ä»»åŠ¡å¿«é€Ÿè‡ªæ£€
                check = Utils.quick_self_check("MULTI_STEP", user_input, final_result)
                if not check.get("pass") and check.get("fix_prompt"):
                    status_msg = "ğŸ©º è‡ªæ£€æœªé€šè¿‡ï¼Œæ­£åœ¨ä¿®æ­£æœ€ç»ˆè¾“å‡º...\n"
                    yield f"data: {json.dumps({'type': 'status', 'message': status_msg})}\n\n"
                    fix_resp = client.models.generate_content(
                        model=SmartDispatcher.get_model_for_task("CHAT"),
                        contents=check["fix_prompt"],
                        config=types.GenerateContentConfig(
                            system_instruction=system_instruction,
                            temperature=0.4,
                            max_output_tokens=3000,
                        )
                    )
                    corrected = fix_resp.text or final_result
                    final_result = corrected
                if use_local_planner:
                    from app.core.routing import LocalPlanner
                    plan_check = LocalPlanner.self_check(user_input, subtasks, step_results)
                    status = plan_check.get("status", "partial")
                    summary = plan_check.get("summary", "")
                    next_actions = plan_check.get("next_actions", []) if isinstance(plan_check.get("next_actions", []), list) else []
                    output_text += f"\nè‡ªæ£€ç»“è®º: {status}\n"
                    if summary:
                        output_text += f"è¯´æ˜: {summary}\n"
                    if next_actions:
                        output_text += f"å»ºè®®åç»­: {', '.join(next_actions)}\n"
                output_text += f"\næœ€ç»ˆè¾“å‡º:\n{final_result}\n"
                output_text += f"{separator}\n"
                
                yield f"data: {json.dumps({'type': 'token', 'content': output_text})}\n\n"
                yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': saved_files})}\n\n"
                
            except Exception as e:
                yield f"data: {json.dumps({'type': 'error', 'message': f'å¤šæ­¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}'})}\n\n"
            
            # ä¿å­˜ MULTI_STEP å¯¹è¯å†å²ï¼ˆåŸºäºç£ç›˜å®Œæ•´å†å²è¿½åŠ ï¼‰
            try:
                _multi_summary = f"[å¤šæ­¥ä»»åŠ¡å®Œæˆ] {', '.join(s['description'] for s in subtasks)}"
                if saved_files:
                    _multi_summary += f"\nç”Ÿæˆæ–‡ä»¶: {', '.join(os.path.basename(p) for p in saved_files)}"
                session_manager.append_and_save(f"{session_name}.json", user_input, _multi_summary)
                print(f"[MULTI_STEP] âœ… å¯¹è¯å†å²å·²ä¿å­˜")
            except Exception as save_err:
                print(f"[MULTI_STEP] âš ï¸ ä¿å­˜å¯¹è¯å†å²å¤±è´¥: {save_err}")
        
        return Response(generate_multi_step(), mimetype='text/event-stream')
    
    # === Agent ä»»åŠ¡æ‰§è¡Œ ===
    if task_type == "AGENT":
        print(f"[STREAM] ğŸ¤– æ‰§è¡Œ Agent ä»»åŠ¡ (UnifiedAgent)")
        
        def generate_agent():
            # å‘é€åˆ†ç±»ä¿¡æ¯
            yield f"data: {json.dumps({'type': 'classification', 'task_type': 'AGENT', 'route_method': route_method, 'message': 'ğŸ¯ ä»»åŠ¡åˆ†ç±»: ğŸ¤– æ™ºèƒ½åŠ©æ‰‹ (å·¥å…·è°ƒç”¨)'})}\n\n"
            
            # ä½¿ç”¨ UnifiedAgent æ›¿ä»£æ—§ agent_loop
            try:
                from app.core.agent.factory import create_agent
                from app.core.agent.types import AgentStepType
                _ua = create_agent(model_id=SmartDispatcher.get_model_for_task("AGENT"))
                
                collected_steps = []
                final_answer = ""
                for step in _ua.run(input_text=user_input, history=history):
                    step_data = step.to_dict()
                    collected_steps.append(step_data)
                    if step.step_type == AgentStepType.ANSWER:
                        final_answer = step.content or ""
                    yield f"data: {json.dumps({'type': 'agent_step', 'data': step_data}, ensure_ascii=False)}\n\n"
                
                if not final_answer and collected_steps:
                    final_answer = collected_steps[-1].get('content', '')
                task_payload = {
                    'id': f'task_{int(time.time() * 1000)}',
                    'status': 'success',
                    'result': final_answer,
                    'steps': collected_steps,
                }
                yield f"data: {json.dumps({'type': 'task_final', 'data': task_payload}, ensure_ascii=False)}\n\n"
                
                # ä¿å­˜å¯¹è¯å†å²
                try:
                    session_manager.append_and_save(f"{session_name}.json", user_input, final_answer or '[Agent ä»»åŠ¡å®Œæˆ]')
                except Exception:
                    pass
            
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                print(f"[AGENT] âŒ Agent æ‰§è¡Œå¤±è´¥:\n{error_detail}")
                yield f"data: {json.dumps({'type': 'error', 'message': f'Agent æ‰§è¡Œå¤±è´¥: {str(e)}'})}\n\n"
        
        return Response(generate_agent(), mimetype='text/event-stream')
    
    if locked_model and locked_model != 'auto':
        model_id = locked_model
    else:
        # ä¼ é€’ complexity ä»¥ä¾¿ä¸ºå¤æ‚ä»»åŠ¡é€‰æ‹©æ›´å¼ºçš„æ¨¡å‹
        _complexity = (context_info or {}).get("complexity", "normal")
        model_id = SmartDispatcher.get_model_for_task(task_type, complexity=_complexity)
    
    print(f"[STREAM] Final: task_type='{task_type}', model_id='{model_id}'\n")
    
    # è¯»å–ç”¨æˆ·è®¾ç½®ï¼šæ˜¯å¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
    _show_thinking = False
    try:
        _show_thinking = settings_manager.get('ai', 'show_thinking') == True
    except:
        pass
    
    def generate():
        start_time = time.time()
        
        def yield_thinking(message: str, phase: str = "thinking"):
            """å‘é€æ€è€ƒè¿‡ç¨‹äº‹ä»¶ï¼ˆä»…å½“ç”¨æˆ·å¼€å¯ show_thinking æ—¶ï¼‰"""
            if not _show_thinking:
                return ""
            elapsed = round(time.time() - start_time, 1)
            return f"data: {json.dumps({'type': 'thinking', 'message': message, 'phase': phase, 'elapsed': elapsed}, ensure_ascii=False)}\n\n"
        
        # === ç«‹å³åé¦ˆä»»åŠ¡åˆ†ç±»ä¿¡æ¯ ===
        task_display_names = {
            "PAINTER": "ğŸ¨ å›¾åƒç”Ÿæˆ",
            "FILE_GEN": "ğŸ“„ æ–‡æ¡£ç”Ÿæˆ",
            "CODER": "ğŸ’» ä»£ç ç¼–ç¨‹",
            "RESEARCH": "ğŸ“š æ·±åº¦ç ”ç©¶",
            "WEB_SEARCH": "ğŸŒ å®æ—¶æœç´¢",
            "CHAT": "ğŸ’¬ å¯¹è¯",
            "SYSTEM": "ğŸ–¥ï¸ ç³»ç»Ÿæ“ä½œ",
            "FILE_OP": "ğŸ“‚ æ–‡ä»¶æ“ä½œ",
            "FILE_EDIT": "âœï¸ æ–‡ä»¶ç¼–è¾‘",
            "FILE_SEARCH": "ğŸ” æ–‡ä»¶æœç´¢",
            "VISION": "ğŸ‘ï¸ å›¾åƒè¯†åˆ«",
            "MULTI_STEP": "ğŸ”„ å¤šæ­¥ä»»åŠ¡",
            "AGENT": "ğŸ¤– æ™ºèƒ½åŠ©æ‰‹"
        }
        
        model_display = get_model_display_name(model_id)
        task_display = task_display_names.get(task_type, task_type)
        
        # å‘é€ä»»åŠ¡åˆ†ç±»ä¿¡æ¯ï¼ˆåœ¨æœ€å¼€å§‹ï¼Œç«‹å³æ˜¾ç¤ºï¼‰
        classification_msg = f"ğŸ¯ ä»»åŠ¡åˆ†ç±»: {task_display}"
        if route_method:
            classification_msg += f" (æ–¹æ³•: {route_method})"

        routing_list = None
        # ä»…ä¿ç•™ routing_list ç”¨äºå†…éƒ¨è°ƒè¯•ï¼Œä¸æ˜¾ç¤ºç»™ç”¨æˆ·
        if context_info and context_info.get("routing_list"):
            routing_list = context_info.get("routing_list")
        
        yield f"data: {json.dumps({'type': 'classification', 'task_type': task_type, 'task_display': task_display, 'model': model_id, 'model_display': model_display, 'route_method': route_method, 'routing_list': routing_list, 'message': classification_msg})}\n\n"
        
        # æ€è€ƒè¿‡ç¨‹ï¼šä»»åŠ¡è·¯ç”±åˆ†æ
        t = yield_thinking(f"åˆ†æç”¨æˆ·æ„å›¾ â†’ è¯†åˆ«ä¸º {task_display}", "routing")
        if t: yield t
        t = yield_thinking(f"è·¯ç”±æ–¹æ³•: {route_method}ï¼Œé€‰æ‹©æ¨¡å‹: {model_display}", "model")
        if t: yield t
        if routing_list:
            steps_str = " â†’ ".join([f"{r.get('method','?')}({r.get('confidence','?')})" for r in routing_list[:5]]) if isinstance(routing_list, list) else str(routing_list)
            t = yield_thinking(f"è·¯ç”±å†³ç­–é“¾: {steps_str}", "routing")
            if t: yield t
        
        # å¦‚æœæœ‰å¤æ‚åº¦ä¿¡æ¯ï¼Œä¹Ÿå‘é€
        if context_info and context_info.get("complexity"):
            complexity_msg = f"ğŸ“Š ä»»åŠ¡å¤æ‚åº¦: {context_info['complexity']}"
            yield f"data: {json.dumps({'type': 'info', 'message': complexity_msg})}\n\n"
            t = yield_thinking(f"ä»»åŠ¡å¤æ‚åº¦è¯„ä¼°: {context_info['complexity']}", "analyzing")
            if t: yield t
        
        # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨å¢å¼ºåçš„è¾“å…¥
        effective_input = user_input
        if context_info and context_info.get("is_continuation") and context_info.get("enhanced_input"):
            effective_input = context_info["enhanced_input"]
            print(f"[STREAM] Using enhanced input (length: {len(effective_input)})")
            yield f"data: {json.dumps({'type': 'info', 'message': 'ğŸ”— æ£€æµ‹åˆ°å»¶ç»­ä»»åŠ¡ï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡å¢å¼º'})}\n\n"
            t = yield_thinking(f"æ£€æµ‹åˆ°ä¸Šä¸‹æ–‡å»¶ç»­ï¼Œå¢å¼ºè¾“å…¥ ({len(effective_input)} å­—ç¬¦)", "context")
            if t: yield t

        # ä½¿ç”¨å¿«é€Ÿå°æ¨¡å‹å°†è¯·æ±‚è½¬ä¸ºç»“æ„åŒ– Markdownï¼ˆä»…å¯¹å¤§æ¨¡å‹ä»»åŠ¡å¯ç”¨ï¼‰
        if task_type not in ["SYSTEM", "FILE_OP", "PAINTER", "VISION"]:
            adapted_input = Utils.adapt_prompt_to_markdown(task_type, effective_input, history=history)
            if adapted_input != effective_input:
                effective_input = adapted_input
                yield f"data: {json.dumps({'type': 'info', 'message': 'ğŸ§¾ å·²å°†è¯·æ±‚ç»“æ„åŒ–ä¸ºMarkdownæç¤º'})}\n\n"
                t = yield_thinking("å°†ç”¨æˆ·è¯·æ±‚ç»“æ„åŒ–ä¸º Markdown æ ¼å¼ä»¥æå‡è¾“å‡ºè´¨é‡", "planning")
                if t: yield t
        
        # é‡ç½®ä¸­æ–­æ ‡å¿—ï¼ˆæ¯æ¬¡æ–°è¯·æ±‚éƒ½é‡ç½®ï¼‰
        _interrupt_manager.reset(session_name)
        interrupt_event = _interrupt_manager.get_event(session_name)

        def interrupted():
            return _interrupt_manager.is_interrupted(session_name)
        
        # å‘é€è¿›åº¦: å¼€å§‹å¤„ç†
        yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸš€ {task_type} ä»»åŠ¡å¼€å§‹...', 'detail': get_model_display_name(model_id)})}\n\n"
        
        try:
            # åˆå§‹åŒ–æ¨¡å‹è¿½è¸ªå˜é‡ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
            used_model = "unknown"
            
            # === SYSTEM Mode (æœ¬åœ°æ‰§è¡Œ - å³æ—¶) ===
            if task_type == "SYSTEM":
                used_model = "LocalExecutor"
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ–¥ï¸ æ­£åœ¨åˆ†æç³»ç»ŸæŒ‡ä»¤...', 'detail': ''})}\n\n"
                yield f"data: {json.dumps({'type': 'progress', 'message': 'âš¡ æ­£åœ¨æ‰§è¡Œæ“ä½œ...', 'detail': ''})}\n\n"
                
                exec_result = LocalExecutor.execute(user_input)
                response_text = exec_result["message"]
                if exec_result.get("details"):
                    response_text += f"\n\n{exec_result['details']}"
                
                if Utils.is_failure_output(response_text):
                    t = yield_thinking("ç³»ç»ŸæŒ‡ä»¤æ‰§è¡Œå¤±è´¥ï¼Œä½¿ç”¨ AI ä¿®æ­£åé‡è¯•", "validating")
                    if t: yield t
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'âš ï¸ åˆæ¬¡æ‰§è¡Œå¤±è´¥ï¼Œæ­£åœ¨ä¿®æ­£...', 'detail': ''})}\n\n"
                    fix_prompt = Utils.build_fix_prompt("SYSTEM", user_input, response_text)
                    fix_resp = client.models.generate_content(
                        model=model_id,
                        contents=fix_prompt,
                        config=types.GenerateContentConfig(
                            system_instruction=system_instruction,
                            temperature=0.4,
                            max_output_tokens=1000,
                        )
                    )
                    response_text = fix_resp.text or response_text
                
                yield f"data: {json.dumps({'type': 'token', 'content': response_text})}\n\n"
                
                # å…ˆä¿å­˜å†å²ï¼Œå†å‘é€ done äº‹ä»¶ï¼ˆé˜²æ­¢å®¢æˆ·ç«¯æ–­å¼€å¯¼è‡´ä¸¢å¤±ï¼‰
                session_manager.append_and_save(
                    f"{session_name}.json",
                    user_input,
                    response_text,
                    task=task_type,
                    model_name=used_model
                )
                
                total_time = time.time() - start_time
                yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                return
            
            # === FILE_OP Mode (æ–‡ä»¶æ“ä½œ - å³æ—¶) ===
            if task_type == "FILE_OP":
                used_model = "LocalExecutor"
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“‚ æ­£åœ¨åˆ†ææ–‡ä»¶æ“ä½œ...', 'detail': ''})}\n\n"
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ” æ­£åœ¨è®¿é—®æ–‡ä»¶ç³»ç»Ÿ...', 'detail': ''})}\n\n"

                batch_manager = get_batch_ops_manager()
                if batch_manager.is_batch_command(user_input):
                    parsed = batch_manager.parse_command(user_input)
                    if not parsed.get("success"):
                        response_text = f"âŒ {parsed.get('error')}\n\n{parsed.get('hint', '')}"
                        yield f"data: {json.dumps({'type': 'token', 'content': response_text})}\n\n"
                        session_manager.append_and_save(
                            f"{session_name}.json",
                            user_input,
                            response_text,
                            task="FILE_OP",
                            model_name=used_model
                        )
                        total_time = time.time() - start_time
                        yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                        return

                    job = batch_manager.create_job(
                        name=f"batch_{parsed.get('operation')}",
                        operation=parsed.get('operation'),
                        input_dir=parsed.get('input_dir'),
                        output_dir=parsed.get('output_dir'),
                        options=parsed.get('options', {})
                    )
                    batch_manager.start_job(job.job_id)
                    yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ§© å·²åˆ›å»ºæ‰¹é‡ä»»åŠ¡: {job.job_id}', 'detail': ''})}\n\n"

                    summary_text = None
                    for event in batch_manager.iter_job_events(job.job_id):
                        if event.get("type") == "progress":
                            current = event.get('current', 0)
                            total = event.get('total', 0)
                            progress_pct = int((current / total) * 100) if total else 0
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'â³ æ‰¹é‡å¤„ç†ä¸­...', 'detail': event.get('detail', ''), 'progress': progress_pct, 'total': total})}\n\n"
                        elif event.get("type") == "final":
                            summary_text = event.get("summary") or "âœ… æ‰¹é‡å¤„ç†å®Œæˆ"
                            break
                        elif event.get("type") == "error":
                            summary_text = event.get("message", "âŒ æ‰¹é‡ä»»åŠ¡å¤±è´¥")
                            break

                    if summary_text:
                        yield f"data: {json.dumps({'type': 'token', 'content': summary_text})}\n\n"
                        session_manager.append_and_save(
                            f"{session_name}.json",
                            user_input,
                            summary_text,
                            task="FILE_OP",
                            model_name=used_model
                        )

                    total_time = time.time() - start_time
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                    return
                
                file_result = FileOperator.execute(user_input)
                response_text = file_result["message"]
                if file_result.get("content"):
                    response_text += f"\n\n{file_result['content']}"
                
                if Utils.is_failure_output(response_text):
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'âš ï¸ åˆæ¬¡æ‰§è¡Œå¤±è´¥ï¼Œæ­£åœ¨ä¿®æ­£...', 'detail': ''})}\n\n"
                    fix_prompt = Utils.build_fix_prompt("FILE_OP", user_input, response_text)
                    fix_resp = client.models.generate_content(
                        model=model_id,
                        contents=fix_prompt,
                        config=types.GenerateContentConfig(
                            system_instruction=system_instruction,
                            temperature=0.4,
                            max_output_tokens=1000,
                        )
                    )
                    response_text = fix_resp.text or response_text
                
                yield f"data: {json.dumps({'type': 'token', 'content': response_text})}\n\n"
                
                # å…ˆä¿å­˜å†å²ï¼Œå†å‘é€ done äº‹ä»¶
                session_manager.append_and_save(
                    f"{session_name}.json",
                    user_input,
                    response_text,
                    task="FILE_OP",
                    model_name=used_model
                )
                
                total_time = time.time() - start_time
                yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                return
            
            # === FILE_EDIT Mode (æ–‡ä»¶ç¼–è¾‘ - æ™ºèƒ½ä¿®æ”¹) ===
            if task_type == "FILE_EDIT":
                used_model = model_id
                t = yield_thinking("è¿›å…¥æ–‡ä»¶ç¼–è¾‘æ¨¡å¼ï¼Œå°†ç†è§£ç”¨æˆ·æŒ‡ä»¤å¹¶ä¿®æ”¹æ–‡ä»¶", "routing")
                if t: yield t
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“ æ­£åœ¨åˆ†æç¼–è¾‘æŒ‡ä»¤...', 'detail': ''})}\n\n"
                
                editor = get_file_editor()
                
                # å°è¯•ä»ç”¨æˆ·è¾“å…¥ä¸­æå–æ–‡ä»¶è·¯å¾„å’ŒæŒ‡ä»¤
                # æ¨¡å¼ 1: "ä¿®æ”¹ path/to/file æŠŠxxxæ”¹æˆyyy"
                match = re.search(r'(?:ä¿®æ”¹|ç¼–è¾‘|æ”¹)\s+["\']?([^"\']+?)["\']?\s+(.+)', user_input)
                if not match:
                    # æ¨¡å¼ 2: "æŠŠ path/to/file çš„xxxæ”¹æˆyyy"
                    match = re.search(r'(?:æŠŠ|å°†)\s+["\']?([^"\']+?)["\']?\s+(?:çš„|ä¸­çš„|é‡Œçš„)\s*(.+)', user_input)
                
                if match:
                    file_path = match.group(1).strip()
                    instruction = match.group(2).strip()
                    
                    t = yield_thinking(f"æå–åˆ°æ–‡ä»¶è·¯å¾„: {file_path}, æŒ‡ä»¤: {instruction}", "analyzing")
                    if t: yield t
                    
                    yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ” ç›®æ ‡æ–‡ä»¶: {os.path.basename(file_path)}', 'detail': ''})}\n\n"
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'âœï¸ æ­£åœ¨æ‰§è¡Œç¼–è¾‘...', 'detail': ''})}\n\n"
                    
                    result = editor.smart_edit(file_path, instruction)
                    
                    if result["success"]:
                        operation = result.get("operation", "edit")
                        edit_result = result.get("result", {})
                        
                        response_text = f"âœ… æ–‡ä»¶ç¼–è¾‘æˆåŠŸï¼\n\n"
                        response_text += f"**æ“ä½œç±»å‹**: {operation}\n"
                        
                        if operation == "replace":
                            response_text += f"**æ›¿æ¢æ¬¡æ•°**: {edit_result.get('replacements', 0)}\n"
                            response_text += f"**é¢„è§ˆ**:\n```\n{edit_result.get('preview', '')}\n```"
                        elif operation == "delete_lines":
                            response_text += f"**åˆ é™¤å†…å®¹**:\n```\n{edit_result.get('deleted_content', '')}\n```"
                        elif operation == "insert_line":
                            response_text += f"**æ¶ˆæ¯**: {edit_result.get('message', '')}"
                        
                        if edit_result.get("backup"):
                            response_text += f"\n\nğŸ’¾ å¤‡ä»½æ–‡ä»¶: `{edit_result.get('backup')}`"
                    else:
                        error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                        hint = result.get("hint", "")
                        response_text = f"âŒ æ–‡ä»¶ç¼–è¾‘å¤±è´¥\n\n{error_msg}\n\n{hint}"
                else:
                    # æ— æ³•æå–æ–‡ä»¶è·¯å¾„ï¼Œè®©AIç†è§£
                    response_text = "âŒ æ— æ³•è¯†åˆ«æ–‡ä»¶è·¯å¾„å’Œç¼–è¾‘æŒ‡ä»¤\n\n"
                    response_text += "è¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼:\n"
                    response_text += "- `ä¿®æ”¹ æ–‡ä»¶è·¯å¾„ æŠŠ'æ—§æ–‡æœ¬'æ”¹æˆ'æ–°æ–‡æœ¬'`\n"
                    response_text += "- `æŠŠ æ–‡ä»¶è·¯å¾„ çš„ç¬¬5-10è¡Œåˆ é™¤`\n"
                    response_text += "- `ç¼–è¾‘ æ–‡ä»¶è·¯å¾„ åœ¨ç¬¬3è¡Œä¹‹åæ’å…¥'æ–°å†…å®¹'`"
                
                yield f"data: {json.dumps({'type': 'token', 'content': response_text})}\n\n"
                
                session_manager.append_and_save(
                    f"{session_name}.json",
                    user_input,
                    response_text,
                    task="FILE_EDIT",
                    model_name=used_model
                )
                
                total_time = time.time() - start_time
                yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                return
            
            # === FILE_SEARCH Mode (æ–‡ä»¶æœç´¢ - å†…å®¹å®šä½) ===
            if task_type == "FILE_SEARCH":
                used_model = "FileIndexer (Local)"
                t = yield_thinking("è¿›å…¥æ–‡ä»¶æœç´¢æ¨¡å¼ï¼Œå°†åœ¨ç´¢å¼•ä¸­æŸ¥æ‰¾åŒ¹é…æ–‡ä»¶", "searching")
                if t: yield t
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ” æ­£åœ¨æœç´¢æ–‡ä»¶...', 'detail': ''})}\n\n"
                
                indexer = get_file_indexer()
                
                # æå–æœç´¢å…³é”®è¯
                keywords = user_input.replace("æ‰¾æ–‡ä»¶", "").replace("æœç´¢", "").replace("æŸ¥æ‰¾", "")
                keywords = keywords.replace("åŒ…å«", "").replace("çš„æ–‡ä»¶", "").strip()
                
                t = yield_thinking(f"æœç´¢å…³é”®è¯: {keywords}", "searching")
                if t: yield t
                
                # å…ˆå°è¯•å…¨æ–‡æœç´¢
                results = indexer.search(keywords, limit=10)
                
                if not results:
                    # å¦‚æœæ²¡æœ‰ç»“æœï¼Œå°è¯•å†…å®¹ç›¸ä¼¼åº¦æœç´¢
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ”„ æ‰©å±•æœç´¢èŒƒå›´...', 'detail': ''})}\n\n"
                    results = indexer.find_by_content(keywords, min_similarity=0.2)
                
                if results:
                    response_text = f"ğŸ” æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…æ–‡ä»¶:\n\n"
                    
                    for i, r in enumerate(results[:10], 1):
                        file_name = r.get("file_name", "æœªçŸ¥æ–‡ä»¶")
                        file_path = r.get("file_path", "")
                        snippet = r.get("match_snippet", "")
                        score = r.get("score", 0)
                        similarity = r.get("similarity")
                        
                        response_text += f"### {i}. {file_name}\n"
                        response_text += f"ğŸ“ è·¯å¾„: `{file_path}`\n"
                        
                        if similarity:
                            response_text += f"ğŸ¯ ç›¸ä¼¼åº¦: {similarity:.0%}\n"
                        elif score:
                            response_text += f"â­ åŒ¹é…åˆ†: {score:.2f}\n"
                        
                        if snippet:
                            snippet_clean = snippet.replace("**", "**`")[:200]
                            response_text += f"ğŸ“„ é¢„è§ˆ: {snippet_clean}...\n"
                        
                        response_text += "\n"
                else:
                    response_text = "âŒ æœªæ‰¾åˆ°åŒ¹é…æ–‡ä»¶\n\n"
                    response_text += "ğŸ’¡ æç¤º:\n"
                    response_text += "- ç¡®ä¿æ–‡ä»¶å·²è¢«ç´¢å¼•ï¼ˆKoto å¤„ç†è¿‡çš„æ–‡ä»¶ä¼šè‡ªåŠ¨ç´¢å¼•ï¼‰\n"
                    response_text += "- å°è¯•ä½¿ç”¨æ›´å…·ä½“çš„å…³é”®è¯\n"
                    response_text += f"- å½“å‰ç´¢å¼•æ–‡ä»¶æ•°: {len(indexer.list_indexed_files(limit=1000))}"
                
                yield f"data: {json.dumps({'type': 'token', 'content': response_text})}\n\n"
                
                session_manager.append_and_save(
                    f"{session_name}.json",
                    user_input,
                    response_text,
                    task="FILE_SEARCH",
                    model_name=used_model
                )
                
                total_time = time.time() - start_time
                yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                return
            
            # === DOC_ANNOTATE Mode (æ–‡æ¡£æ ‡æ³¨/æ¶¦è‰² - æµå¼åé¦ˆ) ===
            if task_type == "DOC_ANNOTATE":
                used_model = model_id if model_id else "gemini-3-flash-preview"
                t = yield_thinking(f"è¿›å…¥æ–‡æ¡£æ ‡æ³¨æ¨¡å¼ï¼Œå°†ä½¿ç”¨ {model_id or 'gemini-3-flash-preview'} åˆ†ææ–‡æ¡£", "routing")
                if t: yield t
                print(f"[STREAM] ğŸ“„ æ‰§è¡Œ DOC_ANNOTATE ä»»åŠ¡")
                
                # ä»è¯·æ±‚ä¸­è·å–task_idï¼Œç”¨äºæ”¯æŒå–æ¶ˆæ“ä½œ
                task_id = request.json.get('task_id')
                
                # æŸ¥æ‰¾æœ€è¿‘ä¸Šä¼ çš„æ–‡æ¡£
                doc_path = None
                upload_dirs = ["web/uploads", "uploads", "workspace/documents"]
                
                for dir_path in upload_dirs:
                    if os.path.exists(dir_path):
                        import glob
                        docs = []
                        for ext in [".docx", ".docxm"]:
                            docs.extend(glob.glob(f"{dir_path}/**/*{ext}", recursive=True))
                        if docs:
                            doc_path = max(docs, key=os.path.getmtime)
                            break
                
                if not doc_path or not os.path.exists(doc_path):
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'âŒ æœªæ‰¾åˆ° Word æ–‡æ¡£', 'detail': 'è¯·ä¸Šä¼  .docx æ–‡ä»¶'})}\n\n"
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': []})}\n\n"
                    return
                
                # Step 1: è¯»å–æ–‡æ¡£ä¿¡æ¯
                yield f"data: {json.dumps({'type': 'progress', 'stage': 'init_reading', 'message': 'ğŸ“– æ­£åœ¨è¯»å–æ–‡æ¡£...', 'detail': os.path.basename(doc_path)})}\n\n"
                
                doc_filename = os.path.basename(doc_path)
                total_chars = 0
                total_paras = 0
                
                try:
                    from docx import Document
                    doc = Document(doc_path)
                    total_paras = len([p for p in doc.paragraphs if p.text.strip()])
                    total_chars = sum(len(p.text) for p in doc.paragraphs)
                    
                    yield f"data: {json.dumps({'type': 'progress', 'stage': 'init_reading_complete', 'message': f'âœ… æ–‡æ¡£è§£æå®Œæˆ', 'detail': f'{doc_filename}: {total_paras} æ®µ  |  {total_chars} å­—'})}\n\n"
                except Exception as e:
                    yield f"data: {json.dumps({'type': 'error', 'message': f'âŒ è¯»å–æ–‡æ¡£å¤±è´¥: {str(e)}'})}\n\n"
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': []})}\n\n"
                    return
                
                # Step 2: å±•ç¤ºä»»åŠ¡ä¿¡æ¯
                nl = '\n'
                task_info_msg = f'ğŸ“‹ ã€ä»»åŠ¡ä¿¡æ¯ã€‘{nl}- æ¨¡å‹: {model_id}{nl}- éœ€æ±‚: {user_input[:100]}{nl}- æ–‡æ¡£: {doc_filename}'
                yield f"data: {json.dumps({'type': 'info', 'message': task_info_msg})}\n\n"
                
                try:
                    from web.document_feedback import DocumentFeedbackSystem
                    feedback_system = DocumentFeedbackSystem(gemini_client=client)
                    
                    # ä½¿ç”¨æµå¼åˆ†æç³»ç»Ÿï¼Œé€æ­¥åé¦ˆè¿›åº¦
                    yield f"data: {json.dumps({'type': 'progress', 'stage': 'processing_start', 'message': 'ğŸ” å¼€å§‹å¤„ç†æ–‡æ¡£...', 'detail': 'è¿™ä¸ªè¿‡ç¨‹ä¼šæ¶‰åŠå¤šä¸ªé˜¶æ®µ'})}\n\n"
                    
                    revised_file = None
                    final_result = None
                    cancelled = False
                    
                    # è¿­ä»£æµå¼ç»“æœï¼Œä¼ å…¥task_idç”¨äºæ”¯æŒå–æ¶ˆ
                    for progress_event in feedback_system.full_annotation_loop_streaming(
                        doc_path,
                        user_input,
                        task_id=task_id,
                        model_id=model_id,
                        cancel_check=lambda: _interrupt_manager.is_interrupted(session_name)
                    ):
                        stage = progress_event.get('stage', 'unknown')
                        progress = progress_event.get('progress', 0)
                        message = progress_event.get('message', '')
                        detail = progress_event.get('detail', '')
                        
                        # å¤„ç†ä»»åŠ¡å–æ¶ˆ
                        if stage == 'cancelled':
                            cancelled = True
                            yield f"data: {json.dumps({'type': 'info', 'message': 'â¸ï¸ ä»»åŠ¡å·²å–æ¶ˆ', 'detail': 'ç”¨æˆ·ä¸­æ­¢äº†å¤„ç†'})}\n\n"
                            break
                        
                        # æ ¹æ®é˜¶æ®µå‘é€ä¸åŒæ ·å¼çš„è¿›åº¦ä¿¡æ¯
                        yield f"data: {json.dumps({'type': 'progress', 'stage': stage, 'message': message, 'detail': detail, 'progress': progress})}\n\n"
                        
                        # ä¿å­˜æœ€ç»ˆç»“æœ
                        if stage == 'complete':
                            final_result = progress_event.get('result', {})
                            revised_file = final_result.get('revised_file')
                    
                    # å¦‚æœä»»åŠ¡è¢«å–æ¶ˆï¼Œè¿”å›å–æ¶ˆå“åº”
                    if cancelled:
                        total_time = time.time() - start_time
                        # ä¿å­˜å–æ¶ˆè®°å½•åˆ°å†å²
                        session_manager.append_and_save(f"{session_name}.json", user_input, "â¸ï¸ æ–‡æ¡£æ ‡æ³¨ä»»åŠ¡å·²å–æ¶ˆ")
                        yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time, 'cancelled': True})}\n\n"
                        return
                    
                    # å¦‚æœå¤„ç†æˆåŠŸï¼Œç”Ÿæˆè¯¦ç»†æ€»ç»“
                    if final_result and final_result.get('success'):
                        applied = final_result.get('applied', 0)
                        failed = final_result.get('failed', 0)
                        total = final_result.get('total', applied + failed)
                        
                        # è®¡ç®—ä¿®æ”¹å¯†åº¦
                        density = (applied / total_chars * 1000) if total_chars > 0 else 0
                        
                        summary_msg = (
                            f"âœ… **æ–‡æ¡£ä¿®æ”¹å®Œæˆï¼**\n\n"
                            f"ğŸ“Š **æµ‹è¯•ç»“æœ**ï¼š\n"
                            f"- **æ–‡æ¡£åˆ†æ**ï¼šæˆåŠŸè¯»å– {total_paras} æ®µï¼Œå…± {total_chars} å­—ã€‚\n"
                            f"- **AI å¤„ç†**ï¼šæ–‡æ¡£è¢«å¹¶å‘å¤„ç†ï¼Œæ€»è€—æ—¶çº¦ {int(time.time() - start_time)} ç§’ã€‚\n"
                            f"- **ç”Ÿæˆè´¨é‡**ï¼šAI æˆåŠŸæ‰¾å‡ºäº† **{total} å¤„** ç¿»è¯‘ç”Ÿç¡¬ã€è¯­åºä¸é¡ºçš„åœ°æ–¹ã€‚\n"
                            f"- **åº”ç”¨ä¿®è®¢**ï¼šæˆåŠŸå°† **{applied} å¤„** ä¿®æ”¹ä»¥â€œä¿®è®¢æ¨¡å¼ï¼ˆTrack Changesï¼‰â€å†™å…¥äº† Word æ–‡æ¡£ï¼ˆä»…æœ‰ {failed} å¤„å› å¤æ‚æ ¼å¼å®šä½å¤±è´¥ï¼Œå±äºæ­£å¸¸å®¹é”™èŒƒå›´ï¼‰ã€‚\n\n"
                            f"ğŸ“‚ **éªŒè¯æ–‡ä»¶**ï¼š\n"
                            f"é«˜è´¨é‡çš„æµ‹è¯•ç»“æœæ–‡ä»¶å·²ç»ç”Ÿæˆåœ¨æ‚¨çš„æœ¬åœ°ç›®å½•ä¸­ï¼Œæ‚¨å¯ä»¥ç›´æ¥æ‰“å¼€æŸ¥çœ‹æ•ˆæœï¼š\n"
                            f"ğŸ‘‰ `{os.path.basename(revised_file) if revised_file else 'å¾…ç”Ÿæˆ'}`\n\n"
                            f"ğŸ’¡ **ä½¿ç”¨æ–¹æ³•**ï¼š\n"
                            f"1. ç”¨ Microsoft Word æ‰“å¼€è¾“å‡ºæ–‡ä»¶\n"
                            f"2. ç‚¹å‡»ã€Œå®¡é˜…ã€æ ‡ç­¾é¡µ\n"
                            f"3. å³ä¾§æ°”æ³¡ä¸­æŸ¥çœ‹å…¨éƒ¨ä¿®æ”¹å»ºè®®\n"
                            f"4. é€æ¡æ¥å—æˆ–å¿½ç•¥ï¼ˆå³é”®æ‰¹æ³¨å¯æ“ä½œï¼‰\n"
                            f"5. ç‚¹å‡»ã€Œæ¥å—å…¨éƒ¨ã€æˆ–é€æ¡å¤„ç†\n\n"
                            f"ğŸ“‚ **æ–‡ä»¶ä½ç½®**: `{os.path.dirname(revised_file) if revised_file else settings_manager.documents_dir}`"
                        )
                        
                        yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...', 'detail': ''})}\n\n"
                        yield f"data: {json.dumps({'type': 'token', 'content': summary_msg})}\n\n"
                        
                        # ä¿å­˜å¯¹è¯å†å²ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
                        session_manager.append_and_save(
                            f"{session_name}.json", user_input, summary_msg,
                            task="DOC_ANNOTATE", model_name=model_id,
                            saved_files=[revised_file] if revised_file else []
                        )
                        
                        total_time = time.time() - start_time
                        yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [revised_file] if revised_file else [], 'total_time': total_time})}\n\n"
                    else:
                        error_msg = final_result.get('message', 'æœªçŸ¥é”™è¯¯') if final_result else 'å¤„ç†å¤±è´¥'
                        # ä¿å­˜å¤±è´¥è®°å½•
                        session_manager.append_and_save(f"{session_name}.json", user_input, f"âŒ æ–‡æ¡£æ ‡æ³¨å¤±è´¥: {error_msg}")
                        yield f"data: {json.dumps({'type': 'error', 'message': f'âŒ å¤„ç†å¤±è´¥: {error_msg}'})}\n\n"
                        
                        total_time = time.time() - start_time
                        yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                
                except Exception as e:
                    import traceback
                    error_detail = traceback.format_exc()
                    print(f"[DOC_ANNOTATE] âŒ å¤±è´¥:\n{error_detail}")
                    # ä¿å­˜å¼‚å¸¸è®°å½•
                    session_manager.append_and_save(f"{session_name}.json", user_input, f"âŒ æ–‡æ¡£æ ‡æ³¨å¼‚å¸¸: {str(e)[:200]}")
                    
                    yield f"data: {json.dumps({'type': 'error', 'message': f'âŒ å¤„ç†å¼‚å¸¸: {str(e)[:200]}'})}\n\n"
                    total_time = time.time() - start_time
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                
                return
                        
            # === WEB_SEARCH Mode (è”ç½‘æœç´¢ - å®æ—¶ä¿¡æ¯) ===
            if task_type == "WEB_SEARCH":
                used_model = "gemini-2.5-flash (Google Search)"
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸŒ æ­£åœ¨è¿æ¥äº’è”ç½‘...', 'detail': ''})}\n\n"
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ” æ­£åœ¨æœç´¢å®æ—¶ä¿¡æ¯...', 'detail': 'Google Search'})}\n\n"
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“Š æ­£åœ¨æ•´ç†æœç´¢ç»“æœ...', 'detail': ''})}\n\n"
                
                search_result = WebSearcher.search_with_grounding(user_input)
                response_text = search_result["response"]
                
                if Utils.is_failure_output(response_text) or "æœç´¢å¤±è´¥" in response_text:
                    t = yield_thinking("åˆæ¬¡æœç´¢ç»“æœä¸ä½³ï¼Œä½¿ç”¨ gemini-2.0-flash-lite æ”¹å†™æŸ¥è¯¢è¯åé‡è¯•", "searching")
                    if t: yield t
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'âš ï¸ åˆæ¬¡æœç´¢å¤±è´¥ï¼Œæ­£åœ¨ä¿®æ­£æŸ¥è¯¢...', 'detail': ''})}\n\n"
                    fix_query_prompt = (
                        "è¯·æŠŠç”¨æˆ·éœ€æ±‚æ”¹å†™æˆæ›´é€‚åˆæœç´¢çš„ç®€çŸ­å…³é”®è¯æˆ–æŸ¥è¯¢è¯­å¥ï¼Œåªè¾“å‡ºæŸ¥è¯¢è¯­å¥ã€‚\n"
                        f"ç”¨æˆ·éœ€æ±‚: {user_input}"
                    )
                    fix_query_resp = client.models.generate_content(
                        model="gemini-2.0-flash-lite",
                        contents=fix_query_prompt,
                        config=types.GenerateContentConfig(
                            temperature=0.2,
                            max_output_tokens=64,
                        )
                    )
                    fixed_query = (fix_query_resp.text or user_input).strip()
                    search_result = WebSearcher.search_with_grounding(fixed_query)
                    response_text = search_result["response"]
                
                if Utils.is_failure_output(response_text):
                    fix_prompt = Utils.build_fix_prompt("WEB_SEARCH", user_input, response_text)
                    fix_resp = client.models.generate_content(
                        model=model_id,
                        contents=fix_prompt,
                        config=types.GenerateContentConfig(
                            system_instruction=system_instruction,
                            temperature=0.4,
                            max_output_tokens=1200,
                        )
                    )
                    response_text = fix_resp.text or response_text
                
                yield f"data: {json.dumps({'type': 'token', 'content': response_text})}\n\n"
                
                # å…ˆä¿å­˜å†å²ï¼Œå†å‘é€ done äº‹ä»¶
                session_manager.append_and_save(f"{session_name}.json", user_input, response_text)
                
                total_time = time.time() - start_time
                yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                return
            
            # === RESEARCH Mode (æ·±åº¦ç ”ç©¶ - æµå¼å“åº”ä¼˜å…ˆ) ===
            if task_type == "RESEARCH":
                used_model = model_id if model_id else "gemini-3-pro"
                t = yield_thinking(f"è¿›å…¥æ·±åº¦ç ”ç©¶æ¨¡å¼ï¼Œä½¿ç”¨ {model_id or 'gemini-3-pro'} è¿›è¡Œä¸“ä¸šçº§åˆ†æ", "analyzing")
                if t: yield t
                newline = '\n'
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ”¬ å¯åŠ¨æ·±åº¦ç ”ç©¶æ¨¡å¼...', 'detail': 'ä½¿ç”¨Gemini 3.0 Proè¿›è¡Œæµå¼åˆ†æ'})}{newline}{newline}"
                
                # æ„å»ºæ·±åº¦ç ”ç©¶çš„system instruction
                research_instruction = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”ç©¶åŠ©æ‰‹ï¼Œæ“…é•¿æ·±åº¦åˆ†æå¤æ‚æŠ€æœ¯è¯é¢˜ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„æä¾›å…¨é¢æ·±å…¥çš„ç ”ç©¶æŠ¥å‘Šï¼š

1. **æŠ€æœ¯æ¦‚è¿°**ï¼šæ¸…æ™°å®šä¹‰å’Œè§£é‡Šæ ¸å¿ƒæ¦‚å¿µ
2. **æŠ€æœ¯åŸç†**ï¼šè¯¦ç»†è¯´æ˜å·¥ä½œæœºåˆ¶å’Œåº•å±‚åŸç†
3. **ä¼˜åŠ¿åˆ†æ**ï¼šåˆ—ä¸¾ä¸»è¦ä¼˜ç‚¹å’Œåº”ç”¨åœºæ™¯
4. **é—®é¢˜ä¸æŒ‘æˆ˜**ï¼šåˆ†æå­˜åœ¨çš„é—®é¢˜å’ŒæŠ€æœ¯ç“¶é¢ˆ
5. **å¯¹æ¯”åˆ†æ**ï¼šä¸å…¶ä»–åŒç±»æŠ€æœ¯è¿›è¡Œæ¨ªå‘å¯¹æ¯”
6. **å‘å±•è¶‹åŠ¿**ï¼šè®¨è®ºæœªæ¥å‘å±•æ–¹å‘å’Œåº”ç”¨å‰æ™¯
7. **å‚è€ƒèµ„æ–™**ï¼šæä¾›ç›¸å…³æŠ€æœ¯æ–‡æ¡£å’Œå­¦æœ¯èµ„æ–™çš„å¼•ç”¨

ğŸ“Œ **ç‰¹æ®ŠæŸ¥è¯¢ç±»å‹å¢å¼ºè§„åˆ™**ï¼š

**ä»·æ ¼/è´¹ç”¨/ç¥¨åŠ¡æŸ¥è¯¢**ï¼ˆå¦‚é«˜é“ç¥¨ã€æœºç¥¨ã€é…’åº—ã€é—¨ç¥¨ç­‰ï¼‰ï¼š
- âœ… **é¦–å…ˆè¾“å‡ºä¸€ä¸ªæ¸…æ™°çš„è¡¨æ ¼**ï¼ŒåŒ…å«å…³é”®ä¿¡æ¯ï¼ˆè½¦æ¬¡ã€å‘è½¦æ—¶é—´ã€åˆ°è¾¾æ—¶é—´ã€åº§ä½ã€ä»·æ ¼ã€æ—¶é•¿ç­‰ï¼‰
- âœ… å¿…é¡»æä¾›**å…·ä½“ä»·æ ¼**ï¼ˆä¾‹å¦‚ï¼šäºŒç­‰åº§ Â¥524.5ï¼‰
- âŒ ç¦æ­¢ä½¿ç”¨ä»·æ ¼åŒºé—´ï¼ˆå¦‚"500-600å…ƒ"ï¼‰
- âœ… æŒ‰åº§ä½/æˆ¿å‹ç­‰çº§**åˆ†åˆ«åˆ—å‡º**æ¯ä¸ªé€‰é¡¹çš„ç¡®åˆ‡ä»·æ ¼
- âœ… åˆ—å‡º**å…·ä½“ç­æ¬¡/è½¦æ¬¡å·**ï¼ˆå¦‚ G12ã€èˆªç­ MU5137ï¼‰
- âœ… åˆ—å‡º**å‘è½¦æ—¶é—´å’Œåˆ°è¾¾æ—¶é—´**ï¼Œæ–¹ä¾¿ç”¨æˆ·å¯¹æ¯”é€‰æ‹©
- âŒ ç¦æ­¢è¾“å‡ºé‡å¤å†…å®¹æˆ–å¤šä¸ªç›¸åŒçš„æ®µè½

**å¼ºåˆ¶ä½¿ç”¨è¡¨æ ¼æ ¼å¼**ï¼š
```
ğŸš„ ä¸Šæµ·è™¹æ¡¥ â†’ åŒ—äº¬å—ï¼ˆ2026å¹´2æœˆ12æ—¥ï¼‰

| è½¦æ¬¡   | å‘è½¦  | åˆ°è¾¾  | åº§ä½ç±»å‹ | ä»·æ ¼     | æ—¶é•¿  |
|--------|-------|-------|----------|----------|-------|
| G12æ¬¡  | 09:00 | 13:24 | å•†åŠ¡åº§   | Â¥1,748   | 4h24m |
| G12æ¬¡  | 09:00 | 13:24 | ä¸€ç­‰åº§   | Â¥933     | 4h24m |
| G12æ¬¡  | 09:00 | 13:24 | äºŒç­‰åº§   | Â¥524.5   | 4h24m |
| G8æ¬¡   | 10:00 | 14:31 | å•†åŠ¡åº§   | Â¥1,748   | 4h31m |
| G8æ¬¡   | 10:00 | 14:31 | ä¸€ç­‰åº§   | Â¥933     | 4h31m |
| G8æ¬¡   | 10:00 | 14:31 | äºŒç­‰åº§   | Â¥524.5   | 4h31m |

ğŸ’¡ è´­ç¥¨æ–¹å¼ï¼šè®¿é—® 12306.cn æœç´¢å¯¹åº”è½¦æ¬¡è´­ä¹°ã€‚
```

è¦æ±‚ï¼š
- æä¾›å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚å’Œæ•°æ®æ”¯æŒ
- ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ä½†ç¡®ä¿å¯ç†è§£æ€§
- ä¿æŒå®¢è§‚ä¸­ç«‹çš„åˆ†ææ€åº¦
- å†…å®¹å…¨é¢ä¸”æœ‰æ·±åº¦
- é€‚å½“ä½¿ç”¨å›¾è¡¨å’Œç¤ºä¾‹è¯´æ˜"""
                
                collected_text = []
                
                try:
                    # ä½¿ç”¨Gemini 3.0 Proè¿›è¡Œæµå¼ç”Ÿæˆ
                    newline = '\n'
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“Š æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æ...', 'detail': 'Gemini 3.0 Pro æ­£åœ¨æ€è€ƒï¼Œå¯èƒ½éœ€è¦30-90ç§’'})}{newline}{newline}"
                    
                    response_stream = client.models.generate_content_stream(
                        model="gemini-3-pro-preview",
                        contents=effective_input,
                        config=types.GenerateContentConfig(
                            system_instruction=research_instruction,
                            temperature=0.7,
                            max_output_tokens=8000,  # å…è®¸æ›´é•¿çš„è¾“å‡º
                            top_p=0.95,
                        )
                    )
                    
                    chunk_count = 0
                    heartbeat_interval = 5  # æ¯5ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
                    first_chunk_received = False
                    
                    # ä½¿ç”¨ä¿æ´»åŒ…è£…å™¨å¤„ç†æµå¼å“åº”
                    for item_type, item_data in stream_with_keepalive(response_stream, start_time, 
                                                                       keepalive_interval=heartbeat_interval,
                                                                       max_wait_first_token=90):  # æœ€å¤šç­‰å¾…90ç§’
                        # æ£€æŸ¥ä¸­æ–­
                        if interrupted():
                            print(f"[RESEARCH] ç”¨æˆ·ä¸­æ–­ç ”ç©¶")
                            newline = '\n'
                            interrupt_msg = f'{newline}{newline}â¹ï¸ ç ”ç©¶å·²è¢«ç”¨æˆ·ä¸­æ–­'
                            yield f"data: {json.dumps({'type': 'token', 'content': interrupt_msg})}{newline}{newline}"
                            break
                        
                        if item_type == 'heartbeat':
                            # å‘é€å¿ƒè·³ä¿æŒè¿æ¥
                            elapsed = item_data
                            if first_chunk_received:
                                char_count = len(''.join(collected_text))
                                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“ æ­£åœ¨ç”Ÿæˆä¸­...', 'detail': f'å·²ç”Ÿæˆ {char_count} å­—ç¬¦ï¼Œè€—æ—¶ {elapsed}s'})}\n\n"
                            else:
                                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ§  æ¨¡å‹æ­£åœ¨æ·±åº¦æ€è€ƒ...', 'detail': f'å·²ç­‰å¾… {elapsed}sï¼Œè¯·è€å¿ƒç­‰å¾…'})}\n\n"
                        
                        elif item_type == 'timeout':
                            # ç­‰å¾…è¶…æ—¶
                            yield f"data: {json.dumps({'type': 'token', 'content': f'âš ï¸ {item_data}ï¼Œæ¨¡å‹å“åº”æ—¶é—´è¿‡é•¿ï¼Œè¯·ç¨åé‡è¯•'})}\n\n"
                            break
                        
                        elif item_type == 'chunk':
                            chunk = item_data
                            if chunk.text:
                                if not first_chunk_received:
                                    first_chunk_received = True
                                    print(f"[RESEARCH] æ”¶åˆ°ç¬¬ä¸€ä¸ªå“åº”å—ï¼Œè€—æ—¶ {time.time() - start_time:.1f}s")
                                
                                collected_text.append(chunk.text)
                                yield f"data: {json.dumps({'type': 'token', 'content': chunk.text})}\n\n"
                                chunk_count += 1
                                
                                # æ¯50ä¸ªchunkæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦æ—¥å¿—
                                if chunk_count % 50 == 0:
                                    print(f"[RESEARCH] å·²ç”Ÿæˆ {chunk_count} ä¸ªchunk, {len(''.join(collected_text))} å­—ç¬¦")
                    
                    final_text = ''.join(collected_text)
                    print(f"[RESEARCH] âœ… ç ”ç©¶å®Œæˆï¼Œå…± {len(final_text)} å­—ç¬¦")
                    
                    # ä¿å­˜å†å²ï¼ˆåŸºäºç£ç›˜å®Œæ•´å†å²è¿½åŠ ï¼‰
                    session_manager.append_and_save(
                        f"{session_name}.json",
                        user_input,
                        final_text[:4000],
                        task="RESEARCH",
                        model_name=used_model
                    )
                    
                except Exception as research_err:
                    error_msg = str(research_err)
                    print(f"[RESEARCH] é”™è¯¯: {error_msg}")
                    
                    # æ™ºèƒ½é”™è¯¯å¤„ç†
                    if "503" in error_msg or "UNAVAILABLE" in error_msg:
                        # APIè¿‡è½½ï¼Œå°è¯•ä½¿ç”¨Flashç‰ˆæœ¬
                        try:
                            newline = '\n'
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'âš ï¸ æœåŠ¡ç¹å¿™ï¼Œåˆ‡æ¢åˆ°Gemini 3.0 Flash...', 'detail': ''})}{newline}{newline}"
                            
                            response_stream = client.models.generate_content_stream(
                                model="gemini-3-flash-preview",
                                contents=effective_input,
                                config=types.GenerateContentConfig(
                                    system_instruction=research_instruction,
                                    temperature=0.7,
                                    max_output_tokens=8000,
                                )
                            )
                            
                            last_heartbeat_flash = time.time()
                            for chunk in response_stream:
                                if interrupted():
                                    break
                                if chunk.text:
                                    collected_text.append(chunk.text)
                                    yield f"data: {json.dumps({'type': 'token', 'content': chunk.text})}\n\n"
                                    
                                    # Flash æ¨¡å¼ä¸‹ä¹Ÿå‘é€å¿ƒè·³
                                    current_time = time.time()
                                    if current_time - last_heartbeat_flash > 3:
                                        elapsed = int(current_time - start_time)
                                        yield f"data: {json.dumps({'type': 'progress', 'message': f'âš¡ å¿«é€Ÿæ¨¡å¼ç”Ÿæˆä¸­...', 'detail': f'{elapsed}s'})}\n\n"
                                        last_heartbeat_flash = current_time
                            
                            final_text = ''.join(collected_text)
                            session_manager.append_and_save(
                                f"{session_name}.json",
                                user_input,
                                final_text[:4000],
                                task="RESEARCH",
                                model_name="gemini-3-flash-preview"
                            )
                            
                        except Exception as fallback_err:
                            error_text = f"âŒ ç ”ç©¶æœåŠ¡æš‚æ—¶ä¸å¯ç”¨\n\né”™è¯¯ä¿¡æ¯: {str(fallback_err)[:200]}\n\nğŸ’¡ å»ºè®®ï¼š\n1. ç¨åé‡è¯•\n2. ç®€åŒ–é—®é¢˜\n3. ä½¿ç”¨æ™®é€šå¯¹è¯æ¨¡å¼"
                            yield f"data: {json.dumps({'type': 'token', 'content': error_text})}\n\n"
                            session_manager.append_and_save(f"{session_name}.json", user_input, error_text[:1000], task="RESEARCH", model_name="gemini-3-flash-preview")
                    
                    elif "timeout" in error_msg.lower() or "disconnect" in error_msg.lower():
                        # è¿æ¥é—®é¢˜
                        error_text = f"âš ï¸ è¿æ¥è¶…æ—¶æˆ–ä¸­æ–­\n\nå¯èƒ½åŸå› ï¼š\n1. ç½‘ç»œä¸ç¨³å®š\n2. æœåŠ¡å™¨ç¹å¿™\n3. ä»£ç†é…ç½®é—®é¢˜\n\nå»ºè®®ï¼šè¯·ç¨åé‡è¯•ï¼Œæˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥"
                        yield f"data: {json.dumps({'type': 'token', 'content': error_text})}\n\n"
                        session_manager.append_and_save(f"{session_name}.json", user_input, error_text[:1000], task="RESEARCH", model_name=used_model)
                    
                    else:
                        # å…¶ä»–é”™è¯¯
                        error_text = f"âŒ ç ”ç©¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯\n\n{error_msg[:300]}\n\nè¯·å°è¯•ï¼š\n1. é‡æ–°æé—®\n2. ç®€åŒ–é—®é¢˜æè¿°\n3. ç¨åé‡è¯•"
                        yield f"data: {json.dumps({'type': 'token', 'content': error_text})}\n\n"
                        session_manager.append_and_save(f"{session_name}.json", user_input, error_text[:1000], task="RESEARCH", model_name=used_model)
                
                total_time = time.time() - start_time
                newline = '\n'
                yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}{newline}{newline}"
                return
            
            # === PAINTER Mode (å›¾åƒç”Ÿæˆ - Nano Banana ä¼˜å…ˆï¼ŒImagen 4.0 å¤‡ç”¨) ===
            if task_type == "PAINTER":
                used_model = "Nano Banana (Imagen 4.0 fallback)"
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ¨ æ­£åœ¨ç†è§£ä½ çš„åˆ›ä½œè¯·æ±‚...', 'detail': ''})}\n\n"
                
                # ä½¿ç”¨ä¸Šä¸‹æ–‡å¢å¼ºçš„è¾“å…¥ï¼ˆå¦‚æœæœ‰ï¼‰
                if context_info and context_info.get("is_continuation") and context_info.get("enhanced_input"):
                    image_prompt = context_info["enhanced_input"]
                    print(f"[PAINTER] ä½¿ç”¨ä¸Šä¸‹æ–‡å¢å¼ºçš„prompt: {image_prompt[:100]}...")
                else:
                    image_prompt = effective_input
                
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ–Œï¸ Nano Banana æ­£åœ¨ç”Ÿæˆå›¾åƒ...', 'detail': 'è¯·è€å¿ƒç­‰å¾…'})}\n\n"
                
                max_retries = 2
                use_fallback = False
                images = []
                
                for attempt in range(max_retries):
                    try:
                        if interrupted():
                            yield f"data: {json.dumps({'type': 'token', 'content': 'â¹ï¸ å›¾åƒç”Ÿæˆå·²ä¸­æ–­'})}\n\n"
                            total_time = time.time() - start_time
                            yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                            return
                        
                        if attempt > 0:
                            yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ”„ ç¬¬ {attempt} æ¬¡é‡è¯•...', 'detail': ''})}\n\n"
                            time.sleep(2)
                        
                        # é€‰æ‹©æ¨¡å‹
                        if use_fallback:
                            model_name = "Imagen 4.0"
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ”„ åˆ‡æ¢åˆ° Imagen 4.0...', 'detail': ''})}\n\n"
                        else:
                            model_name = "Nano Banana"
                        
                        # ä½¿ç”¨åå°çº¿ç¨‹æ‰§è¡Œè¯·æ±‚ï¼Œä¸»çº¿ç¨‹å‘é€å¿ƒè·³
                        import queue
                        import threading
                        result_queue = queue.Queue()
                        
                        def worker():
                            try:
                                if use_fallback:
                                    result = client.models.generate_images(
                                        model="imagen-4.0-generate-preview-06-06",
                                        prompt=image_prompt,
                                        config=types.GenerateImagesConfig(number_of_images=1)
                                    )
                                else:
                                    result = client.models.generate_content(
                                        model="nano-banana-pro-preview",
                                        contents=image_prompt,
                                        config=types.GenerateContentConfig(response_modalities=["IMAGE"])
                                    )
                                result_queue.put(('success', result))
                            except Exception as e:
                                result_queue.put(('error', e))
                        
                        thread = threading.Thread(target=worker, daemon=True)
                        thread.start()
                        
                        timeout_seconds = 90
                        response = None
                        
                        while True:
                            elapsed = time.time() - start_time
                            
                            if elapsed > timeout_seconds:
                                yield f"data: {json.dumps({'type': 'token', 'content': f'âš ï¸ å›¾åƒç”Ÿæˆè¶…æ—¶ ({int(elapsed)}s)ï¼Œè¯·ç¨åé‡è¯•'})}\n\n"
                                total_time = time.time() - start_time
                                yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                                return
                            
                            if interrupted():
                                yield f"data: {json.dumps({'type': 'token', 'content': 'â¹ï¸ å›¾åƒç”Ÿæˆå·²ä¸­æ–­'})}\n\n"
                                total_time = time.time() - start_time
                                yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                                return
                            
                            try:
                                status, data = result_queue.get(timeout=3.0)
                                if status == 'success':
                                    response = data
                                    break
                                else:
                                    raise data
                            except queue.Empty:
                                yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ¨ {model_name} ç”Ÿæˆä¸­...', 'detail': f'{int(elapsed)}s'})}\n\n"
                        
                        # å¤„ç†å“åº”
                        yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ’¾ æ­£åœ¨ä¿å­˜å›¾ç‰‡...', 'detail': ''})}\n\n"
                        
                        if use_fallback:
                            if response.generated_images:
                                for gen_img in response.generated_images:
                                    img_data = gen_img.image.image_bytes
                                    images_dir = settings_manager.images_dir
                                    os.makedirs(images_dir, exist_ok=True)
                                    timestamp = int(time.time())
                                    filename = f"generated_{timestamp}.png"
                                    filepath = os.path.join(images_dir, filename)
                                    with open(filepath, "wb") as f:
                                        f.write(img_data)
                                    
                                    # ç¡®ä¿è·¯å¾„åœ¨ workspace ä¸‹
                                    try:
                                        rel_path = os.path.relpath(filepath, WORKSPACE_DIR).replace("\\", "/")
                                        if ".." not in rel_path:
                                            images.append(rel_path)
                                            print(f"[PAINTER] Imagen å·²ä¿å­˜: {rel_path}")
                                        else:
                                            # é™çº§ä¿å­˜åˆ° workspace/images
                                            abs_workspace_images = os.path.join(WORKSPACE_DIR, "images")
                                            os.makedirs(abs_workspace_images, exist_ok=True)
                                            fallback_filepath = os.path.join(abs_workspace_images, filename)
                                            with open(fallback_filepath, "wb") as f:
                                                f.write(img_data)
                                            fallback_rel = os.path.relpath(fallback_filepath, WORKSPACE_DIR).replace("\\", "/")
                                            images.append(fallback_rel)
                                            print(f"[PAINTER] Imagen é™çº§ä¿å­˜: {fallback_rel}")
                                    except Exception as path_err:
                                        print(f"[PAINTER] Path error: {path_err}")
                        else:
                            if response.candidates and response.candidates[0].content.parts:
                                for part in response.candidates[0].content.parts:
                                    if hasattr(part, "inline_data") and part.inline_data:
                                        img_filename = Utils.save_image_part(part)
                                        if img_filename:
                                            images.append(img_filename)
                                            print(f"[PAINTER] Nano Banana å·²ä¿å­˜: {img_filename}")
                        
                        if images:
                            save_path = settings_manager.images_dir
                            msg = f"âœ¨ å›¾ç‰‡å·²ç”Ÿæˆ! (ä½¿ç”¨ {model_name})\nğŸ–¼ï¸ ä¿å­˜ä½ç½®: {save_path}"
                            yield f"data: {json.dumps({'type': 'token', 'content': msg})}\n\n"
                            
                            # å…ˆä¿å­˜å†å²è®°å½•ï¼ˆåŒ…å«å›¾ç‰‡è·¯å¾„ï¼‰ï¼Œå†å‘é€ done
                            session_manager.append_and_save(
                                f"{session_name}.json", user_input, "å›¾åƒå·²ç”Ÿæˆ",
                                images=images, task="PAINTER", model_name=model_name
                            )
                            
                            total_time = time.time() - start_time
                            print(f"[PAINTER] å‘é€å›¾ç‰‡åˆ—è¡¨: {images}")  # è°ƒè¯•
                            yield f"data: {json.dumps({'type': 'done', 'images': images, 'saved_files': [], 'total_time': total_time})}\n\n"
                            return
                        else:
                            if not use_fallback:
                                use_fallback = True
                                continue
                            else:
                                yield f"data: {json.dumps({'type': 'token', 'content': 'âŒ æ¨¡å‹æœªè¿”å›å›¾ç‰‡'})}\n\n"
                                
                    except Exception as img_err:
                        error_msg = str(img_err)
                        print(f"[PAINTER] å°è¯• {attempt+1} å¤±è´¥: {error_msg[:200]}")
                        
                        if not use_fallback and ("503" in error_msg or "overloaded" in error_msg.lower() or 
                                                 "unavailable" in error_msg.lower() or "400" in error_msg):
                            use_fallback = True
                            continue
                        
                        if "safety" in error_msg.lower() or "blocked" in error_msg.lower():
                            user_msg = "âŒ å†…å®¹è¢«å®‰å…¨ç­–ç•¥è¿‡æ»¤ï¼Œè¯·ä¿®æ”¹æè¿°"
                        elif "location is not supported" in error_msg.lower():
                            user_msg = "âŒ åœ°åŒºé™åˆ¶ï¼Œè¯·é…ç½®ä¸­è½¬æœåŠ¡"
                        else:
                            user_msg = f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {error_msg[:100]}"
                        
                        yield f"data: {json.dumps({'type': 'token', 'content': user_msg})}\n\n"
                
                # PAINTER æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥æ—¶ä¹Ÿè¦ä¿å­˜å†å²
                session_manager.append_and_save(f"{session_name}.json", user_input, "å›¾åƒç”Ÿæˆå¤±è´¥")
                
                total_time = time.time() - start_time
                yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                return
            
            # === FILE_GEN Mode (æ–‡ä»¶ç”Ÿæˆ - è‡ªåŠ¨æ‰§è¡Œ) ===
            if task_type == "FILE_GEN":
                t = yield_thinking(f"è¿›å…¥æ–‡ä»¶ç”Ÿæˆæ¨¡å¼ï¼Œå°†ä½¿ç”¨ {model_id} ç”Ÿæˆæ–‡æ¡£", "generating")
                if t: yield t
                print(f"[FILE_GEN] ===== Starting file generation =====")
                print(f"[FILE_GEN] Model: {model_id}, User input: {user_input[:100]}...")
                
                response_text = ""
                generated_files = []
                temp_scripts = []  # ä¸´æ—¶è„šæœ¬åˆ—è¡¨ï¼ˆæ‰§è¡Œååˆ é™¤ï¼‰
                api_timeout = 120  # å¢åŠ åˆ° 120 ç§’ï¼Œé•¿æ–‡æ¡£éœ€è¦æ›´å¤šæ—¶é—´

                if interrupted():
                    yield f"data: {json.dumps({'type': 'token', 'content': 'â¹ï¸ æ–‡ä»¶ç”Ÿæˆå·²ä¸­æ–­'})}\n\n"
                    total_time = time.time() - start_time
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                    return
                
                # â­ æ£€æŸ¥æ˜¯å¦æ˜¯"è½¬æ¢è¯·æ±‚"ï¼ˆæŠŠä¹‹å‰çš„å†…å®¹åšæˆword/pdfï¼‰
                is_convert_request = (
                    context_info and 
                    context_info.get("is_continuation") and 
                    context_info.get("continuation_type") == "convert" and
                    context_info.get("context_summary", {}).get("last_model_output")
                )
                
                if is_convert_request:
                    # ç›´æ¥è½¬æ¢æ¨¡å¼ - ä¸éœ€è¦è°ƒç”¨æ¨¡å‹ï¼Œç›´æ¥ç”Ÿæˆæ–‡æ¡£
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“ æ­£åœ¨å°†å†…å®¹è½¬æ¢ä¸ºæ–‡æ¡£...', 'detail': ''})}\n\n"
                    
                    try:
                        from web.document_generator import save_docx, save_pdf
                        
                        source_content = context_info["context_summary"]["last_model_output"]
                        print(f"[FILE_GEN] ç›´æ¥è½¬æ¢æ¨¡å¼ï¼Œæºå†…å®¹é•¿åº¦: {len(source_content)}")
                        
                        # æå–æ ‡é¢˜ï¼ˆå°è¯•ä»å†…å®¹ä¸­æ‰¾ # æ ‡é¢˜ï¼‰
                        title_match = re.search(r'^#\s*(.+)$', source_content, re.MULTILINE)
                        if title_match:
                            title = title_match.group(1).strip()[:50]
                        else:
                            title = f"Kotoæ–‡æ¡£_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                        
                        docs_dir = settings_manager.documents_dir
                        os.makedirs(docs_dir, exist_ok=True)
                        
                        # åˆ¤æ–­ç”Ÿæˆ Word è¿˜æ˜¯ PDF
                        user_lower = user_input.lower()
                        
                        if "pdf" in user_lower:
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“„ æ­£åœ¨ç”Ÿæˆ PDF...', 'detail': ''})}\n\n"
                            saved_path = save_pdf(source_content, title=title, output_dir=docs_dir)
                            file_type = "PDF"
                        else:
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“„ æ­£åœ¨ç”Ÿæˆ Word æ–‡æ¡£...', 'detail': ''})}\n\n"
                            saved_path = save_docx(source_content, title=title, output_dir=docs_dir)
                            file_type = "Word"
                        
                        rel_path = os.path.relpath(saved_path, WORKSPACE_DIR).replace("\\", "/")
                        generated_files.append(rel_path)
                        
                        success_msg = f"âœ… **{file_type} æ–‡æ¡£ç”ŸæˆæˆåŠŸï¼**\n\nğŸ“ æ–‡ä»¶: **{os.path.basename(saved_path)}**\nğŸ“ ä½ç½®: `{docs_dir}`"
                        yield f"data: {json.dumps({'type': 'token', 'content': success_msg})}\n\n"
                        
                        print(f"[FILE_GEN] âœ… ç›´æ¥è½¬æ¢æˆåŠŸ: {rel_path}")
                        
                    except Exception as convert_err:
                        error_msg = f"âŒ æ–‡æ¡£è½¬æ¢å¤±è´¥: {str(convert_err)}"
                        print(f"[FILE_GEN] è½¬æ¢é”™è¯¯: {convert_err}")
                        yield f"data: {json.dumps({'type': 'token', 'content': error_msg})}\n\n"
                    
                    # ä¿å­˜å†å²ï¼ˆåŸºäºç£ç›˜å®Œæ•´å†å²è¿½åŠ ï¼‰
                    _model_msg = f"å·²ç”Ÿæˆæ–‡ä»¶: {', '.join(generated_files)}" if generated_files else "æ–‡æ¡£è½¬æ¢å¤±è´¥"
                    session_manager.append_and_save(f"{session_name}.json", user_input, _model_msg)
                    
                    total_time = time.time() - start_time
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': generated_files, 'total_time': total_time})}\n\n"
                    return
                
                # â­ æ£€æŸ¥æ˜¯å¦æ˜¯ PPT ç”Ÿæˆè¯·æ±‚
                ppt_keywords = ["ppt", "å¹»ç¯ç‰‡", "æ¼”ç¤ºæ–‡ç¨¿", "æ¼”ç¤º", "presentation", "slide", "slides"]
                user_lower_check = user_input.lower()
                is_ppt_request = any(kw in user_lower_check for kw in ppt_keywords)
                
                if is_ppt_request:
                    # =============== PPT ä¸“ç”¨ç”Ÿæˆæµç¨‹ ===============
                    print(f"[FILE_GEN] ğŸ¯ æ£€æµ‹åˆ° PPT ç”Ÿæˆè¯·æ±‚")
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ¨ æ­£åœ¨ç”Ÿæˆæ¼”ç¤ºæ–‡ç¨¿...', 'detail': 'æ­£åœ¨è§„åˆ’å†…å®¹ç»“æ„'})}\n\n"
                    
                    try:
                        # â”€â”€â”€â”€â”€â”€â”€â”€ Session: åˆ›å»º PPT ç¼–è¾‘ä¼šè¯ â”€â”€â”€â”€â”€â”€â”€â”€
                        ppt_session_id = None
                        try:
                            from web.ppt_session_manager import get_ppt_session_manager
                            ppt_session_mgr = get_ppt_session_manager()
                            ppt_session_id = ppt_session_mgr.create_session(
                                title=user_input[:50],  # å‰ 50 å­—ä½œä¸ºä¸´æ—¶æ ‡é¢˜
                                user_input=user_input,
                                theme="business"
                            )
                            print(f"[FILE_GEN/PPT] ğŸ“‹ åˆ›å»ºç¼–è¾‘ä¼šè¯: {ppt_session_id}")
                        except Exception as session_err:
                            print(f"[FILE_GEN/PPT] âš ï¸ ä¼šè¯åˆ›å»ºå¼‚å¸¸ï¼ˆä¸å½±å“ç”Ÿæˆï¼‰: {session_err}")
                        
                        # â”€â”€â”€â”€â”€â”€â”€â”€ Step 0: å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€
                        uploaded_file_context = ""
                        uploaded_files = request.files.getlist('files[]') if request.method == 'POST' else []
                        
                        if uploaded_files:
                            yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ“‚ æ­£åœ¨è§£æ {len(uploaded_files)} ä¸ªä¸Šä¼ æ–‡ä»¶...', 'detail': 'æå–æ–‡æœ¬å†…å®¹'})}\n\n"
                            try:
                                from web.file_parser import FileParser
                                
                                uploaded_file_paths = []
                                for uploaded_file in uploaded_files:
                                    if uploaded_file and uploaded_file.filename:
                                        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                                        temp_dir = os.path.join(WORKSPACE_DIR, 'temp_uploads')
                                        os.makedirs(temp_dir, exist_ok=True)
                                        temp_path = os.path.join(temp_dir, uploaded_file.filename)
                                        uploaded_file.save(temp_path)
                                        uploaded_file_paths.append(temp_path)
                                
                                if uploaded_file_paths:
                                    # æ‰¹é‡è§£æ
                                    parse_results = FileParser.batch_parse(uploaded_file_paths)
                                    successful_results = [r for r in parse_results if r.get('success')]
                                    
                                    if successful_results:
                                        uploaded_file_context = FileParser.merge_contents(successful_results)
                                        print(f"[FILE_GEN/PPT] âœ… å·²è§£æ {len(successful_results)} ä¸ªæ–‡ä»¶, æ€»å­—æ•°: {len(uploaded_file_context)}")
                                        yield f"data: {json.dumps({'type': 'progress', 'message': f'âœ… å·²è§£æ {len(successful_results)} ä¸ªä¸Šä¼ æ–‡ä»¶', 'detail': f'{len(uploaded_file_context)} å­—å†…å®¹'})}\n\n"
                                    else:
                                        print(f"[FILE_GEN/PPT] âš ï¸ ä¸Šä¼ æ–‡ä»¶è§£æå¤±è´¥")
                                        failed_reasons = [r.get('error', 'æœªçŸ¥é”™è¯¯') for r in parse_results if not r.get('success')]
                                        print(f"    åŸå› : {', '.join(failed_reasons)}")
                            
                            except ImportError:
                                print(f"[FILE_GEN/PPT] âš ï¸ FileParser æ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡æ–‡ä»¶å¤„ç†")
                            except Exception as file_err:
                                print(f"[FILE_GEN/PPT] âš ï¸ æ–‡ä»¶å¤„ç†å¼‚å¸¸: {file_err}")
                        
                        # â”€â”€â”€â”€â”€â”€â”€â”€ Step 0.1: æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦è”ç½‘æœç´¢ â”€â”€â”€â”€â”€â”€â”€â”€
                        search_context = ""
                        
                        # æ£€æµ‹æ˜¯å¦éœ€è¦æœç´¢æœ€æ–°ä¿¡æ¯
                        _needs_search = WebSearcher.needs_web_search(user_input)
                        
                        # é¢å¤–PPTè¯é¢˜æ£€æµ‹ï¼šåŒ…å«å¹´ä»½/æ—¶é—´/æ–°å“/äº‹ä»¶/æ’è¡Œç­‰çš„PPTå¤§æ¦‚ç‡éœ€è¦æœç´¢
                        import re as _re
                        _time_topic_patterns = [
                            r'20\d{2}',             # å¹´ä»½
                            r'\d+æœˆ',               # æœˆä»½
                            r'(æ–°ç•ª|æ–°ç‰‡|æ–°å‰§|æ–°æ­Œ|æ–°å“|ä¸Šæ˜ |é¦–å‘|å‘å”®)',
                            r'(æ’è¡Œ|æ’å|æ¦œå•|top|ç›˜ç‚¹|å¯¼è§†|é€Ÿé€’|ä¸€è§ˆ)',
                            r'(è¡Œæƒ…|èµ°åŠ¿|è¶‹åŠ¿|å¸‚åœº|ä»·æ ¼|æŠ¥å‘Š)',
                            r'(çƒ­é—¨|çƒ­ç‚¹|ç«çˆ†|æµè¡Œ|äººæ°”)',
                            r'(æœ€æ–°|æœ€è¿‘|è¿‘æœŸ|æœ¬å‘¨|æœ¬æœˆ|å½“å‰|ç›®å‰)',
                        ]
                        if not _needs_search:
                            for pat in _time_topic_patterns:
                                if _re.search(pat, user_input, _re.IGNORECASE):
                                    _needs_search = True
                                    print(f"[FILE_GEN/PPT] ğŸ” è¯é¢˜æ—¶æ•ˆæ€§æ£€æµ‹å‘½ä¸­: {pat}")
                                    break
                        
                        if _needs_search:
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ” æ­£åœ¨æœç´¢æœ€æ–°ä¿¡æ¯...', 'detail': 'ç¡®ä¿å†…å®¹å‡†ç¡®å’Œæ—¶æ•ˆæ€§'})}\n\n"
                            try:
                                search_result = WebSearcher.search_with_grounding(user_input)
                                if search_result.get("success") and search_result.get("response"):
                                    search_context = search_result["response"]
                                    print(f"[FILE_GEN/PPT] âœ… æœç´¢å®Œæˆ, è·å– {len(search_context)} å­—ç¬¦å‚è€ƒä¿¡æ¯")
                                    yield f"data: {json.dumps({'type': 'progress', 'message': 'âœ… æœç´¢å®Œæˆï¼Œæ­£åœ¨æ•´åˆä¿¡æ¯...', 'detail': ''})}\n\n"
                                else:
                                    print(f"[FILE_GEN/PPT] âš ï¸ æœç´¢æ— ç»“æœæˆ–å¤±è´¥")
                            except Exception as search_err:
                                print(f"[FILE_GEN/PPT] âš ï¸ æœç´¢å¼‚å¸¸: {search_err}")
                        
                        # â”€â”€â”€â”€â”€â”€â”€â”€ Step 0.5: å¤æ‚ä¸»é¢˜æ·±åº¦ç ”ç©¶ â”€â”€â”€â”€â”€â”€â”€â”€
                        research_context = ""
                        _complex_patterns = [
                            r'(åŸç†|æœºåˆ¶|æ¶æ„|æŠ€æœ¯|ç®—æ³•|ç†è®º|åˆ†æ|ç ”ç©¶|ç»¼è¿°)',
                            r'(è¡Œä¸š|äº§ä¸š|å¸‚åœº|å•†ä¸š|æˆ˜ç•¥|è§„åˆ’|æ–¹æ¡ˆ)',
                            r'(å­¦æœ¯|è®ºæ–‡|è¯¾é¢˜|æ¯•ä¸š|æ•™å­¦|è¯¾ç¨‹)',
                            r'(å†å²|å‘å±•|æ¼”å˜|å˜è¿|æ²¿é©)',
                            r'(å¯¹æ¯”|æ¯”è¾ƒ|è¯„ä¼°|è¯„æµ‹|benchmark)',
                            r'(ç»æµ|é‡‘è|æŠ•èµ„|è´¢åŠ¡|è´¢æŠ¥)',
                        ]
                        _is_complex = len(user_input) > 30 or any(
                            _re.search(p, user_input) for p in _complex_patterns
                        )
                        
                        if _is_complex:
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ”¬ æ£€æµ‹åˆ°å¤æ‚ä¸»é¢˜ï¼Œå¯åŠ¨æ·±åº¦ç ”ç©¶...', 'detail': 'ä½¿ç”¨ Gemini Pro è¿›è¡Œä¸“ä¸šåˆ†æ'})}\n\n"
                            try:
                                research_context = WebSearcher.deep_research_for_ppt(user_input, search_context)
                                if research_context:
                                    yield f"data: {json.dumps({'type': 'progress', 'message': f'âœ… æ·±åº¦ç ”ç©¶å®Œæˆï¼Œè·å– {len(research_context)} å­—å‚è€ƒ', 'detail': 'æ­£åœ¨æ•´åˆç ”ç©¶æˆæœ...'})}\n\n"
                                else:
                                    print(f"[FILE_GEN/PPT] âš ï¸ æ·±åº¦ç ”ç©¶æœªè¿”å›ç»“æœ")
                            except Exception as res_err:
                                print(f"[FILE_GEN/PPT] âš ï¸ æ·±åº¦ç ”ç©¶å¼‚å¸¸: {res_err}")
                        
                        # â”€â”€â”€â”€â”€â”€â”€â”€ Step 1: ç”¨ AI ç”Ÿæˆç»“æ„åŒ–å¤§çº² â”€â”€â”€â”€â”€â”€â”€â”€
                        # â”€â”€â”€â”€ æå–ç”¨æˆ· PPT åå¥½ï¼ˆé¡µæ•°ã€é‡ç‚¹ã€ç®€è¦è¯é¢˜ï¼‰ â”€â”€â”€â”€
                        import re as _ppt_re
                        
                        def _extract_ppt_preferences(text):
                            prefs = {"target_pages": None, "focus_topics": [], "brief_topics": []}
                            pm = _ppt_re.search(r'(?:åš|ç”Ÿæˆ|éœ€è¦|å¤§æ¦‚|çº¦|å¤§çº¦)?\s*(\d+)\s*é¡µ', text)
                            if pm:
                                prefs["target_pages"] = int(pm.group(1))
                            for pat in [
                                r'(?:é‡ç‚¹|è¯¦ç»†|ç€é‡|æ·±å…¥|å¤šè®²|å¤šä»‹ç»)(?:ä»‹ç»|è®²|åˆ†æ|è¯´æ˜|å±•ç¤º|è®²è§£)\s*(.+?)(?:[ï¼Œ,ã€‚ï¼›;ã€]|$)',
                                r'(?:çªå‡º|å¼ºè°ƒ)\s*(.+?)(?:[ï¼Œ,ã€‚ï¼›;ã€]|$)',
                            ]:
                                for m in _ppt_re.finditer(pat, text):
                                    t = m.group(1).strip()
                                    if t and len(t) < 30:
                                        prefs["focus_topics"].append(t)
                            for pat in [
                                r'(?:ç®€å•|ç®€è¦|ç®€ç•¥|å¤§è‡´)(?:å¸¦è¿‡|ä»‹ç»|è¯´|è®²)\s*(.+?)(?:[ï¼Œ,ã€‚ï¼›;ã€]|$)',
                                r'(.+?)(?:ä¸€ç¬”å¸¦è¿‡|ç•¥è¿‡|è·³è¿‡|ç®€å•è¯´)',
                            ]:
                                for m in _ppt_re.finditer(pat, text):
                                    t = m.group(1).strip()
                                    if t and len(t) < 30:
                                        prefs["brief_topics"].append(t)
                            return prefs
                        
                        ppt_prefs = _extract_ppt_preferences(user_input)
                        _target_pages = ppt_prefs["target_pages"]
                        _target_hint = f"çº¦ {_target_pages} é¡µï¼ˆå°é¢å’Œç»“æŸé¡µé™¤å¤–ï¼Œè¿™æ˜¯ç”¨æˆ·æŒ‡å®šçš„ï¼Œå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰" if _target_pages else "8~15 é¡µï¼ˆæ ¹æ®å†…å®¹å¤æ‚åº¦æ™ºèƒ½è°ƒæ•´ï¼Œå†…å®¹å¤šå¯ä»¥å¤šåšå‡ é¡µï¼Œå†…å®¹å°‘å°±ç²¾ç®€ï¼‰"
                        _focus_hint = ""
                        if ppt_prefs["focus_topics"]:
                            _focus_hint = "\n**ç”¨æˆ·æŒ‡å®šçš„é‡ç‚¹å†…å®¹ï¼ˆå¿…é¡»ç”¨ [è¯¦ç»†] å¤šé¡µå±•å¼€ï¼‰ï¼š**\n" + "\n".join(f"- {t}" for t in ppt_prefs["focus_topics"]) + "\n"
                        _brief_hint = ""
                        if ppt_prefs["brief_topics"]:
                            _brief_hint = "\n**ç”¨æˆ·æŒ‡å®šçš„ç®€è¦å†…å®¹ï¼ˆåˆå¹¶åˆ° [æ¦‚è§ˆ] é¡µï¼‰ï¼š**\n" + "\n".join(f"- {t}" for t in ppt_prefs["brief_topics"]) + "\n"
                        
                        print(f"[FILE_GEN/PPT] ç”¨æˆ·åå¥½: é¡µæ•°={_target_pages}, é‡ç‚¹={ppt_prefs['focus_topics']}, ç®€è¦={ppt_prefs['brief_topics']}")
                        
                        # â”€â”€â”€â”€ æ™ºèƒ½å†…å®¹è§„åˆ’ Prompt â”€â”€â”€â”€
                        ppt_outline_prompt = (
                            "ä½ æ˜¯ä¸€ä¸ªé¡¶å°–çš„æ¼”ç¤ºæ–‡ç¨¿å†…å®¹ç­–åˆ’å¸ˆå’Œæ’ç‰ˆè§„åˆ’å¸ˆã€‚\n\n"
                            "ä½ çš„å·¥ä½œåˆ†ä¸¤æ­¥ï¼š\n"
                            "1. **å†…å®¹è§„åˆ’** â€” åˆ†æä¸»é¢˜ï¼Œåˆ¤æ–­å“ªäº›å†…å®¹æ˜¯é‡ç‚¹ï¼ˆéœ€è¦å¤šé¡µè¯¦ç»†å±•ç¤ºï¼‰ï¼Œå“ªäº›æ˜¯ç®€è¦ï¼ˆå¯ä»¥ä¸€é¡µå¤šä¸»é¢˜é€Ÿè§ˆï¼‰\n"
                            "2. **ç‰ˆå¼é€‰æ‹©** â€” ä¸ºæ¯éƒ¨åˆ†é€‰æ‹©æœ€åˆé€‚çš„å¹»ç¯ç‰‡ç±»å‹\n\n"
                            "## å¯ç”¨çš„å¹»ç¯ç‰‡ç±»å‹\n"
                            "åœ¨æ¯ä¸ª `## ç« èŠ‚æ ‡é¢˜` å‰ä¸€è¡Œå†™ç±»å‹æ ‡ç­¾ï¼š\n\n"
                            "| æ ‡ç­¾ | ç”¨é€” | æ ¼å¼ |\n"
                            "|------|------|------|\n"
                            "| `[è¯¦ç»†]` | å¸¸è§„å†…å®¹é¡µï¼Œæ·±å…¥å±•ç¤º 4-6 ä¸ªè¦ç‚¹ï¼ˆæ¯ä¸ªè¦ç‚¹30-80å­—ï¼‰ | `- **å…³é”®è¯** â€” è¯¦ç»†è§£é‡Šè¯´æ˜å’Œå…·ä½“æ•°æ®` |\n"
                            "| `[æ¦‚è§ˆ]` | å¤šä¸»é¢˜é€Ÿè§ˆé¡µï¼Œ2-4 ä¸ªå°ä¸»é¢˜å¹¶åˆ—ï¼ˆæ¯ä¸ªå°ä¸»é¢˜ä¸‹2-4ä¸ªè¦ç‚¹ï¼‰ | ç”¨ `### å­æ ‡é¢˜` åˆ†ç»„ |\n"
                            "| `[äº®ç‚¹]` | å…³é”®æ•°æ®çªå‡ºé¡µï¼ˆ3-4ç»„æ•°æ®ï¼‰ | `- æ•°å€¼ \\| è¯¦ç»†è¯´æ˜` |\n"
                            "| `[å¯¹æ¯”]` | ä¸¤æ–¹å¯¹æ¯”é¡µï¼ˆæ¯æ–¹3-5ä¸ªè¦ç‚¹ï¼‰ | ç”¨ `### é€‰é¡¹A` å’Œ `### é€‰é¡¹B` åˆ†ä¸¤ç»„ |\n"
                            "| `[è¿‡æ¸¡é¡µ]` | ç« èŠ‚è¿‡æ¸¡ï¼Œå¼•å…¥å¤§ç« èŠ‚ï¼ˆå°‘ç”¨ï¼‰ | ä¸‹æ–¹å†™ä¸€è¡Œæè¿° |\n\n"
                            "## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå¾ªï¼‰\n"
                            "```\n"
                            "# PPTä¸»æ ‡é¢˜\n\n"
                            "[è¿‡æ¸¡é¡µ]\n"
                            "## ç¬¬ä¸€éƒ¨åˆ†æ ‡é¢˜\n"
                            "ç®€çŸ­æè¿°\n\n"
                            "[è¯¦ç»†]\n"
                            "## é¡µé¢æ ‡é¢˜\n"
                            "- **æ ¸å¿ƒæ¦‚å¿µ** â€” è¿™æ˜¯ä¸€æ®µå®Œæ•´çš„è§£é‡Šæ€§æ–‡å­—ï¼ŒåŒ…å«å…³é”®æ•°æ®æˆ–äº‹å®ä¾æ®ï¼Œè®©è§‚ä¼—èƒ½çœŸæ­£ç†è§£è¿™ä¸€ç‚¹çš„å†…å®¹\n"
                            "- **æŠ€æœ¯ç‰¹ç‚¹** â€” å…·ä½“æè¿°æŠ€æœ¯çš„å·¥ä½œåŸç†ã€ä¼˜åŠ¿æ‰€åœ¨ã€å®é™…åº”ç”¨åœºæ™¯å’Œç›¸å…³å‚æ•°\n"
                            "- **å¸‚åœºæ•°æ®** â€” å¼•ç”¨æƒå¨æœºæ„çš„ç»Ÿè®¡æ•°å­—ã€å¸‚åœºè§„æ¨¡ã€å¢é•¿ç‡ç­‰é‡åŒ–ä¿¡æ¯\n"
                            "- **å®é™…æ¡ˆä¾‹** â€” æŸå…¬å¸/é¡¹ç›®çš„å…·ä½“å®è·µç»éªŒï¼Œå–å¾—äº†ä»€ä¹ˆæ ·çš„æˆæœ\n\n"
                            "[æ¦‚è§ˆ]\n"
                            "## é€Ÿè§ˆæ ‡é¢˜\n"
                            "### å­è¯é¢˜1\n"
                            "- ç¬¬ä¸€ä¸ªè¦ç‚¹çš„è¯¦ç»†è¯´æ˜\n"
                            "- ç¬¬äºŒä¸ªè¦ç‚¹çš„è¯¦ç»†è¯´æ˜\n"
                            "- ç¬¬ä¸‰ä¸ªè¦ç‚¹çš„è¯¦ç»†è¯´æ˜\n"
                            "### å­è¯é¢˜2\n"
                            "- ç¬¬ä¸€ä¸ªè¦ç‚¹å’Œå…·ä½“æ•°æ®\n"
                            "- ç¬¬äºŒä¸ªè¦ç‚¹å’Œåº”ç”¨åœºæ™¯\n\n"
                            "[äº®ç‚¹]\n"
                            "## å…³é”®æ•°æ®\n"
                            "- 500äº¿ | å…¨çƒå¸‚åœºè§„æ¨¡\n"
                            "- 35% | å¹´å¢é•¿ç‡\n\n"
                            "[å¯¹æ¯”]\n"
                            "## å¯¹æ¯”æ ‡é¢˜\n"
                            "### æ–¹æ¡ˆA\n"
                            "- ç‰¹ç‚¹1\n"
                            "### æ–¹æ¡ˆB\n"
                            "- ç‰¹ç‚¹1\n"
                            "```\n\n"
                            "## å†…å®¹è§„åˆ’è§„åˆ™\n"
                            f"1. **æ€»é¡µæ•°ç›®æ ‡: {_target_hint}**\n"
                            "2. **é‡ç‚¹å†…å®¹**ä½¿ç”¨å¤šä¸ª `[è¯¦ç»†]` é¡µå±•å¼€ï¼Œæ¯é¡µ 4-6 ä¸ªä¿¡æ¯ä¸°å¯Œçš„è¦ç‚¹\n"
                            "3. âš ï¸ **æ¯ä¸ªè¦ç‚¹å¿…é¡»æ˜¯ä¸€ä¸ªå®Œæ•´çš„ä¿¡æ¯æ®µè½ï¼ˆ30-80å­—ï¼‰ï¼Œä¸èƒ½åªå†™å‡ ä¸ªè¯æˆ–çŸ­è¯­**\n"
                            "4. è¦ç‚¹æ ¼å¼: `- **å…³é”®è¯** â€” å…·ä½“çš„è§£é‡Šè¯´æ˜ï¼ŒåŒ…å«æ•°æ®ã€äº‹å®ã€æ¡ˆä¾‹ç­‰å®è´¨å†…å®¹`\n"
                            "5. **éé‡ç‚¹å†…å®¹**åˆå¹¶åˆ° `[æ¦‚è§ˆ]` é¡µï¼Œä¸€é¡µ 2-4 ä¸ªå°ä¸»é¢˜ï¼Œâš ï¸ **æ¯ä¸ªå°ä¸»é¢˜ä¸‹å¿…é¡»æœ‰ 2-4 ä¸ªè¦ç‚¹**\n"
                            "6. æœ‰æ•°æ®äº®ç‚¹æ—¶ç”¨ `[äº®ç‚¹]` é¡µï¼ˆå…¨æ–‡æœ€å¤š 1-2 æ¬¡ï¼‰ï¼Œæ¯é¡µ 3-4 ç»„æ•°æ®\n"
                            "7. `[è¿‡æ¸¡é¡µ]` æœ€å¤š 2 ä¸ªï¼Œç”¨äºåˆ’åˆ†å¤§ç« èŠ‚\n"
                            "8. âš ï¸ **æœç´¢èµ„æ–™å’Œç ”ç©¶æŠ¥å‘Šä¸­çš„æ•°æ®ã€æ¡ˆä¾‹ã€æ•°å­—å¿…é¡»å¦‚å®å¼•ç”¨ï¼Œä¸å¾—ç¼–é€ ã€‚æ¯é¡µè‡³å°‘å¼•ç”¨ 1 ä¸ªå…·ä½“æ•°æ®æˆ–æ¡ˆä¾‹**\n"
                            "9. ä¸­æ–‡è¾“å‡ºï¼Œåªè¾“å‡ºå¤§çº²ï¼Œä¸è¦é¢å¤–è¯´æ˜\n"
                            "10. âš ï¸ **å†…å®¹å……å®åº¦æ˜¯æœ€é‡è¦çš„è¯„åˆ¤æ ‡å‡† â€” å®å¯è¦ç‚¹å°‘ä¸€äº›ä½†æ¯ä¸ªè¦ç‚¹ä¿¡æ¯é‡å¤§ï¼Œä¸è¦å¾ˆå¤šç©ºæ´çš„è¦ç‚¹**\n"
                            "11. âš ï¸ **ç¦æ­¢å‡ºç°æ¨¡ç³Šè¡¨è¿°**ï¼šå¦‚ 'æ˜¾è‘—å¢é•¿'ã€'å¹¿æ³›åº”ç”¨'ã€'å·¨å¤§æ½œåŠ›' ç­‰ï¼Œå¿…é¡»ç”¨å…·ä½“æ•°å­—æ›¿ä»£ã€‚ä¾‹å¦‚ï¼š'å¸‚åœºè§„æ¨¡è¾¾ XX äº¿' è€Œä¸æ˜¯ 'å¸‚åœºè§„æ¨¡å·¨å¤§'\n"
                            "12. **æ¯ä¸ª [è¯¦ç»†] é¡µè‡³å°‘åŒ…å« 1 ä¸ªçœŸå®æ¡ˆä¾‹æˆ–æ•°æ®ç‚¹**ï¼Œæ•°æ®éœ€æ ‡æ³¨æ¥æºï¼ˆå¦‚ 'æ®IDCæ•°æ®' 'æ ¹æ®XXå¹´æŠ¥'ï¼‰\n"
                            f"{_focus_hint}"
                            f"{_brief_hint}"
                            f"\nç”¨æˆ·éœ€æ±‚: {user_input}\n"
                        )
                        
                        # æ³¨å…¥æœç´¢ç»“æœï¼ˆå¢åŠ é™é¢ä»¥ä¿ç•™æ›´å¤šæ•°æ®ï¼‰
                        if uploaded_file_context:
                            ppt_outline_prompt = (
                                ppt_outline_prompt[:-len("\nç”¨æˆ·éœ€æ±‚: " + user_input)] 
                                + f"\n\n## ä¸Šä¼ çš„å‚è€ƒæ–‡ä»¶å†…å®¹\n"
                                f"ä»¥ä¸‹æ˜¯ç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£èµ„æ–™ï¼Œè¯·å……åˆ†åˆ©ç”¨å…¶ä¸­çš„å†…å®¹ã€æ•°æ®ã€æ¡ˆä¾‹æ¥ç”Ÿæˆ PPTï¼š\n"
                                f"---\n{uploaded_file_context[:15000]}\n---\n"
                                f"\nç”¨æˆ·éœ€æ±‚: {user_input}\n"
                            )
                        
                        if search_context:
                            ppt_outline_prompt += (
                                f"\n**ä»¥ä¸‹æ˜¯è”ç½‘æœç´¢è·å–çš„æœ€æ–°å‚è€ƒèµ„æ–™ï¼ˆåŒ…å«é‡è¦æ•°æ®ï¼‰ï¼Œè¯·åŠ¡å¿…åŸºäºè¿™äº›ä¿¡æ¯ç”Ÿæˆå†…å®¹ï¼Œå°¤å…¶æ˜¯å…¶ä¸­çš„æ•°å­—ã€æ¡ˆä¾‹ã€å¸‚åœºæ•°æ®ï¼š**\n"
                                f"---\n{search_context[:10000]}\n---\n"
                            )
                        
                        # æ³¨å…¥æ·±åº¦ç ”ç©¶ç»“æœï¼ˆå¢åŠ é™é¢ï¼‰
                        if research_context:
                            ppt_outline_prompt += (
                                f"\n**ä»¥ä¸‹æ˜¯æ·±åº¦ç ”ç©¶åˆ†ææŠ¥å‘Šâ€”â€”è¿™æ˜¯ä½ æœ€é‡è¦çš„å†…å®¹æ¥æºï¼Œå…¶ä¸­çš„æ•°æ®å’Œåˆ†æå¿…é¡»å……åˆ†èå…¥å¤§çº²ï¼š**\n"
                                f"---\n{research_context[:12000]}\n---\n"
                            )
                        
                        # ä¹Ÿæ³¨å…¥ä¸Šä¸‹æ–‡
                        if context_info and context_info.get("is_continuation") and context_info.get("enhanced_input"):
                            ppt_outline_prompt += f"\n\nå†å²ä¸Šä¸‹æ–‡å‚è€ƒèµ„æ–™:\n{context_info['enhanced_input'][:3000]}"
                        
                        yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“ æ­£åœ¨ç”Ÿæˆå†…å®¹å¤§çº²...', 'detail': ''})}\n\n"
                        
                        outline_response = None
                        outline_models = ["gemini-2.5-flash", model_id, "gemini-2.0-flash"]
                        # æ ¹æ®ç›®æ ‡é¡µæ•°è°ƒæ•´ token é™é¢ï¼š20é¡µå¤§çº²éœ€è¦æ›´å¤šç©ºé—´
                        _outline_tokens = 16384 if (_target_pages and _target_pages >= 15) else 8192
                        for om in outline_models:
                            try:
                                resp = client.models.generate_content(
                                    model=om,
                                    contents=ppt_outline_prompt,
                                    config=types.GenerateContentConfig(
                                        temperature=0.6,
                                        max_output_tokens=_outline_tokens
                                    )
                                )
                                if resp.text:
                                    outline_response = resp.text
                                    print(f"[FILE_GEN/PPT] âœ… å¤§çº²ç”ŸæˆæˆåŠŸ ({om}), é•¿åº¦: {len(outline_response)}")
                                    break
                            except Exception as oe:
                                print(f"[FILE_GEN/PPT] å¤§çº²æ¨¡å‹ {om} å¤±è´¥: {oe}")
                                continue
                        
                        if not outline_response:
                            raise Exception("æ‰€æœ‰æ¨¡å‹å‡æ— æ³•ç”Ÿæˆå¤§çº²")
                        
                        # Step 2: è§£ææ™ºèƒ½è§„åˆ’å¤§çº²ï¼ˆæ”¯æŒå¤šç§å¹»ç¯ç‰‡ç±»å‹æ ‡ç­¾ï¼‰
                        def _parse_ppt_plan(md_text):
                            """è§£æå¸¦ [ç±»å‹] æ ‡ç­¾çš„æ™ºèƒ½ PPT å¤§çº²"""
                            import re as _re
                            lines = md_text.split('\n')
                            plan = {"title": "", "subtitle": "", "slides": []}
                            
                            _type_map = {
                                "è¿‡æ¸¡é¡µ": "divider", "è¿‡æ¸¡": "divider", "åˆ†éš”": "divider",
                                "è¯¦ç»†": "detail", "é‡ç‚¹": "detail",
                                "äº®ç‚¹": "highlight", "æ•°æ®": "highlight", "å…³é”®": "highlight",
                                "æ¦‚è§ˆ": "overview", "é€Ÿè§ˆ": "overview", "ç®€è¦": "overview", "æ€»è§ˆ": "overview",
                                "å¯¹æ¯”": "comparison", "æ¯”è¾ƒ": "comparison", "vs": "comparison",
                            }
                            
                            current_slide = None
                            current_type = "detail"
                            current_sub = None  # å½“å‰å­ä¸»é¢˜ï¼ˆç”¨äº overview / comparisonï¼‰
                            
                            for line in lines:
                                line = line.rstrip()
                                
                                # è·³è¿‡ markdown ä»£ç å—æ ‡è®°
                                if line.strip() in ('```', '```markdown'):
                                    continue
                                
                                # ç±»å‹æ ‡ç­¾è¡Œ: [xxx]
                                tag_m = _re.match(r'^\s*\[(.+?)\]\s*$', line)
                                if tag_m:
                                    tag = tag_m.group(1).strip()
                                    current_type = _type_map.get(tag, "detail")
                                    continue
                                
                                # ä¸»æ ‡é¢˜: # xxx
                                if line.startswith('# ') and not line.startswith('## '):
                                    raw = line[2:].strip()
                                    for pfx in ["å¹»ç¯ç‰‡æ ‡é¢˜ï¼š", "å¹»ç¯ç‰‡æ ‡é¢˜:", "æ¼”ç¤ºæ ‡é¢˜ï¼š", "æ¼”ç¤ºæ ‡é¢˜:", "PPTæ ‡é¢˜ï¼š", "PPTæ ‡é¢˜:"]:
                                        if raw.startswith(pfx):
                                            raw = raw[len(pfx):].strip()
                                    plan["title"] = raw
                                    continue
                                
                                # ç« èŠ‚æ ‡é¢˜: ## xxx
                                if line.startswith('## '):
                                    # ä¿å­˜ä¸Šä¸€ä¸ª slide çš„ subsection
                                    if current_sub and current_slide and current_slide.get("type") in ("overview", "comparison"):
                                        current_slide.setdefault("subsections", []).append(current_sub)
                                        current_sub = None
                                    # ä¿å­˜ä¸Šä¸€ä¸ª slide
                                    if current_slide:
                                        plan["slides"].append(current_slide)
                                    
                                    current_slide = {
                                        "type": current_type,
                                        "title": line[3:].strip(),
                                        "points": [],
                                        "content": [],
                                    }
                                    if current_type == "divider":
                                        current_slide["description"] = ""
                                    current_type = "detail"  # é‡ç½®ï¼ˆæ¯ä¸ªæ ‡ç­¾åªä½œç”¨äºç´§è·Ÿçš„ ## ï¼‰
                                    current_sub = None
                                    continue
                                
                                # å­æ ‡é¢˜: ### xxx ï¼ˆç”¨äº overview / comparisonï¼‰
                                if line.startswith('### ') and current_slide:
                                    # å¦‚æœå½“å‰ slide ä¸æ˜¯ overview/comparisonï¼Œè‡ªåŠ¨å‡çº§ä¸º overview
                                    if current_slide.get("type") not in ("overview", "comparison"):
                                        current_slide["type"] = "overview"
                                    if current_sub:
                                        current_slide.setdefault("subsections", []).append(current_sub)
                                    current_sub = {
                                        "subtitle": line[4:].strip(),
                                        "label": line[4:].strip(),
                                        "points": [],
                                    }
                                    continue
                                
                                # è¦ç‚¹è¡Œ: - / â€¢ / * æˆ–æ•°å­—ç¼–å· 1. 2. ç­‰
                                if (_re.match(r'^[\s]*[-â€¢*]\s', line) or _re.match(r'^[\s]*\d+[.ã€)\s]\s*', line)) and current_slide is not None:
                                    pt = _re.sub(r'^[\s]*[-â€¢*\d.ã€)\s]+\s*', '', line).strip()
                                    if not pt:
                                        continue
                                    if current_sub is not None:
                                        current_sub["points"].append(pt)
                                    else:
                                        current_slide["points"].append(pt)
                                        current_slide["content"].append(pt)
                                    continue
                                
                                # æ™®é€šæ–‡æœ¬è¡Œï¼ˆéç©ºã€éæ ‡é¢˜ï¼‰â†’ ä¹Ÿæ•è·ä¸ºè¦ç‚¹
                                if current_slide is not None and line.strip() and not line.startswith('#'):
                                    # è¿‡æ¸¡é¡µæè¿°æ–‡å­—ä¼˜å…ˆ
                                    if current_slide.get("type") == "divider":
                                        current_slide["description"] = line.strip()
                                        continue
                                    # æ¸…ç†å¯èƒ½æ®‹ç•™çš„ markdown æ ‡è®°
                                    cleaned = _re.sub(r'^#{1,4}\s+', '', line.strip())
                                    cleaned = cleaned.strip()
                                    if not cleaned:
                                        continue
                                    if current_sub is not None:
                                        current_sub["points"].append(cleaned)
                                    else:
                                        current_slide["points"].append(cleaned)
                                        current_slide["content"].append(cleaned)
                                    continue
                                
                                # è¿‡æ¸¡é¡µæè¿°æ–‡å­— (fallback - ä¸åº”åˆ°è¾¾è¿™é‡Œ)
                                if current_slide and current_slide.get("type") == "divider" and line.strip() and not line.startswith('#'):
                                    current_slide["description"] = line.strip()
                            
                            # æ”¶å°¾
                            if current_sub and current_slide:
                                current_slide.setdefault("subsections", []).append(current_sub)
                            if current_slide:
                                plan["slides"].append(current_slide)
                            
                            # åå¤„ç†: å¦‚æœ slide æœ‰ subsections ä½†ç±»å‹ä¸æ˜¯ overview/comparisonï¼Œè‡ªåŠ¨ä¿®æ­£
                            for sl in plan["slides"]:
                                if sl.get("subsections") and sl.get("type") not in ("overview", "comparison"):
                                    sl["type"] = "overview"
                            
                            # åå¤„ç†: comparison çš„ subsections â†’ left / right
                            for sl in plan["slides"]:
                                if sl.get("type") == "comparison" and "subsections" in sl:
                                    subs = sl["subsections"]
                                    if len(subs) >= 2:
                                        sl["left"] = subs[0]
                                        sl["right"] = subs[1]
                            
                            return plan
                        
                        ppt_data = _parse_ppt_plan(outline_response)
                        slide_count = len(ppt_data["slides"])
                        slide_types_summary = ", ".join(f'{s.get("type","detail")}' for s in ppt_data["slides"])
                        print(f"[FILE_GEN/PPT] è§£æå®Œæˆ: æ ‡é¢˜='{ppt_data['title']}', {slide_count} é¡µ, ç±»å‹=[{slide_types_summary}]")
                        
                        if slide_count == 0:
                            raise Exception("å¤§çº²è§£æå¤±è´¥ï¼Œæœªæå–åˆ°å¹»ç¯ç‰‡å†…å®¹")
                        
                        # â”€â”€â”€â”€â”€â”€â”€â”€ Step 2.1: ç”¨æˆ·æŒ‡å®šé¡µæ•°æ—¶è°ƒæ•´å¹»ç¯ç‰‡æ•°é‡ â”€â”€â”€â”€â”€â”€â”€â”€
                        _max_slides = _target_pages  # åªæœ‰ç”¨æˆ·æ˜ç¡®æŒ‡å®šæ—¶æ‰ç”Ÿæ•ˆ
                        if _max_slides and slide_count > _max_slides:
                            print(f"[FILE_GEN/PPT] âš ï¸ é¡µæ•°è¶…é™ ({slide_count} > {_max_slides})ï¼Œæ‰§è¡Œæ™ºèƒ½ç²¾ç®€...")
                            yield f"data: {json.dumps({'type': 'progress', 'message': f'âœ‚ï¸ ç²¾ç®€é¡µé¢: {slide_count} â†’ {_max_slides} é¡µ', 'detail': 'åˆå¹¶ç›¸ä¼¼å†…å®¹ï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯'})}\n\n"
                            
                            slides = ppt_data["slides"]
                            # ç­–ç•¥: 1) åˆå¹¶ç›¸é‚»çš„è¯¦ç»†é¡µä¸ºæ¦‚è§ˆé¡µ  2) å»æ‰å¤šä½™è¿‡æ¸¡é¡µ  3) æˆªæ–­å°¾éƒ¨
                            
                            # å…ˆå»æ‰å¤šä½™è¿‡æ¸¡é¡µï¼ˆåªä¿ç•™æœ€å¤š 1 ä¸ªï¼‰
                            divider_indices = [i for i, s in enumerate(slides) if s.get("type") == "divider"]
                            if len(divider_indices) > 1:
                                for idx in divider_indices[1:]:
                                    slides[idx]["_remove"] = True
                                slides = [s for s in slides if not s.get("_remove")]
                            
                            # ç„¶ååˆå¹¶ç›¸é‚»çš„è¯¦ç»†é¡µä¸ºæ¦‚è§ˆé¡µ
                            while len(slides) > _max_slides:
                                merged = False
                                for i in range(len(slides) - 1):
                                    if (slides[i].get("type") == "detail" and 
                                        slides[i+1].get("type") == "detail"):
                                        # åˆå¹¶: ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªè¯¦ç»†é¡µå˜æˆä¸€ä¸ªæ¦‚è§ˆé¡µ
                                        s1 = slides[i]
                                        s2 = slides[i+1]
                                        merged_slide = {
                                            "type": "overview",
                                            "title": s1.get("title", ""),
                                            "points": [],
                                            "content": [],
                                            "subsections": [
                                                {"subtitle": s1.get("title", ""), "label": s1.get("title", ""),
                                                 "points": (s1.get("points", []) or s1.get("content", []))[:4]},
                                                {"subtitle": s2.get("title", ""), "label": s2.get("title", ""),
                                                 "points": (s2.get("points", []) or s2.get("content", []))[:4]},
                                            ]
                                        }
                                        slides[i] = merged_slide
                                        slides.pop(i+1)
                                        merged = True
                                        break
                                if not merged:
                                    # æ— æ³•åˆå¹¶äº†ï¼Œç›´æ¥æˆªæ–­
                                    slides = slides[:_max_slides]
                                    break
                            
                            ppt_data["slides"] = slides
                            slide_count = len(slides)
                            print(f"[FILE_GEN/PPT] ç²¾ç®€å: {slide_count} é¡µ")
                        
                        yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ“Š å¤§çº²å°±ç»ª: {slide_count} é¡µå¹»ç¯ç‰‡', 'detail': ppt_data['title']})}\n\n"
                        
                        # â”€â”€â”€â”€â”€â”€â”€â”€ Step 2.2: å†…å®¹å……å®ï¼ˆé€é¡µæ‰©å†™ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€
                        # æ£€æŸ¥å†…å®¹æ˜¯å¦å•è–„ï¼ˆå¹³å‡æ¯é¡µè¦ç‚¹å°‘äº 3 ä¸ªæˆ–è¦ç‚¹å¤ªçŸ­ï¼‰
                        _thin_slides = []
                        for si, sl in enumerate(ppt_data["slides"]):
                            stype = sl.get("type", "detail")
                            if stype in ("divider",):
                                continue  # è¿‡æ¸¡é¡µä¸éœ€è¦å……å®
                            pts = sl.get("points", [])
                            subs = sl.get("subsections", [])
                            # è¦ç‚¹å¤ªå°‘ æˆ– å¹³å‡è¦ç‚¹å¤ªçŸ­
                            avg_len = sum(len(p) for p in pts) / max(len(pts), 1)
                            sub_pts_count = sum(len(sub.get("points", [])) for sub in subs) if subs else 0
                            
                            if stype == "overview":
                                # æ¦‚è§ˆé¡µï¼šå­ä¸»é¢˜æ•°å¤ªå°‘æˆ–æ¯ä¸ªå­ä¸»é¢˜è¦ç‚¹å¤ªå°‘
                                if not subs or sub_pts_count < len(subs) * 2:
                                    _thin_slides.append(si)
                            elif stype in ("detail", "comparison"):
                                if len(pts) < 3 or avg_len < 20:
                                    _thin_slides.append(si)
                            elif stype == "highlight":
                                if len(pts) < 2:
                                    _thin_slides.append(si)
                        
                        if _thin_slides:
                            yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ“ æ­£åœ¨å……å® {len(_thin_slides)} é¡µå†…å®¹...', 'detail': 'ç¡®ä¿æ¯é¡µéƒ½æœ‰ä¸°å¯Œè¯¦å®çš„ä¿¡æ¯'})}\n\n"
                            
                            # æ„å»ºæ‰¹é‡å……å® promptï¼ˆä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰è–„å¼±é¡µé¢ï¼‰
                            _enrich_prompt = (
                                "ä½ æ˜¯PPTå†…å®¹æ’°å†™ä¸“å®¶ã€‚ä»¥ä¸‹å¹»ç¯ç‰‡å†…å®¹å¤ªå•è–„ï¼Œè¯·é€é¡µå……å®ã€‚\n\n"
                                "**è¦æ±‚ï¼š**\n"
                                "1. æ¯ä¸ª[è¯¦ç»†]é¡µå¿…é¡»æœ‰ 4-6 ä¸ªè¦ç‚¹ï¼Œæ¯ä¸ªè¦ç‚¹ 30-80 å­—\n"
                                "2. æ¯ä¸ª[æ¦‚è§ˆ]é¡µçš„æ¯ä¸ªå­ä¸»é¢˜ä¸‹å¿…é¡»æœ‰ 2-4 ä¸ªè¦ç‚¹\n"
                                "3. ä¿æŒ `- **å…³é”®è¯** â€” è¯¦ç»†è§£é‡Š` çš„æ ¼å¼\n"
                                "4. âš ï¸ **å¿…é¡»åŒ…å«å…·ä½“æ•°æ®ã€æ¡ˆä¾‹ã€äº‹å®** â€” ç¦æ­¢å†™ 'æ˜¾è‘—å¢é•¿' 'å¹¿æ³›åº”ç”¨' ç­‰æ¨¡ç³Šè¡¨è¿°ï¼Œ\n"
                                "   å¿…é¡»å†™ 'æ®IDCæ•°æ®ï¼Œ2025å¹´å¸‚åœºè§„æ¨¡è¾¾XXXäº¿' è¿™æ ·æœ‰æ•°å­—æœ‰æ¥æºçš„å†…å®¹\n"
                                "5. ä¼˜å…ˆä½¿ç”¨ä¸‹æ–¹ã€å‚è€ƒèµ„æ–™ã€‘å’Œã€ç ”ç©¶åˆ†æã€‘ä¸­çš„çœŸå®æ•°æ®\n"
                                "6. ä¸¥æ ¼æŒ‰ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦é¢å¤–æ–‡å­—\n\n"
                            )
                            
                            _slides_to_enrich = []
                            for si in _thin_slides:
                                sl = ppt_data["slides"][si]
                                _slides_to_enrich.append({
                                    "index": si,
                                    "type": sl.get("type", "detail"),
                                    "title": sl.get("title", ""),
                                    "current_points": sl.get("points", []),
                                    "subsections": [
                                        {"subtitle": sub.get("subtitle", ""), "points": sub.get("points", [])}
                                        for sub in sl.get("subsections", [])
                                    ] if sl.get("subsections") else []
                                })
                            
                            _enrich_prompt += f"ä¸»é¢˜: {ppt_data['title']}\n"
                            if search_context:
                                _enrich_prompt += f"\nå‚è€ƒèµ„æ–™ï¼ˆåŒ…å«é‡è¦æ•°æ®ï¼Œè¯·å……åˆ†åˆ©ç”¨ï¼‰:\n{search_context[:6000]}\n"
                            if research_context:
                                _enrich_prompt += f"\nç ”ç©¶åˆ†æï¼ˆåŒ…å«æ ¸å¿ƒæ•°æ®å’Œæ¡ˆä¾‹ï¼Œå¿…é¡»èå…¥ï¼‰:\n{research_context[:6000]}\n"
                            
                            _enrich_prompt += (
                                f"\néœ€è¦å……å®çš„å¹»ç¯ç‰‡:\n```json\n{json.dumps(_slides_to_enrich, ensure_ascii=False, indent=2)}\n```\n\n"
                                "è¯·è¾“å‡ºå……å®åçš„ç»“æœï¼Œæ ¼å¼:\n"
                                "```json\n"
                                "[{\"index\": 0, \"points\": [\"...\", ...], \"subsections\": [{\"subtitle\": \"...\", \"points\": [\"...\"]}, ...]}]\n"
                                "```\n"
                                "åªè¾“å‡º JSONï¼Œä¸è¦é¢å¤–æ–‡å­—ã€‚"
                            )
                            
                            try:
                                _enrich_resp = client.models.generate_content(
                                    model="gemini-2.5-flash",
                                    contents=_enrich_prompt,
                                    config=types.GenerateContentConfig(temperature=0.5, max_output_tokens=8192)
                                )
                                _enrich_text = _enrich_resp.text or ""
                                import re as _enrich_re
                                _em = _enrich_re.search(r'\[.*\]', _enrich_text, _enrich_re.DOTALL)
                                if _em:
                                    _enriched = json.loads(_em.group())
                                    _applied = 0
                                    for _e in _enriched:
                                        _idx = _e.get("index")
                                        if _idx is not None and 0 <= _idx < len(ppt_data["slides"]):
                                            _sl = ppt_data["slides"][_idx]
                                            # æ›´æ–° points
                                            if _e.get("points") and len(_e["points"]) >= len(_sl.get("points", [])):
                                                _sl["points"] = _e["points"]
                                                _sl["content"] = _e["points"]
                                            # æ›´æ–° subsections
                                            if _e.get("subsections") and len(_e["subsections"]) > 0:
                                                _new_subs = []
                                                for _ns in _e["subsections"]:
                                                    _new_subs.append({
                                                        "subtitle": _ns.get("subtitle", ""),
                                                        "label": _ns.get("subtitle", ""),
                                                        "points": _ns.get("points", [])
                                                    })
                                                if _new_subs:
                                                    _sl["subsections"] = _new_subs
                                                    # ä¹Ÿæ›´æ–° comparison çš„ left/right
                                                    if _sl.get("type") == "comparison" and len(_new_subs) >= 2:
                                                        _sl["left"] = _new_subs[0]
                                                        _sl["right"] = _new_subs[1]
                                            _applied += 1
                                    
                                    if _applied > 0:
                                        yield f"data: {json.dumps({'type': 'progress', 'message': f'âœ… å·²å……å® {_applied} é¡µå†…å®¹', 'detail': ''})}\n\n"
                                        print(f"[FILE_GEN/PPT] âœ… å†…å®¹å……å®å®Œæˆ: {_applied}/{len(_thin_slides)} é¡µ")
                                    else:
                                        print(f"[FILE_GEN/PPT] âš ï¸ å†…å®¹å……å®è§£ææˆåŠŸä½†æœªåº”ç”¨")
                                else:
                                    print(f"[FILE_GEN/PPT] âš ï¸ å†…å®¹å……å®è¿”å›æ ¼å¼å¼‚å¸¸")
                            except Exception as enrich_err:
                                print(f"[FILE_GEN/PPT] âš ï¸ å†…å®¹å……å®å¼‚å¸¸ï¼ˆä¸å½±å“ç”Ÿæˆï¼‰: {enrich_err}")
                        
                        # â”€â”€â”€â”€â”€â”€â”€â”€ Step 2.5: ä¸ºå¹»ç¯ç‰‡ç”Ÿæˆé…å›¾ï¼ˆNano Banana ä¼˜å…ˆï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€
                        ppt_images = []
                        # å¯¹è¯¦ç»†é¡µé…å›¾ï¼ˆæ¦‚è§ˆ/å¯¹æ¯”/è¿‡æ¸¡/äº®ç‚¹é¡µä¸é€‚åˆæ’å›¾ï¼‰
                        img_candidate_slides = [(i, s) for i, s in enumerate(ppt_data["slides"]) 
                                         if s.get("type", "detail") == "detail"]
                        
                        if img_candidate_slides:
                            _n_images = min(4, max(2, len(img_candidate_slides) // 2 + 1))
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ–¼ï¸ Nano Banana æ­£åœ¨ç”Ÿæˆé…å›¾...', 'detail': f'ä¸º {_n_images} ä¸ªé‡ç‚¹é¡µé¢ç”Ÿæˆä¸“ä¸šæ’å›¾'})}\n\n"
                            try:
                                slide_titles_for_img = [s.get("title", "") for _, s in img_candidate_slides]
                                img_results = WebSearcher.generate_ppt_images(
                                    slide_titles_for_img,
                                    topic=ppt_data["title"],
                                    max_images=_n_images
                                )
                                # å°†é…å›¾è·¯å¾„æ³¨å…¥åˆ°å¯¹åº” slide
                                for img_info in img_results:
                                    picked_idx = img_info["slide_index"]
                                    if picked_idx < len(img_candidate_slides):
                                        real_idx = img_candidate_slides[picked_idx][0]
                                        ppt_data["slides"][real_idx]["image"] = img_info["image_path"]
                                        ppt_images.append(img_info["image_path"])
                                
                                if ppt_images:
                                    yield f"data: {json.dumps({'type': 'progress', 'message': f'âœ… å·²ç”Ÿæˆ {len(ppt_images)} å¼ é…å›¾', 'detail': ''})}\n\n"
                                else:
                                    yield f"data: {json.dumps({'type': 'progress', 'message': 'âš ï¸ é…å›¾ç”ŸæˆæœªæˆåŠŸï¼Œç»§ç»­ä½¿ç”¨çº¯æ–‡æœ¬', 'detail': ''})}\n\n"
                            except Exception as img_err:
                                print(f"[FILE_GEN/PPT] âš ï¸ é…å›¾ç”Ÿæˆå¼‚å¸¸: {img_err}")
                                yield f"data: {json.dumps({'type': 'progress', 'message': 'âš ï¸ é…å›¾è·³è¿‡ï¼Œä¸å½±å“PPTç”Ÿæˆ', 'detail': ''})}\n\n"
                        
                        # â”€â”€â”€â”€â”€â”€â”€â”€ Step 3: ç”Ÿæˆ PPT æ–‡ä»¶(å«é€é¡µè¿›åº¦) â”€â”€â”€â”€â”€â”€â”€â”€
                        yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ¨ å¼€å§‹æ¸²æŸ“ PPT æ–‡ä»¶...', 'detail': ''})}\n\n"
                        
                        from web.ppt_generator import PPTGenerator
                        
                        # æ£€æµ‹ä¸»é¢˜
                        theme = "business"
                        if any(kw in user_lower_check for kw in ["æŠ€æœ¯", "tech", "ç§‘æŠ€", "ç¼–ç¨‹", "å¼€å‘"]):
                            theme = "tech"
                        elif any(kw in user_lower_check for kw in ["åˆ›æ„", "creative", "è‰ºæœ¯", "è®¾è®¡"]):
                            theme = "creative"
                        
                        ppt_gen = PPTGenerator(theme=theme)
                        
                        ppt_title = ppt_data["title"] or "æ¼”ç¤ºæ–‡ç¨¿"
                        safe_title = re.sub(r'[\\/*?:"<>|]', '_', ppt_title)[:50]
                        filename = f"{safe_title}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pptx"
                        docs_dir = settings_manager.documents_dir
                        os.makedirs(docs_dir, exist_ok=True)
                        ppt_path = os.path.join(docs_dir, filename)
                        
                        # ä½¿ç”¨ progress_callback æ¥æ”¶é›†è¿›åº¦æ¶ˆæ¯ï¼ˆç”Ÿæˆå™¨æ— æ³•åœ¨å›è°ƒä¸­yieldï¼‰
                        _slide_progress_msgs = []
                        def _ppt_progress_cb(cur, total, stitle, stype):
                            _slide_progress_msgs.append((cur, total, stitle, stype))
                        
                        ppt_gen.generate_from_outline(
                            title=ppt_title,
                            outline=ppt_data["slides"],
                            output_path=ppt_path,
                            subtitle=ppt_data.get("subtitle", ""),
                            author="Koto AI",
                            progress_callback=_ppt_progress_cb
                        )
                        
                        # å‘é€é€é¡µè¿›åº¦ï¼ˆå›è°ƒå·²ç»æ”¶é›†å®Œæ¯•ï¼‰
                        for cur, total, stitle, stype in _slide_progress_msgs:
                            if stitle:
                                yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ“„ æ¸²æŸ“ {cur}/{total}: {stitle}', 'detail': stype})}\n\n"
                        
                        yield f"data: {json.dumps({'type': 'progress', 'message': 'âœ… PPT æ¸²æŸ“å®Œæˆï¼Œæ­£åœ¨ä¿å­˜...', 'detail': ''})}\n\n"
                        
                        rel_path = os.path.relpath(ppt_path, WORKSPACE_DIR).replace("\\", "/")
                        generated_files.append(rel_path)
                        
                        # ç»Ÿè®¡å„ç±»å‹å¹»ç¯ç‰‡æ•°é‡
                        _type_names = {"detail": "è¯¦ç»†é¡µ", "overview": "æ¦‚è§ˆé¡µ", "highlight": "äº®ç‚¹é¡µ", "divider": "è¿‡æ¸¡é¡µ", "comparison": "å¯¹æ¯”é¡µ"}
                        _type_counts = {}
                        for _s in ppt_data["slides"]:
                            _t = _s.get("type", "detail")
                            _type_counts[_t] = _type_counts.get(_t, 0) + 1
                        _type_desc = "ã€".join(f"{_type_names.get(k,k)} Ã—{v}" for k, v in _type_counts.items())
                        
                        _img_desc = f"\nğŸ–¼ï¸ é…å›¾: {len(ppt_images)} å¼ " if ppt_images else ""
                        _research_desc = "\nğŸ”¬ å·²èå…¥æ·±åº¦ç ”ç©¶åˆ†æ" if research_context else ""
                        
                        # â”€â”€â”€â”€â”€â”€â”€â”€ ä¿å­˜ä¼šè¯æ•°æ®ï¼ˆP1 ç¼–è¾‘åŠŸèƒ½æ”¯æŒï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€
                        if ppt_session_id:
                            try:
                                from web.ppt_session_manager import get_ppt_session_manager
                                ppt_session_mgr = get_ppt_session_manager()
                                ppt_session_mgr.save_generation_data(
                                    session_id=ppt_session_id,
                                    ppt_data=ppt_data,
                                    ppt_file_path=rel_path,
                                    search_context=search_context,
                                    research_context=research_context,
                                    uploaded_file_context=uploaded_file_context
                                )
                                print(f"[FILE_GEN/PPT] ğŸ’¾ ä¼šè¯æ•°æ®å·²ä¿å­˜ï¼Œå¯ç”¨äºåç»­ç¼–è¾‘")
                            except Exception as save_err:
                                print(f"[FILE_GEN/PPT] âš ï¸ ä¼šè¯ä¿å­˜å¼‚å¸¸: {save_err}")
                        
                        success_msg = (
                            f"âœ… **PPT æ¼”ç¤ºæ–‡ç¨¿ç”ŸæˆæˆåŠŸï¼**\n\n"
                            f"ğŸ“Š æ ‡é¢˜: **{ppt_title}**\n"
                            f"ğŸ“„ é¡µæ•°: {slide_count} é¡µï¼ˆ{_type_desc}ï¼‰{_img_desc}{_research_desc}\n"
                            f"ğŸ“ æ–‡ä»¶: **{filename}**\n"
                            f"ğŸ“ ä½ç½®: `{docs_dir}`"
                        )
                        
                        # å¦‚æœæœ‰ä¼šè¯ï¼Œé™„åŠ ç¼–è¾‘é“¾æ¥
                        if ppt_session_id:
                            success_msg += f"\n\nğŸ¨ **[ç‚¹å‡»ç¼–è¾‘ PPT](/edit-ppt/{ppt_session_id})** - ä¿®æ”¹å†…å®¹ã€è°ƒæ•´é¡ºåºã€é‡æ–°ç”Ÿæˆé¡µé¢"
                        
                        yield f"data: {json.dumps({'type': 'token', 'content': success_msg})}\n\n"
                        print(f"[FILE_GEN/PPT] âœ… PPT ç”ŸæˆæˆåŠŸ: {rel_path}")
                        
                    except Exception as ppt_err:
                        print(f"[FILE_GEN/PPT] âŒ PPT ç”Ÿæˆå¤±è´¥: {ppt_err}")
                        import traceback
                        traceback.print_exc()
                        error_msg = f"âŒ PPT ç”Ÿæˆå¤±è´¥: {str(ppt_err)}"
                        yield f"data: {json.dumps({'type': 'token', 'content': error_msg})}\n\n"
                    
                    # ä¿å­˜å†å²ï¼ˆåŸºäºç£ç›˜å®Œæ•´å†å²è¿½åŠ ï¼Œåœ¨ done äº‹ä»¶ä¹‹å‰ï¼‰
                    _ppt_msg = f"å·²ç”ŸæˆPPT: {', '.join(generated_files)}" if generated_files else "PPTç”Ÿæˆå¤±è´¥"
                    session_manager.append_and_save(f"{session_name}.json", user_input, _ppt_msg)
                    
                    total_time = time.time() - start_time
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': generated_files, 'total_time': total_time})}\n\n"
                    return
                
                # ä½¿ç”¨ä¸Šä¸‹æ–‡å¢å¼ºçš„è¾“å…¥ï¼ˆå¦‚æœæœ‰ï¼Œä¾‹å¦‚"æŠŠè¿™ä¸ªåšæˆword"æ—¶ä¼šåŒ…å«ä¹‹å‰çš„å†…å®¹ï¼‰
                if context_info and context_info.get("is_continuation") and context_info.get("enhanced_input"):
                    file_gen_input = context_info["enhanced_input"]
                    print(f"[FILE_GEN] ä½¿ç”¨ä¸Šä¸‹æ–‡å¢å¼ºè¾“å…¥ (length: {len(file_gen_input)})")
                else:
                    file_gen_input = effective_input

                # â­ FILE_GEN å‰ç½®æ­¥éª¤ï¼šæ—¶é—´è§£æ + ä¿¡æ¯æ”¶é›†
                _time_context_text, _time_parse = _build_filegen_time_context(user_input)
                _web_context = ""
                _should_collect = WebSearcher.needs_web_search(user_input)

                # å¯¹â€œXæœˆæ–°ç•ª/ç•ªå‰§/åŠ¨ç”»â€ç­‰æ—¶é—´æ•æ„Ÿä¸»é¢˜å¼ºåˆ¶å¯ç”¨ä¿¡æ¯æ”¶é›†
                _anime_time_patterns = [
                    r'([1-9]|1[0-2])\s*æœˆ\s*(æ–°ç•ª|ç•ªå‰§|åŠ¨ç”»)',
                    r'(æ–°ç•ª|ç•ªå‰§|åŠ¨ç”»).*(\d{1,2}\s*æœˆ)',
                ]
                if not _should_collect and any(re.search(p, user_input, re.IGNORECASE) for p in _anime_time_patterns):
                    _should_collect = True

                if _should_collect:
                    try:
                        if _time_parse.get("resolved_month"):
                            _q = f"{_time_parse['resolved_year']}å¹´{_time_parse['resolved_month']}æœˆ æ–°ç•ª åŠ¨ç”» ç•ªå‰§ åå• ä»‹ç»"
                        else:
                            _q = user_input

                        _time_detail = _time_context_text.replace("\n", " | ")[:180]
                        yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ•’ æ­£åœ¨è§£ææ—¶é—´è¯­ä¹‰...', 'detail': _time_detail})}\n\n"
                        yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸŒ æ­£åœ¨æ”¶é›†æœ€æ–°ä¿¡æ¯...', 'detail': _q[:120]})}\n\n"

                        _search_res = WebSearcher.search_with_grounding(_q)
                        if _search_res.get("success") and _search_res.get("response"):
                            _web_context = _search_res.get("response", "")
                            print(f"[FILE_GEN] âœ… ä¿¡æ¯æ”¶é›†å®Œæˆï¼Œé•¿åº¦: {len(_web_context)}")
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'âœ… ä¿¡æ¯æ”¶é›†å®Œæˆ', 'detail': f'å·²è·å– {len(_web_context)} å­—ç¬¦å‚è€ƒä¿¡æ¯'})}\n\n"
                        else:
                            print(f"[FILE_GEN] âš ï¸ ä¿¡æ¯æ”¶é›†æœªè¿”å›ç»“æœ")
                    except Exception as _collect_err:
                        print(f"[FILE_GEN] âš ï¸ ä¿¡æ¯æ”¶é›†å¼‚å¸¸: {_collect_err}")

                # å°†æ—¶é—´ä¸Šä¸‹æ–‡/æ£€ç´¢ç»“æœæ‹¼æ¥è¿›ç”Ÿæˆè¾“å…¥
                _prepended_blocks = [_time_context_text]
                if _web_context:
                    _prepended_blocks.append("[è”ç½‘æ£€ç´¢å‚è€ƒ]\n" + _web_context[:9000])
                file_gen_input = "\n\n".join(_prepended_blocks) + "\n\n" + file_gen_input

                # â­ åˆ¤æ–­æ˜¯å¦æ˜¯æ–‡æ¡£ç”Ÿæˆè¯·æ±‚ï¼ˆWord/PDFï¼‰
                _doc_keywords = ["word", "docx", "doc", "pdf", "æŠ¥å‘Š", "æ–‡æ¡£", "è®ºæ–‡", "ç»¼è¿°", "whitepaper"]
                _is_doc_request = any(k in user_input.lower() for k in _doc_keywords)
                _is_complex = (context_info or {}).get("complexity") == "complex"

                if _is_doc_request:
                    # ============== æ–‡æ¡£ç›´å‡ºæ¨¡å¼ï¼ˆæµå¼ï¼‰ ==============
                    # ä½¿ç”¨ generate_content_stream ä¿æŒè¿æ¥æ´»è·ƒï¼Œé¿å…ä»£ç†è¶…æ—¶æ–­å¼€
                    _doc_type = "PDF" if "pdf" in user_input.lower() else "Word"
                    yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ“„ æ­£åœ¨ç”Ÿæˆ {_doc_type} æ–‡æ¡£...', 'detail': 'è¯·ç¨å€™ï¼Œæ­£åœ¨æ’°å†™å†…å®¹'})}\n\n"
                    print(f"[FILE_GEN] ğŸ“„ æ–‡æ¡£ç›´å‡ºæ¨¡å¼-æµå¼ (type={_doc_type}, complex={_is_complex})")

                    _doc_instruction = """ä½ æ˜¯ Koto ä¸“ä¸šæ–‡æ¡£æ’°å†™åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œç›´æ¥è¾“å‡º**å®Œæ•´ã€è¯¦ç»†ã€é«˜è´¨é‡**çš„æ–‡æ¡£æ­£æ–‡å†…å®¹ã€‚

## è¾“å‡ºè§„åˆ™
- ç›´æ¥è¾“å‡º Markdown æ ¼å¼çš„æ–‡æ¡£æ­£æ–‡ï¼Œä¸è¦è¾“å‡ºä»£ç 
- ä½¿ç”¨ # ## ### ç»„ç»‡æ ‡é¢˜å±‚çº§
- ä½¿ç”¨æ®µè½ã€åˆ—è¡¨ã€è¡¨æ ¼ä¸°å¯Œå†…å®¹
- ä¸­æ–‡æ’°å†™ï¼Œä¸“ä¸šæœ¯è¯­å‡†ç¡®
- å†…å®¹è¦**å……å®è¯¦å°½**ï¼Œæ¯ä¸€èŠ‚è‡³å°‘2-3æ®µï¼Œæ€»å­—æ•°ä¸å°‘äº3000å­—
- å¦‚æœæ˜¯æŠ€æœ¯æŠ¥å‘Šï¼Œå¿…é¡»åŒ…å«ï¼šè¡Œä¸šæ¦‚è¿°ã€æŠ€æœ¯åŸç†ã€å…³é”®å·¥è‰ºã€å¯¹æ¯”åˆ†æã€åº”ç”¨åœºæ™¯ã€å‘å±•è¶‹åŠ¿
- ä¸è¦è¾“å‡ºä»»ä½• BEGIN_FILE/END_FILE æ ‡è®°
- ä¸è¦è¾“å‡º JSON æˆ–ä»£ç æ ¼å¼"""

                    _doc_instruction += "\n\næ—¶é—´è¦æ±‚ï¼šè‹¥ç”¨æˆ·è¯·æ±‚æ¶‰åŠæœˆä»½ä½†æœªå†™å¹´ä»½ï¼ˆå¦‚â€˜1æœˆæ–°ç•ªâ€™ï¼‰ï¼Œå¿…é¡»æŒ‰å½“å‰å¹´ä»½æ’°å†™ï¼Œç¦æ­¢é»˜è®¤å›é€€åˆ°å†å²å¹´ä»½ã€‚"

                    _max_tokens = 16384 if _is_complex else 8192
                    _doc_models = list(dict.fromkeys([
                        model_id,
                        "gemini-3-pro-preview",
                        "gemini-2.5-flash",
                        "gemini-2.0-flash",
                    ]))

                    _doc_collected = []  # æ”¶é›†æ‰€æœ‰æµå¼æ–‡æœ¬å—

                    for model_attempt, current_model in enumerate(_doc_models):
                        if _doc_collected:
                            break
                        if interrupted():
                            yield f"data: {json.dumps({'type': 'token', 'content': 'â¹ï¸ æ–‡ä»¶ç”Ÿæˆå·²ä¸­æ–­'})}\n\n"
                            total_time = time.time() - start_time
                            yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                            return
                        if model_attempt > 0:
                            yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ”„ åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹ {current_model}...', 'detail': ''})}\n\n"
                            _doc_collected.clear()
                        else:
                            yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸš€ æ­£åœ¨è°ƒç”¨ {current_model}...', 'detail': 'æµå¼ç”Ÿæˆä¸­'})}\n\n"

                        try:
                            _doc_stream = client.models.generate_content_stream(
                                model=current_model,
                                contents=file_gen_input,
                                config=types.GenerateContentConfig(
                                    system_instruction=_doc_instruction,
                                    max_output_tokens=_max_tokens,
                                    temperature=0.7,
                                )
                            )
                            _first_chunk = False
                            for item_type, item_data in stream_with_keepalive(
                                _doc_stream, start_time,
                                keepalive_interval=5,
                                max_wait_first_token=120  # æ–‡æ¡£ç”Ÿæˆå…è®¸ç­‰å¾…æ›´ä¹…
                            ):
                                if interrupted():
                                    print(f"[FILE_GEN/DOC] ç”¨æˆ·ä¸­æ–­")
                                    _interrupt_msg = '\n\nâ¹ï¸ æ–‡ä»¶ç”Ÿæˆå·²ä¸­æ–­'
                                    yield f"data: {json.dumps({'type': 'token', 'content': _interrupt_msg})}\n\n"
                                    break

                                if item_type == 'heartbeat':
                                    _elapsed = item_data
                                    _char_count = sum(len(c) for c in _doc_collected)
                                    if _first_chunk:
                                        yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“ æ­£åœ¨æ’°å†™æ–‡æ¡£...', 'detail': f'å·²ç”Ÿæˆ {_char_count} å­—ç¬¦ï¼Œè€—æ—¶ {_elapsed}s'})}\n\n"
                                    else:
                                        yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ§  æ¨¡å‹æ­£åœ¨ç»„ç»‡å†…å®¹...', 'detail': f'å·²ç­‰å¾… {_elapsed}sï¼Œè¯·è€å¿ƒç­‰å¾…'})}\n\n"

                                elif item_type == 'timeout':
                                    print(f"[FILE_GEN/DOC] âš ï¸ {current_model} ç­‰å¾…é¦–tokenè¶…æ—¶: {item_data}")
                                    break  # å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹

                                elif item_type == 'chunk':
                                    chunk = item_data
                                    if chunk.text:
                                        if not _first_chunk:
                                            _first_chunk = True
                                            print(f"[FILE_GEN/DOC] âœ… {current_model} æ”¶åˆ°ç¬¬ä¸€ä¸ªå“åº”å—ï¼Œè€—æ—¶ {time.time() - start_time:.1f}s")
                                        _doc_collected.append(chunk.text)
                                        # æ¯æ”¶åˆ°10ä¸ªchunkå‘é€ä¸€æ¬¡è¿›åº¦æ›´æ–°ï¼Œä¿æŒå®¢æˆ·ç«¯è¿æ¥æ´»è·ƒ
                                        if len(_doc_collected) % 10 == 0:
                                            _char_count = sum(len(c) for c in _doc_collected)
                                            _elapsed = int(time.time() - start_time)
                                            yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“ æ­£åœ¨æ’°å†™æ–‡æ¡£...', 'detail': f'å·²ç”Ÿæˆ {_char_count} å­—ç¬¦ï¼Œè€—æ—¶ {_elapsed}s'})}\n\n"

                        except Exception as _doc_err:
                            err_str = str(_doc_err)
                            print(f"[FILE_GEN/DOC] âŒ {current_model}: {err_str[:200]}")
                            if "location is not supported" in err_str.lower():
                                response_text = "âŒ åœ°åŒºé™åˆ¶ï¼Œè¯·é…ç½®ä¸­è½¬æœåŠ¡"
                                break
                            continue

                    response_text = ''.join(_doc_collected)
                    if response_text:
                        print(f"[FILE_GEN/DOC] âœ… æµå¼ç”Ÿæˆå®Œæˆï¼Œå…± {len(response_text)} å­—ç¬¦")

                    if not response_text or response_text.startswith("âŒ"):
                        yield f"data: {json.dumps({'type': 'token', 'content': response_text or 'âŒ æ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•'})}\n\n"
                    else:
                        # ç›´æ¥ä¿å­˜æ–‡æ¡£
                        yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ“ æ­£åœ¨ä¿å­˜ {_doc_type} æ–‡æ¡£...', 'detail': ''})}\n\n"
                        try:
                            try:
                                from web.document_generator import save_docx, save_pdf
                            except ModuleNotFoundError:
                                from document_generator import save_docx, save_pdf
                            docs_dir = settings_manager.documents_dir
                            os.makedirs(docs_dir, exist_ok=True)
                            title_match = re.search(r'^#\s*(.+)$', response_text, re.MULTILINE)
                            title = title_match.group(1).strip()[:50] if title_match else f"Kotoæ–‡æ¡£_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                            if _doc_type == "PDF":
                                saved_path = save_pdf(response_text, title=title, output_dir=docs_dir)
                            else:
                                saved_path = save_docx(response_text, title=title, output_dir=docs_dir)
                            rel_path = os.path.relpath(saved_path, WORKSPACE_DIR).replace("\\", "/")
                            generated_files.append(rel_path)
                            success_msg = f"âœ… **{_doc_type} æ–‡æ¡£ç”ŸæˆæˆåŠŸï¼**\n\nğŸ“ æ–‡ä»¶: **{os.path.basename(saved_path)}**\nğŸ“ ä½ç½®: `{docs_dir}`"
                            yield f"data: {json.dumps({'type': 'token', 'content': success_msg})}\n\n"
                            print(f"[FILE_GEN/DOC] âœ… æ–‡æ¡£å·²ä¿å­˜: {rel_path}")
                        except Exception as doc_err:
                            import traceback
                            traceback.print_exc()
                            print(f"[FILE_GEN/DOC] âŒ æ–‡æ¡£ä¿å­˜å¤±è´¥: {doc_err}")
                            fallback_msg = f"âš ï¸ æ–‡æ¡£ä¿å­˜å¤±è´¥ ({doc_err})ï¼Œä»¥ä¸‹æ˜¯ç”Ÿæˆçš„å†…å®¹ï¼š\n\n"
                            yield f"data: {json.dumps({'type': 'token', 'content': fallback_msg + response_text})}\n\n"

                    _gen_msg = f"å·²ç”Ÿæˆæ–‡ä»¶: {', '.join(generated_files)}" if generated_files else (response_text[:500] if response_text else "ç”Ÿæˆå¤±è´¥")
                    session_manager.append_and_save(f"{session_name}.json", user_input, _gen_msg)
                    total_time = time.time() - start_time
                    print(f"[FILE_GEN/DOC] â˜…â˜…â˜… done event, files: {generated_files}, time: {total_time:.2f}s")
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': generated_files, 'total_time': total_time})}\n\n"
                    return

                # æ™®é€š FILE_GEN æ¨¡å¼ï¼ˆéœ€è¦æ¨¡å‹ç”Ÿæˆä»£ç /è„šæœ¬ï¼‰
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“„ æ­£åœ¨ç”Ÿæˆæ–‡ä»¶ä»£ç ...', 'detail': 'è¯·ç¨å€™ï¼Œå¯èƒ½éœ€è¦ 10-30 ç§’'})}\n\n"
                
                # æ¨¡å‹åˆ—è¡¨ï¼ˆä¸»æ¨¡å‹ + å¤‡ç”¨æ¨¡å‹ï¼‰
                file_gen_models = [
                    model_id,  # ä¸»æ¨¡å‹
                    "gemini-3-pro-preview",  # å¤‡ç”¨1 (æ›´å¼ºçš„æ¨ç†)
                    "gemini-2.5-flash",  # å¤‡ç”¨2
                    "gemini-2.0-flash",  # å¤‡ç”¨3
                ]
                
                # ä½¿ç”¨çº¿ç¨‹ + è¶…æ—¶æ¥è°ƒç”¨APIï¼ˆå¸¦é‡è¯•ï¼‰
                import threading
                import tempfile
                
                for model_attempt, current_model in enumerate(file_gen_models):
                    if response_text and not response_text.startswith("âŒ"):
                        break  # å·²æˆåŠŸ

                    if interrupted():
                        yield f"data: {json.dumps({'type': 'token', 'content': 'â¹ï¸ æ–‡ä»¶ç”Ÿæˆå·²ä¸­æ–­'})}\n\n"
                        total_time = time.time() - start_time
                        yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                        return
                    
                    if model_attempt > 0:
                        yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ”„ åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹ {current_model}...', 'detail': ''})}\n\n"
                        print(f"[FILE_GEN] Trying fallback model: {current_model}")
                    else:
                        yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸš€ æ­£åœ¨è°ƒç”¨ {current_model}...', 'detail': 'ç”Ÿæˆä¸­'})}\n\n"
                    
                    response_holder = {'data': None, 'error': None}
                    
                    def call_api(m=current_model):
                        try:
                            print(f"[FILE_GEN] Calling API: {m}")
                            response = client.models.generate_content(
                                model=m,
                                contents=file_gen_input,  # ä½¿ç”¨ä¸Šä¸‹æ–‡å¢å¼ºçš„è¾“å…¥
                                config=types.GenerateContentConfig(
                                    system_instruction=_get_system_instruction(),
                                    max_output_tokens=8192
                                )
                            )
                            response_holder['data'] = response
                            print(f"[FILE_GEN] âœ… API call successful with {m}")
                        except Exception as e:
                            print(f"[FILE_GEN] âŒ API call exception with {m}: {type(e).__name__}: {str(e)}")
                            response_holder['error'] = e
                    
                    api_thread = threading.Thread(target=call_api, daemon=True)
                    api_thread.start()
                    
                    # åœ¨ç­‰å¾…æœŸé—´å‘é€å¿ƒè·³è¿›åº¦
                    wait_interval = 5  # æ¯ 5 ç§’å‘é€ä¸€æ¬¡è¿›åº¦
                    elapsed = 0
                    while api_thread.is_alive() and elapsed < api_timeout:
                        api_thread.join(timeout=wait_interval)
                        elapsed += wait_interval
                        if interrupted():
                            yield f"data: {json.dumps({'type': 'token', 'content': 'â¹ï¸ æ–‡ä»¶ç”Ÿæˆå·²ä¸­æ–­'})}\n\n"
                            total_time = time.time() - start_time
                            yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                            return
                        if api_thread.is_alive() and elapsed < api_timeout:
                            yield f"data: {json.dumps({'type': 'progress', 'message': f'â³ æ­£åœ¨ç”Ÿæˆä¸­...', 'detail': f'å·²ç­‰å¾… {elapsed} ç§’'})}\n\n"
                    
                    if api_thread.is_alive():
                        print(f"[FILE_GEN] âš ï¸ API call timeout with {current_model} after {api_timeout}s")
                        yield f"data: {json.dumps({'type': 'progress', 'message': f'âš ï¸ {current_model} å“åº”è¶…æ—¶', 'detail': 'æ­£åœ¨åˆ‡æ¢æ¨¡å‹...'})}\n\n"
                        response_text = ""
                        continue  # å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
                    elif response_holder['error']:
                        error_str = str(response_holder['error'])
                        print(f"[FILE_GEN] API Error with {current_model}: {error_str}")
                        
                        # åœ°åŒºé™åˆ¶é”™è¯¯ - ç›´æ¥å¤±è´¥ï¼Œä¸é‡è¯•
                        if "location is not supported" in error_str.lower() or "failed_precondition" in error_str.lower():
                            response_text = "âŒ åœ°åŒºé™åˆ¶\n\næ‚¨æ‰€åœ¨çš„åœ°åŒºä¸æ”¯æŒ Gemini APIã€‚\n\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:\n1. åœ¨ config/gemini_config.env é…ç½®ä¸­è½¬æœåŠ¡ GEMINI_API_BASE\n2. æˆ–ä½¿ç”¨æ”¯æŒçš„ä»£ç†æœåŠ¡"
                            break  # åœ°åŒºé™åˆ¶ï¼Œä¸ç»§ç»­é‡è¯•
                        elif "503" in error_str or "overloaded" in error_str.lower() or "unavailable" in error_str.lower():
                            yield f"data: {json.dumps({'type': 'progress', 'message': f'âš ï¸ {current_model} æœåŠ¡ç¹å¿™', 'detail': 'æ­£åœ¨åˆ‡æ¢æ¨¡å‹...'})}\n\n"
                            response_text = ""
                            continue  # 503 é”™è¯¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
                        else:
                            response_text = f"âŒ API è°ƒç”¨å¤±è´¥: {error_str[:200]}"
                            continue  # å…¶ä»–é”™è¯¯ä¹Ÿå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
                    elif response_holder['data']:
                        file_gen_response = response_holder['data']
                        if file_gen_response.candidates and file_gen_response.candidates[0].content.parts:
                            for part in file_gen_response.candidates[0].content.parts:
                                if hasattr(part, 'text') and part.text:
                                    response_text += part.text
                        print(f"[FILE_GEN] Response length: {len(response_text)}")
                        if response_text:
                            break  # æˆåŠŸè·å–å“åº”
                
                if not response_text:
                    response_text = "âŒ æ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
                
                if Utils.is_failure_output(response_text):
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'âš ï¸ åˆæ¬¡ç”Ÿæˆå¤±è´¥ï¼Œæ­£åœ¨ä¿®æ­£...', 'detail': ''})}\n\n"
                    fix_prompt = Utils.build_fix_prompt("FILE_GEN", user_input, response_text)
                    try:
                        fix_resp = client.models.generate_content(
                            model=model_id,
                            contents=fix_prompt,
                            config=types.GenerateContentConfig(
                                system_instruction=_get_system_instruction(),
                                max_output_tokens=8192,
                                temperature=0.4
                            )
                        )
                        response_text = fix_resp.text or response_text
                    except Exception as fix_err:
                        print(f"[FILE_GEN] ä¿®æ­£é‡è¯•å¤±è´¥: {fix_err}")
                
                # åªæ˜¾ç¤ºç®€çŸ­çš„è¿›åº¦ï¼Œä¸æ˜¾ç¤ºå®Œæ•´ä»£ç 
                if response_text and not response_text.startswith("âŒ"):
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ”§ æ­£åœ¨å¤„ç†ä»£ç ...', 'detail': ''})}\n\n"
                    
                    # æå–ä»£ç åˆ°ä¸´æ—¶æ–‡ä»¶
                    patterns = [
                        r"---BEGIN_FILE:\s*([a-zA-Z0-9_.-]+)\s*---\s*(.*?)---\s*END_FILE\s*---",
                        r"---BEGIN_FILE:\s*([a-zA-Z0-9_.-]+)\s*---\n(.*?)\n---END_FILE---",
                    ]
                    
                    code_content = None
                    for pattern in patterns:
                        matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)
                        if matches:
                            _, code_content = matches[0]
                            code_content = code_content.strip()
                            print(f"[FILE_GEN] Extracted code, length: {len(code_content)}")
                            break
                    
                    # æ£€æŸ¥æå–çš„å†…å®¹æ˜¯å¦æ˜¯æœ‰æ•ˆçš„Pythonä»£ç ï¼ˆä¸æ˜¯JSONæˆ–å…¶ä»–æ ¼å¼ï¼‰
                    is_valid_python = False
                    if code_content:
                        code_lower = code_content.lower()
                        # å¦‚æœæå–çš„å†…å®¹æ˜¯ JSON æˆ– HTML æˆ–å…¶ä»–æ ¼å¼ï¼Œç›´æ¥è·³è¿‡ä»£ç æ‰§è¡Œ
                        if code_lower.startswith(('{', '[', '<', '"')):
                            print(f"[FILE_GEN] Extracted content is not Python code (starts with {code_content[0]}), treating as text content")
                            code_content = None
                        else:
                            is_valid_python = True
                    
                    if code_content and is_valid_python:
                        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                        temp_dir = tempfile.gettempdir()
                        temp_script = os.path.join(temp_dir, f"koto_gen_{int(time.time())}.py")
                        
                        with open(temp_script, 'w', encoding='utf-8') as f:
                            f.write(code_content)
                        temp_scripts.append(temp_script)
                        print(f"[FILE_GEN] Saved temp script: {temp_script}")
                        
                        # æ‰§è¡Œè„šæœ¬
                        yield f"data: {json.dumps({'type': 'progress', 'message': 'âš™ï¸ æ­£åœ¨æ‰§è¡Œè„šæœ¬ç”Ÿæˆæ–‡ä»¶...', 'detail': ''})}\n\n"
                        
                        try:
                            result = subprocess.run(
                                [sys.executable, temp_script],
                                capture_output=True,
                                text=True,
                                timeout=60,
                                cwd=WORKSPACE_DIR,
                                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == "win32" else 0
                            )
                            print(f"[FILE_GEN] Script exit code: {result.returncode}")
                            print(f"[FILE_GEN] Script stdout: {result.stdout}")
                            print(f"[FILE_GEN] Script stderr: {result.stderr}")
                            
                            if result.returncode == 0:
                                # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
                                docs_dir = settings_manager.documents_dir
                                if os.path.exists(docs_dir):
                                    for f in os.listdir(docs_dir):
                                        if f.endswith(('.pdf', '.docx', '.xlsx', '.pptx', '.ppt', '.png', '.jpg')):
                                            full_path = os.path.join(docs_dir, f)
                                            age = time.time() - os.path.getmtime(full_path)
                                            if age < 60:
                                                rel_path = os.path.relpath(full_path, WORKSPACE_DIR).replace("\\", "/")
                                                if rel_path not in generated_files:
                                                    generated_files.append(rel_path)
                                                    print(f"[FILE_GEN] Generated: {rel_path}")
                                
                                if generated_files:
                                    files_list = ", ".join([os.path.basename(f) for f in generated_files])
                                    success_msg = "âœ… **æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼**\n\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶: **" + files_list + "**\nğŸ“ ä¿å­˜ä½ç½®: `" + docs_dir + "`"
                                    yield f"data: {json.dumps({'type': 'token', 'content': success_msg})}\n\n"
                                else:
                                    # è„šæœ¬æ‰§è¡ŒæˆåŠŸä½†æ²¡æœ‰æ£€æµ‹åˆ°æ–°æ–‡ä»¶
                                    output = result.stdout.strip()
                                    if output:
                                        msg = "âœ… è„šæœ¬æ‰§è¡Œå®Œæˆ\n```\n" + output + "\n```"
                                        yield f"data: {json.dumps({'type': 'token', 'content': msg})}\n\n"
                                    else:
                                        yield f"data: {json.dumps({'type': 'token', 'content': 'âš ï¸ è„šæœ¬æ‰§è¡Œå®Œæˆï¼Œä½†æœªæ£€æµ‹åˆ°æ–°æ–‡ä»¶'})}\n\n"
                            else:
                                error_msg = result.stderr.strip() or "æœªçŸ¥é”™è¯¯"
                                err_content = "âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥\n```\n" + error_msg[:500] + "\n```"
                                yield f"data: {json.dumps({'type': 'token', 'content': err_content})}\n\n"
                        
                        except subprocess.TimeoutExpired:
                            yield f"data: {json.dumps({'type': 'token', 'content': 'âš ï¸ è„šæœ¬æ‰§è¡Œè¶…æ—¶ï¼ˆ60ç§’ï¼‰'})}\n\n"
                        except Exception as e:
                            print(f"[FILE_GEN] Execution error: {e}")
                            err_msg = "âŒ æ‰§è¡Œé”™è¯¯: " + str(e)
                            yield f"data: {json.dumps({'type': 'token', 'content': err_msg})}\n\n"
                        
                        # åˆ é™¤ä¸´æ—¶è„šæœ¬
                        for temp_file in temp_scripts:
                            try:
                                if os.path.exists(temp_file):
                                    os.remove(temp_file)
                                    print(f"[FILE_GEN] Deleted temp script: {temp_file}")
                            except:
                                pass
                    else:
                        # æ²¡æœ‰åŒ¹é…åˆ°ä»£ç æ ¼å¼ï¼šç›´æ¥æŠŠæ¨¡å‹å†…å®¹ç”Ÿæˆæ–‡æ¡£
                        try:
                            from web.document_generator import save_docx, save_pdf

                            docs_dir = settings_manager.documents_dir
                            os.makedirs(docs_dir, exist_ok=True)

                            # æå–æ ‡é¢˜ï¼ˆå°è¯•ä»å†…å®¹ä¸­æ‰¾ # æ ‡é¢˜ï¼‰
                            title_match = re.search(r'^#\s*(.+)$', response_text, re.MULTILINE)
                            if title_match:
                                title = title_match.group(1).strip()[:50]
                            else:
                                # å°è¯•ä»ç”¨æˆ·è¾“å…¥æå–å…³é”®è¯ä½œä¸ºæ–‡ä»¶å
                                try:
                                    clean_input = user_input
                                    # å»é™¤å¸¸ç”¨æŒ‡ä»¤è¯
                                    stop_patterns = ["ç”Ÿæˆçš„", "å†™ä¸€ä¸ª", "å†™ä¸€ç¯‡", "å¸®æˆ‘", "è¯·", "å…³äº", "ä¸€ä¸‹", "æ–‡æ¡£", "file", "generate", "write", "about", "make", "create"]
                                    for pattern in stop_patterns:
                                        clean_input = clean_input.replace(pattern, " ")
                                    
                                    # æå–ä¸­è‹±æ–‡å…³é”®è¯ (2-20 chars)
                                    keywords = [w for w in re.split(r'[^a-zA-Z0-9\u4e00-\u9fa5]', clean_input) if w.strip()]
                                    valid_keywords = [k for k in keywords if len(k) > 1 and len(k) < 20]
                                    
                                    if valid_keywords:
                                        # å–å‰å‡ ä¸ªå…³é”®è¯ç»„åˆ
                                        title = "_".join(valid_keywords[:3])
                                    else:
                                        title = f"Kotoæ–‡æ¡£_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                                except:
                                    title = f"Kotoæ–‡æ¡£_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

                            user_lower = user_input.lower()
                            if "pdf" in user_lower:
                                saved_path = save_pdf(response_text, title=title, output_dir=docs_dir)
                                file_type = "PDF"
                            else:
                                saved_path = save_docx(response_text, title=title, output_dir=docs_dir)
                                file_type = "Word"

                            rel_path = os.path.relpath(saved_path, WORKSPACE_DIR).replace("\\", "/")
                            if rel_path not in generated_files:
                                generated_files.append(rel_path)

                            success_msg = f"âœ… **{file_type} æ–‡æ¡£ç”ŸæˆæˆåŠŸï¼**\n\nğŸ“ æ–‡ä»¶: **{os.path.basename(saved_path)}**\nğŸ“ ä½ç½®: `{docs_dir}`"
                            yield f"data: {json.dumps({'type': 'token', 'content': success_msg})}\n\n"
                        except Exception as direct_err:
                            print(f"[FILE_GEN] Direct save failed: {direct_err}")
                            # å›é€€å±•ç¤ºåŸå§‹å“åº”
                            yield f"data: {json.dumps({'type': 'token', 'content': response_text})}\n\n"
                else:
                    yield f"data: {json.dumps({'type': 'token', 'content': response_text or 'âš ï¸ æ¨¡å‹æœªè¿”å›å“åº”'})}\n\n"
                
                # ä¿å­˜å†å²ï¼ˆåŸºäºç£ç›˜å®Œæ•´å†å²è¿½åŠ ï¼Œåœ¨ done äº‹ä»¶ä¹‹å‰ï¼‰
                _gen_msg = f"å·²ç”Ÿæˆæ–‡ä»¶: {', '.join(generated_files)}" if generated_files else (response_text[:500] if response_text else "ç”Ÿæˆå¤±è´¥")
                session_manager.append_and_save(f"{session_name}.json", user_input, _gen_msg)
                
                # å‘é€å®Œæˆäº‹ä»¶
                total_time = time.time() - start_time
                print(f"[FILE_GEN] â˜…â˜…â˜… Sending done event, generated_files: {generated_files}, total_time: {total_time:.2f}s")
                yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': generated_files, 'total_time': total_time})}\n\n"
                return
            
            # === Regular Mode (æµå¼è¾“å‡º) ===
            # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©ç³»ç»ŸæŒ‡ä»¤
            # CHAT/RESEARCHç­‰ä½¿ç”¨ç®€åŒ–æŒ‡ä»¤ï¼Œé¿å…ä¸å¿…è¦çš„æ–‡ä»¶ç”Ÿæˆ
            use_instruction = _get_DEFAULT_CHAT_SYSTEM_INSTRUCTION() if task_type in ["CHAT", "RESEARCH"] else _get_system_instruction()

            # æ³¨å…¥é•¿æœŸè®°å¿†ä¸Šä¸‹æ–‡
            _memory_manager = get_memory_manager()
            memory_context = _memory_manager.get_context_string(user_input)
            if memory_context:
                use_instruction += f"\n\n{memory_context}"
                print(f"[MEMORY] æ³¨å…¥äº† {len(memory_context)} å­—ç¬¦çš„è®°å¿†ä¸Šä¸‹æ–‡")
                t = yield_thinking(f"ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢åˆ° {len(memory_context)} å­—ç¬¦çš„ç›¸å…³ä¸Šä¸‹æ–‡å¹¶æ³¨å…¥", "context")
                if t: yield t

            # æ ¹æ®ä»»åŠ¡ç±»å‹æä¾›å·®å¼‚åŒ–è¿›åº¦æç¤º
            if task_type == "CODER":
                used_model = model_id
                t = yield_thinking(f"è¿›å…¥ä»£ç ç”Ÿæˆæ¨¡å¼ï¼Œä½¿ç”¨ {model_id} è¿›è¡Œä»£ç åˆ†æä¸ç”Ÿæˆ", "generating")
                if t: yield t
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ’» æ­£åœ¨åˆ†æä»£ç éœ€æ±‚...', 'detail': f'ä½¿ç”¨ {model_id}'})}\n\n"
                
                # ç‰¹æ®Šä¼˜åŒ–ï¼šå¯¹äºæ¸¸æˆå¼€å‘æˆ–å®‰è£…åŒ…ï¼Œæ·»åŠ ç®€çŸ­æŒ‡ä»¤é¿å…å•°å—¦
                if any(k in user_input.lower() for k in ["æ¸¸æˆ", "app", "äº”å­æ£‹", "pygame", "install", "å®‰è£…"]):
                     use_instruction += "\n\n[Important] If suggesting to install packages (like pygame), assume the user knows how to use pip. Just output `pip install package_name` in a code block. Do NOT write long tutorials about installation. Focus on the Python Code."

            elif task_type == "CHAT":
                used_model = model_id
                t = yield_thinking(f"è¿›å…¥å¯¹è¯æ¨¡å¼ï¼Œä½¿ç”¨ {model_id} ç”Ÿæˆå›å¤", "generating")
                if t: yield t
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ’¬ Koto æ­£åœ¨æ€è€ƒ...', 'detail': 'è¯·ç¨å€™'})}\n\n"

                # â•â•â• æœ¬åœ°æ¨¡å‹å¿«é€Ÿé€šé“ï¼šç®€å•é—®é¢˜ç›´æ¥èµ° Ollama â•â•â•
                from app.core.routing import LocalModelRouter
                if LocalModelRouter.is_simple_query(user_input, task_type, history):
                    local_stream = LocalModelRouter.generate_stream(
                        user_input, history=history,
                        system_instruction=_get_DEFAULT_CHAT_SYSTEM_INSTRUCTION()
                    )
                    if local_stream is not None:
                        print(f"[CHAT] âš¡ ä½¿ç”¨æœ¬åœ°æ¨¡å‹å¿«é€Ÿå“åº”: {LocalModelRouter._response_model}")
                        t = yield_thinking(f"æ£€æµ‹åˆ°ç®€å•æŸ¥è¯¢ï¼Œåˆ‡æ¢åˆ°æœ¬åœ°æ¨¡å‹ {LocalModelRouter._response_model} å¿«é€Ÿå“åº”", "model")
                        if t: yield t
                        yield f"data: {json.dumps({'type': 'classification', 'task_type': task_type, 'task_display': 'ğŸ’¬ å¯¹è¯', 'model': f'ğŸ  {LocalModelRouter._response_model} (æœ¬åœ°)', 'message': f'ğŸ¯ ä»»åŠ¡åˆ†ç±»: ğŸ’¬ å¯¹è¯ (æ–¹æ³•: ğŸ  {LocalModelRouter._response_model} æœ¬åœ°å¿«é€Ÿé€šé“)'})}\n\n"
                        local_full_text = ""
                        local_ok = False
                        try:
                            for chunk in local_stream:
                                local_full_text += chunk
                                yield f"data: {json.dumps({'type': 'token', 'content': chunk})}\n\n"
                            local_ok = bool(local_full_text.strip())
                        except Exception as local_err:
                            print(f"[CHAT] æœ¬åœ°æ¨¡å‹ç”Ÿæˆå¤±è´¥: {local_err}")

                        if local_ok:
                            # æœ¬åœ°æ¨¡å‹æˆåŠŸ â†’ ä¿å­˜å¹¶è¿”å›
                            session_manager.append_and_save(
                                f"{session_name}.json", user_input, local_full_text,
                                task=task_type, model_name=f"ollama/{LocalModelRouter._response_model}"
                            )
                            if task_type == "CHAT":
                                _start_memory_extraction(user_input, local_full_text, history)
                            total_time = time.time() - start_time
                            print(f"[CHAT] âš¡ æœ¬åœ°æ¨¡å‹å“åº”å®Œæˆ ({total_time:.2f}s)")
                            yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                            return
                        else:
                            # æœ¬åœ°æ¨¡å‹å¤±è´¥ â†’ é™é»˜é™çº§åˆ°äº‘æ¨¡å‹
                            print(f"[CHAT] æœ¬åœ°æ¨¡å‹è¾“å‡ºä¸ºç©ºï¼Œé™çº§åˆ°äº‘æ¨¡å‹")
                            t = yield_thinking(f"æœ¬åœ°æ¨¡å‹è¾“å‡ºä¸ºç©ºï¼Œé™çº§åˆ°äº‘ç«¯æ¨¡å‹ {model_id}", "model")
                            if t: yield t
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'â˜ï¸ åˆ‡æ¢åˆ°äº‘ç«¯æ¨¡å‹...', 'detail': model_id})}\n\n"
            elif task_type == "RESEARCH":
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ”¬ æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æ...', 'detail': f'ä½¿ç”¨ {model_id}'})}\n\n"
            else:
                yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ’­ Koto æ­£åœ¨æ€è€ƒ...', 'detail': 'è¯·ç¨å€™'})}\n\n"
            
            # æ„å»ºå†å²è®°å½•ï¼ˆéå»¶ç»­ä»»åŠ¡æ—¶è¿‡æ»¤æ— å…³å†å²ï¼‰
            if context_info and context_info.get("is_continuation"):
                history_for_model = history
                t = yield_thinking(f"æ£€æµ‹åˆ°ä¸Šä¸‹æ–‡å»¶ç»­ï¼Œä¿ç•™å…¨éƒ¨ {len(history)} è½®å¯¹è¯å†å²", "context")
                if t: yield t
            else:
                history_for_model = ContextAnalyzer.filter_history(user_input, history)
                if len(history_for_model) != len(history):
                    t = yield_thinking(f"è¿‡æ»¤å¯¹è¯å†å²: {len(history)} è½® â†’ {len(history_for_model)} è½®ç›¸å…³è®°å½•", "context")
                    if t: yield t

            formatted_history = []
            for turn in history_for_model:
                formatted_history.append(types.Content(
                    role=turn['role'],
                    parts=[types.Part.from_text(text=p) for p in turn['parts']]
                ))
            
            t = yield_thinking(f"å‡†å¤‡è°ƒç”¨ {model_id} APIï¼Œå‘é€ {len(formatted_history)+1} æ¡æ¶ˆæ¯", "generating")
            if t: yield t
            
            # ä½¿ç”¨æµå¼å“åº”
            response = client.models.generate_content_stream(
                model=model_id,
                contents=formatted_history + [types.Content(
                    role="user",
                    parts=[types.Part.from_text(text=effective_input)]
                )],
                config=types.GenerateContentConfig(
                    system_instruction=use_instruction
                )
            )
            
            full_text = ""
            chunk_count = 0
            heartbeat_interval = 5  # æ¯5ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
            first_chunk_received = False
            
            try:
                # ä½¿ç”¨ä¿æ´»åŒ…è£…å™¨å¤„ç†æµå¼å“åº”
                max_wait = 60 if task_type == "CODER" else 120
                for item_type, item_data in stream_with_keepalive(response, start_time,
                                                                   keepalive_interval=heartbeat_interval,
                                                                   max_wait_first_token=max_wait):
                    # æ£€æŸ¥ä¸­æ–­æ ‡å¿—
                    if _interrupt_manager.is_interrupted(session_name):
                        print(f"[INTERRUPT] User interrupted at chunk {chunk_count}")
                        interrupt_msg = "\n\nâ¸ï¸ ç”¨æˆ·å·²ä¸­æ–­"
                        yield f"data: {json.dumps({'type': 'token', 'content': interrupt_msg})}\n\n"
                        break
                    
                    if item_type == 'heartbeat':
                        elapsed = item_data
                        if first_chunk_received:
                            # æ ¹æ®ä»»åŠ¡ç±»å‹å·®å¼‚åŒ–å¿ƒè·³
                            char_count = len(full_text)
                            if task_type == "CODER":
                                hb_msg = f'ğŸ’» ä»£ç ç”Ÿæˆä¸­... å·²è¾“å‡º {char_count} å­—ç¬¦'
                            elif task_type == "RESEARCH":
                                hb_msg = f'ğŸ”¬ æ·±åº¦åˆ†æä¸­... å·²è¾“å‡º {char_count} å­—ç¬¦'
                            else:
                                hb_msg = 'ğŸ’­ æ­£åœ¨ç”Ÿæˆ...'
                            yield f"data: {json.dumps({'type': 'progress', 'message': hb_msg, 'detail': f'{elapsed}s'})}\n\n"
                        else:
                            if task_type == "CODER":
                                hb_msg = 'ğŸ’» ä»£ç åˆ†æä¸­ï¼Œè¯·ç¨å€™...'
                            elif task_type == "RESEARCH":
                                hb_msg = 'ğŸ”¬ æ·±åº¦æ€è€ƒä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…...'
                            else:
                                hb_msg = 'ğŸ§  æ¨¡å‹æ€è€ƒä¸­...'
                            yield f"data: {json.dumps({'type': 'progress', 'message': hb_msg, 'detail': f'å·²ç­‰å¾… {elapsed}s'})}\n\n"
                    
                    elif item_type == 'timeout':
                        if task_type == "CODER" and not full_text:
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'âš ï¸ é¦–åŒ…è¶…æ—¶ï¼Œåˆ‡æ¢åˆ°å¿«é€Ÿæ¨¡å‹...', 'detail': ''})}\n\n"
                            try:
                                fallback_resp = client.models.generate_content(
                                    model="gemini-3-flash-preview",
                                    contents=formatted_history + [types.Content(
                                        role="user",
                                        parts=[types.Part.from_text(text=effective_input)]
                                    )],
                                    config=types.GenerateContentConfig(
                                        system_instruction=use_instruction,
                                        temperature=0.4,
                                        max_output_tokens=4000,
                                    )
                                )
                                fallback_text = fallback_resp.text or ""
                                if fallback_text:
                                    full_text = fallback_text
                                    yield f"data: {json.dumps({'type': 'token', 'content': fallback_text})}\n\n"
                            except Exception:
                                yield f"data: {json.dumps({'type': 'token', 'content': f'âš ï¸ {item_data}ï¼Œè¯·ç¨åé‡è¯•'})}\n\n"
                        else:
                            yield f"data: {json.dumps({'type': 'token', 'content': f'âš ï¸ {item_data}ï¼Œè¯·ç¨åé‡è¯•'})}\n\n"
                        break
                    
                    elif item_type == 'chunk':
                        chunk = item_data
                        if chunk.text:
                            if not first_chunk_received:
                                first_chunk_received = True
                                print(f"[CHAT] æ”¶åˆ°ç¬¬ä¸€ä¸ªå“åº”ï¼Œè€—æ—¶ {time.time() - start_time:.1f}s")
                            
                            full_text += chunk.text
                            chunk_count += 1
                            yield f"data: {json.dumps({'type': 'token', 'content': chunk.text})}\n\n"
                            
            except Exception as stream_error:
                error_str = str(stream_error)
                print(f"[CHAT] Stream error: {error_str}")
                
                # åœ°åŒºé™åˆ¶é”™è¯¯
                if "location is not supported" in error_str.lower() or "failed_precondition" in error_str.lower():
                    error_text = "âŒ åœ°åŒºé™åˆ¶\n\næ‚¨æ‰€åœ¨çš„åœ°åŒºä¸æ”¯æŒ Gemini APIã€‚\n\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:\n1. åœ¨ `config/gemini_config.env` é…ç½®ä¸­è½¬æœåŠ¡ `GEMINI_API_BASE`\n2. æˆ–ä½¿ç”¨æ”¯æŒçš„ä»£ç†æœåŠ¡"
                    yield f"data: {json.dumps({'type': 'token', 'content': error_text})}\n\n"
                    total_time = time.time() - start_time
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
                    return
                # æµå¼ä¼ è¾“ä¸­æ–­ï¼Œä½†å·²æœ‰éƒ¨åˆ†å†…å®¹
                elif full_text:
                    error_msg = error_str[:50]
                    warn_text = f"\n\nâš ï¸ (ä¼ è¾“ä¸­æ–­: {error_msg}...)"
                    yield f"data: {json.dumps({'type': 'token', 'content': warn_text})}\n\n"
                else:
                    raise stream_error
            
            # å¤±è´¥æ—¶å…ˆä¿®æ­£ä¸€æ¬¡ï¼ˆä¸ç›´æ¥æŠ¥é”™ï¼‰
            if Utils.is_failure_output(full_text):
                yield f"data: {json.dumps({'type': 'progress', 'message': 'âš ï¸ åˆæ¬¡ç”Ÿæˆå¤±è´¥ï¼Œæ­£åœ¨ä¿®æ­£...', 'detail': ''})}\n\n"
                fix_prompt = Utils.build_fix_prompt(task_type, user_input, full_text)
                fix_resp = client.models.generate_content(
                    model=model_id,
                    contents=fix_prompt,
                    config=types.GenerateContentConfig(
                        system_instruction=use_instruction,
                        temperature=0.4,
                        max_output_tokens=4000,
                    )
                )
                corrected_text = fix_resp.text or full_text
                if corrected_text and corrected_text != full_text:
                    corrected_msg = f"\n\nğŸ” ä¿®æ­£ç‰ˆæœ¬:\n{corrected_text}"
                    yield f"data: {json.dumps({'type': 'token', 'content': corrected_msg})}\n\n"
                    full_text = corrected_text
            else:
                # å¤æ‚ä»»åŠ¡è¿›è¡Œå¿«é€Ÿè‡ªæ£€
                is_complex_task = (
                    task_type in ["RESEARCH", "FILE_GEN", "CODER"] or
                    (context_info and context_info.get("complexity") == "complex") or
                    len(user_input) > 200
                )
                if is_complex_task:
                    check = Utils.quick_self_check(task_type, user_input, full_text)
                    if not check.get("pass") and check.get("fix_prompt"):
                        status_msg = "ğŸ©º è‡ªæ£€æœªé€šè¿‡ï¼Œæ­£åœ¨ä¿®æ­£..."
                        yield f"data: {json.dumps({'type': 'progress', 'message': status_msg, 'detail': 'å¿«é€Ÿæ¨¡å‹è‡ªæ£€'})}\n\n"
                        fix_resp = client.models.generate_content(
                            model=model_id,
                            contents=check["fix_prompt"],
                            config=types.GenerateContentConfig(
                                system_instruction=use_instruction,
                                temperature=0.4,
                                max_output_tokens=4000,
                            )
                        )
                        corrected_text = fix_resp.text or full_text
                        if corrected_text and corrected_text != full_text:
                            corrected_msg = f"\n\nğŸ” ä¿®æ­£ç‰ˆæœ¬:\n{corrected_text}"
                            yield f"data: {json.dumps({'type': 'token', 'content': corrected_msg})}\n\n"
                            full_text = corrected_text

            # å¤„ç†è‡ªåŠ¨ä¿å­˜çš„æ–‡ä»¶
            saved_files = Utils.auto_save_files(full_text)

            # ä»£ç ä»»åŠ¡: æ£€æµ‹å¹¶è‡ªåŠ¨å®‰è£…ä¾èµ–
            if task_type == "CODER":
                pkgs = Utils.detect_required_packages(full_text)
                if pkgs:
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“¦ æ£€æµ‹åˆ°ä¾èµ–ï¼Œæ­£åœ¨æ£€æŸ¥/å®‰è£…...', 'detail': ', '.join(pkgs)})}\n\n"
                    install_result = Utils.auto_install_packages(pkgs)
                    installed = install_result.get("installed", [])
                    failed = install_result.get("failed", [])
                    skipped = install_result.get("skipped", [])
                    msg_parts = []
                    if installed:
                        msg_parts.append(f"âœ… å·²å®‰è£…: {', '.join(installed)}")
                    if skipped:
                        msg_parts.append(f"â„¹ï¸ å·²å­˜åœ¨: {', '.join(skipped)}")
                    if failed:
                        msg_parts.append(f"âš ï¸ å®‰è£…å¤±è´¥: {', '.join(failed)}")
                    if msg_parts:
                        msg_content = '\n\n' + '\n'.join(msg_parts)
                        yield f"data: {json.dumps({'type': 'token', 'content': msg_content})}\n\n"
            
            # å¦‚æœæœ‰ä¿å­˜çš„æ–‡ä»¶ï¼Œæç¤ºç”¨æˆ·ä¿å­˜ä½ç½®
            if saved_files:
                files_list = ", ".join(saved_files)
                save_hint = f"\n\nğŸ“ æ–‡ä»¶å·²ä¿å­˜: **{files_list}**\nğŸ“‚ ä½ç½®: `{WORKSPACE_DIR}`"
                yield f"data: {json.dumps({'type': 'token', 'content': save_hint})}\n\n"
            
            # å…ˆä¿å­˜å†å²ï¼Œå†å‘é€ done äº‹ä»¶ï¼ˆåŒ…å«å…ƒæ•°æ®ç”¨äºå‰ç«¯æ¸²æŸ“ï¼‰
            session_manager.append_and_save(
                f"{session_name}.json", user_input, full_text,
                task=task_type, model_name=model_id, saved_files=saved_files
            )
            if task_type == "CHAT":
                _start_memory_extraction(user_input, full_text, history_for_model)
            
            total_time = time.time() - start_time
            yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': saved_files, 'total_time': total_time})}\n\n"
            
        except Exception as e:
            error_str = str(e)
            print(f"[CHAT] Exception: {error_str}")
            
            # åœ°åŒºé™åˆ¶é”™è¯¯
            if "location is not supported" in error_str.lower() or "failed_precondition" in error_str.lower():
                error_response = "âŒ åœ°åŒºé™åˆ¶\n\næ‚¨æ‰€åœ¨çš„åœ°åŒºä¸æ”¯æŒ Gemini APIã€‚\n\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:\n1. åœ¨ `config/gemini_config.env` é…ç½®ä¸­è½¬æœåŠ¡ `GEMINI_API_BASE`\n2. æˆ–ä½¿ç”¨æ”¯æŒçš„ä»£ç†æœåŠ¡"
            else:
                error_response = f"âŒ å‘ç”Ÿé”™è¯¯: {error_str[:200]}"
            
            # å³ä½¿å‡ºé”™ä¹Ÿè¦ä¿å­˜ç”¨æˆ·çš„é—®é¢˜
            session_manager.append_and_save(
                f"{session_name}.json",
                user_input,
                error_response,
                task=task_type,
                model_name=model_id
            )
            
            yield f"data: {json.dumps({'type': 'token', 'content': error_response})}\n\n"
            total_time = time.time() - start_time
            yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': total_time})}\n\n"
    
    response = Response(stream_with_context(generate()), mimetype='text/event-stream')
    response.headers['Cache-Control'] = 'no-cache'
    response.headers['X-Accel-Buffering'] = 'no'  # ç¦ç”¨ nginx ç¼“å†²
    response.headers['Connection'] = 'keep-alive'
    return response


@app.route('/api/chat/file', methods=['POST'])
def chat_with_file():
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ å’ŒèŠå¤©è¯·æ±‚"""
    from web.file_processor import process_uploaded_file
    from web.document_generator import save_docx, save_pdf, to_workspace_rel

    def _strip_code_blocks(text: str) -> str:
        if not text:
            return text
        # Remove fenced code blocks entirely
        text = re.sub(r"```[\s\S]*?```", "", text)
        # Remove inline code ticks but keep the content
        text = text.replace("`", "")
        return text.strip()

    def _build_analysis_title(user_text: str, filename: str, is_binary: bool) -> str:
        name_base = os.path.splitext(filename)[0]
        text_lower = (user_text or "").lower()
        ext = os.path.splitext(filename)[1].lower()
        
        # 1. Determine File Type Prefix
        if ext in [".png", ".jpg", ".jpeg", ".bmp", ".gif", ".webp"]:
            prefix = "å›¾ç‰‡"
        elif ext == ".pdf":
            prefix = "PDF"
        elif ext in [".doc", ".docx"]:
            prefix = "Word"
        elif ext in [".ppt", ".pptx"]:
            prefix = "PPT"
        else:
            prefix = "æ–‡ä»¶" if is_binary else "æ–‡æ¡£"

        # 2. Determine Intent
        intent = "åˆ†æ"
        intent_map = {
            "ç¿»è¯‘": ["ç¿»è¯‘", "translate", "è¯‘æ–‡", "ä¸­è¯‘è‹±", "è‹±è¯‘ä¸­"],
            "æ€»ç»“": ["æ€»ç»“", "å½’çº³", "æ‘˜è¦", "summary", "æ¦‚æ‹¬", "æ ¸å¿ƒå†…å®¹"],
            "æ–‡å­—è¯†åˆ«": ["æå–", "è¯†åˆ«", "ocr", "æ–‡å­—", "è½¬æ–‡å­—", "è¯»å›¾"],
            "è¡¨æ ¼è¯†åˆ«": ["è¡¨æ ¼", "table", "excel", "è½¬è¡¨"],
            "å¯¹æ¯”åˆ†æ": ["å¯¹æ¯”", "æ¯”è¾ƒ", "diff", "åŒºåˆ«", "å·®å¼‚"],
            "æ ¡å¯¹": ["æ ¡å¯¹", "æ£€æŸ¥", "å®¡é˜…", "çº é”™", "æ”¹é”™"],
            "æ¶¦è‰²": ["æ¶¦è‰²", "æ”¹å†™", "polish", "rewrite", "ä¼˜åŒ–", "ç¾åŒ–"],
            "ç»­å†™": ["ç»­å†™", "æ‰©å†™", "continue", "è¡¥å……"],
            "å¤§çº²": ["å¤§çº²", "æ¡†æ¶", "outline", "ç›®å½•"],
            "è§£é‡Š": ["è§£é‡Š", "explain", "ä»€ä¹ˆæ„æ€", "å«ä¹‰"],
        }
        
        found_intent_keywords = []
        for k, v in intent_map.items():
            for kw in v:
                if kw in text_lower:
                    intent = k
                    found_intent_keywords.append(kw)
                    break
            if intent != "åˆ†æ":
                break

        # 3. Extract Topic Keywords (Improved)
        stop_words = [
            "å¸®æˆ‘", "è¯·", "ä¸€ä¸‹", "æŠŠ", "è¿™ä¸ª", "è¿™ç¯‡", "æ–‡ä»¶", "æ–‡ç« ", "å†…å®¹", "ç”Ÿæˆ", "å†™ä¸€ä¸ª", "åšä¸€ä»½",
            "koto", "åˆ†æ", "é˜…è¯»", "æå–", "è¯†åˆ«", "output", "make", "create", "generate", "please", 
            "the", "a", "an", "is", "of", "to", "for", "with", "in", "on", "user", "file", "document",
            "from", "this", "that", "it", "what", "how", "why", "where", "into", "check", "run"
        ]
        
        # Prepare text
        text_lower = user_text.lower()
        
        # Safe replacement for Chinese phrases (which don't use spaces)
        zh_stops = [w for w in stop_words if re.match(r'[\u4e00-\u9fa5]+', w)]
        for stop in zh_stops + found_intent_keywords:
            if re.match(r'[\u4e00-\u9fa5]+', stop): # Only safe-replace Chinese phrases
                text_lower = text_lower.replace(stop, " ")

        # Tokenize by non-word chars (separates English words, breaks Chinese into blocks if spaces inserted)
        # Regex: Keep Chinese chars and English words
        # This splits "summary of report" -> "summary", "of", "report"
        tokens = re.findall(r'[a-zA-Z0-9\u4e00-\u9fa5]+', text_lower)
        
        # Filter tokens
        valid_keywords = []
        en_stops = set([w for w in stop_words if not re.match(r'[\u4e00-\u9fa5]+', w)])
        
        for token in tokens:
            if token in en_stops: continue
            if token in found_intent_keywords: continue # Filter intent words token-wise
            if len(token) < 2: continue
            valid_keywords.append(token)
            
        # Select best keyword
        topic = ""
        if valid_keywords:
             topic = "_".join(valid_keywords[:3])
        
        # 4. Construct Final Title
        # Strategy: 
        # If user provided a specific topic, prioritize it: "{Intent}_{Topic}_{Filename}"
        # If no detected topic but intent exists: "{Intent}_{Filename}"
        # Fallback: "{Prefix}{Intent}_{Filename}"
        
        sanitized_name = name_base.replace(" ", "_")
        
        if topic:
             return f"{intent}_{topic}_{sanitized_name}"
        else:
             return f"{prefix}{intent}_{sanitized_name}"
    
    session_name = request.form.get('session')
    user_input = request.form.get('message', '')
    files = request.files.getlist('file')
    
    # ğŸ” è°ƒè¯•æ—¥å¿—
    print(f"[FILE UPLOAD DEBUG] ========== æ¥æ”¶åˆ°æ–‡ä»¶ä¸Šä¼ è¯·æ±‚ ==========")
    print(f"[FILE UPLOAD DEBUG] request.files keys: {list(request.files.keys())}")
    print(f"[FILE UPLOAD DEBUG] request.files.getlist('file'): {len(files)} ä¸ªæ–‡ä»¶")
    for i, f in enumerate(files):
        print(f"[FILE UPLOAD DEBUG]   {i+1}. {f.filename if f else 'None'}")
    
    if not files:
        single_file = request.files.get('file')
        if single_file:
            files = [single_file]
            print(f"[FILE UPLOAD DEBUG] ä½¿ç”¨å•æ–‡ä»¶æ¨¡å¼ï¼Œæ–‡ä»¶: {single_file.filename}")
    
    locked_task = request.form.get('locked_task')
    locked_model = request.form.get('locked_model', 'auto')
    stream_mode = request.form.get('stream', '').lower() in ('1', 'true', 'yes')
    
    print(f"[FILE UPLOAD DEBUG] æœ€ç»ˆ files åˆ—è¡¨: {len(files)} ä¸ªæ–‡ä»¶")
    print(f"[FILE UPLOAD DEBUG] åˆ¤æ–­: len(files) > 1 = {len(files) > 1}")
    
    if not session_name or not files:
        return jsonify({"error": "Missing session or file"}), 400
    if len(files) > 10:
        return jsonify({"error": "æœ€å¤šä¸€æ¬¡ä¸Šä¼  10 ä¸ªæ–‡ä»¶"}), 400

    if len(files) > 1:
        # æ£€æµ‹æ˜¯å¦æ˜¯ PPT ç”Ÿæˆæ„å›¾ (å¤šæ–‡ä»¶åˆå¹¶ç”Ÿæˆ PPT)
        ppt_keywords = ["ppt", "slide", "å¹»ç¯ç‰‡", "æ¼”ç¤ºæ–‡ç¨¿", "powerpoint"]
        is_ppt_intent = any(kw in (user_input or "").lower() for kw in ppt_keywords)

        if is_ppt_intent:
            print(f"[FILE UPLOAD] æ£€æµ‹åˆ°å¤šæ–‡ä»¶ PPT ç”Ÿæˆæ„å›¾: {user_input}")
            
            # é¢„å…ˆä¿å­˜æ‰€æœ‰æ–‡ä»¶ï¼Œé¿å…åœ¨ç”Ÿæˆå™¨ä¸­è®¿é—®å·²å…³é—­çš„ FileStorage
            saved_file_paths = []
            source_filenames = []
            
            for f in files:
                if f and f.filename:
                    fname = f.filename
                    fpath = os.path.join(UPLOAD_DIR, fname)
                    # å¦‚æœæ–‡ä»¶æŒ‡é’ˆä¸åœ¨å¼€å¤´ï¼Œé‡ç½®å®ƒ
                    f.seek(0)
                    f.save(fpath)
                    saved_file_paths.append(fpath)
                    source_filenames.append(fname)

            def generate_ppt_stream():
                try:
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ“Š æ­£åœ¨å‡†å¤‡ PPT ç”Ÿæˆ...', 'detail': f'æ£€æµ‹åˆ° {len(saved_file_paths)} ä¸ªæºæ–‡ä»¶'})}\n\n"
                    
                    context_text = ""
                    
                    # 1. æå–æ‰€æœ‰å·²ä¿å­˜æ–‡ä»¶å†…å®¹
                    for i, filepath in enumerate(saved_file_paths):
                        filename = os.path.basename(filepath)
                        yield f"data: {json.dumps({'type': 'progress', 'message': f'ğŸ“– æ­£åœ¨è¯»å–æ–‡ä»¶ ({i+1}/{len(saved_file_paths)})...', 'detail': filename})}\n\n"
                        
                        try:
                            # æå–å†…å®¹
                            from web.file_processor import FileProcessor
                            processor = FileProcessor()
                            # ç®€åŒ–ç‰ˆçš„ process
                            f_result = processor.process_file(filepath)
                            content = f_result.get('text_content') or f_result.get('content', '')
                            
                            # æˆªæ–­è¿‡é•¿å†…å®¹é¿å…Tokençˆ†ç‚¸ï¼Œä½†ä¿ç•™è¶³å¤Ÿä¸Šä¸‹æ–‡
                            if len(content) > 50000:
                                content = content[:50000] + "...(truncated)"
                                
                            context_text += f"\n\n=== {filename} ===\n{content}\n"
                            
                        except Exception as e:
                            print(f"[PPT BATCH] è¯»å–æ–‡ä»¶ {filename} å¤±è´¥: {e}")
                            context_text += f"\n\n=== {filename} (Error) ===\næ— æ³•è¯»å–å†…å®¹\n"

                    # 2. è°ƒç”¨ PPT ç”Ÿæˆç®¡é“
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ¨ æ­£åœ¨è®¾è®¡ PPT ç»“æ„...', 'detail': 'åŸºäºå¤šä¸ªæ–‡ä»¶å†…å®¹'})}\n\n"
                    
                    from web.ppt_pipeline import PPTGenerationPipeline
                    import asyncio
                    
                    # æ„é€ å¢å¼ºåçš„ Prompt
                    enhanced_prompt = f"{user_input}\n\nã€å‚è€ƒèµ„æ–™ã€‘\nåŸºäºä»¥ä¸‹æ–‡ä»¶ç”Ÿæˆçš„ PPT:\n{context_text}"
                    
                    # é™åˆ¶ Prompt é•¿åº¦
                    if len(enhanced_prompt) > 100000:
                         enhanced_prompt = enhanced_prompt[:100000] + "\n...(context truncated)"
                    
                    # å¼‚æ­¥æ‰§è¡Œ PPT ç”Ÿæˆ
                    # ä½¿ç”¨é¡¹ç›®å†…çš„ get_client() è·å– Gemini å®¢æˆ·ç«¯
                    ai_client = get_client()
                    pipeline = PPTGenerationPipeline(ai_client=ai_client)
                    
                    import threading
                    import traceback
                    import queue

                    pipeline_timeout_sec = 300
                    start_ts = time.time()
                    
                    # æ··åˆæ¶ˆæ¯é˜Ÿåˆ—ï¼ˆè¿›åº¦+æ€è€ƒï¼‰
                    event_queue = queue.Queue()

                    def _progress_listener(msg, p=None):
                        event_queue.put({"type": "progress", "msg": msg, "progress": p})
                    
                    def _thought_listener(text):
                        # Use a dedicated type for thought/reasoning text
                        event_queue.put({"type": "thought", "text": text})

                    run_state = {
                        "done": False,
                        "result": None,
                        "error": None,
                        "traceback": "",
                    }

                    def _run_pipeline_bg():
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            # ä¼ é€’ progress_callback å’Œ thought_callback
                            run_state["result"] = loop.run_until_complete(
                                pipeline.generate(
                                    user_request=enhanced_prompt,
                                    output_path=os.path.join(settings_manager.documents_dir, f"Koto_Presentation_{int(time.time())}.pptx"),
                                    enable_auto_images=True,  # å…è®¸è‡ªåŠ¨é…å›¾
                                    progress_callback=_progress_listener,
                                    thought_callback=_thought_listener
                                )
                            )
                        except Exception as bg_err:
                            run_state["error"] = str(bg_err)
                            run_state["traceback"] = traceback.format_exc()
                        finally:
                            try:
                                loop.close()
                            except Exception:
                                pass
                            run_state["done"] = True

                    worker = threading.Thread(target=_run_pipeline_bg, daemon=True)
                    worker.start()

                    # å®æ—¶è½®è¯¢è¿›åº¦é˜Ÿåˆ—ï¼Œè½¬å‘ç»™å‰ç«¯
                    last_progress_msg = "åˆå§‹åŒ–ç”Ÿæˆç¯å¢ƒ..."
                    
                    while not run_state["done"]:
                        elapsed = int(time.time() - start_ts)
                        if elapsed > pipeline_timeout_sec:
                            _progress_listener("ç”Ÿæˆè¶…æ—¶ï¼Œæ­£åœ¨å¼ºåˆ¶åœæ­¢...", 100)
                            run_state["error"] = f"PPT ç”Ÿæˆè¶…æ—¶ï¼ˆ>{pipeline_timeout_sec}sï¼‰"
                            break
                        
                        # æ¶ˆè´¹æ‰€æœ‰çš„äº‹ä»¶
                        try:
                            while not event_queue.empty():
                                item = event_queue.get_nowait()
                                
                                if item['type'] == 'progress':
                                    msg = item['msg']
                                    p = item['progress']
                                    last_progress_msg = msg
                                    detail_text = f"è¿›åº¦: {p}%" if p is not None else f"å·²ç”¨æ—¶ {elapsed}s"
                                    yield f"data: {json.dumps({'type': 'progress', 'message': msg, 'detail': detail_text})}\n\n"
                                
                                elif item['type'] == 'thought':
                                    # Send thought as a partial text response or a special 'thought' event
                                    # Assuming frontend can handle 'text' type for appending to the assistant's message
                                    # or 'thought' for a distinct UI block. 
                                    # Let's use 'text' for now to ensure it appears in the chat stream.
                                    thought_text = f"\n\n> ğŸ¤– **Koto æ€è€ƒ**: {item['text']}\n"
                                    yield f"data: {json.dumps({'type': 'text', 'content': thought_text})}\n\n"

                        except queue.Empty:
                            pass
                        
                        # å¦‚æœæ²¡æœ‰æ–°æ¶ˆæ¯ï¼Œæ¯2ç§’å‘ä¸€æ¬¡å¿ƒè·³é˜²æ­¢è¿æ¥æ–­å¼€
                        if elapsed % 2 == 0 and event_queue.empty():
                             yield f"data: {json.dumps({'type': 'progress', 'message': last_progress_msg, 'detail': f'å·²ç”¨æ—¶ {elapsed}s'})}\n\n"

                        time.sleep(0.5)

                    # å‘é€æœ€åå‰©ä½™çš„æ¶ˆæ¯
                    try:
                        while not event_queue.empty():
                             item = event_queue.get_nowait()
                             if item['type'] == 'progress':
                                  yield f"data: {json.dumps({'type': 'progress', 'message': item['msg'], 'detail': ''})}\n\n"
                             elif item['type'] == 'thought':
                                  thought_text = f"\n\n> ğŸ¤– **Koto æ€è€ƒ**: {item['text']}\n"
                                  yield f"data: {json.dumps({'type': 'text', 'content': thought_text})}\n\n"
                    except: pass

                    if run_state["error"]:
                        err = run_state["error"]
                        tb = run_state.get("traceback", "")
                        print(f"[PPT BATCH] Background pipeline error: {err}")
                        if tb:
                            print(f"[PPT BATCH] Traceback: {tb[:800]}")
                        raise Exception(f"PPT ç®¡é“å¼‚å¸¸: {err}")

                    ppt_result = run_state["result"] or {}
                    
                    # pipeline returns 'output_path', also check 'file_path' for compat
                    saved_path = ppt_result.get("output_path") or ppt_result.get("file_path")
                    
                    if not ppt_result.get("success"):
                        err_detail = ppt_result.get('error', 'æœªçŸ¥é”™è¯¯')
                        tb = ppt_result.get('traceback', '')
                        print(f"[PPT BATCH] Pipeline returned failure: {err_detail}")
                        if tb:
                            print(f"[PPT BATCH] Traceback: {tb[:500]}")
                        raise Exception(f"PPT ç®¡é“ç”Ÿæˆå¤±è´¥: {err_detail}")
                    
                    if saved_path and os.path.exists(saved_path):
                        yield f"data: {json.dumps({'type': 'progress', 'message': 'âœ… PPT ç”Ÿæˆå®Œæˆï¼', 'detail': os.path.basename(saved_path)})}\n\n"
                        
                        rel_path = os.path.relpath(saved_path, WORKSPACE_DIR).replace("\\", "/")
                        success_msg = f"âœ… **PPT ç”ŸæˆæˆåŠŸï¼**\n\nåŸºäº {len(saved_file_paths)} ä¸ªæ–‡ä»¶ç”Ÿæˆçš„æ¼”ç¤ºæ–‡ç¨¿ã€‚\nğŸ“ æ–‡ä»¶: **{os.path.basename(saved_path)}**"
                        
                        yield f"data: {json.dumps({'type': 'token', 'content': success_msg})}\n\n"
                        
                        yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [rel_path], 'total_time': 0})}\n\n"
                    else:
                        raise Exception("PPT æ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼Œæœªè¿”å›è·¯å¾„")
                        
                except Exception as e:
                    print(f"[PPT BATCH ERROR] {e}")
                    import traceback
                    traceback.print_exc()
                    err_msg = f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"
                    yield f"data: {json.dumps({'type': 'token', 'content': err_msg})}\n\n"
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': 0})}\n\n"

            return Response(stream_with_context(generate_ppt_stream()), mimetype='text/event-stream')

        history = session_manager.load(f"{session_name}.json")
        file_names = [f.filename for f in files if f and f.filename]
        user_message = f"[Files: {', '.join(file_names)}] {user_input}"
        session_manager.append_user_early(f"{session_name}.json", user_message)

        batch_results = []
        combined_saved_files = []
        combined_images = []

        def _process_single_file(file):
            if not file or not file.filename:
                return None

            filename = file.filename
            filepath = os.path.join(UPLOAD_DIR, filename)
            file.save(filepath)
            print(f"[FILE UPLOAD] æ–‡ä»¶å·²ä¿å­˜: {filename} -> {filepath}")
            file_type = file.mimetype or file.content_type or ""
            file_ext = os.path.splitext(filename)[1].lower()

            # æ£€æµ‹æ˜¯å¦æ˜¯çº¯å½’æ¡£/æ•´ç†è¯·æ±‚ï¼ˆä¸éœ€è¦AIåˆ†æå†…å®¹ï¼‰
            organize_keywords = ["æ•´ç†", "å½’æ¡£", "å½’çº³", "åˆ†ç±»", "æ•´ç†ä¸€ä¸‹", "æ•´ç†ä¸‹", "å¸®æˆ‘æ•´ç†", "æ–‡ä»¶æ•´ç†", "organize", "sort"]
            is_organize_only = any(kw in (user_input or "") for kw in organize_keywords)

            try:
                # formatted_message, file_data = process_uploaded_file(filepath, user_input)
                # --- Modify to use FileProcessor directly for simultaneous KB indexing ---
                from web.file_processor import FileProcessor
                _processor = FileProcessor()
                _file_raw = _processor.process_file(filepath)
                
                # 1. è‡ªåŠ¨å»ºåº“ (Auto-Indexing to Knowledge Base) - Use threading to not block UI
                try:
                    _text_content = _file_raw.get('text_content', '')
                    if _text_content and len(_text_content) > 50: # Ignore tiny files
                        def _bg_index(content, meta):
                            try:
                                from web.knowledge_base import KnowledgeBase
                                _kb = KnowledgeBase()
                                res = _kb.add_content(content, meta)
                                print(f"[KB] Auto-indexing completed: {res}")
                            except Exception as e:
                                print(f"[KB] Auto-indexing failed: {e}")
                        
                        import threading
                        _idx_thread = threading.Thread(target=_bg_index, args=(_text_content, {
                            "file_path": filepath,
                            "file_name": filename,
                            "file_type": file_ext,
                            "mtime": os.path.getmtime(filepath)
                        }))
                        _idx_thread.start()
                        print(f"[KB] å·²å¯åŠ¨åå°å»ºåº“ä»»åŠ¡: {filename}")
                except Exception as _kb_err:
                    print(f"[KB] Indexing trigger failed: {_kb_err}")

                # 2. Continue with standard chat formatting
                formatted_message, file_data = _processor.format_result_for_chat(_file_raw, user_input)

                task_type = locked_task
                context_info = None
                route_method = "Auto"
                if not task_type:
                    if file_data and file_type and file_type.startswith('image'):
                        message_lower = (user_input or "").lower()
                        is_edit = any(kw in message_lower for kw in KotoBrain.IMAGE_EDIT_KEYWORDS)
                        task_type = "PAINTER" if is_edit else "VISION"
                        route_method = "ğŸ–¼ï¸ Image Edit" if is_edit else "ğŸ‘ï¸ Image Analysis"
                        print(f"[FILE UPLOAD] å›¾ç‰‡ä»»åŠ¡ç›´é€šè·¯ç”±: {task_type} (æ–¹æ³•: {route_method})")
                    else:
                        use_annotation = _should_use_annotation_system(user_input, has_file=True) and file_ext in [".doc", ".docx"]
                        use_analysis = _is_analysis_request(user_input)

                        if use_annotation:
                            task_type = "DOC_ANNOTATE"
                            route_method = "ğŸ“Œ Annotation-Strict"
                        elif use_analysis:
                            task_type = "RESEARCH"
                            route_method = "ğŸ”¬ Analysis"
                        else:
                            task_analysis, route_method, context_info = SmartDispatcher.analyze(
                                formatted_message,
                                history=history
                            )
                            task_type = task_analysis

                        if task_type == "CHAT":
                            task_type = "FILE_GEN"
                            route_method = "ğŸ“„ Upload-Default"

                if task_type == "DOC_ANNOTATE":
                    task_type = "FILE_GEN"
                    route_method = "ğŸ“„ Batch-Upload-Default"

                if locked_model != 'auto':
                    model_to_use = locked_model
                else:
                    complexity = "complex" if file_data is None else "normal"
                    if context_info and context_info.get("complexity"):
                        complexity = context_info["complexity"]

                    if task_type == "FILE_GEN":
                        model_to_use = SmartDispatcher.get_model_for_task(
                            task_type,
                            has_image=bool(file_data),
                            complexity=complexity
                        )
                    else:
                        model_to_use = SmartDispatcher.get_model_for_task(
                            task_type,
                            has_image=bool(file_data)
                        )

                print(f"[FILE UPLOAD] ä»»åŠ¡ç±»å‹: {task_type}, æ¨¡å‹: {model_to_use}")

                result = {
                    "task": task_type,
                    "model": model_to_use,
                    "route_method": route_method,
                    "response": "",
                    "images": [],
                    "saved_files": [],
                }

                # çº¯å½’æ¡£æ¨¡å¼ï¼šè·³è¿‡AIå†…å®¹åˆ†æï¼Œç›´æ¥å½’æ¡£
                if is_organize_only:
                    print(f"[FILE UPLOAD] çº¯å½’æ¡£æ¨¡å¼: {filename}ï¼Œè·³è¿‡AIåˆ†æ")
                    result["response"] = ""
                    result["task"] = "FILE_ORGANIZE"
                else:
                    print(f"[FILE UPLOAD] å¤„ç†æ–‡ä»¶: {filename}, ä½¿ç”¨ brain.chat")
                    brain_result = brain.chat(
                        history=history,
                        user_input=formatted_message,
                        file_data=file_data,
                        model=model_to_use,
                        auto_model=(locked_model == 'auto')
                    )
                    result.update(brain_result)

                # ğŸ—‚ï¸ å…³é”®ï¼šä¸ºæ¯ä¸ªæ–‡ä»¶è°ƒç”¨FileOrganizerè¿›è¡Œå½’æ¡£
                organize_info = {"success": False, "message": "æœªå½’æ¡£"}
                try:
                    # ä½¿ç”¨AIåˆ†ææ–‡ä»¶ç±»å‹å’Œå»ºè®®ç›®å½•
                    from web.file_analyzer import FileAnalyzer
                    analyzer = FileAnalyzer()
                    analysis = analyzer.analyze_file(filepath)  # åªä¼ æ–‡ä»¶è·¯å¾„
                    suggested_folder = analysis.get('suggested_folder')
                    entity_name = analysis.get('entity')
                    entity_type = analysis.get('entity_type')
                    organizer = get_file_organizer()

                    # å¦‚æœå·²å­˜åœ¨åŒåå…¬å¸/é¡¹ç›®æ–‡ä»¶å¤¹ï¼Œåˆ™å¤ç”¨
                    if entity_name:
                        existing_folder = organizer.find_entity_folder(entity_name)
                        if existing_folder:
                            suggested_folder = existing_folder
                    
                    if suggested_folder:
                        org_result = organizer.organize_file(
                            filepath,
                            suggested_folder,
                            auto_confirm=True,
                            metadata={
                                "entity": entity_name,
                                "entity_type": entity_type
                            }
                        )
                        
                        if org_result.get('success'):
                            organize_info = {
                                "success": True,
                                "message": f"âœ… å·²å½’æ¡£åˆ°: {org_result.get('relative_path', suggested_folder)}",
                                "category": suggested_folder,
                                "path": org_result.get('dest_file')
                            }
                            print(f"[FILE ORGANIZE] âœ… {filename} -> {suggested_folder}")
                        else:
                            organize_info = {
                                "success": False,
                                "message": f"âš ï¸ å½’æ¡£å¤±è´¥: {org_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                            }
                    else:
                        organize_info = {
                            "success": False,
                            "message": "âš ï¸ æ— æ³•ç¡®å®šæ–‡ä»¶åˆ†ç±»"
                        }
                except Exception as e:
                    organize_info = {
                        "success": False,
                        "message": f"âš ï¸ å½’æ¡£å¼‚å¸¸: {str(e)}"
                    }
                    print(f"[FILE ORGANIZE ERROR] {filename}: {e}")

                result["file_name"] = filename
                result["organize"] = organize_info
                return result

            except Exception as e:
                return {
                    "file_name": filename,
                    "task": "ERROR",
                    "model": "none",
                    "response": f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}",
                    "images": [],
                    "saved_files": [],
                    "organize": {
                        "success": False,
                        "message": "âŒ å¤„ç†å¤±è´¥ï¼Œæœªå½’æ¡£"
                    }
                }

        if stream_mode:
            def generate_progress():
                total = len([f for f in files if f and f.filename])
                started = {
                    "type": "progress",
                    "current": 0,
                    "total": total,
                    "status": "start",
                    "detail": f"å¼€å§‹å¤„ç† {total} ä¸ªæ–‡ä»¶"
                }
                yield f"data: {json.dumps(started)}\n\n"

                current = 0
                for file in files:
                    if not file or not file.filename:
                        continue

                    current += 1
                    payload = {
                        "type": "progress",
                        "current": current,
                        "total": total,
                        "status": "processing",
                        "detail": f"å¤„ç†ä¸­: {file.filename} ({current}/{total})"
                    }
                    yield f"data: {json.dumps(payload)}\n\n"

                    result = _process_single_file(file)
                    if result:
                        batch_results.append(result)
                        combined_saved_files.extend(result.get("saved_files", []))
                        combined_images.extend(result.get("images", []))

                    payload = {
                        "type": "progress",
                        "current": current,
                        "total": total,
                        "status": "done",
                        "detail": f"å®Œæˆ: {file.filename} ({current}/{total})"
                    }
                    yield f"data: {json.dumps(payload)}\n\n"

                summary_lines = [f"ğŸ“¦ æ‰¹é‡å¤„ç†å®Œæˆï¼Œå…± {len(batch_results)} ä¸ªæ–‡ä»¶", ""]

                organized_count = sum(1 for item in batch_results if item.get("organize", {}).get("success"))
                if organized_count > 0:
                    summary_lines.append(f"âœ… å·²å½’æ¡£: {organized_count} ä¸ªæ–‡ä»¶")

                summary_lines.append("\nğŸ“„ **æ–‡ä»¶è¯¦æƒ…ï¼š**")
                for i, item in enumerate(batch_results, 1):
                    fname = item.get('file_name', 'unknown')
                    task = item.get('task', 'UNKNOWN')
                    organize = item.get('organize', {})

                    status = "âœ…" if task != "ERROR" else "âŒ"
                    org_status = organize.get('message', 'æœªå½’æ¡£')

                    summary_lines.append(f"{i}. {status} **{fname}**")
                    summary_lines.append(f"   ğŸ“‚ {org_status}")

                    response = item.get('response', '')
                    if response and len(response) > 100:
                        summary_lines.append(f"   ğŸ’¬ {response[:100]}...")
                    elif response:
                        summary_lines.append(f"   ğŸ’¬ {response}")

                summary_msg = "\n".join(summary_lines)

                session_manager.update_last_model_response(
                    f"{session_name}.json", summary_msg,
                    task="FILE_BATCH",
                    model_name=locked_model if locked_model != 'auto' else "auto",
                    saved_files=combined_saved_files,
                    images=combined_images
                )

                final_payload = {
                    "type": "final",
                    "response": summary_msg,
                    "task": "FILE_BATCH",
                    "model": locked_model if locked_model != 'auto' else "auto",
                    "results": batch_results,
                    "images": combined_images,
                    "saved_files": combined_saved_files
                }
                yield f"data: {json.dumps(final_payload)}\n\n"

            return Response(generate_progress(), mimetype='text/event-stream')

        for file in files:
            result = _process_single_file(file)
            if not result:
                continue
            batch_results.append(result)
            combined_saved_files.extend(result.get("saved_files", []))
            combined_images.extend(result.get("images", []))

        # ç”Ÿæˆè¯¦ç»†æ‘˜è¦ï¼ŒåŒ…å«å½’æ¡£ä¿¡æ¯
        summary_lines = [f"ğŸ“¦ æ‰¹é‡å¤„ç†å®Œæˆï¼Œå…± {len(batch_results)} ä¸ªæ–‡ä»¶", ""]
        
        organized_count = sum(1 for item in batch_results if item.get("organize", {}).get("success"))
        if organized_count > 0:
            summary_lines.append(f"âœ… å·²å½’æ¡£: {organized_count} ä¸ªæ–‡ä»¶")
        
        summary_lines.append("\nğŸ“„ **æ–‡ä»¶è¯¦æƒ…ï¼š**")
        for i, item in enumerate(batch_results, 1):
            fname = item.get('file_name', 'unknown')
            task = item.get('task', 'UNKNOWN')
            organize = item.get('organize', {})
            
            status = "âœ…" if task != "ERROR" else "âŒ"
            org_status = organize.get('message', 'æœªå½’æ¡£')
            
            summary_lines.append(f"{i}. {status} **{fname}**")
            summary_lines.append(f"   ğŸ“‚ {org_status}")
            
            # æ˜¾ç¤ºAIå“åº”æ‘˜è¦ï¼ˆæˆªå–å‰100å­—ï¼‰
            response = item.get('response', '')
            if response and len(response) > 100:
                summary_lines.append(f"   ğŸ’¬ {response[:100]}...")
            elif response:
                summary_lines.append(f"   ğŸ’¬ {response}")
        
        summary_msg = "\n".join(summary_lines)

        session_manager.update_last_model_response(
            f"{session_name}.json", summary_msg,
            task="FILE_BATCH",
            model_name=locked_model if locked_model != 'auto' else "auto",
            saved_files=combined_saved_files,
            images=combined_images
        )

        return jsonify({
            "response": summary_msg,
            "task": "FILE_BATCH",
            "model": locked_model if locked_model != 'auto' else "auto",
            "results": batch_results,
            "images": combined_images,
            "saved_files": combined_saved_files
        })

    file = files[0]
    
    # Save uploaded file
    filename = file.filename
    filepath = os.path.join(UPLOAD_DIR, filename)
    file.save(filepath)
    print(f"[FILE UPLOAD] æ–‡ä»¶å·²ä¿å­˜: {filename} -> {filepath}")
    file_type = file.mimetype or file.content_type or ""
    file_ext = os.path.splitext(filename)[1].lower()
    
    # Load history first (ä¿è¯å³ä½¿å‡ºé”™ä¹Ÿèƒ½ä¿å­˜ç”¨æˆ·è¾“å…¥)
    history = session_manager.load(f"{session_name}.json")
    user_message = f"[File: {filename}] {user_input}"
    
    # ğŸ”’ ç«‹å³ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°ç£ç›˜ï¼Œé˜²æ­¢æ–­è¿/å´©æºƒå¯¼è‡´ä¸¢å¤±
    session_manager.append_user_early(f"{session_name}.json", user_message)
    
    try:
        # ä½¿ç”¨æ–°çš„æ–‡ä»¶å¤„ç†å™¨ï¼ˆæå–æ–‡æœ¬/äºŒè¿›åˆ¶ï¼‰
        formatted_message, file_data = process_uploaded_file(filepath, user_input)
        
        # ==================== æ™ºèƒ½æ–‡æ¡£åˆ†æå¼•æ“ ====================
        # å¯¹ .docx/.doc æ–‡ä»¶ï¼Œä½¿ç”¨ LLM é©±åŠ¨çš„æ™ºèƒ½åˆ†æå¼•æ“åˆ¤æ–­ç”¨æˆ·æ„å›¾
        # ä¸å†ç¡¬ç¼–ç æ­£åˆ™ï¼Œè€Œæ˜¯è®©åˆ†æå™¨ç†è§£ç”¨æˆ·çœŸå®éœ€æ±‚
        if file_ext in ['.docx', '.doc']:
            # æ ‡æ³¨ä»»åŠ¡ä¼˜å…ˆçº§æ›´é«˜ï¼šæ˜¾å¼æ ‡æ³¨æ„å›¾æˆ–ç”¨æˆ·é”å®š DOC_ANNOTATE æ—¶ï¼Œä¸è¿›å…¥æ™ºèƒ½åˆ†æå¼•æ“
            force_annotation = (locked_task == "DOC_ANNOTATE") or _should_use_annotation_system(user_input, has_file=True)

            # æ™ºèƒ½æ£€æµ‹ï¼šä»»ä½•å¯¹æ–‡æ¡£å†…å®¹æœ‰å®è´¨æ€§å¤„ç†éœ€æ±‚çš„è¯·æ±‚
            # åŒ…æ‹¬ä½†ä¸é™äºï¼šå†™æ‘˜è¦ã€æ”¹å¼•è¨€ã€æ”¹ç»“è®ºã€æ¶¦è‰²ã€åˆ†æç»“æ„ç­‰
            _doc_intent_keywords = [
                # ç”Ÿæˆç±»
                'å†™', 'ç”Ÿæˆ', 'å¸®æˆ‘å†™', 'å†™ä¸€æ®µ', 'å†™ä¸ª',
                # ä¿®æ”¹/æ”¹å–„ç±»
                'æ”¹', 'æ”¹å–„', 'æ”¹è¿›', 'ä¼˜åŒ–', 'æ¶¦è‰²', 'é‡å†™', 'ä¿®æ”¹', 'æå‡',
                # å­¦æœ¯éƒ¨ä»¶
                'æ‘˜è¦', 'å¼•è¨€', 'ç»“è®º', 'abstract', 'å‰è¨€', 'å¯¼è¨€',
                # åˆ†æç±»
                'åˆ†æ', 'æ€»ç»“', 'æ¢³ç†', 'æ¦‚è¿°', 'è¯„ä¼°',
                # è´¨é‡ç±»
                'ä¸æ»¡æ„', 'ä¸å¥½', 'ä¸å¤Ÿ', 'éœ€è¦æ”¹', 'æœ‰é—®é¢˜',
            ]
            is_doc_processing_request = any(kw in user_input.lower() for kw in _doc_intent_keywords)
            
            if is_doc_processing_request and not force_annotation:
                print(f"[INTELLIGENT ANALYZER] æ£€æµ‹åˆ°æ–‡æ¡£å¤„ç†è¯·æ±‚ï¼Œå¯ç”¨æ™ºèƒ½åˆ†æå¼•æ“")
                from web.intelligent_document_analyzer import create_intelligent_analyzer
                
                # åˆ›å»ºæ™ºèƒ½åˆ†æå™¨
                analyzer = create_intelligent_analyzer(client)
                
                # æµå¼å¤„ç†æ–‡æ¡£åˆ†æ
                def generate_intelligent_analysis():
                    """ç”Ÿæˆæ™ºèƒ½æ–‡æ¡£åˆ†æçš„æµå¼å“åº”"""
                    try:
                        # ä½¿ç”¨asyncç”Ÿæˆå™¨ï¼ˆéœ€è¦åœ¨async contextä¸­ï¼‰
                        import asyncio
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        
                        async def run_analysis():
                            async for event in analyzer.process_document_intelligent_streaming(
                                filepath,
                                user_input,
                                session_name
                            ):
                                yield f"data: {json.dumps(event, ensure_ascii=False)}\n\n"
                        
                        gen = run_analysis()
                        while True:
                            try:
                                result = loop.run_until_complete(gen.__anext__())
                                yield result
                            except StopAsyncIteration:
                                break
                    except Exception as e:
                        error_event = {
                            'stage': 'error',
                            'message': f'æ™ºèƒ½åˆ†æå¤±è´¥: {str(e)}'
                        }
                        yield f"data: {json.dumps(error_event, ensure_ascii=False)}\n\n"
                    finally:
                        loop.close()
                
                return Response(
                    stream_with_context(generate_intelligent_analysis()),
                    content_type='text/event-stream'
                )
        # ==================== æ™ºèƒ½æ–‡æ¡£åˆ†æå¼•æ“ç»“æŸ ====================
        
        # æ™ºèƒ½ä»»åŠ¡åˆ†æ
        task_type = locked_task
        context_info = None
        route_method = "Auto"
        if not task_type:
            # å¦‚æœæ˜¯å›¾ç‰‡ä¸Šä¼ ï¼Œç›´æ¥åˆ¤æ–­ç¼–è¾‘æˆ–åˆ†æï¼Œé¿å…åˆå§‹åŒ–æœ¬åœ°è·¯ç”±å™¨å¯¼è‡´å¡é¡¿
            if file_data and file_type and file_type.startswith('image'):
                message_lower = (user_input or "").lower()
                is_edit = any(kw in message_lower for kw in KotoBrain.IMAGE_EDIT_KEYWORDS)
                task_type = "PAINTER" if is_edit else "VISION"
                route_method = "ğŸ–¼ï¸ Image Edit" if is_edit else "ğŸ‘ï¸ Image Analysis"
                print(f"[FILE UPLOAD] å›¾ç‰‡ä»»åŠ¡ç›´é€šè·¯ç”±: {task_type} (æ–¹æ³•: {route_method})")
            else:
                # æ–‡æ¡£ä¸Šä¼ ï¼šä¸¥æ ¼æ£€æµ‹æ ‡æ³¨æ„å›¾ï¼ˆå¿…é¡»æ˜ç¡®è¦æ±‚åœ¨åŸæ–‡ä¸Šæ ‡è®°ï¼‰
                use_annotation = _should_use_annotation_system(user_input, has_file=True) and file_ext in [".doc", ".docx"]
                # çº¯åˆ†æè¯·æ±‚ï¼ˆä¸å«ç”Ÿæˆ/æ”¹å–„æ„å›¾ï¼‰èµ° RESEARCH
                use_analysis = _is_analysis_request(user_input)
                
                # ğŸ¯ PPT ç”Ÿæˆè¯·æ±‚æ˜¾å¼æ£€æµ‹ï¼ˆP0 å…³é”®è·¯ç”±ï¼‰
                ppt_keywords = ["ppt", "å¹»ç¯ç‰‡", "æ¼”ç¤º", "æ±‡æŠ¥", "presentation", "slide", "deck"]
                prefer_ppt = any(kw in user_input.lower() for kw in ppt_keywords)

                if use_annotation:
                    task_type = "DOC_ANNOTATE"
                    route_method = "ğŸ“Œ Annotation-Strict"
                elif use_analysis:
                    task_type = "RESEARCH"
                    route_method = "ğŸ”¬ Analysis"
                elif prefer_ppt:
                    # ğŸ¯ PPT ç”Ÿæˆè·¯ç”±ï¼ˆæ–°å¢ P0 åŠŸèƒ½ï¼‰
                    task_type = "FILE_GEN"
                    route_method = "ğŸ“Š PPT-from-File"
                    print(f"[FILE UPLOAD] ğŸ¯ æ£€æµ‹åˆ° PPT ç”Ÿæˆè¯·æ±‚ï¼Œå¯ç”¨ FILE_GEN + PPT æ¨¡å¼")
                else:
                    # å¦‚æœç”¨æˆ·æ²¡æœ‰é”å®šä»»åŠ¡ï¼Œæ™ºèƒ½åˆ¤æ–­
                    task_analysis, route_method, context_info = SmartDispatcher.analyze(
                        formatted_message,
                        history=history
                    )
                    task_type = task_analysis

                # ä¸Šä¼ æ–‡ä»¶çš„è¯·æ±‚ä¸åº”å½’ç±»ä¸º CHAT
                if task_type == "CHAT":
                    task_type = "FILE_GEN"
                    route_method = "ğŸ“„ Upload-Default"

                print(f"[FILE UPLOAD] æ™ºèƒ½è·¯ç”±é€‰æ‹©ä»»åŠ¡ç±»å‹: {task_type} (æ–¹æ³•: {route_method})")
        
        # ç¡®å®šä½¿ç”¨çš„æ¨¡å‹
        if locked_model != 'auto':
            model_to_use = locked_model
        else:
            # è·å–ä»»åŠ¡å¤æ‚åº¦ï¼ˆä¸Šä¼ æ–‡ä»¶é»˜è®¤æŒ‰å¤æ‚ä»»åŠ¡å¤„ç†ï¼‰
            complexity = "complex" if file_data is None else "normal"
            if context_info and context_info.get("complexity"):
                complexity = context_info["complexity"]
            
            if task_type == "DOC_ANNOTATE":
                model_to_use = "gemini-3-pro-preview"
            elif task_type == "FILE_GEN":
                model_to_use = SmartDispatcher.get_model_for_task(
                    task_type,
                    has_image=bool(file_data),
                    complexity=complexity
                )
            else:
                model_to_use = SmartDispatcher.get_model_for_task(
                    task_type,
                    has_image=bool(file_data)
                )
        
        print(f"[FILE UPLOAD] ä»»åŠ¡ç±»å‹: {task_type}, æ¨¡å‹: {model_to_use}")
        
        # å¦‚æœæ˜¯æ–‡æœ¬ç±»æ–‡ä»¶ï¼ŒæŒ‰ä»»åŠ¡ç±»å‹å¤„ç†
        result = {
            "task": "FILE_GEN" if task_type == "DOC_ANNOTATE" else task_type,
            "subtask": "DOC_ANNOTATE" if task_type == "DOC_ANNOTATE" else None,
            "model": model_to_use,
            "route_method": route_method,
            "response": "",
            "images": [],
            "saved_files": [],
        }

        # æ–‡æ¡£æ ‡æ³¨ä»»åŠ¡ - æµå¼åé¦ˆï¼Œç”Ÿæˆå¸¦Track Changesçš„Wordæ–‡æ¡£
        if task_type == "DOC_ANNOTATE":
            docs_dir = settings_manager.documents_dir
            os.makedirs(docs_dir, exist_ok=True)

            source_path = filepath
            target_path = os.path.join(docs_dir, filename)
            if os.path.abspath(source_path) != os.path.abspath(target_path):
                shutil.copy2(source_path, target_path)

            # ä½¿ç”¨æµå¼SSEè¿”å›è¿›åº¦ï¼Œè®©å‰ç«¯èƒ½å®æ—¶æ˜¾ç¤º
            def generate_doc_annotate_stream():
                import time as _time
                _start = _time.time()
                task_id = f"doc_annotate_{session_name}_{int(_start * 1000)}"
                
                try:
                    from web.document_feedback import DocumentFeedbackSystem
                    feedback_system = DocumentFeedbackSystem(gemini_client=client)
                    
                    # å‘é€åˆ†ç±»ä¿¡æ¯
                    yield f"data: {json.dumps({'type': 'classification', 'task_type': 'DOC_ANNOTATE', 'route_method': route_method, 'model': model_to_use, 'task_id': task_id, 'message': 'ğŸ“„ DOC_ANNOTATE'})}\n\n"
                    
                    # å‘é€åˆå§‹è¿›åº¦
                    yield f"data: {json.dumps({'type': 'progress', 'stage': 'init_reading', 'message': 'ğŸ“– æ­£åœ¨è¯»å–æ–‡æ¡£...', 'detail': filename, 'progress': 5})}\n\n"
                    
                    revised_file = None
                    final_result = None
                    
                    for progress_event in feedback_system.full_annotation_loop_streaming(
                        target_path,
                        user_input,
                        task_id=task_id,
                        model_id=model_to_use,
                        cancel_check=lambda: _interrupt_manager.is_interrupted(session_name)
                    ):
                        stage = progress_event.get('stage', 'unknown')
                        progress = progress_event.get('progress', 0)
                        message_text = progress_event.get('message', '')
                        detail = progress_event.get('detail', '')
                        
                        if stage == 'cancelled':
                            yield f"data: {json.dumps({'type': 'info', 'message': 'â¸ï¸ ä»»åŠ¡å·²å–æ¶ˆ'})}\n\n"
                            _elapsed = _time.time() - _start
                            # ä¿å­˜å–æ¶ˆè®°å½•
                            session_manager.update_last_model_response(f"{session_name}.json", "â¸ï¸ æ–‡æ¡£æ ‡æ³¨ä»»åŠ¡å·²å–æ¶ˆ")
                            yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': _elapsed, 'cancelled': True})}\n\n"
                            return
                        
                        yield f"data: {json.dumps({'type': 'progress', 'stage': stage, 'message': message_text, 'detail': detail, 'progress': progress})}\n\n"
                        
                        if stage == 'complete':
                            final_result = progress_event.get('result', {})
                            revised_file = final_result.get('revised_file')
                    
                    _elapsed = _time.time() - _start
                    
                    if final_result and final_result.get('success'):
                        applied = final_result.get('applied', 0)
                        failed = final_result.get('failed', 0)
                        total = final_result.get('total', applied + failed)
                        
                        # è¯»å–æ–‡æ¡£ä¿¡æ¯
                        try:
                            from docx import Document as _Doc
                            _d = _Doc(target_path)
                            _total_paras = len([p for p in _d.paragraphs if p.text.strip()])
                            _total_chars = sum(len(p.text) for p in _d.paragraphs)
                        except Exception:
                            _total_paras = 0
                            _total_chars = 0
                        
                        density = (applied / _total_chars * 1000) if _total_chars > 0 else 0
                        
                        summary_lines = [
                            "## âœ… æ–‡æ¡£ä¿®æ”¹å®Œæˆï¼",
                            "",
                            "### ğŸ“Š ä¿®æ”¹ç»Ÿè®¡",
                            f"- æ‰¾åˆ°å¹¶åº”ç”¨: **{applied}** å¤„ä¿®æ”¹",
                            f"- å®šä½å¤±è´¥: {failed} å¤„",
                            f"- æ€»è®¡åˆ†æ: {total} å¤„",
                            "",
                            "### ğŸ“‹ æ–‡æ¡£ä¿¡æ¯",
                            f"- æ–‡ä»¶å: `{filename}`",
                            f"- æ®µè½æ•°: {_total_paras} æ®µ",
                            f"- å­—æ•°: {_total_chars} å­—",
                            f"- ä¿®æ”¹å¯†åº¦: **{density:.1f}** å¤„/åƒå­—",
                            "",
                            f"### ğŸ“„ æ¨¡å‹: `{model_to_use}`",
                            "",
                            f"### ğŸ“ è¾“å‡ºæ–‡ä»¶: `{os.path.basename(revised_file) if revised_file else 'å¾…ç”Ÿæˆ'}`",
                            "",
                            "### ğŸ’¡ ä½¿ç”¨æ–¹æ³•",
                            "1. ç”¨ Microsoft Word æ‰“å¼€è¾“å‡ºæ–‡ä»¶",
                            "2. ç‚¹å‡»ã€Œå®¡é˜…ã€æ ‡ç­¾é¡µ",
                            "3. å³ä¾§æ°”æ³¡ä¸­æŸ¥çœ‹å…¨éƒ¨ä¿®æ”¹å»ºè®®",
                            "4. é€æ¡æ¥å—æˆ–å¿½ç•¥ï¼ˆå³é”®æ‰¹æ³¨å¯æ“ä½œï¼‰",
                        ]
                        summary_msg = "\n".join(summary_lines)
                        
                        yield f"data: {json.dumps({'type': 'token', 'content': summary_msg})}\n\n"
                        
                        session_manager.update_last_model_response(
                            f"{session_name}.json", summary_msg,
                            task="DOC_ANNOTATE", model_name=model_to_use,
                            saved_files=[revised_file] if revised_file else []
                        )
                        
                        yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [revised_file] if revised_file else [], 'total_time': _elapsed})}\n\n"
                    else:
                        err_msg = final_result.get('message', 'æœªçŸ¥é”™è¯¯') if final_result else 'å¤„ç†å¤±è´¥'
                        # ä¿å­˜å¤±è´¥è®°å½•
                        session_manager.update_last_model_response(f"{session_name}.json", f"âŒ æ–‡æ¡£æ ‡æ³¨å¤±è´¥: {err_msg}")
                        yield f"data: {json.dumps({'type': 'error', 'message': 'âŒ ' + err_msg})}\n\n"
                        yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [], 'total_time': _elapsed})}\n\n"
                
                except Exception as e:
                    import traceback
                    traceback.print_exc()
                    # ä¿å­˜å¼‚å¸¸è®°å½•
                    session_manager.update_last_model_response(f"{session_name}.json", f"âŒ æ ‡æ³¨ç³»ç»Ÿé”™è¯¯: {str(e)[:200]}")
                    yield f"data: {json.dumps({'type': 'error', 'message': 'âŒ æ ‡æ³¨ç³»ç»Ÿé”™è¯¯: ' + str(e)[:200]})}\n\n"
                    yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': []})}\n\n"
            
            return Response(generate_doc_annotate_stream(), mimetype='text/event-stream')

        # ğŸ¯ FILE_GEN + PPT ç”Ÿæˆï¼ˆP0 æ–°å¢ï¼‰
        elif task_type == "FILE_GEN" and prefer_ppt:
            print(f"[FILE_GEN PPT] å¼€å§‹ PPT ç”Ÿæˆæµç¨‹")
            
            # ç¬¬ 1 æ­¥ï¼šä½¿ç”¨ FileParser æå–ç»“æ„åŒ–å†…å®¹
            from web.file_parser import FileParser
            from web.ppt_session_manager import PPTSessionManager
            
            parser = FileParser()
            parse_result = parser.parse_file(filepath)
            file_content = parse_result.get('content', '') if parse_result else ""
            
            # ç¬¬ 2 æ­¥ï¼šåˆ›å»º PPT ä¼šè¯
            ppt_session_dir = os.path.join(WORKSPACE_DIR, 'workspace', 'ppt_sessions')
            os.makedirs(ppt_session_dir, exist_ok=True)
            
            session_manager_ppt = PPTSessionManager(ppt_session_dir)
            ppt_session_id = session_manager_ppt.create_session(
                title=f"PPT from {os.path.splitext(filename)[0]}",
                user_input=user_input,
                theme="business"
            )
            print(f"[FILE_GEN PPT] åˆ›å»ºä¼šè¯: {ppt_session_id}")
            
            # ç¬¬ 3 æ­¥ï¼šä¿å­˜æ–‡ä»¶å†…å®¹åˆ°ä¼šè¯
            session_manager_ppt.save_generation_data(
                session_id=ppt_session_id,
                ppt_data=None,
                ppt_file_path=None,
                uploaded_file_context=file_content[:3000]  # å°†å†…å®¹é™åˆ¶ä¸ºå‰3000å­—ç¬¦
            )
            print(f"[FILE_GEN PPT] æ–‡ä»¶å†…å®¹å·²ä¿å­˜åˆ°ä¼šè¯")
            
            # ä½¿ç”¨æµå¼å“åº”ï¼ˆStreamed Responseï¼‰ä»¥æ”¯æŒå®æ—¶è¿›åº¦æ˜¾ç¤º
            def generate_ppt_file_stream():
                import asyncio
                import queue
                import threading
                from web.app import TaskOrchestrator
                import time as _time
                _start = _time.time()
                
                # å‘é€åˆå§‹åŒ–ä¿¡æ¯
                yield f"data: {json.dumps({'type': 'classification', 'task_type': 'FILE_GEN', 'subtask': 'PPT_CREATION', 'message': 'ğŸ“Š å¼€å§‹ PPT æ¼”ç¤ºæ–‡ç¨¿ç”Ÿæˆæµç¨‹'})}\n\n"
                
                # å‡†å¤‡ä»»åŠ¡å‚æ•°
                subtask = {
                    "task_type": "FILE_GEN",
                    "index": 1,
                    "description": f"ä»æ–‡æ¡£ {filename} ç”Ÿæˆ PPT"
                }
                context = {
                    "original_input": user_input,
                    "step_1_output": file_content
                }
                
                # è¿›åº¦é˜Ÿåˆ—
                progress_queue = queue.Queue()
                def _progress_cb(msg, detail=""):
                    progress_queue.put({"msg": msg, "detail": detail})
                
                # ä»»åŠ¡ç»“æœå®¹å™¨
                task_result_holder = {"result": None}

                # åå°æ‰§è¡Œå‡½æ•°
                def _run_task_thread():
                    # ä¸ºæ–°çº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„äº‹ä»¶å¾ªç¯
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        task_result_holder["result"] = loop.run_until_complete(
                            TaskOrchestrator._execute_file_gen(user_input, context, subtask, _progress_cb)
                        )
                    except Exception as e:
                        task_result_holder["result"] = {"success": False, "error": str(e)}
                    finally:
                        loop.close()
                        progress_queue.put(None) # Signal done

                # å¯åŠ¨åå°çº¿ç¨‹
                t = threading.Thread(target=_run_task_thread)
                t.start()
                
                # ä¸»çº¿ç¨‹å¾ªç¯è¯»å–è¿›åº¦
                while True:
                    try:
                        item = progress_queue.get(timeout=0.1)
                        if item is None:
                            break
                        # å‘é€è¿›åº¦SSE
                        yield f"data: {json.dumps({'type': 'progress', 'message': item['msg'], 'detail': item['detail']})}\n\n"
                    except queue.Empty:
                        if not t.is_alive():
                            break
                
                t.join()
                ppt_result = task_result_holder["result"]
                _elapsed = _time.time() - _start

                # å¤„ç†æœ€ç»ˆç»“æœ
                if ppt_result and ppt_result.get('success'):
                    saved_files = ppt_result.get('saved_files', [])
                    if saved_files:
                        ppt_file_path = saved_files[0] if isinstance(saved_files, list) else saved_files
                        # ä¿å­˜ä¼šè¯æ•°æ®
                        session_manager_ppt.save_generation_data(
                            session_id=ppt_session_id,
                            ppt_data=ppt_result.get('ppt_data'),
                            ppt_file_path=ppt_file_path
                        )
                        
                        final_msg = (
                             f"âœ… PPT æ¼”ç¤ºå·²ç”Ÿæˆ\n\n"
                             f"ğŸ“„ æ–‡ä»¶: [{os.path.basename(ppt_file_path)}]({ppt_file_path.replace(os.sep, '/')})\n"
                             f"ğŸ”— ä¼šè¯ID: `{ppt_session_id}`\n"
                             f"â±ï¸ è€—æ—¶: {_elapsed:.1f}s"
                        )
                        yield f"data: {json.dumps({'type': 'token', 'content': final_msg})}\n\n"
                        
                        # æ›´æ–°å†å²
                        session_manager.update_last_model_response(
                            f"{session_name}.json", final_msg,
                            task="FILE_GEN", model_name=model_to_use, saved_files=[ppt_file_path]
                        )
                        
                        yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': [ppt_file_path], 'ppt_session_id': ppt_session_id})}\n\n"
                    else:
                        err_msg = "âš ï¸ PPT æ¡†æ¶å·²ç”Ÿæˆï¼Œä½†æ–‡ä»¶ä¿å­˜å¤±è´¥"
                        yield f"data: {json.dumps({'type': 'error', 'message': err_msg})}\n\n"
                        yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': []})}\n\n"
                else:
                     err_msg = ppt_result.get('error', 'æœªçŸ¥é”™è¯¯') if ppt_result else "ä»»åŠ¡æ‰§è¡Œæ— ç»“æœ"
                     yield f"data: {json.dumps({'type': 'error', 'message': f'âŒ ç”Ÿæˆå¤±è´¥: {err_msg}'})}\n\n"
                     yield f"data: {json.dumps({'type': 'done', 'images': [], 'saved_files': []})}\n\n"

            return Response(stream_with_context(generate_ppt_file_stream()), mimetype='text/event-stream')
        
            analysis_prompt = (
                "ä½ æ˜¯Kotoï¼Œä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ã€‚\n"
                "è¯·åŸºäºç”¨æˆ·ä¸Šä¼ çš„åŸå§‹æ–‡ä»¶å†…å®¹ï¼ŒæŒ‰ä»¥ä¸‹ç»“æ„ç”Ÿæˆé«˜è´¨é‡æ€»ç»“ï¼š\n\n"
                "# æ‘˜è¦\n"
                "- ç”¨3-5æ¡è¦ç‚¹æ¦‚è¿°æ ¸å¿ƒä¿¡æ¯\n\n"
                "# è¯¦ç»†åˆ†æ\n"
                "## èƒŒæ™¯ä¸ä¸Šä¸‹æ–‡\n"
                "## å…³é”®è§‚ç‚¹ä¸è¦ç‚¹\n"
                "## æ•°æ®ä¸è¯æ®\n"
                "## ç»“è®ºä¸å»ºè®®\n\n"
                "è¦æ±‚ï¼š\n"
                "- ç”¨ä¸­æ–‡è¾“å‡ºï¼Œæ¡ç†æ¸…æ™°ï¼Œé¿å…å†—é•¿\n"
                "- ä¸è¦è¾“å‡ºä»»ä½•ä»£ç æˆ–BEGIN_FILEæ ‡è®°\n"
                "- ä½¿ç”¨æ ‡é¢˜å’Œé¡¹ç›®ç¬¦å·ç»„ç»‡å†…å®¹\n"
            )

            full_input = formatted_message + "\n\n" + analysis_prompt
            print(f"[FILE UPLOAD] è°ƒç”¨æ¨¡å‹: {model_to_use}")
            
            response = client.models.generate_content(
                model=model_to_use,
                contents=full_input,
                config=types.GenerateContentConfig(
                    system_instruction=_get_filegen_brief_instruction(),
                    temperature=0.7,
                    max_output_tokens=4000,
                )
            )
            text_out = response.text or "(æ— è¾“å‡º)"
            print(f"[FILE UPLOAD] æ¨¡å‹è¿”å›é•¿åº¦: {len(text_out)} å­—ç¬¦")

            # Save DOCX and optionally PDF
            title = _build_analysis_title(user_input, filename, is_binary=False)
            cleaned_text = _strip_code_blocks(text_out)
            saved_docx = save_docx(cleaned_text, title=title, output_dir=settings_manager.documents_dir)
            docx_rel = os.path.relpath(saved_docx, WORKSPACE_DIR).replace("\\", "/")
            result["saved_files"].append(docx_rel)
            print(f"[FILE UPLOAD] âœ… å·²ä¿å­˜ DOCX: {docx_rel}")
            
            # Also save as PDF if user wants both formats
            if user_input and any(kw in user_input.lower() for kw in ['pdf', 'ä¸¤ç§æ ¼å¼', 'both']):
                try:
                    saved_pdf = save_pdf(cleaned_text, title=title, output_dir=settings_manager.documents_dir)
                    pdf_rel = os.path.relpath(saved_pdf, WORKSPACE_DIR).replace("\\", "/")
                    result["saved_files"].append(pdf_rel)
                    print(f"[FILE UPLOAD] âœ… å·²ä¿å­˜ PDF: {pdf_rel}")
                except Exception as pdf_err:
                    print(f"[FILE UPLOAD] âš ï¸ PDFä¿å­˜å¤±è´¥: {pdf_err}")
            
            result["response"] = (
                "âœ… æ–‡æ¡£åˆ†æå®Œæˆå¹¶å·²ä¿å­˜\n\n"
                f"ğŸ“„ ç”Ÿæˆæ–‡ä»¶: {', '.join([os.path.basename(f) for f in result['saved_files']])}\n"
                f"ğŸ“‚ ä½ç½®: `{settings_manager.documents_dir}`\n\n"
                f"ğŸ’¡ æç¤º: æ–‡ä»¶å·²è‡ªåŠ¨ä¿å­˜åˆ° workspace/documents ç›®å½•"
            )
        else:
            # Binary (image/PDF) â†’ let brain handle vision and optionally save analysis as DOCX
            print(f"[FILE UPLOAD] äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œä½¿ç”¨ brain.chat è¿›è¡Œè§†è§‰åˆ†æ")
            brain_result = brain.chat(
                history=history,
                user_input=formatted_message,
                file_data=file_data,
                model=model_to_use,
                auto_model=(locked_model == 'auto')
            )
            result.update(brain_result)
            # If model returned text, save a DOCX analysis too
            if brain_result.get("response") and len(brain_result["response"]) > 50:
                try:
                    title = _build_analysis_title(user_input, filename, is_binary=True)
                    cleaned_text = _strip_code_blocks(brain_result["response"])
                    saved_path = save_docx(cleaned_text, title=title, output_dir=settings_manager.documents_dir)
                    docx_rel = os.path.relpath(saved_path, WORKSPACE_DIR).replace("\\", "/")
                    result.setdefault("saved_files", []).append(docx_rel)
                    print(f"[FILE UPLOAD] âœ… è§†è§‰åˆ†æå·²ä¿å­˜ä¸º DOCX: {docx_rel}")
                    
                    # Update response to mention saved analysis
                    if result.get("response"):
                        result["response"] += f"\n\nğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {os.path.basename(saved_path)}"
                except Exception as docx_err:
                    print(f"[FILE UPLOAD] âš ï¸ DOCXä¿å­˜å¤±è´¥: {docx_err}")
        
        # ç¡®ä¿resultåŒ…å«å®Œæ•´çš„å“åº”
        if not result.get('response'):
            result['response'] = "å¤„ç†å®Œæˆ"
        if not result.get('task'):
            result['task'] = task_type
        if not result.get('model'):
            result['model'] = model_to_use
        
        # Update historyï¼ˆæ›´æ–°æ¨¡å‹å›å¤ï¼Œç”¨æˆ·æ¶ˆæ¯å·²æ—©æœŸä¿å­˜ï¼ŒåŒ…å«å…ƒæ•°æ®ï¼‰
        session_manager.update_last_model_response(
            f"{session_name}.json", result.get("response", ""),
            task=result.get('task', task_type),
            model_name=result.get('model', model_to_use),
            saved_files=result.get('saved_files', []),
            images=result.get('images', [])
        )
        
        print(f"[FILE UPLOAD] å“åº”æˆåŠŸï¼Œä»»åŠ¡: {result.get('task')}, æ–‡ä»¶: {len(result.get('saved_files', []))} ä¸ª")
        return jsonify(result)
        
    except Exception as e:
        # å³ä½¿å‡ºé”™ä¹Ÿä¿å­˜ç”¨æˆ·çš„é—®é¢˜å’Œé”™è¯¯ä¿¡æ¯
        import traceback
        error_detail = traceback.format_exc()
        print(f"[FILE UPLOAD ERROR] {error_detail}")
        
        error_response = f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"
        session_manager.update_last_model_response(f"{session_name}.json", error_response)
        
        return jsonify({
            "response": error_response,
            "task": "ERROR",
            "model": "none",
            "images": [],
            "saved_files": []
        })

# ==================== PPT ç›¸å…³ API ç«¯ç‚¹ï¼ˆP0 è¡¥å……ï¼‰====================

@app.route('/api/ppt/download', methods=['POST'])
def download_ppt():
    """ä¸‹è½½ PPT PPTX æ–‡ä»¶"""
    try:
        session_id = request.json.get('session_id')
        if not session_id:
            return jsonify({"error": "Missing session_id"}), 400
        
        # ä» PPT ä¼šè¯ä¸­è·å–æ–‡ä»¶è·¯å¾„
        from web.ppt_session_manager import PPTSessionManager
        ppt_session_dir = os.path.join(WORKSPACE_DIR, 'workspace', 'ppt_sessions')
        manager = PPTSessionManager(ppt_session_dir)
        
        session_data = manager.load_session(session_id)
        if not session_data:
            return jsonify({"error": "Session not found"}), 404
        
        ppt_file_path = session_data.get('ppt_file_path')
        if not ppt_file_path:
            # å¦‚æœæ–‡ä»¶è¿˜æ²¡ç”Ÿæˆï¼Œå°è¯•ç”Ÿæˆä¸€ä¸ªä¸´æ—¶çš„
            return jsonify({"error": "PPT file not generated yet"}), 400
        
        # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
        full_path = os.path.join(WORKSPACE_DIR, ppt_file_path.lstrip('/').replace('/', os.sep))
        
        if not os.path.exists(full_path):
            return jsonify({"error": "PPT file not found"}), 404
        
        # è¿”å›æ–‡ä»¶ä¸‹è½½
        return send_file(
            full_path,
            mimetype='application/vnd.openxmlformats-officedocument.presentationml.presentation',
            as_attachment=True,
            download_name=os.path.basename(full_path)
        )
    
    except Exception as e:
        print(f"[PPT DOWNLOAD] é”™è¯¯: {e}")
        return jsonify({"error": f"Download failed: {str(e)}"}), 500


@app.route('/api/ppt/session/<session_id>', methods=['GET'])
def get_ppt_session(session_id):
    """è·å– PPT ä¼šè¯ä¿¡æ¯"""
    try:
        from web.ppt_session_manager import PPTSessionManager
        ppt_session_dir = os.path.join(WORKSPACE_DIR, 'workspace', 'ppt_sessions')
        manager = PPTSessionManager(ppt_session_dir)
        
        session_data = manager.load_session(session_id)
        if not session_data:
            return jsonify({"error": "Session not found"}), 404
        
        return jsonify({
            "success": True,
            "session": {
                "id": session_data.get('session_id'),
                "title": session_data.get('title'),
                "status": session_data.get('status'),
                "ppt_file_path": session_data.get('ppt_file_path'),
                "created_at": session_data.get('created_at'),
                "updated_at": session_data.get('updated_at')
            }
        })
    
    except Exception as e:
        print(f"[PPT SESSION] é”™è¯¯: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/ping', methods=['GET'])
def ping():
    start = time.time()
    try:
        client.models.get(model=MODEL_MAP['CHAT'])
        latency = (time.time() - start) * 1000
        return jsonify({
            "status": "ok",
            "latency": latency,
            "ollama": LocalDispatcher.is_ollama_running()
        })
    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e)
        })

@app.route('/api/health', methods=['GET'])
def health():
    """è½»é‡å¥åº·æ£€æŸ¥ï¼ˆä¸è§¦å‘æ¨¡å‹è°ƒç”¨ï¼‰"""
    return jsonify({
        "status": "ok",
        "time": time.time()
    })

@app.route('/api/analyze', methods=['POST'])
def analyze_task():
    """é¢„åˆ†æä»»åŠ¡ç±»å‹å’Œæ¨¡å‹é€‰æ‹© - è®©å‰ç«¯ç«‹å³æ˜¾ç¤º"""
    data = request.json
    message = data.get('message', '')
    locked_task = data.get('locked_task')
    locked_model = data.get('locked_model', 'auto')
    has_file = data.get('has_file', False)
    file_type = data.get('file_type', '')
    
    if not message:
        return jsonify({"task": "CHAT", "model": MODEL_MAP["CHAT"], "route_method": "Empty"})
    
    # å›¾åƒç¼–è¾‘å…³é”®è¯
    IMAGE_EDIT_KEYWORDS = [
        "ä¿®æ”¹", "æ¢", "æ”¹æˆ", "å˜æˆ", "åº•è‰²", "èƒŒæ™¯", "é¢œè‰²",
        "æŠ å›¾", "å»èƒŒæ™¯", "På›¾", "ç¾åŒ–", "æ»¤é•œ", "è°ƒè‰²", "ç¼–è¾‘",
        "change", "modify", "edit", "background", "color",
    ]
    
    # å¦‚æœç”¨æˆ·é”å®šäº†ä»»åŠ¡ç±»å‹
    if locked_task:
        task = locked_task
        route_method = "ğŸ”’ Manual"
    elif has_file and file_type and file_type.startswith('image'):
        # æœ‰å›¾ç‰‡æ–‡ä»¶ï¼Œåˆ¤æ–­æ˜¯ç¼–è¾‘è¿˜æ˜¯åˆ†æ
        message_lower = message.lower()
        is_edit = any(kw in message_lower for kw in IMAGE_EDIT_KEYWORDS)
        if is_edit:
            task = "PAINTER"
            route_method = "ğŸ–¼ï¸ Image Edit"
        else:
            task = "VISION"
            route_method = "ğŸ‘ï¸ Image Analysis"
    else:
        # ä½¿ç”¨æ™ºèƒ½è·¯ç”±å™¨
        task, route_method, _ = SmartDispatcher.analyze(message)
    
    # å¦‚æœç”¨æˆ·é€‰æ‹©äº†ç‰¹å®šæ¨¡å‹
    if locked_model and locked_model != 'auto':
        model = locked_model
    else:
        model = SmartDispatcher.get_model_for_task(task, has_image=has_file)
    
    # è·å–æ¨¡å‹æ˜¾ç¤ºä¿¡æ¯
    model_info = MODEL_INFO.get(model, {"name": model, "speed": ""})
    
    return jsonify({
        "task": task,
        "model": model,
        "model_name": model_info.get("name", model),
        "model_speed": model_info.get("speed", ""),
        "route_method": route_method,  # è·¯ç”±ç®—æ³•ä¿¡æ¯
        "strengths": model_info.get("strengths", []),
    })

@app.route('/api/workspace/<path:filepath>')
def get_workspace_file(filepath):
    """è·å– workspace ä¸­çš„æ–‡ä»¶ï¼Œæ”¯æŒå­ç›®å½•"""
    print(f"[API] Serving workspace file: {filepath}")
    full_path = os.path.join(WORKSPACE_DIR, filepath)
    
    # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿è¯·æ±‚çš„è·¯å¾„åœ¨ WORKSPACE_DIR ä¸‹
    try:
        resolved_path = os.path.abspath(full_path)
        resolved_workspace = os.path.abspath(WORKSPACE_DIR)
        if not resolved_path.startswith(resolved_workspace):
            print(f"[API] Security violation: {resolved_path} not under {resolved_workspace}")
            return jsonify({"error": "Access denied"}), 403
        
        if not os.path.exists(resolved_path):
            print(f"[API] File not found: {resolved_path}")
            return jsonify({"error": "File not found"}), 404
        
        print(f"[API] Serving: {resolved_path}")
        return send_from_directory(WORKSPACE_DIR, filepath)
    except Exception as e:
        print(f"[API] Error serving {filepath}: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": "Server error", "detail": str(e)}), 500

@app.route('/api/workspace', methods=['GET'])
def list_workspace_files():
    files = os.listdir(WORKSPACE_DIR)
    return jsonify({"files": files})

@app.route('/api/open-workspace', methods=['POST'])
def open_workspace():
    """æ‰“å¼€ workspace æ–‡ä»¶å¤¹"""
    try:
        if sys.platform == "win32":
            subprocess.Popen(
                f'explorer "{WORKSPACE_DIR}"',
                shell=True,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
        elif sys.platform == "darwin":
            subprocess.Popen(["open", WORKSPACE_DIR])
        else:
            subprocess.Popen(["xdg-open", WORKSPACE_DIR])
        return jsonify({"success": True, "path": WORKSPACE_DIR})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})

@app.route('/api/open-file', methods=['POST'])
def open_file_native():
    """ç”¨ç³»ç»Ÿé»˜è®¤ç¨‹åºæ‰“å¼€æ–‡ä»¶ï¼ˆä¸ç»è¿‡æµè§ˆå™¨ï¼‰"""
    try:
        data = request.get_json()
        filepath = data.get("filepath", "")
        if not filepath:
            return jsonify({"success": False, "error": "No filepath provided"}), 400
        
        full_path = os.path.join(WORKSPACE_DIR, filepath)
        resolved_path = os.path.abspath(full_path)
        resolved_workspace = os.path.abspath(WORKSPACE_DIR)
        
        if not resolved_path.startswith(resolved_workspace):
            return jsonify({"success": False, "error": "Access denied"}), 403
        
        if not os.path.exists(resolved_path):
            return jsonify({"success": False, "error": "File not found"}), 404
        
        print(f"[API] Opening file natively: {resolved_path}")
        if sys.platform == "win32":
            os.startfile(resolved_path)
        elif sys.platform == "darwin":
            subprocess.Popen(["open", resolved_path])
        else:
            subprocess.Popen(["xdg-open", resolved_path])
        
        return jsonify({"success": True, "path": resolved_path})
    except Exception as e:
        print(f"[API] Error opening file: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

# ================= Settings API =================

@app.route('/api/settings', methods=['GET'])
def get_settings():
    # åˆå¹¶ appearance ä¸»é¢˜ï¼ˆå¦‚æœ‰ cookie/å‚æ•°å¯åœ¨æ­¤åˆå¹¶ï¼‰
    return jsonify(settings_manager.get_all())

@app.route('/api/settings', methods=['POST'])
def update_settings():
    data = request.json
    category = data.get('category')
    key = data.get('key')
    value = data.get('value')
    
    if category and key:
        success = settings_manager.set(category, key, value)
        settings_manager.ensure_directories()
        return jsonify({"success": success})
    return jsonify({"success": False, "error": "Missing category or key"})

@app.route('/api/settings/reset', methods=['POST'])
def reset_settings():
    success = settings_manager.reset()
    return jsonify({"success": success})

# ================= Mini Mode Switch API =================

@app.route('/api/switch-to-mini', methods=['POST'])
def switch_to_mini():
    """åˆ‡æ¢åˆ°è¿·ä½ æ¨¡å¼"""
    import subprocess
    import sys
    
    try:
        # å¯åŠ¨è¿·ä½ çª—å£
        mini_koto_path = os.path.join(PROJECT_ROOT, 'web', 'mini_koto.py')
        if os.path.exists(mini_koto_path):
            # åœ¨æ–°è¿›ç¨‹ä¸­å¯åŠ¨è¿·ä½ çª—å£
            subprocess.Popen(
                [sys.executable, mini_koto_path],
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == 'win32' else 0,
                cwd=PROJECT_ROOT
            )
            return jsonify({"success": True, "message": "è¿·ä½ æ¨¡å¼å·²å¯åŠ¨"})
        else:
            return jsonify({"success": False, "error": "æ‰¾ä¸åˆ°è¿·ä½ æ¨¡å¼ç¨‹åº"})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})

@app.route('/api/switch-to-main', methods=['POST'])
def switch_to_main():
    """åˆ‡æ¢åˆ°ä¸»ç¨‹åº"""
    import subprocess
    import sys
    
    try:
        # å¯åŠ¨ä¸»çª—å£
        main_app_path = os.path.join(PROJECT_ROOT, 'koto_app.py')
        if os.path.exists(main_app_path):
            subprocess.Popen(
                [sys.executable, main_app_path],
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == 'win32' else 0,
                cwd=PROJECT_ROOT
            )
            return jsonify({"success": True, "message": "ä¸»ç¨‹åºå·²å¯åŠ¨"})
        else:
            return jsonify({"success": False, "error": "æ‰¾ä¸åˆ°ä¸»ç¨‹åº"})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})

@app.route('/mini')
def mini_page():
    """è¿·ä½ æ¨¡å¼é¡µé¢ï¼ˆæµè§ˆå™¨è®¿é—®ç”¨ï¼‰"""
    return render_template('mini_koto.html')

@app.route('/api/mini/chat', methods=['POST'])
def mini_chat():
    """è¿·ä½ æ¨¡å¼ä¸“ç”¨èŠå¤©API - ä½¿ç”¨ä¸åŸç‰ˆå®Œå…¨ç›¸åŒçš„ä»»åŠ¡åˆ†é…å’Œæ‰§è¡Œé€»è¾‘"""
    data = request.json
    user_input = data.get('message', '').strip()
    
    if not user_input:
        return jsonify({"error": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"}), 400
    
    user_input = Utils.sanitize_string(user_input)
    
    # ä½¿ç”¨å›ºå®šçš„è¿·ä½ ä¼šè¯
    session_name = "MiniKoto_Quick"
    history = session_manager.load(f"{session_name}.json")
    
    # ğŸ¯ ä½¿ç”¨ SmartDispatcher è¿›è¡Œä»»åŠ¡åˆ†æï¼ˆä¸å®Œæ•´ç‰ˆç›¸åŒï¼‰
    task_type, route_method, context_info = SmartDispatcher.analyze(user_input, history)
    print(f"[MINI_CHAT] SmartDispatcher åˆ†æç»“æœ: task_type='{task_type}', method='{route_method}'")
    
    response_text = ""
    is_error = False
    used_model = "unknown"
    
    try:
        # ===== æ ¹æ®ä»»åŠ¡ç±»å‹æ‰§è¡Œä¸åŒçš„å¤„ç†é€»è¾‘ï¼ˆä¸å®Œæ•´ç‰ˆç›¸åŒï¼‰=====
        
        if task_type == "WEB_SEARCH":
            # ğŸŒ ç½‘ç»œæœç´¢ - ä½¿ç”¨ Gemini Google Search Grounding
            print(f"[MINI_CHAT] ğŸŒ æ‰§è¡Œç½‘ç»œæœç´¢...")
            search_result = WebSearcher.search_with_grounding(user_input)
            response_text = search_result.get("response", "")
            used_model = "gemini-2.5-flash (Google Search)"
            
            # å¦‚æœæœç´¢å¤±è´¥ï¼Œå°è¯•ä¿®æ­£æŸ¥è¯¢
            if not search_result.get("success") or Utils.is_failure_output(response_text) or "æœç´¢å¤±è´¥" in response_text:
                print(f"[MINI_CHAT] âš ï¸ åˆæ¬¡æœç´¢å¤±è´¥ï¼Œå°è¯•ä¿®æ­£æŸ¥è¯¢...")
                fix_query_prompt = (
                    "è¯·æŠŠç”¨æˆ·éœ€æ±‚æ”¹å†™æˆæ›´é€‚åˆæœç´¢çš„ç®€çŸ­å…³é”®è¯æˆ–æŸ¥è¯¢è¯­å¥ï¼Œåªè¾“å‡ºæŸ¥è¯¢è¯­å¥ã€‚\n"
                    f"ç”¨æˆ·éœ€æ±‚: {user_input}"
                )
                try:
                    fix_query_resp = client.models.generate_content(
                        model="gemini-2.0-flash",
                        contents=fix_query_prompt,
                        config=types.GenerateContentConfig(temperature=0.2, max_output_tokens=64)
                    )
                    fixed_query = (fix_query_resp.text or user_input).strip()
                    print(f"[MINI_CHAT] ä¿®æ­£åçš„æŸ¥è¯¢: {fixed_query}")
                    search_result = WebSearcher.search_with_grounding(fixed_query)
                    response_text = search_result.get("response", "")
                except Exception as e:
                    print(f"[MINI_CHAT] ä¿®æ­£æŸ¥è¯¢å¤±è´¥: {e}")
            
            if not response_text or Utils.is_failure_output(response_text):
                is_error = True
                response_text = f"æœç´¢å¤±è´¥ï¼šæ— æ³•è·å– '{user_input}' çš„å®æ—¶ä¿¡æ¯"
        
        elif task_type == "SYSTEM":
            # ğŸ–¥ï¸ ç³»ç»Ÿå‘½ä»¤ - æœ¬åœ°æ‰§è¡Œ
            print(f"[MINI_CHAT] ğŸ–¥ï¸ æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ï¼š{user_input}")
            try:
                exec_result = LocalExecutor.execute(user_input)
                response_text = exec_result.get("message", "å‘½ä»¤æ‰§è¡Œå¤±è´¥")
                if exec_result.get("details"):
                    response_text += f"\n\n{exec_result['details']}"
                used_model = "LocalExecutor"
                is_error = not exec_result.get("success", False)
                
                # å¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œå°è¯•ç”¨ AI ä¿®æ­£
                if is_error or Utils.is_failure_output(response_text):
                    print(f"[MINI_CHAT] âš ï¸ æœ¬åœ°æ‰§è¡Œå¤±è´¥ï¼Œå°è¯• AI ä¿®æ­£...")
                    fix_prompt = Utils.build_fix_prompt("SYSTEM", user_input, response_text)
                    try:
                        fix_resp = client.models.generate_content(
                            model="gemini-2.0-flash",
                            contents=fix_prompt,
                            config=types.GenerateContentConfig(
                                system_instruction=_get_DEFAULT_CHAT_SYSTEM_INSTRUCTION(),
                                temperature=0.4,
                                max_output_tokens=1000,
                            )
                        )
                        response_text = fix_resp.text or response_text
                        used_model = "gemini-2.0-flash (fallback)"
                        is_error = False
                    except Exception as e:
                        print(f"[MINI_CHAT] AI ä¿®æ­£å¤±è´¥: {e}")
            except Exception as e:
                print(f"[MINI_CHAT] âŒ ç³»ç»Ÿå‘½ä»¤æ‰§è¡Œå‡ºé”™: {e}")
                response_text = f"ç³»ç»Ÿå‘½ä»¤æ‰§è¡Œå‡ºé”™ï¼š{str(e)}"
                used_model = "LocalExecutor"
                is_error = True
        
        else:
            # ğŸ’¬ å…¶ä»–ä»»åŠ¡ï¼ˆCHAT, RESEARCH, CODER ç­‰ï¼‰- ä½¿ç”¨ brain.chat()
            print(f"[MINI_CHAT] ğŸ’¬ æ‰§è¡Œ {task_type} ä»»åŠ¡...")
            model = MODEL_MAP.get(task_type, MODEL_MAP['CHAT'])
            result = brain.chat(history, user_input, model=model, auto_model=False)
            response_text = result.get("response", "")
            used_model = result.get("model", model)
            is_error = response_text.startswith("Error:")
            
            # å¦‚æœé‡åˆ° 404 é”™è¯¯ï¼Œå°è¯•å¤‡ç”¨æ¨¡å‹
            if is_error and "404" in response_text:
                print(f"[MINI_CHAT] âš ï¸ æ¨¡å‹ 404ï¼Œå°è¯•å¤‡ç”¨æ¨¡å‹...")
                for fallback_model in ["gemini-2.0-flash", "gemini-1.5-pro"]:
                    try:
                        result = brain.chat(history, user_input, model=fallback_model, auto_model=False)
                        if not result.get("response", "").startswith("Error:"):
                            response_text = result.get("response", "")
                            used_model = fallback_model
                            is_error = False
                            break
                    except Exception as e:
                        continue
    
    except Exception as e:
        print(f"[MINI_CHAT] âŒ æ‰§è¡Œå‡ºé”™: {e}")
        is_error = True
        response_text = f"Error: {str(e)}"
    
    # æ›´æ–°å†å²ï¼ˆæˆåŠŸå’Œå¤±è´¥éƒ½ä¿å­˜ï¼Œä¾¿äºæ’æŸ¥ï¼‰
    if response_text:
        session_manager.append_and_save(f"{session_name}.json", user_input, response_text)
    
    print(f"[MINI_CHAT] âœ… å®Œæˆ: task_type={task_type}, model={used_model}, success={not is_error}")
    
    # è¿”å›ç»Ÿä¸€æ ¼å¼
    return jsonify({
        "success": not is_error,
        "response": response_text,
        "model": used_model,
        "task_type": task_type,
        "route_method": route_method,
        "error": response_text if is_error else ""
    })

# ================= Setup & Initialization API =================

@app.route('/api/setup/status', methods=['GET'])
def get_setup_status():
    """æ£€æŸ¥é¦–æ¬¡è®¾ç½®çŠ¶æ€"""
    config_path = os.path.join(PROJECT_ROOT, "config", "gemini_config.env")
    has_api_key = bool(API_KEY and len(API_KEY) > 10)
    has_workspace = os.path.exists(WORKSPACE_DIR)
    
    return jsonify({
        "initialized": has_api_key and has_workspace,
        "has_api_key": has_api_key,
        "has_workspace": has_workspace,
        "workspace_path": os.path.abspath(WORKSPACE_DIR),
        "config_path": os.path.abspath(config_path)
    })

@app.route('/api/setup/apikey', methods=['POST'])
def setup_api_key():
    """è®¾ç½® API Key"""
    data = request.json
    api_key = data.get('api_key', '').strip()
    
    if not api_key or len(api_key) < 10:
        return jsonify({"success": False, "error": "Invalid API key"})
    
    config_path = os.path.join(PROJECT_ROOT, "config", "gemini_config.env")
    os.makedirs(os.path.dirname(config_path), exist_ok=True)
    
    try:
        # å†™å…¥é…ç½®æ–‡ä»¶
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(f"# Koto Configuration\nAPI_KEY={api_key}\n")
        
        # æ›´æ–°ç¯å¢ƒå˜é‡
        os.environ['API_KEY'] = api_key
        global API_KEY, client
        API_KEY = api_key
        client = create_client()
        
        return jsonify({"success": True})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})

@app.route('/api/setup/workspace', methods=['POST'])
def setup_workspace():
    """è®¾ç½®å·¥ä½œåŒºç›®å½•"""
    data = request.json
    workspace_path = data.get('path', '').strip()
    
    if not workspace_path:
        workspace_path = os.path.join(PROJECT_ROOT, "workspace")
    
    try:
        os.makedirs(workspace_path, exist_ok=True)
        os.makedirs(os.path.join(workspace_path, "documents"), exist_ok=True)
        os.makedirs(os.path.join(workspace_path, "images"), exist_ok=True)
        os.makedirs(os.path.join(workspace_path, "code"), exist_ok=True)
        
        # æ›´æ–°è®¾ç½®
        settings_manager.set('storage', 'workspace_dir', workspace_path)
        
        return jsonify({"success": True, "path": workspace_path})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})

@app.route('/api/setup/test', methods=['GET'])
def test_api_connection():
    """æµ‹è¯• API è¿æ¥"""
    try:
        start = time.time()
        response = client.models.generate_content(
            model="gemini-3-flash-preview",
            contents="Say 'Koto is ready!' in one short sentence."
        )
        latency = time.time() - start
        return jsonify({
            "success": True,
            "message": response.text,
            "latency": round(latency, 2)
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})

@app.route('/api/diagnose', methods=['GET'])
def diagnose_models():
    """è¯Šæ–­æ‰€æœ‰æ¨¡å‹çš„å¯ç”¨æ€§"""
    import threading
    
    results = {
        "proxy": {
            "detected": get_detected_proxy(),
            "force": FORCE_PROXY or None,
            "custom_endpoint": GEMINI_API_BASE or None
        },
        "models": {}
    }
    
    # æµ‹è¯•æ¨¡å‹åˆ—è¡¨
    test_models = [
        ("gemini-2.0-flash-lite", "è·¯ç”±åˆ†ç±»"),
        ("gemini-3-flash-preview", "æ—¥å¸¸å¯¹è¯"),
        ("gemini-3-pro-preview", "ä»£ç ç”Ÿæˆ"),
        ("gemini-2.5-flash", "è”ç½‘æœç´¢"),
        ("nano-banana-pro-preview", "å›¾åƒç”Ÿæˆ"),
    ]
    
    def test_model(model_id, purpose):
        try:
            start = time.time()
            if "nano-banana" in model_id or "imagen" in model_id:
                # å›¾åƒæ¨¡å‹åªæµ‹è¯•è¿é€šæ€§
                response = client.models.generate_content(
                    model=model_id,
                    contents="test",
                    config=types.GenerateContentConfig(
                        max_output_tokens=10
                    )
                )
            else:
                response = client.models.generate_content(
                    model=model_id,
                    contents="Reply with only: OK",
                    config=types.GenerateContentConfig(
                        max_output_tokens=10
                    )
                )
            latency = time.time() - start
            return {
                "status": "âœ… å¯ç”¨",
                "latency": round(latency, 2),
                "purpose": purpose
            }
        except Exception as e:
            error_msg = str(e)
            if "location is not supported" in error_msg:
                status = "âŒ åœ°åŒºé™åˆ¶"
            elif "not found" in error_msg.lower():
                status = "âŒ æ¨¡å‹ä¸å­˜åœ¨"
            elif "quota" in error_msg.lower():
                status = "âš ï¸ é…é¢è€—å°½"
            elif "timeout" in error_msg.lower():
                status = "âš ï¸ è¶…æ—¶"
            else:
                status = f"âŒ é”™è¯¯"
            return {
                "status": status,
                "error": error_msg[:150],
                "purpose": purpose
            }
    
    # å¹¶è¡Œæµ‹è¯•ï¼ˆå¸¦è¶…æ—¶ï¼‰
    threads = []
    for model_id, purpose in test_models:
        def run_test(m=model_id, p=purpose):
            results["models"][m] = test_model(m, p)
        t = threading.Thread(target=run_test, daemon=True)
        threads.append(t)
        t.start()
    
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆï¼ˆæœ€å¤š 15 ç§’ï¼‰
    for t in threads:
        t.join(timeout=15)
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨
    all_failed = all(
        "âŒ" in results["models"].get(m, {}).get("status", "")
        for m, _ in test_models
    )
    
    if all_failed:
        results["recommendation"] = "æ‰€æœ‰æ¨¡å‹å‡ä¸å¯ç”¨ã€‚å»ºè®®ï¼š\n1. æ£€æŸ¥ä»£ç†é…ç½®æ˜¯å¦æ­£ç¡®\n2. è€ƒè™‘ä½¿ç”¨ API ä¸­è½¬æœåŠ¡\n3. åœ¨ gemini_config.env ä¸­é…ç½® GEMINI_API_BASE"
    
    return jsonify(results)

@app.route('/api/browse', methods=['GET'])
def browse_folders():
    import os
    path = request.args.get('path', 'C:\\')
    
    try:
        if not os.path.exists(path):
            return jsonify({"error": "è·¯å¾„ä¸å­˜åœ¨", "folders": [], "parent": None})
        
        if not os.path.isdir(path):
            return jsonify({"error": "ä¸æ˜¯æ–‡ä»¶å¤¹", "folders": [], "parent": None})
        
        folders = []
        try:
            for item in os.listdir(path):
                item_path = os.path.join(path, item)
                if os.path.isdir(item_path):
                    folders.append({"name": item, "path": item_path})
        except PermissionError:
            return jsonify({"error": "æ²¡æœ‰æƒé™è®¿é—®", "folders": [], "parent": None})
        
        folders.sort(key=lambda x: x['name'].lower())
        
        # Get parent path
        parent = os.path.dirname(path)
        if parent == path:  # Root drive
            parent = None
        
        return jsonify({
            "folders": folders,
            "parent": parent,
            "current": path
        })
    except Exception as e:
        return jsonify({"error": str(e), "folders": [], "parent": None})


@app.route('/api/chat/interrupt', methods=['POST'])
def interrupt_chat():
    """ä¸­æ–­å½“å‰å¯¹è¯ç”Ÿæˆ"""
    payload = request.json or {}
    session_name = payload.get('session')
    task_id = payload.get('task_id')
    if not session_name:
        return jsonify({"error": "Missing session"}), 400
    
    # ä½¿ç”¨æ–°çš„ä¸­æ–­ç®¡ç†å™¨
    _interrupt_manager.set_interrupt(session_name)
    # ä¿æŒå‘åå…¼å®¹
    _interrupt_flags[session_name] = True

    # å¯é€‰ï¼šå¦‚æœå‰ç«¯ä¼ å…¥ task_idï¼ŒåŒæ­¥å–æ¶ˆè°ƒåº¦å™¨ä»»åŠ¡ï¼ˆç”¨äº DOC_ANNOTATE ç­‰æµå¼é•¿ä»»åŠ¡ï¼‰
    if task_id:
        try:
            from task_scheduler import get_task_scheduler
            get_task_scheduler().cancel_task(task_id)
            print(f"[INTERRUPT] Cancel task_id={task_id}")
        except Exception as e:
            print(f"[INTERRUPT] cancel task failed: {e}")
    
    # åŒæ­¥ä¸­æ–­æ ‡å¿—åˆ° AgentLoopï¼ˆå¦‚æœæ­£åœ¨æ‰§è¡Œ Agent ä»»åŠ¡ï¼‰
    # NOTE: Legacy agent_loop retired â€” interrupt handled by _interrupt_manager above
    pass
    
    return jsonify({"success": True, "message": "Chat interrupted"})


@app.route('/api/chat/reset-interrupt', methods=['POST'])
def reset_interrupt():
    """é‡ç½®ä¸­æ–­æ ‡å¿—"""
    session_name = request.json.get('session')
    if session_name:
        # ä½¿ç”¨æ–°çš„ä¸­æ–­ç®¡ç†å™¨
        _interrupt_manager.reset(session_name)
        # ä¿æŒå‘åå…¼å®¹
        if session_name in _interrupt_flags:
            del _interrupt_flags[session_name]
    return jsonify({"success": True})


# ================= æ–°åŠŸèƒ½ API è·¯ç”± =================

# === å¿«é€Ÿç¬”è®° API ===
@app.route('/api/notes/add', methods=['POST'])
def add_note():
    """æ·»åŠ ç¬”è®°"""
    from note_manager import get_note_manager
    
    data = request.json
    title = data.get('title', '')
    content = data.get('content', '')
    category = data.get('category', 'default')
    tags = data.get('tags', [])
    
    note_manager = get_note_manager()
    note_id = note_manager.add_note(title, content, category, tags)
    
    return jsonify({"success": True, "note_id": note_id})


@app.route('/api/notes/list', methods=['GET'])
def list_notes():
    """åˆ—å‡ºæœ€è¿‘ç¬”è®°"""
    from note_manager import get_note_manager
    
    limit = int(request.args.get('limit', 20))
    category = request.args.get('category')
    
    note_manager = get_note_manager()
    notes = note_manager.get_recent_notes(limit, category)
    
    return jsonify({"notes": notes})


@app.route('/api/notes/search', methods=['GET'])
def search_notes():
    """æœç´¢ç¬”è®°"""
    from note_manager import get_note_manager
    
    query = request.args.get('query', '')
    note_manager = get_note_manager()
    results = note_manager.search_notes(query)
    
    return jsonify({"results": results})


@app.route('/api/notes/<note_id>', methods=['DELETE'])
def delete_note(note_id):
    """åˆ é™¤ç¬”è®°"""
    from note_manager import get_note_manager
    
    note_manager = get_note_manager()
    success = note_manager.delete_note(note_id)
    
    return jsonify({"success": success})


# === æœ¬åœ°æé†’ APIï¼ˆWindows ç³»ç»Ÿé€šçŸ¥ï¼‰ ===
@app.route('/api/reminders/add', methods=['POST'])
def add_reminder():
    """åˆ›å»ºæœ¬åœ°ç³»ç»Ÿæé†’
    è¯·æ±‚ä½“: {"title": str, "message": str, "time": ISO8601, "seconds": int}
    - ä¼  time (ISO æ—¶é—´) æˆ– seconds (ç›¸å¯¹ç§’æ•°) ä»»é€‰å…¶ä¸€
    """
    from reminder_manager import get_reminder_manager
    from datetime import datetime

    data = request.json or {}
    title = data.get('title') or 'æé†’'
    message = data.get('message') or ''
    icon = data.get('icon')
    remind_time = data.get('time')
    seconds = data.get('seconds')

    mgr = get_reminder_manager()
    if remind_time:
        try:
            dt = datetime.fromisoformat(remind_time)
        except Exception:
            return jsonify({"success": False, "error": "æ—¶é—´æ ¼å¼éœ€ä¸º ISO8601"}), 400
        rid = mgr.add_reminder(title, message, dt, icon)
    elif seconds is not None:
        try:
            sec = int(seconds)
        except Exception:
            return jsonify({"success": False, "error": "seconds éœ€ä¸ºæ•´æ•°"}), 400
        rid = mgr.add_reminder_in(title, message, sec, icon)
    else:
        return jsonify({"success": False, "error": "éœ€æä¾› time æˆ– seconds"}), 400

    return jsonify({"success": True, "reminder_id": rid})


@app.route('/api/reminders/list', methods=['GET'])
def list_reminders_api():
    """åˆ—å‡ºæ‰€æœ‰æé†’"""
    from reminder_manager import get_reminder_manager
    mgr = get_reminder_manager()
    return jsonify({"reminders": mgr.list_reminders()})


@app.route('/api/reminders/<reminder_id>', methods=['DELETE'])
def cancel_reminder(reminder_id):
    """å–æ¶ˆæé†’"""
    from reminder_manager import get_reminder_manager
    mgr = get_reminder_manager()
    ok = mgr.cancel_reminder(reminder_id)
    return jsonify({"success": ok})


# === æ—¥ç¨‹ï¼ˆæœ¬åœ°æ—¥å†ï¼‰ API ===
@app.route('/api/calendar/add', methods=['POST'])
def add_calendar_event():
    """æ–°å¢æ—¥ç¨‹å¹¶è‡ªåŠ¨åˆ›å»ºæœ¬åœ°æé†’
    è¯·æ±‚ä½“: {"title": str, "description": str, "start": ISO8601, "end": ISO8601?, "remind_before_minutes": int?}
    """
    from calendar_manager import get_calendar_manager
    from datetime import datetime

    data = request.json or {}
    title = data.get('title') or 'æ—¥ç¨‹'
    description = data.get('description') or ''
    start = data.get('start')
    end = data.get('end')
    remind_before_minutes = int(data.get('remind_before_minutes') or 0)

    if not start:
        return jsonify({"success": False, "error": "start ä¸èƒ½ä¸ºç©º (ISO8601)"}), 400
    try:
        start_dt = datetime.fromisoformat(start)
    except Exception:
        return jsonify({"success": False, "error": "start å¿…é¡»æ˜¯ ISO8601 æ—¶é—´"}), 400
    end_dt = None
    if end:
        try:
            end_dt = datetime.fromisoformat(end)
        except Exception:
            return jsonify({"success": False, "error": "end å¿…é¡»æ˜¯ ISO8601 æ—¶é—´"}), 400

    mgr = get_calendar_manager()
    event_id = mgr.add_event(title, description, start_dt, end_dt, remind_before_minutes)
    return jsonify({"success": True, "event_id": event_id})


@app.route('/api/calendar/list', methods=['GET'])
def list_calendar_events():
    from calendar_manager import get_calendar_manager
    limit = int(request.args.get('limit', 100))
    mgr = get_calendar_manager()
    return jsonify({"events": mgr.list_events(limit)})


@app.route('/api/calendar/<event_id>', methods=['DELETE'])
def delete_calendar_event(event_id):
    from calendar_manager import get_calendar_manager
    mgr = get_calendar_manager()
    ok = mgr.delete_event(event_id)
    return jsonify({"success": ok})


# === å‰ªè´´æ¿ API ===
@app.route('/api/clipboard/history', methods=['GET'])
def get_clipboard_history():
    """è·å–å‰ªè´´æ¿å†å²"""
    from clipboard_manager import get_clipboard_manager
    
    limit = int(request.args.get('limit', 50))
    type_filter = request.args.get('type')
    clipboard_manager = get_clipboard_manager()
    history = clipboard_manager.get_history(limit)
    if type_filter:
        history = [item for item in history if item.get('type') == type_filter]
    
    return jsonify({"history": history})


@app.route('/api/clipboard/search', methods=['GET'])
def search_clipboard():
    """æœç´¢å‰ªè´´æ¿å†å²"""
    from clipboard_manager import get_clipboard_manager
    
    query = request.args.get('query', '')
    type_filter = request.args.get('type')
    clipboard_manager = get_clipboard_manager()
    results = clipboard_manager.search(query)
    if type_filter:
        results = [item for item in results if item.get('type') == type_filter]
    
    return jsonify({"results": results})


@app.route('/api/clipboard/copy', methods=['POST'])
def copy_from_history():
    """ä»å†å²ä¸­å¤åˆ¶"""
    from clipboard_manager import get_clipboard_manager
    
    content = request.json.get('content')
    index = request.json.get('index')
    clipboard_manager = get_clipboard_manager()
    if index is not None:
        try:
            index = int(index)
        except Exception:
            return jsonify({"success": False, "error": "index å¿…é¡»æ˜¯æ•´æ•°"}), 400
        success = clipboard_manager.copy_from_history(index)
    else:
        success = clipboard_manager.copy_from_history(content or "")
    
    return jsonify({"success": success})


# === ä»»åŠ¡è°ƒåº¦ API ===
@app.route('/api/tasks/add', methods=['POST'])
def add_task():
    """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
    from task_scheduler import get_task_scheduler, Task, TaskPriority
    
    data = request.json
    task_name = data.get('name', '')
    priority = data.get('priority', 'NORMAL')
    
    # è¿™é‡Œéœ€è¦æ ¹æ®ä»»åŠ¡ç±»å‹åˆ›å»ºç›¸åº”çš„action
    # ç®€åŒ–ç¤ºä¾‹ï¼šåªè®°å½•ä»»åŠ¡ä¿¡æ¯
    def dummy_action():
        print(f"æ‰§è¡Œä»»åŠ¡: {task_name}")
        return {"status": "completed"}
    
    task = Task(
        task_id=f"task_{int(time.time())}",
        name=task_name,
        action=dummy_action,
        priority=TaskPriority[priority]
    )
    
    scheduler = get_task_scheduler()
    task_id = scheduler.add_task(task)
    
    return jsonify({"success": True, "task_id": task_id})


@app.route('/api/tasks/schedule', methods=['POST'])
def schedule_task():
    """è°ƒåº¦å®šæ—¶ä»»åŠ¡"""
    from task_scheduler import get_task_scheduler
    
    data = request.json
    task_name = data.get('name', '')
    schedule_type = data.get('schedule_type', 'daily')
    time_str = data.get('time', '09:00')
    
    def dummy_action():
        print(f"æ‰§è¡Œå®šæ—¶ä»»åŠ¡: {task_name}")
        return {"status": "completed"}
    
    scheduler = get_task_scheduler()
    task_id = scheduler.schedule_task(
        name=task_name,
        action=dummy_action,
        schedule_type=schedule_type,
        time_str=time_str
    )
    
    return jsonify({"success": True, "task_id": task_id})


@app.route('/api/tasks/list', methods=['GET'])
def list_tasks():
    """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡"""
    from task_scheduler import get_task_scheduler, TaskStatus
    
    status = request.args.get('status')
    scheduler = get_task_scheduler()
    
    if status:
        tasks = scheduler.list_tasks(TaskStatus[status])
    else:
        tasks = scheduler.list_tasks()
    
    return jsonify({"tasks": tasks})


@app.route('/api/tasks/<task_id>/cancel', methods=['POST'])
def cancel_task(task_id):
    """å–æ¶ˆä»»åŠ¡"""
    from task_scheduler import get_task_scheduler
    
    scheduler = get_task_scheduler()
    success = scheduler.cancel_task(task_id)
    
    return jsonify({"success": success})


# === é‚®ä»¶ API ===
@app.route('/api/email/accounts', methods=['GET'])
def list_email_accounts():
    """åˆ—å‡ºé‚®ç®±è´¦æˆ·"""
    from email_manager import get_email_manager
    
    email_manager = get_email_manager()
    accounts = list(email_manager.accounts.keys())
    default = email_manager.default_account
    
    return jsonify({"accounts": accounts, "default": default})


@app.route('/api/email/accounts/add', methods=['POST'])
def add_email_account():
    """æ·»åŠ é‚®ç®±è´¦æˆ·"""
    from email_manager import get_email_manager
    
    data = request.json
    email_address = data.get('email')
    password = data.get('password')
    smtp_server = data.get('smtp_server')
    smtp_port = data.get('smtp_port', 587)
    imap_server = data.get('imap_server')
    set_as_default = data.get('set_as_default', False)
    
    email_manager = get_email_manager()
    success = email_manager.add_account(
        email_address=email_address,
        password=password,
        smtp_server=smtp_server,
        smtp_port=smtp_port,
        imap_server=imap_server,
        set_as_default=set_as_default
    )
    
    return jsonify({"success": success})


@app.route('/api/email/send', methods=['POST'])
def send_email():
    """å‘é€é‚®ä»¶"""
    from email_manager import get_email_manager
    
    data = request.json
    to_addrs = data.get('to', [])
    subject = data.get('subject', '')
    body = data.get('body', '')
    cc_addrs = data.get('cc', [])
    attachments = data.get('attachments', [])
    html = data.get('html', False)
    
    email_manager = get_email_manager()
    success = email_manager.send_email(
        to_addrs=to_addrs,
        subject=subject,
        body=body,
        cc_addrs=cc_addrs,
        attachments=attachments,
        html=html
    )
    
    return jsonify({"success": success})


@app.route('/api/email/fetch', methods=['GET'])
def fetch_emails():
    """è·å–é‚®ä»¶åˆ—è¡¨"""
    from email_manager import get_email_manager
    
    folder = request.args.get('folder', 'INBOX')
    limit = int(request.args.get('limit', 20))
    unread_only = request.args.get('unread_only', 'false').lower() == 'true'
    
    email_manager = get_email_manager()
    emails = email_manager.fetch_emails(
        folder=folder,
        limit=limit,
        unread_only=unread_only
    )
    
    return jsonify({"emails": emails})


@app.route('/api/email/search', methods=['GET'])
def search_emails():
    """æœç´¢é‚®ä»¶"""
    from email_manager import get_email_manager
    
    keyword = request.args.get('query', '')
    folder = request.args.get('folder', 'INBOX')
    
    email_manager = get_email_manager()
    results = email_manager.search_emails(keyword, folder=folder)
    
    return jsonify({"results": results})


# === æµè§ˆå™¨è‡ªåŠ¨åŒ– API ===
@app.route('/api/browser/open', methods=['POST'])
def browser_open():
    """æ‰“å¼€ URL"""
    from browser_automation import get_browser_automation
    
    url = request.json.get('url', '')
    browser = get_browser_automation()
    success = browser.open_url(url)
    
    return jsonify({"success": success})


@app.route('/api/browser/search', methods=['POST'])
def browser_search():
    """Google æœç´¢"""
    from browser_automation import get_browser_automation
    
    query = request.json.get('query', '')
    browser = get_browser_automation()
    results = browser.search_google(query)
    
    return jsonify({"results": results})


@app.route('/api/browser/screenshot', methods=['POST'])
def browser_screenshot():
    """æˆªå›¾"""
    from browser_automation import get_browser_automation
    import os
    
    filename = request.json.get('filename', f'screenshot_{int(time.time())}.png')
    file_path = os.path.join(WORKSPACE_DIR, 'images', filename)
    
    browser = get_browser_automation()
    success = browser.take_screenshot(file_path)
    
    return jsonify({"success": success, "path": file_path})


# === æ™ºèƒ½æœç´¢ API ===
@app.route('/api/search/all', methods=['GET'])
def search_all():
    """å…¨å±€æœç´¢"""
    from search_engine import get_search_engine
    
    query = request.args.get('query', '')
    max_results = int(request.args.get('max_results', 50))
    
    search_engine = get_search_engine()
    results = search_engine.search_all(query, max_results)
    
    return jsonify(results)


@app.route('/api/search/files', methods=['GET'])
def search_files():
    """æœç´¢æ–‡ä»¶"""
    from search_engine import get_search_engine
    
    query = request.args.get('query', '')
    max_results = int(request.args.get('max_results', 20))
    
    search_engine = get_search_engine()
    results = search_engine.search_files(query, max_results)
    
    return jsonify({"results": results})


# ================= è¯­éŸ³è¯†åˆ« API (æ–°æ¶æ„) =================
@app.route('/api/voice/engines', methods=['GET'])
def voice_engines():
    """è·å–å¯ç”¨è¯­éŸ³å¼•æ“åˆ—è¡¨"""
    try:
        from web.voice_fast import get_available_engines
        result = get_available_engines()
        return jsonify(result)
    except Exception as e:
        return jsonify({
            "success": False,
            "engines": [],
            "message": f"è·å–å¼•æ“åˆ—è¡¨å¤±è´¥: {str(e)}"
        }), 500

@app.route('/api/voice/record', methods=['POST'])
def voice_record():
    """å½•åˆ¶éŸ³é¢‘"""
    try:
        data = request.json or {}
        duration = data.get('duration', 5)
        
        from web.voice_input import record_audio
        result = record_audio(duration=int(duration))
        
        return jsonify(result)
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"å½•éŸ³å¤±è´¥: {str(e)}",
            "audio_file": None
        }), 500

@app.route('/api/voice/recognize', methods=['POST'])
def voice_recognize():
    """è¯†åˆ«éŸ³é¢‘æ–‡ä»¶"""
    try:
        data = request.json or {}
        audio_path = data.get('audio_path')
        engine = data.get('engine', None)
        
        if not audio_path:
            return jsonify({
                "success": False,
                "message": "ç¼ºå°‘éŸ³é¢‘æ–‡ä»¶è·¯å¾„"
            }), 400
        
        from web.voice_input import recognize_audio
        result = recognize_audio(audio_path, engine)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"è¯†åˆ«å¤±è´¥: {str(e)}"
        }), 500

@app.route('/api/voice/listen', methods=['POST'])
def voice_listen():
    """ä¸€é”®éº¦å…‹é£è¯†åˆ«ï¼ˆæœ¬åœ°æ¨¡å¼ - ä¼˜åŒ–ç‰ˆï¼šç«‹å³å¯åŠ¨ï¼‰"""
    try:
        data = request.json or {}
        timeout = data.get('timeout', 5)
        language = data.get('language', 'zh-CN')
        
        # ä½¿ç”¨å¿«é€Ÿæœ¬åœ°è¯†åˆ«
        from web.voice_fast import recognize_voice
        result = recognize_voice(timeout=int(timeout), language=language)
        
        # ä¼˜åŒ–ï¼šè®¾ç½®å“åº”å¤´åŠ å¿«ä¼ è¾“
        response = jsonify(result)
        response.headers['Cache-Control'] = 'no-cache, no-store'
        response.headers['Content-Type'] = 'application/json; charset=utf-8'
        return response
            
    except Exception as e:
        import traceback
        traceback.print_exc()
        response = jsonify({
            "success": False,
            "text": "",
            "message": f"è¯­éŸ³è¯†åˆ«å‡ºé”™: {str(e)}",
            "engine": "error"
        })
        response.status_code = 500
        response.headers['Cache-Control'] = 'no-cache'
        return response


@app.route('/api/voice/stream')
def voice_stream():
    """æµå¼è¯­éŸ³è¯†åˆ« - å®æ—¶è¿”å›è¯†åˆ«ç»“æœï¼ˆSSEï¼‰"""
    from flask import Response
    
    def generate():
        try:
            from web.voice_fast import recognize_streaming
            
            for result in recognize_streaming(timeout=12):
                # å‘é€ SSE æ ¼å¼æ•°æ®
                import json
                yield f"data: {json.dumps(result, ensure_ascii=False)}\n\n"
                
                # å¦‚æœæ˜¯æœ€ç»ˆç»“æœæˆ–é”™è¯¯ï¼Œç»“æŸæµ
                if result.get('type') in ('final', 'error'):
                    break
                    
        except Exception as e:
            import json
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"
    
    return Response(
        generate(),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'X-Accel-Buffering': 'no'
        }
    )


# å…¨å±€å˜é‡ï¼šæ§åˆ¶è¯­éŸ³è¯†åˆ«åœæ­¢
_voice_stop_flag = False

@app.route('/api/voice/stop', methods=['POST'])
def voice_stop():
    """åœæ­¢è¯­éŸ³è¯†åˆ«"""
    global _voice_stop_flag
    _voice_stop_flag = True
    return jsonify({"success": True, "message": "å·²å‘é€åœæ­¢ä¿¡å·"})


# ================= å¢å¼ºåŠŸèƒ½ API (åœºæ™¯1-3) =================

@app.route('/api/data/extract-transform', methods=['POST'])
def data_extract_transform():
    """æ•°æ®æå–ä¸è½¬æ¢ - åœºæ™¯1ï¼šè·¨åº”ç”¨æ•°æ®æ¬è¿"""
    try:
        data = request.json
        source_type = data.get('source_type', 'wechat_contact')
        source_data = data.get('source_data')
        target_format = data.get('target_format', 'excel')
        output_filename = data.get('output_filename', f'æå–æ•°æ®_{datetime.now().strftime("%Y%m%d_%H%M%S")}')
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if target_format == 'excel':
            ext = '.xlsx'
        elif target_format == 'csv':
            ext = '.csv'
        else:
            ext = '.json'
        
        output_path = os.path.join(WORKSPACE_DIR, 'documents', f'{output_filename}{ext}')
        
        # æ‰§è¡Œæ•°æ®ç®¡é“
        from web.data_pipeline import CrossAppDataPipeline
        pipeline = CrossAppDataPipeline()
        result = pipeline.run_pipeline(source_type, source_data, target_format, output_path)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/code/generate', methods=['POST'])
def code_generate():
    """ä»£ç ç”Ÿæˆ - åœºæ™¯2ï¼šå¸®åŠ©ç”¨æˆ·å®Œæˆç¼–ç¨‹ä»»åŠ¡"""
    try:
        data = request.json
        template_name = data.get('template_name')
        description = data.get('description')
        language = data.get('language', 'python')
        output_filename = data.get('output_filename')
        
        from web.code_generator import CodeGenerator
        generator = CodeGenerator()
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        output_path = None
        if output_filename:
            output_path = os.path.join(WORKSPACE_DIR, 'code', output_filename)
        
        # ç”Ÿæˆä»£ç 
        if template_name:
            result = generator.generate(template_name, output_path, **data.get('params', {}))
        elif description:
            # ä½¿ç”¨AIç”Ÿæˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
            result = generator.generate_from_description(description, language)
        else:
            return jsonify({
                "success": False,
                "error": "éœ€è¦æä¾›template_nameæˆ–description"
            }), 400
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/code/templates', methods=['GET'])
def code_templates():
    """è·å–å¯ç”¨ä»£ç æ¨¡æ¿åˆ—è¡¨"""
    try:
        from web.code_generator import CodeGenerator
        generator = CodeGenerator()
        
        language = request.args.get('language')
        templates = generator.list_templates(language)
        
        return jsonify({
            "success": True,
            "templates": templates,
            "count": len(templates)
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/ppt/generate', methods=['POST'])
def ppt_generate():
    """PPTç”Ÿæˆ - åœºæ™¯3ï¼šé«˜è´¨é‡æ¼”ç¤ºæ–‡ç¨¿"""
    try:
        data = request.json
        title = data.get('title', 'æ¼”ç¤ºæ–‡ç¨¿')
        subtitle = data.get('subtitle', '')
        outline = data.get('outline')
        content = data.get('content')
        theme = data.get('theme', 'business')
        output_filename = data.get('output_filename', f'{title}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.pptx')
        
        output_path = os.path.join(WORKSPACE_DIR, 'documents', output_filename)
        
        from web.ppt_generator import PPTGenerator
        generator = PPTGenerator(theme=theme)
        
        # ç”ŸæˆPPT
        if outline:
            result = generator.generate_from_outline(title, outline, output_path, subtitle=subtitle)
        elif content:
            result = generator.generate_from_text(content, output_path, title)
        else:
            return jsonify({
                "success": False,
                "error": "éœ€è¦æä¾›outlineæˆ–content"
            }), 400
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500



# ==================== æ™ºèƒ½æ–‡æ¡£å¤„ç†è·¯ç”± ====================

def _should_use_annotation_system(requirement: str, has_file: bool = False) -> bool:
    """
    ä¸¥æ ¼åˆ¤æ–­æ˜¯å¦ä½¿ç”¨æ–‡æ¡£æ ‡æ³¨ç³»ç»Ÿï¼ˆåœ¨åŸæ–‡ä¸Šæ ‡çº¢ä¿®æ”¹ï¼‰
    
    æ ‡æ³¨ç³»ç»Ÿä»…é€‚ç”¨äºï¼šç”¨æˆ·æ˜ç¡®è¦æ±‚åœ¨åŸæ–‡ä¸Šåšæ ‡è®°/æ‰¹æ³¨/æ ‡çº¢/Track Changes
    
    æ³¨æ„ï¼š"ä¿®æ”¹"ã€"ä¼˜åŒ–"ã€"æ”¹å–„"ç­‰è¯å¤ªå®½æ³›ï¼Œä¸èƒ½å•ç‹¬è§¦å‘æ ‡æ³¨ã€‚
    åªæœ‰ä¸"åœ¨åŸæ–‡ä¸Š"ã€"æ ‡å‡ºæ¥"ã€"æ ‡çº¢"ç­‰å®šä½è¯ç»„åˆæ‰è§¦å‘ã€‚
    """
    if not requirement:
        return False
    
    requirement_lower = requirement.lower()
    
    # ç¬¬ä¸€å±‚ï¼šæ˜ç¡®çš„æ ‡æ³¨/æ‰¹æ³¨å…³é”®è¯ â€” ç›´æ¥è§¦å‘
    explicit_annotation = ['æ ‡æ³¨', 'æ ‡è®°', 'æ‰¹æ³¨', 'æ ‡å‡º', 'æ ‡çº¢', 'track changes', 'æ‰¹æ”¹']
    if any(kw in requirement_lower for kw in explicit_annotation):
        return True
    
    # ç¬¬äºŒå±‚ï¼šç¼–è¾‘æ„å›¾ + å®šä½è¯ç»„åˆæ‰è§¦å‘
    # "ä¿®æ”¹"å•ç‹¬å‡ºç° â‰  æ ‡æ³¨ï¼Œ"ä¿®æ”¹+æ ‡å‡ºæ¥" = æ ‡æ³¨
    edit_words = ['ä¿®æ”¹', 'æ”¹æ­£', 'çº æ­£', 'æ ¡å¯¹', 'å®¡æ ¡', 'çº é”™']
    location_words = ['åœ¨åŸæ–‡', 'åŸæ–‡ä¸Š', 'æ ‡å‡º', 'æ ‡è®°å‡º', 'æŒ‡å‡º.*ä½ç½®', 'å“ªäº›åœ°æ–¹', 'å“ªäº›ä½ç½®']
    has_edit = any(kw in requirement_lower for kw in edit_words)
    has_location = any(re.search(kw, requirement_lower) for kw in location_words)
    
    if has_edit and has_location:
        return True
    
    # ç¬¬ä¸‰å±‚ï¼šå®¡æŸ¥/ä¿®æ”¹+è´¨é‡æè¿°ç»„åˆ
    review_words = ['å®¡æŸ¥', 'è¯„å®¡', 'å®¡æ ¸', 'æ”¹å–„', 'ä¼˜åŒ–', 'ä¿®æ”¹', 'æ¶¦è‰²', 'è°ƒæ•´']
    quality_words = ['ä¸åˆé€‚', 'ç”Ÿç¡¬', 'ç¿»è¯‘è…”', 'è¯­åº', 'ç”¨è¯', 'é€»è¾‘', 'é—®é¢˜']
    has_review = any(kw in requirement_lower for kw in review_words)
    has_quality = any(kw in requirement_lower for kw in quality_words)
    
    if has_review and has_quality:
        return True
    
    # é»˜è®¤ä¸è§¦å‘ â€” å®å¯æ¼åˆ¤ä¹Ÿä¸è¯¯åˆ¤
    return False


def _is_analysis_request(requirement: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºçº¯åˆ†æ/ç ”ç©¶ç±»è¯·æ±‚ï¼ˆåªè¯»åˆ†æï¼Œä¸ç”Ÿæˆæ–°å†…å®¹ï¼‰"""
    if not requirement:
        return False

    requirement_lower = requirement.lower()
    
    # æ˜ç¡®çš„åˆ†æåŠ¨ä½œè¯
    analysis_actions = [
        "åˆ†æ", "æ€»ç»“", "æ¦‚è¿°", "æ¢³ç†", "è§£è¯»",
        "è¯„ä¼°", "å¯¹æ¯”", "æç‚¼", "å½’çº³",
        "ä¸»è¦è§‚ç‚¹", "æ ¸å¿ƒè§‚ç‚¹", "è¦ç‚¹",
        "review", "analysis", "summary", "summarize"
    ]
    
    # æ’é™¤è¯ï¼šå¦‚æœåŒæ—¶åŒ…å«ç”Ÿæˆ/å†™/æ”¹å–„æ„å›¾ï¼Œè¿™ä¸æ˜¯çº¯åˆ†æ
    generation_words = [
        'å†™', 'ç”Ÿæˆ', 'æ”¹å–„', 'æ”¹è¿›', 'ä¼˜åŒ–', 'æ¶¦è‰²',
        'é‡å†™', 'æ‘˜è¦', 'å¼•è¨€', 'ç»“è®º', 'å¸®æˆ‘åš'
    ]
    
    has_analysis = any(kw in requirement_lower for kw in analysis_actions)
    has_generation = any(kw in requirement_lower for kw in generation_words)
    
    # åªæœ‰çº¯åˆ†æï¼ˆæ— ç”Ÿæˆæ„å›¾ï¼‰æ‰è¿”å›True
    if has_analysis and not has_generation:
        return True
    
    return False


@app.route('/api/document/smart-process', methods=['POST'])
def document_smart_process():
    """
    æ™ºèƒ½æ–‡æ¡£å¤„ç†å…¥å£
    è‡ªåŠ¨åˆ¤æ–­ä½¿ç”¨ï¼šæ ‡æ³¨ç³»ç»Ÿ or æ–‡ä»¶åˆ†æç³»ç»Ÿ
    """
    try:
        data = request.json
        file_path = data.get('file_path')
        requirement = data.get('requirement', '')
        
        if not file_path:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘file_pathå‚æ•°"
            }), 400
        
        # æ™ºèƒ½åˆ¤æ–­åº”è¯¥ç”¨å“ªä¸ªç³»ç»Ÿ
        use_annotation = _should_use_annotation_system(requirement)
        
        print(f"[SmartProcess] æ™ºèƒ½åˆ¤æ–­: use_annotation={use_annotation}")
        print(f"[SmartProcess] éœ€æ±‚: {requirement[:100]}")
        
        if use_annotation:
            # ä½¿ç”¨æ–‡æ¡£æ ‡æ³¨ç³»ç»Ÿ
            print(f"[SmartProcess] è·¯ç”±åˆ°: æ–‡æ¡£è‡ªåŠ¨æ ‡æ³¨ç³»ç»Ÿ")
            return _call_document_annotate(file_path, requirement)
        else:
            # ä½¿ç”¨ä¼ ç»Ÿçš„æ–‡ä»¶åˆ†æç³»ç»Ÿ
            print(f"[SmartProcess] è·¯ç”±åˆ°: æ–‡ä»¶åˆ†æç³»ç»Ÿ")
            return _call_document_analysis(file_path, requirement)
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


def _call_document_annotate(file_path: str, requirement: str):
    """è°ƒç”¨æ–‡æ¡£æ ‡æ³¨ç³»ç»Ÿ"""
    try:
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(file_path):
            file_path = os.path.join(WORKSPACE_DIR, 'documents', file_path)
        
        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }), 404
        
        from web.document_feedback import DocumentFeedbackSystem
        feedback_system = DocumentFeedbackSystem(gemini_client=client)
        
        result = feedback_system.full_annotation_loop(
            file_path=file_path,
            user_requirement=requirement,
            model_id="gemini-3-pro-preview"
        )
        
        # æ·»åŠ å¤„ç†æ¨¡å¼æ ‡è®°
        result['processing_mode'] = 'annotation'
        result['mode_description'] = 'æ–‡æ¡£è‡ªåŠ¨æ ‡æ³¨'
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e),
            "processing_mode": "annotation"
        }), 500


def _call_document_analysis(file_path: str, requirement: str):
    """è°ƒç”¨ä¼ ç»Ÿçš„æ–‡ä»¶åˆ†æç³»ç»Ÿ"""
    try:
        # è¿™é‡Œè°ƒç”¨ç°æœ‰çš„æ–‡ä»¶åˆ†æé€»è¾‘
        # ä¸´æ—¶è¿”å›è¯´æ˜ï¼ˆå®é™…åº”è¯¥è°ƒç”¨ç°æœ‰çš„åˆ†æç«¯ç‚¹ï¼‰
        return jsonify({
            "success": False,
            "error": "æ–‡ä»¶åˆ†æç³»ç»Ÿéœ€è¦å•ç‹¬å®ç°",
            "processing_mode": "analysis",
            "mode_description": "æ–‡ä»¶åˆ†æ"
        }), 501
    
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e),
            "processing_mode": "analysis"
        }), 500


@app.route('/api/document/feedback', methods=['POST'])
def document_feedback():
    """æ–‡æ¡£æ™ºèƒ½åé¦ˆï¼šè¯»å–æ–‡æ¡£ â†’ AIåˆ†æ â†’ åº”ç”¨ä¿®æ”¹"""
    try:
        data = request.json
        file_path = data.get('file_path')
        user_requirement = data.get('requirement', '')
        auto_apply = data.get('auto_apply', True)
        
        if not file_path:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘file_pathå‚æ•°"
            }), 400
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(file_path):
            file_path = os.path.join(WORKSPACE_DIR, 'documents', file_path)
        
        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }), 404
        
        # åˆå§‹åŒ–åé¦ˆç³»ç»Ÿ
        from web.document_feedback import DocumentFeedbackSystem
        feedback_system = DocumentFeedbackSystem(gemini_client=client)
        
        # æ‰§è¡Œå®Œæ•´åé¦ˆé—­ç¯
        result = feedback_system.full_feedback_loop(
            file_path=file_path,
            user_requirement=user_requirement,
            auto_apply=auto_apply
        )
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/document/analyze', methods=['POST'])
def document_analyze():
    """ä»…åˆ†ææ–‡æ¡£ï¼Œä¸åº”ç”¨ä¿®æ”¹"""
    try:
        data = request.json
        file_path = data.get('file_path')
        user_requirement = data.get('requirement', '')
        
        if not file_path:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘file_pathå‚æ•°"
            }), 400
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(file_path):
            file_path = os.path.join(WORKSPACE_DIR, 'documents', file_path)
        
        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }), 404
        
        # åˆå§‹åŒ–åé¦ˆç³»ç»Ÿ
        from web.document_feedback import DocumentFeedbackSystem
        feedback_system = DocumentFeedbackSystem(gemini_client=client)
        
        # ä»…åˆ†æ
        result = feedback_system.analyze_and_suggest(
            file_path=file_path,
            user_requirement=user_requirement
        )
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/document/apply', methods=['POST'])
def document_apply():
    """åº”ç”¨ä¿®æ”¹å»ºè®®åˆ°æ–‡æ¡£"""
    try:
        data = request.json
        file_path = data.get('file_path')
        modifications = data.get('modifications', [])
        
        if not file_path or not modifications:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘file_pathæˆ–modificationså‚æ•°"
            }), 400
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(file_path):
            file_path = os.path.join(WORKSPACE_DIR, 'documents', file_path)
        
        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }), 404
        
        # åº”ç”¨ä¿®æ”¹
        from web.document_feedback import DocumentFeedbackSystem
        feedback_system = DocumentFeedbackSystem(gemini_client=client)
        
        result = feedback_system.apply_suggestions(
            file_path=file_path,
            modifications=modifications
        )
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/document/annotate', methods=['POST'])
def document_annotate():
    """æ–‡æ¡£è‡ªåŠ¨æ ‡æ³¨ï¼šAIåˆ†æ -> ç”Ÿæˆæ ‡æ³¨ -> åº”ç”¨åˆ°å‰¯æœ¬"""
    try:
        data = request.json
        file_path = data.get('file_path')
        user_requirement = data.get('requirement', '')
        model_id = data.get('model_id', 'gemini-3-pro-preview')
        
        if not file_path:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘file_pathå‚æ•°"
            }), 400
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(file_path):
            file_path = os.path.join(WORKSPACE_DIR, 'documents', file_path)
        
        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }), 404
        
        # åˆå§‹åŒ–åé¦ˆç³»ç»Ÿ
        from web.document_feedback import DocumentFeedbackSystem
        feedback_system = DocumentFeedbackSystem(gemini_client=client)
        
        # æ‰§è¡Œå®Œæ•´æ ‡æ³¨é—­ç¯
        result = feedback_system.full_annotation_loop(
            file_path=file_path,
            user_requirement=user_requirement,
            model_id=model_id
        )
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/document/analyze-annotations', methods=['POST'])
def document_analyze_annotations():
    """ä»…åˆ†ææ–‡æ¡£å¹¶ç”Ÿæˆæ ‡æ³¨å»ºè®®ï¼ˆä¸åº”ç”¨ï¼‰- å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ /api/document/batch-annotate-stream"""
    try:
        data = request.json
        file_path = data.get('file_path')
        user_requirement = data.get('requirement', '')
        
        if not file_path:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘file_pathå‚æ•°"
            }), 400
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(file_path):
            file_path = os.path.join(WORKSPACE_DIR, 'documents', file_path)
        
        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }), 404
        
        # ä½¿ç”¨V2æ‰¹é‡æ ‡æ³¨ç³»ç»Ÿï¼ˆç«‹å³è¿”å›ç»“æœï¼Œä¸æµå¼ï¼‰
        from web.document_direct_edit import ImprovedBatchAnnotator
        annotator = ImprovedBatchAnnotator(gemini_client=client, batch_size=5)
        
        # æ”¶é›†æ‰€æœ‰äº‹ä»¶ï¼ˆéæµå¼ï¼‰
        events = []
        final_result = None
        
        for event in annotator.annotate_document_streaming(file_path, user_requirement):
            # è§£æäº‹ä»¶
            if event.startswith("event: complete"):
                data_line = event.split("\n")[1]
                if data_line.startswith("data: "):
                    final_result = json.loads(data_line[6:])
            events.append(event)
        
        if final_result:
            return jsonify({
                "success": True,
                **final_result
            })
        else:
            return jsonify({
                "success": False,
                "error": "å¤„ç†å¤±è´¥ï¼Œæœªæ”¶åˆ°å®Œæˆäº‹ä»¶"
            }), 500
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/document/batch-annotate-stream', methods=['POST'])
def document_batch_annotate_stream():
    """
    æ‰¹é‡æ ‡æ³¨æ–‡æ¡£ï¼ˆSSEæµå¼è¿”å›ï¼Œå®æ—¶åé¦ˆè¿›åº¦ï¼‰
    
    æ¥æ”¶å‚æ•°:
        file_path: æ–‡æ¡£è·¯å¾„
        requirement: ç”¨æˆ·éœ€æ±‚ï¼ˆå¯é€‰ï¼‰
        batch_size: æ¯æ‰¹å¤„ç†æ®µè½æ•°ï¼ˆé»˜è®¤5ï¼‰
    
    è¿”å›: SSEäº‹ä»¶æµ
        event: progress - è¿›åº¦æ›´æ–°
        event: batch_complete - æ‰¹æ¬¡å®Œæˆ
        event: complete - å…¨éƒ¨å®Œæˆ
        event: error - é”™è¯¯
    """
    try:
        data = request.json
        file_path = data.get('file_path')
        user_requirement = data.get('requirement', '')
        batch_size = data.get('batch_size', 5)
        
        if not file_path:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘file_pathå‚æ•°"
            }), 400
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(file_path):
            file_path = os.path.join(WORKSPACE_DIR, 'documents', file_path)
        
        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }), 404
        
        # å¯¼å…¥V2æ‰¹é‡æ ‡æ³¨ç³»ç»Ÿ
        from web.document_batch_annotator_v2 import annotate_large_document
        
        # è¿”å›SSEæµ
        return Response(
            annotate_large_document(
                file_path=file_path,
                user_requirement=user_requirement,
                gemini_client=client,
                batch_size=batch_size
            ),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no',
                'Connection': 'keep-alive'
            }
        )
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/document/apply-annotations', methods=['POST'])
def document_apply_annotations():
    """åº”ç”¨æ ‡æ³¨å»ºè®®åˆ°æ–‡æ¡£"""
    try:
        data = request.json
        file_path = data.get('file_path')
        annotations = data.get('annotations', [])
        
        if not file_path or not annotations:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘file_pathæˆ–annotationså‚æ•°"
            }), 400
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(file_path):
            file_path = os.path.join(WORKSPACE_DIR, 'documents', file_path)
        
        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }), 404
        
        # åº”ç”¨æ ‡æ³¨
        from web.document_feedback import DocumentFeedbackSystem
        feedback_system = DocumentFeedbackSystem(gemini_client=client)
        
        result = feedback_system.annotate_document(file_path, annotations)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


# ==================== æ–°åŠŸèƒ½ API è·¯ç”± ====================

# ==================== æ”¹è¿›çš„å»ºè®®å¼æ ‡æ³¨ API ====================

@app.route('/api/document/suggest-stream', methods=['POST'])
def document_suggest_stream():
    """
    ç”Ÿæˆä¿®æ”¹å»ºè®®æµï¼ˆSSEï¼‰
    
    è¯·æ±‚å‚æ•°:
        file_path: æ–‡æ¡£è·¯å¾„
        requirement: ç”¨æˆ·éœ€æ±‚ï¼ˆå¯é€‰ï¼‰
    
    è¿”å›: SSEäº‹ä»¶æµ
        event: progress - è¿›åº¦
        event: suggestion - å•ä¸ªå»ºè®®
        event: suggestions_complete - æ‰€æœ‰å»ºè®®å®Œæˆ
        event: complete - å®Œæˆ
    """
    try:
        data = request.json
        file_path = data.get('file_path')
        user_requirement = data.get('requirement', '')
        
        if not file_path:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘file_pathå‚æ•°"
            }), 400
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(file_path):
            file_path = os.path.join(WORKSPACE_DIR, 'documents', file_path)
        
        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }), 404
        
        # ä½¿ç”¨å»ºè®®å¼æ ‡æ³¨å™¨
        from web.suggestion_annotator import SuggestionAnnotator
        annotator = SuggestionAnnotator(batch_size=3)
        
        # è¿”å›SSEæµ
        return Response(
            annotator.analyze_document_streaming(file_path, user_requirement),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no',
                'Connection': 'keep-alive'
            }
        )
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/document/apply-suggestions', methods=['POST'])
def document_apply_suggestions():
    """
    æ ¹æ®ç”¨æˆ·é€‰æ‹©åº”ç”¨ä¿®æ”¹å»ºè®®
    
    è¯·æ±‚å‚æ•°:
        file_path: åŸå§‹æ–‡æ¡£è·¯å¾„
        suggestions: ç”¨æˆ·çš„é€‰æ‹©åˆ—è¡¨
            [
                {
                    "id": "s_5_0",
                    "åŸæ–‡": "åœ¨è¢«è®°å½•çš„",
                    "ä¿®æ”¹": "åœ¨è®°å½•çš„",
                    "æ¥å—": True/False
                },
                ...
            ]
    
    è¿”å›:
        {
            "success": True,
            "output_file": "ä¿®æ”¹åçš„æ–‡ä»¶è·¯å¾„",
            "applied_count": å®é™…åº”ç”¨çš„ä¿®æ”¹æ•°,
            "accepted_count": ç”¨æˆ·æ¥å—çš„æ•°é‡
        }
    """
    try:
        from docx import Document
        
        data = request.json
        file_path = data.get('file_path')
        suggestions = data.get('suggestions', [])
        
        if not file_path:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘file_pathå‚æ•°"
            }), 400
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(file_path):
            file_path = os.path.join(WORKSPACE_DIR, 'documents', file_path)
        
        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
            }), 404
        
        # è¯»å–æ–‡æ¡£
        doc = Document(file_path)
        
        # ç­›é€‰ç”¨æˆ·æ¥å—çš„å»ºè®®
        accepted_suggestions = [s for s in suggestions if s.get("æ¥å—", False)]
        
        applied_count = 0
        
        # åº”ç”¨ä¿®æ”¹ï¼ˆç›´æ¥åœ¨æ®µè½ä¸­æŸ¥æ‰¾å¹¶æ›¿æ¢ï¼‰
        for suggestion in accepted_suggestions:
            original = suggestion.get("åŸæ–‡", "")
            modified = suggestion.get("ä¿®æ”¹", "")
            
            if not original or not modified:
                continue
            
            # åœ¨æ‰€æœ‰æ®µè½ä¸­æŸ¥æ‰¾å¹¶æ›¿æ¢
            for para in doc.paragraphs:
                if original in para.text:
                    # æ›¿æ¢æ–‡æœ¬
                    full_text = para.text
                    new_text = full_text.replace(original, modified, 1)
                    
                    if new_text != full_text:
                        # æ¸…ç©ºå¹¶é‡æ–°æ·»åŠ ï¼ˆä¿ç•™æ ¼å¼ï¼‰
                        para.clear()
                        para.add_run(new_text)
                        applied_count += 1
                        break  # æ¯ä¸ªå»ºè®®åªåº”ç”¨ä¸€æ¬¡
            
            # æ£€æŸ¥è¡¨æ ¼ä¸­çš„æ–‡æœ¬
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for para in cell.paragraphs:
                            if original in para.text:
                                full_text = para.text
                                new_text = full_text.replace(original, modified, 1)
                                if new_text != full_text:
                                    para.clear()
                                    para.add_run(new_text)
                                    applied_count += 1
        
        # ä¿å­˜ä¸ºæ–°æ–‡ä»¶
        base_name = os.path.splitext(file_path)[0]
        output_path = f"{base_name}_accepted.docx"
        doc.save(output_path)
        
        return jsonify({
            "success": True,
            "output_file": output_path,
            "applied_count": applied_count,
            "accepted_count": len(accepted_suggestions),
            "message": f"å·²åº”ç”¨ {applied_count} å¤„ä¿®æ”¹ï¼ˆç”¨æˆ·æ¥å—äº† {len(accepted_suggestions)} ä¸ªå»ºè®®ï¼‰"
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


# çŸ¥è¯†åº“ API
@app.route('/api/knowledge-base/add', methods=['POST'])
def kb_add_document():
    """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
    try:
        from web.knowledge_base import KnowledgeBase
        
        data = request.json
        file_path = data.get('file_path')
        
        if not file_path:
            return jsonify({"success": False, "error": "ç¼ºå°‘file_pathå‚æ•°"}), 400
        
        kb = KnowledgeBase()
        result = kb.add_document(file_path)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/knowledge-base/search', methods=['POST'])
def kb_search():
    """æœç´¢çŸ¥è¯†åº“"""
    try:
        from web.knowledge_base import KnowledgeBase
        
        data = request.json
        query = data.get('query')
        max_results = data.get('max_results', 10)
        
        if not query:
            return jsonify({"success": False, "error": "ç¼ºå°‘queryå‚æ•°"}), 400
        
        kb = KnowledgeBase()
        results = kb.search(query, max_results=max_results)
        
        return jsonify({"success": True, "results": results})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/knowledge-base/stats', methods=['GET'])
def kb_stats():
    """è·å–çŸ¥è¯†åº“ç»Ÿè®¡"""
    try:
        from web.knowledge_base import KnowledgeBase
        
        kb = KnowledgeBase()
        stats = kb.get_stats()
        
        return jsonify({"success": True, "stats": stats})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


# ==================== æ–‡ä»¶ç½‘ç»œç´¢å¼• API ====================

@app.route('/api/file-network/search', methods=['POST'])
def file_network_search():
    """å¤šç»´æŸ¥è¯¢æ–‡ä»¶
    
    è¯·æ±‚å‚æ•°:
        query: æ–‡æœ¬æœç´¢æŸ¥è¯¢ï¼ˆå¯é€‰ï¼‰
        file_type: æ–‡ä»¶ç±»å‹ï¼ˆdocx, pdfç­‰ï¼Œå¯é€‰ï¼‰
        tags: æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        operation: å¤„ç†æ“ä½œï¼ˆannotate, editç­‰ï¼Œå¯é€‰ï¼‰
        date_from: å¼€å§‹æ—¥æœŸï¼ˆISOæ ¼å¼ï¼Œå¯é€‰ï¼‰
        date_to: ç»“æŸæ—¥æœŸï¼ˆISOæ ¼å¼ï¼Œå¯é€‰ï¼‰
        limit: è¿”å›æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤50ï¼‰
    """
    try:
        from web.processed_file_network import get_file_network
        
        data = request.json or {}
        file_network = get_file_network()
        
        result = file_network.search_files(
            query=data.get('query'),
            file_type=data.get('file_type'),
            tags=data.get('tags'),
            operation=data.get('operation'),
            date_from=data.get('date_from'),
            date_to=data.get('date_to'),
            limit=data.get('limit', 50)
        )
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/file-network/open', methods=['POST'])
def file_network_open():
    """å¿«é€Ÿæ‰“å¼€æ–‡ä»¶
    
    è¯·æ±‚å‚æ•°:
        file_id: æ–‡ä»¶ID
    """
    try:
        from web.processed_file_network import get_file_network
        
        data = request.json
        file_id = data.get('file_id')
        
        if not file_id:
            return jsonify({"success": False, "error": "ç¼ºå°‘file_idå‚æ•°"}), 400
        
        file_network = get_file_network()
        result = file_network.open_file(file_id)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/file-network/network', methods=['POST'])
def file_network_get_network():
    """è·å–æ–‡ä»¶å…³ç³»ç½‘ç»œ
    
    è¯·æ±‚å‚æ•°:
        file_id: æ–‡ä»¶ID
        depth: å…³ç³»æ·±åº¦ï¼ˆ1=ç›´æ¥å…³ç³»ï¼Œ2=äºŒçº§å…³ç³»ï¼Œé»˜è®¤2ï¼‰
    """
    try:
        from web.processed_file_network import get_file_network
        
        data = request.json
        file_id = data.get('file_id')
        depth = data.get('depth', 2)
        
        if not file_id:
            return jsonify({"success": False, "error": "ç¼ºå°‘file_idå‚æ•°"}), 400
        
        file_network = get_file_network()
        result = file_network.get_file_network(file_id, depth)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/file-network/statistics', methods=['GET'])
def file_network_statistics():
    """è·å–æ–‡ä»¶ç½‘ç»œç»Ÿè®¡ä¿¡æ¯"""
    try:
        from web.processed_file_network import get_file_network
        
        file_network = get_file_network()
        result = file_network.get_statistics()
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/file-network/register', methods=['POST'])
def file_network_register():
    """æ‰‹åŠ¨æ³¨å†Œæ–‡ä»¶åˆ°ç½‘ç»œ
    
    è¯·æ±‚å‚æ•°:
        file_path: æ–‡ä»¶è·¯å¾„
        tags: æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        extract_snippets: æ˜¯å¦æå–æ–‡æœ¬ç‰‡æ®µï¼ˆé»˜è®¤trueï¼‰
    """
    try:
        from web.processed_file_network import get_file_network
        
        data = request.json
        file_path = data.get('file_path')
        
        if not file_path:
            return jsonify({"success": False, "error": "ç¼ºå°‘file_pathå‚æ•°"}), 400
        
        file_network = get_file_network()
        result = file_network.register_file(
            file_path=file_path,
            tags=data.get('tags'),
            extract_snippets=data.get('extract_snippets', True)
        )
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


# æ‰¹é‡å¤„ç† API
@app.route('/api/batch/rename', methods=['POST'])
def batch_rename():
    """æ‰¹é‡é‡å‘½åæ–‡ä»¶"""
    try:
        from web.batch_processor import BatchFileProcessor
        
        data = request.json
        directory = data.get('directory')
        pattern = data.get('pattern')
        
        processor = BatchFileProcessor()
        result = processor.batch_rename(directory, **pattern)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/batch/convert', methods=['POST'])
def batch_convert():
    """æ‰¹é‡æ ¼å¼è½¬æ¢"""
    try:
        from web.batch_processor import BatchFileProcessor
        
        data = request.json
        directory = data.get('directory')
        from_format = data.get('from_format')
        to_format = data.get('to_format')
        
        processor = BatchFileProcessor()
        result = processor.batch_convert(directory, from_format, to_format)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


# æ¨¡æ¿åº“ API
@app.route('/api/template/list', methods=['GET'])
def template_list():
    """è·å–æ¨¡æ¿åˆ—è¡¨"""
    try:
        from web.template_library import TemplateLibrary
        
        library = TemplateLibrary()
        templates = library.list_templates()
        
        return jsonify({"success": True, "templates": templates})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/template/generate', methods=['POST'])
def template_generate():
    """ä»æ¨¡æ¿ç”Ÿæˆæ–‡æ¡£"""
    try:
        from web.template_library import TemplateLibrary
        
        data = request.json
        template_name = data.get('template_id') or data.get('template_name')
        variables = data.get('variables', {})
        output_dir = data.get('output_dir')
        output_file = data.get('output_file')
        if output_file and not output_dir:
            if os.path.isdir(output_file):
                output_dir = output_file
            else:
                output_dir = os.path.dirname(output_file) or None
        
        library = TemplateLibrary()
        result = library.generate_from_template(template_name, variables, output_dir)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


# ä¸€è‡´æ€§æ£€æŸ¥ API
@app.route('/api/check/consistency', methods=['POST'])
def check_consistency():
    """æ£€æŸ¥æ–‡æ¡£ä¸€è‡´æ€§"""
    try:
        from web.consistency_checker import ConsistencyChecker
        
        data = request.json
        file_path = data.get('file_path')
        
        checker = ConsistencyChecker()
        result = checker.check_document(file_path)
        report = checker.generate_report(result)
        
        return jsonify({"success": True, "result": result, "report": report})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


# æ–‡æ¡£å¯¹æ¯” API
@app.route('/api/compare/documents', methods=['POST'])
def compare_documents():
    """å¯¹æ¯”æ–‡æ¡£"""
    try:
        from web.document_comparator import DocumentComparator
        
        data = request.json
        file_a = data.get('file_a')
        file_b = data.get('file_b')
        output_format = data.get('output_format', 'markdown')
        
        comparator = DocumentComparator()
        result = comparator.compare_documents(file_a, file_b, output_format)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


# OCR åŠ©æ‰‹ API
@app.route('/api/ocr/screenshot', methods=['POST'])
def ocr_screenshot():
    """æˆªå›¾å¹¶OCR"""
    try:
        from web.clipboard_ocr_assistant import ClipboardOCRAssistant
        
        data = request.json
        save_image = data.get('save_image', True)
        auto_index = data.get('auto_index', False)
        
        assistant = ClipboardOCRAssistant()
        result = assistant.capture_and_ocr(source='screenshot', save_image=save_image)
        
        if auto_index and result.get('ocr_success'):
            assistant.auto_index_to_knowledge_base(result)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/ocr/clipboard', methods=['POST'])
def ocr_clipboard():
    """å‰ªè´´æ¿å›¾ç‰‡OCR"""
    try:
        from web.clipboard_ocr_assistant import ClipboardOCRAssistant
        
        data = request.json
        save_image = data.get('save_image', True)
        auto_index = data.get('auto_index', False)
        
        assistant = ClipboardOCRAssistant()
        result = assistant.capture_and_ocr(source='clipboard', save_image=save_image)
        
        if auto_index and result.get('ocr_success'):
            assistant.auto_index_to_knowledge_base(result)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


# æ“ä½œå†å² API
@app.route('/api/history/list', methods=['GET'])
def history_list():
    """è·å–æ“ä½œå†å²"""
    try:
        from web.operation_history import OperationHistory
        
        limit = request.args.get('limit', 50, type=int)
        file_path = request.args.get('file_path')
        
        history = OperationHistory()
        operations = history.get_history(limit=limit, file_path=file_path)
        
        return jsonify({"success": True, "operations": operations})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/history/rollback/<op_id>', methods=['POST'])
def history_rollback(op_id):
    """å›æ»šæ“ä½œ"""
    try:
        from web.operation_history import OperationHistory
        
        history = OperationHistory()
        result = history.rollback(op_id)
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/history/stats', methods=['GET'])
def history_stats():
    """è·å–å†å²ç»Ÿè®¡"""
    try:
        from web.operation_history import OperationHistory
        
        history = OperationHistory()
        stats = history.get_statistics()
        
        return jsonify({"success": True, "stats": stats})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


# è¯­éŸ³è½¬å†™ API
@app.route('/api/speech/transcribe-file', methods=['POST'])
def speech_transcribe_file():
    """è½¬å†™éŸ³é¢‘æ–‡ä»¶"""
    try:
        from web.speech_transcriber import SpeechTranscriber
        
        data = request.json
        audio_path = data.get('audio_path')
        language = data.get('language', 'zh-CN')
        output_format = data.get('output_format', 'txt')
        title = data.get('title')
        auto_summary = data.get('auto_summary', True)
        
        if not audio_path:
            return jsonify({"success": False, "error": "ç¼ºå°‘audio_pathå‚æ•°"}), 400
        
        transcriber = SpeechTranscriber()
        result = transcriber.process_audio_complete(
            audio_path,
            language=language,
            output_format=output_format,
            title=title,
            auto_summary=auto_summary
        )
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/speech/transcribe-microphone', methods=['POST'])
def speech_transcribe_microphone():
    """ä»éº¦å…‹é£å½•éŸ³å¹¶è½¬å†™"""
    try:
        from web.speech_transcriber import SpeechTranscriber
        
        data = request.json
        duration = data.get('duration', 30)
        language = data.get('language', 'zh-CN')
        output_format = data.get('output_format', 'txt')
        title = data.get('title')
        
        transcriber = SpeechTranscriber()
        
        # å½•éŸ³
        mic_result = transcriber.transcribe_microphone(duration=duration, language=language)
        
        if not mic_result["success"]:
            return jsonify(mic_result), 400
        
        text = mic_result["text"]
        
        # æå–æ€»ç»“
        summary_result = transcriber.extract_keywords_and_summary(text)
        keywords = summary_result.get("keywords", []) if summary_result["success"] else []
        summary = summary_result.get("summary", []) if summary_result["success"] else []
        
        # ç”Ÿæˆæ–‡æ¡£
        output_file = transcriber.generate_transcript_document(
            text,
            keywords=keywords,
            summary=summary,
            title=title,
            output_format=output_format
        )
        
        return jsonify({
            "success": True,
            "text": text,
            "keywords": keywords,
            "summary": summary,
            "output_file": output_file,
            "format": output_format
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/speech/extract-summary', methods=['POST'])
def speech_extract_summary():
    """ä»æ–‡æœ¬æå–å…³é”®è¯å’Œæ€»ç»“"""
    try:
        from web.speech_transcriber import SpeechTranscriber
        
        data = request.json
        text = data.get('text')
        max_keywords = data.get('max_keywords', 10)
        
        if not text:
            return jsonify({"success": False, "error": "ç¼ºå°‘textå‚æ•°"}), 400
        
        transcriber = SpeechTranscriber()
        result = transcriber.extract_keywords_and_summary(
            text,
            max_keywords=max_keywords
        )
        
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


# ================= ä¸»ç¨‹åºå…¥å£ =================

# ================= NotebookLM åŠŸèƒ½å¤åˆ» API =================

@app.route('/api/notebook/overview', methods=['POST'])
def notebook_overview():
    """ç”ŸæˆéŸ³é¢‘æ¦‚è§ˆ (Podcast)"""
    data = request.json
    content = data.get('content', '')
    if not content:
        return jsonify({"success": False, "error": "å†…å®¹ä¸èƒ½ä¸ºç©º"}), 400
        
    try:
        from web.audio_overview import AudioOverviewGenerator
        generator = AudioOverviewGenerator(output_dir=os.path.join(settings_manager.workspace_dir, "audio_cache"))
        
        # 1. ç”Ÿæˆå‰§æœ¬
        # è·å–æ¨¡å‹å®ä¾‹ (å¤ç”¨ç°æœ‰çš„ KotoBrain æˆ–ç›´æ¥è°ƒç”¨ API)
        # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œå‡è®¾æˆ‘ä»¬èƒ½è·å–åˆ°ä¸€ä¸ª genai model å®ä¾‹
        # å®é™…é¡¹ç›®ä¸­åº”è¯¥å¤ç”¨ koto_brain.client.models
        # æš‚æ—¶ä½¿ç”¨ä¸´æ—¶çš„ model å®ä¾‹
        import google.genai as genai
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))
        model = client.models
        
        script = asyncio.run(generator.generate_script(content, model))
        if not script:
             return jsonify({"success": False, "error": "å‰§æœ¬ç”Ÿæˆå¤±è´¥"}), 500
             
        # 2. åˆæˆéŸ³é¢‘
        session_id = f"overview_{int(time.time())}"
        audio_path = asyncio.run(generator.synthesize_audio(script, session_id))
        
        if audio_path:
            # è¿”å›ç›¸å¯¹äº workspace çš„è·¯å¾„æˆ–è€… download url
            rel_path = os.path.relpath(audio_path, settings_manager.workspace_dir)
            # æ³¨æ„ï¼šå®é™…è®¿é—®å¯èƒ½éœ€è¦é€šè¿‡ send_from_directory è·¯ç”±
            # å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ª /files/ è·¯ç”±å¯ä»¥è®¿é—® workspace/
            audio_url = f"/api/files/download?path={requests.utils.quote(audio_path)}" 
            
            return jsonify({
                "success": True, 
                "audio_url": audio_url,
                "script": script
            })
        else:
            return jsonify({"success": False, "error": "éŸ³é¢‘åˆæˆå¤±è´¥"}), 500

    except Exception as e:
        print(f"Error processing audio overview: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/notebook/qa', methods=['POST'])
def notebook_qa():
    """æºæ–‡æ¡£æ·±åº¦é—®ç­” (Source-Grounded Q&A)"""
    data = request.json
    question = data.get('question')
    file_ids = data.get('file_ids', []) # å‡è®¾å‰ç«¯ä¼ å› files (è¿™é‡Œå…ˆç®€åŒ–ä¸º content ç›´æ¥ä¼ å…¥ æˆ–è€… file paths)
    # ä¸ºäº†ç®€åŒ–æ¼”ç¤ºï¼Œæˆ‘ä»¬å…ˆæ¥å—çº¯æ–‡æœ¬ content
    context_content = data.get('context', '') 
    
    if not question or not context_content:
        return jsonify({"success": False, "error": "ç¼ºå°‘é—®é¢˜æˆ–ä¸Šä¸‹æ–‡"}), 400

    prompt = f"""
    Answer the user's question mostly based on the provided source context.
    
    [Source Context]
    {context_content[:30000]} 

    [User Question]
    {question}

    [Rules]
    1. You must cite your sources. When you use information from the context, append [Source] at the end of the sentence.
    2. If the answer is not in the context, state that clearly.
    3. Be precise and concise.
    """
    
    try:
         # å¤ç”¨ KotoBrain çš„é€»è¾‘æˆ–è€…ç›´æ¥è°ƒç”¨
        import google.genai as genai
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))
        response = client.models.generate_content(
            model='gemini-2.5-flash', 
            contents=prompt
        )
        return jsonify({"success": True, "answer": response.text})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/notebook/study_guide', methods=['POST'])
def notebook_study_guide():
    """ç”Ÿæˆå­¦ä¹ æŒ‡å—/ç®€æŠ¥"""
    data = request.json
    content = data.get('content', '')
    type_ = data.get('type', 'summary') # summary, quiz, timelime, faq
    
    prompts = {
        'summary': "Create a comprehensive briefing document summarizing the key points, key people, and timeline from the text.",
        'quiz': "Create 5 multiple-choice questions based on the text to test understanding. Include the correct answer key at the end.",
        'timeline': "Extract a chronological timeline of events mentioned in the text.",
        'faq': "Create a FAQ section based on the text, anticipating what a reader might ask."
    }
    
    selected_prompt = prompts.get(type_, prompts['summary'])
    full_prompt = f"{selected_prompt}\n\n[Source Text]\n{content[:20000]}"
    
    try:
        import google.genai as genai
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))
        response = client.models.generate_content(
            model='gemini-2.5-flash', 
            contents=full_prompt
        )
        return jsonify({"success": True, "result": response.text})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/files/download', methods=['GET'])
def download_file_proxy():
    """é€šç”¨çš„æ–‡ä»¶ä¸‹è½½ä»£ç†"""
    file_path = request.args.get('path')
    if not file_path or not os.path.exists(file_path):
        return "File not found", 404
    return send_file(file_path, as_attachment=True)


@app.route('/api/notebook/upload', methods=['POST'])
def notebook_upload():
    """ä¸Šä¼ å¹¶è§£ææ–‡ä»¶ (PDF/Docx/Txt)"""
    if 'file' not in request.files:
        return jsonify({"success": False, "error": "No file part"}), 400
    file = request.files['file']
    if file.filename == '':
        return jsonify({"success": False, "error": "No selected file"}), 400
        
    try:
        # Save temp file
        filename = file.filename
        temp_path = os.path.join(tempfile.gettempdir(), f"koto_{int(time.time())}_{filename}")
        file.save(temp_path)
        
        # Parse using FileParser
        from web.file_parser import FileParser
        result = FileParser.parse_file(temp_path)
        
        # Cleanup
        try:
            os.remove(temp_path)
        except:
            pass
            
        if result.get("success"):
            return jsonify({
                "success": True,
                "filename": filename,
                "content": result.get("content", ""),
                "char_count": result.get("char_count", 0)
            })
        else:
            return jsonify({"success": False, "error": result.get("error")}), 500
            
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/notebook')
def notebook_ui():
    """NotebookLM é£æ ¼ç•Œé¢"""
    return render_template('notebook_lm.html')

if __name__ == '__main__':

    print("\nğŸš€ Koto Web Server Starting...")
    print(f"ğŸ“ Chat Directory: {os.path.abspath(CHAT_DIR)}")
    print(f"ğŸ“ Workspace: {os.path.abspath(WORKSPACE_DIR)}")
    
    # å»¶è¿Ÿæ£€æŸ¥ Ollama çŠ¶æ€ï¼ˆä¸é˜»å¡å¯åŠ¨ï¼‰
    def check_ollama_async():
        time.sleep(2)  # å»¶è¿Ÿ2ç§’åæ£€æŸ¥
        if LocalDispatcher.is_ollama_running():
            print("ğŸ¦™ Ollama: Running")
        else:
            print("ğŸ¦™ Ollama: Not Running")
    threading.Thread(target=check_ollama_async, daemon=True).start()
    
    print("âš ï¸ æœ¬åœ°æ¨¡å‹ä»»åŠ¡è·¯ç”±å™¨å·²ç¦ç”¨ï¼Œä½¿ç”¨è¿œç¨‹ AI")
    
    print("\nğŸŒ Open http://localhost:5000 in your browser\n")
    
    # å¯åŠ¨åå°æœåŠ¡ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡å¯åŠ¨ï¼‰
    def start_background_services():
        time.sleep(1)  # å»¶è¿Ÿ1ç§’åå¯åŠ¨åå°æœåŠ¡
        try:
            from clipboard_manager import get_clipboard_manager
            from task_scheduler import get_task_scheduler
            from auto_catalog_scheduler import get_auto_catalog_scheduler
            
            # å¯åŠ¨å‰ªè´´æ¿ç›‘æ§
            clipboard_manager = get_clipboard_manager()
            clipboard_manager.start_monitoring()
            print("ğŸ“‹ å‰ªè´´æ¿ç›‘æ§å·²å¯åŠ¨")
            
            # å¯åŠ¨ä»»åŠ¡è°ƒåº¦å™¨
            task_scheduler = get_task_scheduler()
            task_scheduler.start()
            print("â° ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")
            
            # åˆå§‹åŒ–è‡ªåŠ¨å½’çº³è°ƒåº¦å™¨ï¼ˆå¦‚æœå·²å¯ç”¨ï¼‰
            auto_catalog = get_auto_catalog_scheduler()
            if auto_catalog.is_auto_catalog_enabled():
                auto_catalog._register_scheduled_task()
                print(f"ğŸ—‚ï¸ è‡ªåŠ¨å½’çº³å·²å¯ç”¨ï¼Œæ¯æ—¥ {auto_catalog.get_catalog_schedule()} æ‰§è¡Œ")
            
        except Exception as e:
            print(f"âš ï¸ åå°æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
    
    threading.Thread(target=start_background_services, daemon=True).start()
    
    try:
        debug_mode = os.environ.get('KOTO_DEBUG', 'false').lower() == 'true'
        port = int(os.environ.get('KOTO_PORT', '5000'))
        app.run(debug=debug_mode, host='0.0.0.0', port=port, threaded=True)
    finally:
        # åº”ç”¨å…³é—­æ—¶æ¸…ç†å¹¶è¡Œæ‰§è¡Œç³»ç»Ÿ
        if PARALLEL_SYSTEM_ENABLED:
            print("[PARALLEL] ğŸ›‘ Shutting down parallel execution system...")
            stop_dispatcher()
            print("[PARALLEL] âœ… Parallel execution system shut down")



# â•â•â• æ–‡ä»¶ç»„ç»‡ç³»ç»Ÿ API â•â•â•

# åˆå§‹åŒ–æ–‡ä»¶ç»„ç»‡å™¨
_file_organizer_cache = {}
_batch_ops_cache = {}

def get_file_organizer():
    """æ‡’åŠ è½½æ–‡ä»¶ç»„ç»‡å™¨"""
    if 'organizer' not in _file_organizer_cache:
        try:
            from web.file_organizer import FileOrganizer
        except ImportError:
            from file_organizer import FileOrganizer
        
        organize_root = get_organize_root()
        _file_organizer_cache['organizer'] = FileOrganizer(organize_root)
    
    return _file_organizer_cache['organizer']

def get_file_analyzer():
    """æ‡’åŠ è½½æ–‡ä»¶åˆ†æå™¨"""
    if 'analyzer' not in _file_organizer_cache:
        try:
            from web.file_analyzer import FileAnalyzer
        except ImportError:
            from file_analyzer import FileAnalyzer
        
        _file_organizer_cache['analyzer'] = FileAnalyzer()
    
    return _file_organizer_cache['analyzer']

def get_batch_ops_manager():
    """æ‡’åŠ è½½æ‰¹é‡æ–‡ä»¶å¤„ç†ç®¡ç†å™¨"""
    if 'batch_ops' not in _batch_ops_cache:
        try:
            from web.batch_file_ops import BatchFileOpsManager
        except ImportError:
            from batch_file_ops import BatchFileOpsManager
        _batch_ops_cache['batch_ops'] = BatchFileOpsManager()
    return _batch_ops_cache['batch_ops']

_file_editor_cache = {}
_file_indexer_cache = {}
_concept_extractor_cache = {}
_knowledge_graph_cache = {}
_behavior_monitor_cache = {}
_suggestion_engine_cache = {}
_insight_reporter_cache = {}

def get_file_editor():
    """æ‡’åŠ è½½æ–‡ä»¶ç¼–è¾‘å™¨"""
    if 'editor' not in _file_editor_cache:
        try:
            from web.file_editor import FileEditor
        except ImportError:
            from file_editor import FileEditor
        _file_editor_cache['editor'] = FileEditor()
    return _file_editor_cache['editor']

def get_file_indexer():
    """æ‡’åŠ è½½æ–‡ä»¶ç´¢å¼•å™¨"""
    if 'indexer' not in _file_indexer_cache:
        try:
            from web.file_indexer import FileIndexer
        except ImportError:
            from file_indexer import FileIndexer
        _file_indexer_cache['indexer'] = FileIndexer()
    return _file_indexer_cache['indexer']

def get_concept_extractor():
    """æ‡’åŠ è½½æ¦‚å¿µæå–å™¨"""
    if 'extractor' not in _concept_extractor_cache:
        try:
            from web.concept_extractor import ConceptExtractor
        except ImportError:
            from concept_extractor import ConceptExtractor
        _concept_extractor_cache['extractor'] = ConceptExtractor()
    return _concept_extractor_cache['extractor']

def get_knowledge_graph():
    """æ‡’åŠ è½½çŸ¥è¯†å›¾è°±"""
    if 'graph' not in _knowledge_graph_cache:
        try:
            from web.knowledge_graph import KnowledgeGraph
        except ImportError:
            from knowledge_graph import KnowledgeGraph
        _knowledge_graph_cache['graph'] = KnowledgeGraph()
    return _knowledge_graph_cache['graph']

def get_behavior_monitor():
    """æ‡’åŠ è½½è¡Œä¸ºç›‘æ§å™¨"""
    if 'monitor' not in _behavior_monitor_cache:
        try:
            from web.behavior_monitor import BehaviorMonitor
        except ImportError:
            from behavior_monitor import BehaviorMonitor
        _behavior_monitor_cache['monitor'] = BehaviorMonitor()
    return _behavior_monitor_cache['monitor']

def get_suggestion_engine():
    """æ‡’åŠ è½½å»ºè®®å¼•æ“"""
    if 'engine' not in _suggestion_engine_cache:
        try:
            from web.suggestion_engine import SuggestionEngine
        except ImportError:
            from suggestion_engine import SuggestionEngine
        _suggestion_engine_cache['engine'] = SuggestionEngine()
    return _suggestion_engine_cache['engine']

def get_insight_reporter():
    """æ‡’åŠ è½½æ´å¯ŸæŠ¥å‘Šç”Ÿæˆå™¨"""
    if 'reporter' not in _insight_reporter_cache:
        try:
            from web.insight_reporter import InsightReporter
        except ImportError:
            from insight_reporter import InsightReporter
        _insight_reporter_cache['reporter'] = InsightReporter()
    return _insight_reporter_cache['reporter']

# ==================== å¢å¼ºä¸»åŠ¨èƒ½åŠ›æ¨¡å—ç¼“å­˜ ====================
_notification_manager_cache = {}
_proactive_dialogue_cache = {}
_context_awareness_cache = {}
_auto_execution_cache = {}
_trigger_system_cache = {}

def get_notification_manager():
    """æ‡’åŠ è½½é€šçŸ¥ç®¡ç†å™¨"""
    if 'manager' not in _notification_manager_cache:
        try:
            from web.notification_manager import get_notification_manager as _get_mgr
        except ImportError:
            from notification_manager import get_notification_manager as _get_mgr
        _notification_manager_cache['manager'] = _get_mgr()
    return _notification_manager_cache['manager']

def get_proactive_dialogue():
    """æ‡’åŠ è½½ä¸»åŠ¨å¯¹è¯å¼•æ“"""
    if 'engine' not in _proactive_dialogue_cache:
        try:
            from web.proactive_dialogue import get_proactive_dialogue_engine
        except ImportError:
            from proactive_dialogue import get_proactive_dialogue_engine
        
        # é›†æˆä¾èµ–æ¨¡å—
        notif_mgr = get_notification_manager()
        behavior_mon = get_behavior_monitor()
        suggestion_eng = get_suggestion_engine()
        
        _proactive_dialogue_cache['engine'] = get_proactive_dialogue_engine(
            notification_manager=notif_mgr,
            behavior_monitor=behavior_mon,
            suggestion_engine=suggestion_eng
        )
    return _proactive_dialogue_cache['engine']

def get_context_awareness():
    """æ‡’åŠ è½½æƒ…å¢ƒæ„ŸçŸ¥ç³»ç»Ÿ"""
    if 'system' not in _context_awareness_cache:
        try:
            from web.context_awareness import get_context_awareness_system
        except ImportError:
            from context_awareness import get_context_awareness_system
        
        behavior_mon = get_behavior_monitor()
        _context_awareness_cache['system'] = get_context_awareness_system(
            behavior_monitor=behavior_mon
        )
    return _context_awareness_cache['system']

def get_auto_execution():
    """æ‡’åŠ è½½è‡ªåŠ¨æ‰§è¡Œå¼•æ“"""
    if 'engine' not in _auto_execution_cache:
        try:
            from web.auto_execution import get_auto_execution_engine
        except ImportError:
            from auto_execution import get_auto_execution_engine
        
        notif_mgr = get_notification_manager()
        _auto_execution_cache['engine'] = get_auto_execution_engine(
            notification_manager=notif_mgr
        )
    return _auto_execution_cache['engine']

def get_trigger_system():
    """æ‡’åŠ è½½ä¸»åŠ¨äº¤äº’è§¦å‘ç³»ç»Ÿ"""
    if 'system' not in _trigger_system_cache:
        try:
            from web.proactive_trigger import get_trigger_system as _get_trigger_system
        except ImportError:
            from proactive_trigger import get_trigger_system as _get_trigger_system
        
        behavior_mon = get_behavior_monitor()
        context_sys = get_context_awareness()
        suggestion_eng = get_suggestion_engine()
        notif_mgr = get_notification_manager()
        dialogue_eng = get_proactive_dialogue()
        
        _trigger_system_cache['system'] = _get_trigger_system(
            behavior_monitor=behavior_mon,
            context_awareness=context_sys,
            suggestion_engine=suggestion_eng,
            notification_manager=notif_mgr,
            dialogue_engine=dialogue_eng
        )
    return _trigger_system_cache['system']


@app.route('/api/batch/submit', methods=['POST'])
def batch_submit():
    """æäº¤æ‰¹é‡æ–‡ä»¶å¤„ç†ä»»åŠ¡"""
    try:
        data = request.json or {}
        command = data.get('command', '')
        manager = get_batch_ops_manager()

        if command:
            parsed = manager.parse_command(command)
            if not parsed.get('success'):
                return jsonify({"success": False, "error": parsed.get('error'), "hint": parsed.get('hint')}), 400
            operation = parsed.get('operation')
            input_dir = parsed.get('input_dir')
            output_dir = parsed.get('output_dir')
            options = parsed.get('options', {})
        else:
            operation = data.get('operation')
            input_dir = data.get('input_dir')
            output_dir = data.get('output_dir')
            options = data.get('options', {})

        if not operation or not input_dir or not output_dir:
            return jsonify({"success": False, "error": "ç¼ºå°‘å¿…è¦å‚æ•°"}), 400

        job = manager.create_job(
            name=f"batch_{operation}",
            operation=operation,
            input_dir=input_dir,
            output_dir=output_dir,
            options=options
        )
        manager.start_job(job.job_id)
        return jsonify({"success": True, "job_id": job.job_id, "job": manager.get_job(job.job_id)})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/batch/jobs', methods=['GET'])
def batch_list_jobs():
    """åˆ—å‡ºæ‰¹é‡ä»»åŠ¡"""
    manager = get_batch_ops_manager()
    return jsonify({"success": True, "jobs": manager.list_jobs()})


@app.route('/api/batch/jobs/<job_id>', methods=['GET'])
def batch_get_job(job_id):
    """è·å–å•ä¸ªä»»åŠ¡è¯¦æƒ…"""
    manager = get_batch_ops_manager()
    job = manager.get_job(job_id)
    if not job:
        return jsonify({"success": False, "error": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404
    return jsonify({"success": True, "job": job})


@app.route('/api/batch/stream/<job_id>', methods=['GET'])
def batch_stream_job(job_id):
    """æ‰¹é‡ä»»åŠ¡è¿›åº¦æµ"""
    manager = get_batch_ops_manager()
    return Response(manager.stream_job(job_id), mimetype='text/event-stream')

@app.route('/api/organize/scan-file', methods=['POST'])
def organize_scan_file():
    """æ‰«æå’Œåˆ†æå•ä¸ªæ–‡ä»¶"""
    try:
        data = request.json
        file_path = data.get('file_path')
        
        if not file_path:
            return jsonify({"error": "ç¼ºå°‘ file_path å‚æ•°"}), 400
        
        if not os.path.exists(file_path):
            return jsonify({"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}), 404
        
        analyzer = get_file_analyzer()
        analysis_result = analyzer.analyze_file(file_path)
        
        return jsonify({
            "success": True,
            "file": os.path.basename(file_path),
            "analysis": analysis_result
        })
    
    except Exception as e:
        return jsonify({
            "error": f"åˆ†æå¤±è´¥: {str(e)}"
        }), 500

@app.route('/api/organize/auto-organize', methods=['POST'])
def organize_auto_organize():
    """è‡ªåŠ¨ç»„ç»‡æ–‡ä»¶ï¼ˆåˆ†æ+ç§»åŠ¨ï¼‰"""
    try:
        data = request.json
        file_path = data.get('file_path')
        auto_confirm = data.get('auto_confirm', True)
        
        if not file_path:
            return jsonify({"error": "ç¼ºå°‘ file_path å‚æ•°"}), 400
        
        if not os.path.exists(file_path):
            return jsonify({"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}), 404
        
        # ç¬¬ä¸€æ­¥ï¼šåˆ†ææ–‡ä»¶
        analyzer = get_file_analyzer()
        analysis = analyzer.analyze_file(file_path)
        suggested_folder = analysis.get('suggested_folder')
        
        if not suggested_folder:
            return jsonify({
                "error": "æ— æ³•ç¡®å®šæ–‡ä»¶åˆ†ç±»",
                "analysis": analysis
            }), 400
        
        # ç¬¬äºŒæ­¥ï¼šç»„ç»‡æ–‡ä»¶
        organizer = get_file_organizer()
        org_result = organizer.organize_file(
            file_path,
            suggested_folder,
            auto_confirm=auto_confirm
        )
        
        if org_result.get('success'):
            return jsonify({
                "success": True,
                "file": os.path.basename(file_path),
                "analysis": analysis,
                "organized": org_result
            })
        else:
            return jsonify({
                "error": org_result.get('error', 'ç»„ç»‡å¤±è´¥'),
                "analysis": analysis
            }), 500
    
    except Exception as e:
        return jsonify({
            "error": f"è‡ªåŠ¨ç»„ç»‡å¤±è´¥: {str(e)}"
        }), 500

@app.route('/api/organize/list-categories', methods=['GET'])
def organize_list_categories():
    """åˆ—å‡ºæ‰€æœ‰åˆ†ç±»å’Œæ–‡ä»¶å¤¹"""
    try:
        organizer = get_file_organizer()
        folders = organizer.list_organized_folders()
        stats = organizer.get_categories_stats()
        
        return jsonify({
            "success": True,
            "folders": folders,
            "stats": stats,
            "total_files": len(organizer.get_index().get('files', []))
        })
    
    except Exception as e:
        return jsonify({
            "error": f"è·å–åˆ†ç±»å¤±è´¥: {str(e)}"
        }), 500

@app.route('/api/organize/search', methods=['POST'])
def organize_search():
    """æœç´¢å·²ç»„ç»‡çš„æ–‡ä»¶"""
    try:
        data = request.json
        keyword = data.get('keyword', '')
        
        if not keyword:
            return jsonify({"error": "ç¼ºå°‘æœç´¢å…³é”®è¯"}), 400
        
        organizer = get_file_organizer()
        results = organizer.search_files(keyword)
        
        return jsonify({
            "success": True,
            "keyword": keyword,
            "count": len(results),
            "results": results
        })
    
    except Exception as e:
        return jsonify({
            "error": f"æœç´¢å¤±è´¥: {str(e)}"
        }), 500

@app.route('/api/organize/stats', methods=['GET'])
def organize_stats():
    """è·å–ç»„ç»‡ç»Ÿè®¡ä¿¡æ¯"""
    try:
        organizer = get_file_organizer()
        index = organizer.get_index()
        stats = organizer.get_categories_stats()
        folders = organizer.list_organized_folders()
        
        return jsonify({
            "success": True,
            "total_files": index.get('total_files', 0),
            "total_folders": len(folders),
            "by_industry": stats,
            "last_updated": index.get('last_updated')
        })
    
    except Exception as e:
        return jsonify({
            "error": f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}"
        }), 500


@app.route('/api/organize/cleanup', methods=['POST'])
def organize_cleanup():
    """æ•´åˆæ¸…ç† _organize ç›®å½•ä¸­çš„é‡å¤æ–‡ä»¶å¤¹"""
    try:
        data = request.get_json(silent=True) or {}
        dry_run = data.get('dry_run', True)
        ai_rename = data.get('ai_rename', False)

        organize_root = get_organize_root()

        try:
            from web.organize_cleanup import OrganizeCleanup
        except ImportError:
            from organize_cleanup import OrganizeCleanup

        cleanup = OrganizeCleanup(organize_root=organize_root)
        report = cleanup.run(dry_run=dry_run, ai_rename=ai_rename)

        return jsonify({
            "success": True,
            "dry_run": dry_run,
            "total_folders_scanned": report.get("total_folders_scanned", 0),
            "similarity_groups": report.get("similarity_groups", 0),
            "merge_plans": report.get("merge_plans", 0),
            "merged_files": report.get("merged_files", 0),
            "deduped_files": report.get("deduped_files", 0),
            "removed_folders": report.get("removed_folders", 0),
            "empty_cleaned": report.get("empty_cleaned", 0),
            "ai_renames": report.get("ai_renames", 0),
            "log": report.get("log", [])[-50:],  # æœ€è¿‘50æ¡æ—¥å¿—
        })

    except Exception as e:
        return jsonify({
            "error": f"æ•´åˆæ¸…ç†å¤±è´¥: {str(e)}"
        }), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ–‡ä»¶ç¼–è¾‘ä¸æœç´¢ API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/api/file-editor/read', methods=['POST'])
def file_editor_read():
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    try:
        data = request.json or {}
        file_path = data.get('file_path')
        
        if not file_path:
            return jsonify({"error": "ç¼ºå°‘æ–‡ä»¶è·¯å¾„"}), 400
        
        editor = get_file_editor()
        result = editor.read_file(file_path)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/file-editor/write', methods=['POST'])
def file_editor_write():
    """å†™å…¥æ–‡ä»¶å†…å®¹"""
    try:
        data = request.json or {}
        file_path = data.get('file_path')
        content = data.get('content')
        
        if not file_path or content is None:
            return jsonify({"error": "ç¼ºå°‘å¿…è¦å‚æ•°"}), 400
        
        editor = get_file_editor()
        result = editor.write_file(file_path, content)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/file-editor/replace', methods=['POST'])
def file_editor_replace():
    """æ›¿æ¢æ–‡ä»¶å†…å®¹"""
    try:
        data = request.json or {}
        file_path = data.get('file_path')
        old_text = data.get('old_text')
        new_text = data.get('new_text')
        use_regex = data.get('use_regex', False)
        
        if not all([file_path, old_text is not None, new_text is not None]):
            return jsonify({"error": "ç¼ºå°‘å¿…è¦å‚æ•°"}), 400
        
        editor = get_file_editor()
        result = editor.replace_text(file_path, old_text, new_text, use_regex=use_regex)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/file-editor/smart-edit', methods=['POST'])
def file_editor_smart_edit():
    """æ™ºèƒ½ç¼–è¾‘ï¼ˆç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼‰"""
    try:
        data = request.json or {}
        file_path = data.get('file_path')
        instruction = data.get('instruction')
        
        if not file_path or not instruction:
            return jsonify({"error": "ç¼ºå°‘å¿…è¦å‚æ•°"}), 400
        
        editor = get_file_editor()
        result = editor.smart_edit(file_path, instruction)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/file-search/index', methods=['POST'])
def file_search_index():
    """ç´¢å¼•æ–‡ä»¶æˆ–ç›®å½•"""
    try:
        data = request.json or {}
        path = data.get('path')
        is_directory = data.get('is_directory', False)
        
        if not path:
            return jsonify({"error": "ç¼ºå°‘è·¯å¾„å‚æ•°"}), 400
        
        indexer = get_file_indexer()
        
        if is_directory:
            result = indexer.index_directory(path, recursive=True)
        else:
            result = indexer.index_file(path)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/file-search/search', methods=['POST'])
def file_search_search():
    """æœç´¢æ–‡ä»¶"""
    try:
        data = request.json or {}
        query = data.get('query')
        limit = data.get('limit', 20)
        file_types = data.get('file_types')
        
        if not query:
            return jsonify({"error": "ç¼ºå°‘æœç´¢å…³é”®è¯"}), 400
        
        indexer = get_file_indexer()
        results = indexer.search(query, limit=limit, file_types=file_types)
        
        return jsonify({
            "success": True,
            "results": results,
            "count": len(results)
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/file-search/find-by-content', methods=['POST'])
def file_search_find_by_content():
    """æ ¹æ®å†…å®¹ç‰‡æ®µæŸ¥æ‰¾æ–‡ä»¶"""
    try:
        data = request.json or {}
        content_sample = data.get('content')
        min_similarity = data.get('min_similarity', 0.3)
        
        if not content_sample:
            return jsonify({"error": "ç¼ºå°‘å†…å®¹æ ·æœ¬"}), 400
        
        indexer = get_file_indexer()
        results = indexer.find_by_content(content_sample, min_similarity=min_similarity)
        
        return jsonify({
            "success": True,
            "results": results,
            "count": len(results)
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/file-search/list', methods=['GET'])
def file_search_list():
    """åˆ—å‡ºæ‰€æœ‰å·²ç´¢å¼•æ–‡ä»¶"""
    try:
        limit = request.args.get('limit', 100, type=int)
        offset = request.args.get('offset', 0, type=int)
        
        indexer = get_file_indexer()
        files = indexer.list_indexed_files(limit=limit, offset=offset)
        
        return jsonify({
            "success": True,
            "files": files,
            "count": len(files)
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ¦‚å¿µæå– API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/api/concepts/extract', methods=['POST'])
def concepts_extract():
    """ä»æ–‡ä»¶ä¸­æå–å…³é”®æ¦‚å¿µ"""
    try:
        data = request.json or {}
        file_path = data.get('file_path')
        content = data.get('content')  # å¯é€‰ï¼Œå¦‚æœå·²è¯»å–å†…å®¹
        top_n = data.get('top_n', 10)
        
        if not file_path:
            return jsonify({"error": "ç¼ºå°‘æ–‡ä»¶è·¯å¾„"}), 400
        
        extractor = get_concept_extractor()
        result = extractor.analyze_file(file_path, content=content)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/concepts/related-files', methods=['POST'])
def concepts_related_files():
    """æŸ¥æ‰¾ä¸æ–‡ä»¶ç›¸å…³çš„å…¶ä»–æ–‡ä»¶"""
    try:
        data = request.json or {}
        file_path = data.get('file_path')
        limit = data.get('limit', 5)
        
        if not file_path:
            return jsonify({"error": "ç¼ºå°‘æ–‡ä»¶è·¯å¾„"}), 400
        
        extractor = get_concept_extractor()
        related = extractor.find_related_files(file_path, limit=limit)
        
        return jsonify({
            "success": True,
            "file_path": file_path,
            "related_files": related
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/concepts/top', methods=['GET'])
def concepts_top():
    """è·å–å…¨å±€çƒ­é—¨æ¦‚å¿µ"""
    try:
        limit = request.args.get('limit', 20, type=int)
        
        extractor = get_concept_extractor()
        concepts = extractor.get_top_concepts(limit=limit)
        
        return jsonify({
            "success": True,
            "concepts": concepts
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/concepts/stats', methods=['GET'])
def concepts_stats():
    """è·å–æ¦‚å¿µæå–ç»Ÿè®¡"""
    try:
        extractor = get_concept_extractor()
        stats = extractor.get_statistics()
        
        return jsonify(stats)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# çŸ¥è¯†å›¾è°± API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/api/knowledge-graph/build', methods=['POST'])
def knowledge_graph_build():
    """æ„å»ºçŸ¥è¯†å›¾è°±"""
    try:
        data = request.json or {}
        file_paths = data.get('file_paths', [])
        force_rebuild = data.get('force_rebuild', False)
        
        if not file_paths:
            return jsonify({"error": "ç¼ºå°‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨"}), 400
        
        kg = get_knowledge_graph()
        kg.build_file_graph(file_paths, force_rebuild=force_rebuild)
        
        stats = kg.get_statistics()
        
        return jsonify({
            "success": True,
            "message": "çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ",
            "statistics": stats
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/knowledge-graph/data', methods=['GET'])
def knowledge_graph_data():
    """è·å–çŸ¥è¯†å›¾è°±æ•°æ®ç”¨äºå¯è§†åŒ–"""
    try:
        max_nodes = request.args.get('max_nodes', 100, type=int)
        
        kg = get_knowledge_graph()
        graph_data = kg.get_graph_data(max_nodes=max_nodes)
        
        return jsonify(graph_data)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/knowledge-graph/neighbors', methods=['POST'])
def knowledge_graph_neighbors():
    """è·å–æ–‡ä»¶çš„é‚»å±…èŠ‚ç‚¹"""
    try:
        data = request.json or {}
        file_path = data.get('file_path')
        depth = data.get('depth', 1)
        
        if not file_path:
            return jsonify({"error": "ç¼ºå°‘æ–‡ä»¶è·¯å¾„"}), 400
        
        kg = get_knowledge_graph()
        neighbors = kg.get_file_neighbors(file_path, depth=depth)
        
        return jsonify(neighbors)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/knowledge-graph/concept-cluster', methods=['POST'])
def knowledge_graph_concept_cluster():
    """è·å–æ¦‚å¿µç›¸å…³çš„æ–‡ä»¶é›†ç¾¤"""
    try:
        data = request.json or {}
        concept = data.get('concept')
        limit = data.get('limit', 20)
        
        if not concept:
            return jsonify({"error": "ç¼ºå°‘æ¦‚å¿µå‚æ•°"}), 400
        
        kg = get_knowledge_graph()
        cluster = kg.get_concept_cluster(concept, limit=limit)
        
        return jsonify(cluster)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/knowledge-graph/stats', methods=['GET'])
def knowledge_graph_stats():
    """è·å–çŸ¥è¯†å›¾è°±ç»Ÿè®¡"""
    try:
        kg = get_knowledge_graph()
        stats = kg.get_statistics()
        
        return jsonify(stats)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è¡Œä¸ºç›‘æ§ API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/api/behavior/log-event', methods=['POST'])
def behavior_log_event():
    """è®°å½•ç”¨æˆ·è¡Œä¸ºäº‹ä»¶"""
    try:
        data = request.json or {}
        event_type = data.get('event_type')
        file_path = data.get('file_path')
        session_id = data.get('session_id')
        event_data = data.get('event_data')
        duration_ms = data.get('duration_ms')
        user_id = data.get('user_id', 'default')
        auto_trigger = data.get('auto_trigger', True)
        
        if not event_type:
            return jsonify({"error": "ç¼ºå°‘äº‹ä»¶ç±»å‹"}), 400
        
        monitor = get_behavior_monitor()
        event_id = monitor.log_event(
            event_type=event_type,
            file_path=file_path,
            session_id=session_id,
            event_data=event_data,
            duration_ms=duration_ms
        )

        decision_payload = None
        triggered = False
        if auto_trigger:
            trigger_system = get_trigger_system()
            decision = trigger_system.evaluate_interaction_need(user_id)
            if decision and decision.should_interact:
                trigger_system.execute_interaction(decision, user_id)
                triggered = True
                decision_payload = {
                    "interaction_type": decision.interaction_type.value,
                    "priority": decision.priority,
                    "reason": decision.reason,
                    "content": decision.content,
                    "scores": {
                        "urgency": decision.urgency_score,
                        "importance": decision.importance_score,
                        "disturbance": decision.disturbance_cost,
                        "final": decision.final_score
                    }
                }
        
        return jsonify({
            "success": True,
            "event_id": event_id,
            "triggered": triggered,
            "decision": decision_payload
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/behavior/recent-events', methods=['GET'])
def behavior_recent_events():
    """è·å–æœ€è¿‘çš„äº‹ä»¶"""
    try:
        limit = request.args.get('limit', 50, type=int)
        event_type = request.args.get('event_type')
        
        monitor = get_behavior_monitor()
        events = monitor.get_recent_events(limit=limit, event_type=event_type)
        
        return jsonify({
            "success": True,
            "events": events
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/behavior/top-files', methods=['GET'])
def behavior_top_files():
    """è·å–æœ€å¸¸ç”¨çš„æ–‡ä»¶"""
    try:
        limit = request.args.get('limit', 10, type=int)
        
        monitor = get_behavior_monitor()
        files = monitor.get_frequently_used_files(limit=limit)
        
        return jsonify({
            "success": True,
            "files": files
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/behavior/work-patterns', methods=['GET'])
def behavior_work_patterns():
    """è·å–å·¥ä½œæ¨¡å¼åˆ†æ"""
    try:
        monitor = get_behavior_monitor()
        patterns = monitor.get_work_patterns()
        
        return jsonify(patterns)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/behavior/stats', methods=['GET'])
def behavior_stats():
    """è·å–è¡Œä¸ºç»Ÿè®¡"""
    try:
        monitor = get_behavior_monitor()
        stats = monitor.get_statistics()
        
        return jsonify(stats)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ™ºèƒ½å»ºè®® API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/api/suggestions/generate', methods=['POST'])
def suggestions_generate():
    """ç”Ÿæˆæ™ºèƒ½å»ºè®®"""
    try:
        data = request.json or {}
        force_regenerate = data.get('force_regenerate', False)
        
        engine = get_suggestion_engine()
        suggestions = engine.generate_suggestions(force_regenerate=force_regenerate)
        
        return jsonify({
            "success": True,
            "suggestions": suggestions,
            "count": len(suggestions)
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/suggestions/pending', methods=['GET'])
def suggestions_pending():
    """è·å–å¾…å¤„ç†çš„å»ºè®®"""
    try:
        limit = request.args.get('limit', 10, type=int)
        
        engine = get_suggestion_engine()
        suggestions = engine.get_pending_suggestions(limit=limit)
        
        return jsonify({
            "success": True,
            "suggestions": suggestions,
            "count": len(suggestions)
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/suggestions/dismiss', methods=['POST'])
def suggestions_dismiss():
    """æ‹’ç»å»ºè®®"""
    try:
        data = request.json or {}
        suggestion_id = data.get('suggestion_id')
        feedback = data.get('feedback')
        
        if not suggestion_id:
            return jsonify({"error": "ç¼ºå°‘å»ºè®®ID"}), 400
        
        engine = get_suggestion_engine()
        engine.dismiss_suggestion(suggestion_id, feedback=feedback)
        
        return jsonify({
            "success": True,
            "message": "å»ºè®®å·²æ‹’ç»"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/suggestions/apply', methods=['POST'])
def suggestions_apply():
    """åº”ç”¨å»ºè®®"""
    try:
        data = request.json or {}
        suggestion_id = data.get('suggestion_id')
        feedback = data.get('feedback')
        
        if not suggestion_id:
            return jsonify({"error": "ç¼ºå°‘å»ºè®®ID"}), 400
        
        engine = get_suggestion_engine()
        engine.apply_suggestion(suggestion_id, feedback=feedback)
        
        return jsonify({
            "success": True,
            "message": "å»ºè®®å·²åº”ç”¨"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/suggestions/stats', methods=['GET'])
def suggestions_stats():
    """è·å–å»ºè®®ç»Ÿè®¡"""
    try:
        engine = get_suggestion_engine()
        stats = engine.get_statistics()
        
        return jsonify(stats)
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ´å¯ŸæŠ¥å‘Š API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/api/insights/generate-weekly', methods=['POST'])
def insights_generate_weekly():
    """ç”Ÿæˆå‘¨æŠ¥"""
    try:
        reporter = get_insight_reporter()
        report = reporter.generate_weekly_report()
        
        return jsonify({
            "success": True,
            "report": report
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/insights/generate-monthly', methods=['POST'])
def insights_generate_monthly():
    """ç”ŸæˆæœˆæŠ¥"""
    try:
        reporter = get_insight_reporter()
        report = reporter.generate_monthly_report()
        
        return jsonify({
            "success": True,
            "report": report
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/insights/latest', methods=['GET'])
def insights_latest():
    """è·å–æœ€æ–°æŠ¥å‘Š"""
    try:
        report_type = request.args.get('type', 'weekly')
        
        reporter = get_insight_reporter()
        report = reporter.get_latest_report(report_type=report_type)
        
        if report:
            return jsonify({
                "success": True,
                "report": report
            })
        else:
            return jsonify({
                "success": False,
                "message": "æš‚æ— æŠ¥å‘Š"
            })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/insights/export-markdown', methods=['POST'])
def insights_export_markdown():
    """å¯¼å‡ºæŠ¥å‘Šä¸ºMarkdown"""
    try:
        data = request.json or {}
        report = data.get('report')
        output_path = data.get('output_path', 'workspace/report.md')
        
        if not report:
            return jsonify({"error": "ç¼ºå°‘æŠ¥å‘Šæ•°æ®"}), 400
        
        reporter = get_insight_reporter()
        saved_path = reporter.export_report_markdown(report, output_path)
        
        return jsonify({
            "success": True,
            "file_path": saved_path
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ==================== é€šçŸ¥ç®¡ç† API ====================

@app.route('/api/notifications/unread', methods=['GET'])
def get_unread_notifications():
    """è·å–æœªè¯»é€šçŸ¥"""
    try:
        user_id = request.args.get('user_id', 'default')
        limit = int(request.args.get('limit', 50))
        
        manager = get_notification_manager()
        notifications = manager.get_unread_notifications(user_id, limit)
        
        return jsonify({
            "success": True,
            "notifications": notifications,
            "count": len(notifications)
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/notifications/mark-read', methods=['POST'])
def mark_notification_read():
    """æ ‡è®°é€šçŸ¥å·²è¯»"""
    try:
        data = request.json or {}
        notification_id = data.get('notification_id')
        user_id = data.get('user_id', 'default')
        
        if not notification_id:
            return jsonify({"error": "ç¼ºå°‘notification_id"}), 400
        
        manager = get_notification_manager()
        manager.mark_as_read(notification_id, user_id)
        
        return jsonify({"success": True})
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/notifications/dismiss', methods=['POST'])
def dismiss_notification():
    """å¿½ç•¥é€šçŸ¥"""
    try:
        data = request.json or {}
        notification_id = data.get('notification_id')
        user_id = data.get('user_id', 'default')
        
        if not notification_id:
            return jsonify({"error": "ç¼ºå°‘notification_id"}), 400
        
        manager = get_notification_manager()
        manager.dismiss_notification(notification_id, user_id)
        
        return jsonify({"success": True})
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/notifications/stats', methods=['GET'])
def get_notification_stats():
    """è·å–é€šçŸ¥ç»Ÿè®¡"""
    try:
        user_id = request.args.get('user_id', 'default')
        days = int(request.args.get('days', 7))
        
        manager = get_notification_manager()
        stats = manager.get_notification_stats(user_id, days)
        
        return jsonify({
            "success": True,
            "stats": stats
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/notifications/preferences', methods=['GET', 'POST'])
def notification_preferences():
    """è·å–æˆ–è®¾ç½®é€šçŸ¥åå¥½"""
    try:
        user_id = request.args.get('user_id', 'default')
        manager = get_notification_manager()
        
        if request.method == 'GET':
            prefs = manager.get_user_preferences(user_id)
            return jsonify({
                "success": True,
                "preferences": prefs
            })
        
        else:  # POST
            data = request.json or {}
            manager.update_user_preferences(user_id, data)
            return jsonify({"success": True})
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ==================== ä¸»åŠ¨å¯¹è¯ API ====================

@app.route('/api/dialogue/start-monitoring', methods=['POST'])
def start_dialogue_monitoring():
    """å¯åŠ¨ä¸»åŠ¨å¯¹è¯ç›‘æ§"""
    try:
        data = request.json or {}
        check_interval = data.get('check_interval', 300)  # é»˜è®¤5åˆ†é’Ÿ
        
        engine = get_proactive_dialogue()
        engine.start_monitoring(check_interval)
        
        return jsonify({
            "success": True,
            "message": "ä¸»åŠ¨å¯¹è¯ç›‘æ§å·²å¯åŠ¨"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dialogue/stop-monitoring', methods=['POST'])
def stop_dialogue_monitoring():
    """åœæ­¢ä¸»åŠ¨å¯¹è¯ç›‘æ§"""
    try:
        engine = get_proactive_dialogue()
        engine.stop_monitoring()
        
        return jsonify({
            "success": True,
            "message": "ä¸»åŠ¨å¯¹è¯ç›‘æ§å·²åœæ­¢"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dialogue/trigger', methods=['POST'])
def trigger_dialogue():
    """æ‰‹åŠ¨è§¦å‘å¯¹è¯"""
    try:
        data = request.json or {}
        user_id = data.get('user_id', 'default')
        scene_type = data.get('scene_type')
        context = data.get('context', {})
        
        if not scene_type:
            return jsonify({"error": "ç¼ºå°‘scene_type"}), 400
        
        engine = get_proactive_dialogue()
        engine.manual_trigger(user_id, scene_type, **context)
        
        return jsonify({
            "success": True,
            "message": f"å·²è§¦å‘{scene_type}å¯¹è¯"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dialogue/history', methods=['GET'])
def get_dialogue_history():
    """è·å–å¯¹è¯å†å²"""
    try:
        user_id = request.args.get('user_id', 'default')
        limit = int(request.args.get('limit', 50))
        
        engine = get_proactive_dialogue()
        history = engine.get_dialogue_history(user_id, limit)
        
        return jsonify({
            "success": True,
            "history": history,
            "count": len(history)
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ==================== æƒ…å¢ƒæ„ŸçŸ¥ API ====================

@app.route('/api/context/detect', methods=['POST'])
def detect_context():
    """æ£€æµ‹å½“å‰å·¥ä½œåœºæ™¯"""
    try:
        data = request.json or {}
        user_id = data.get('user_id', 'default')
        
        system = get_context_awareness()
        context = system.detect_context(user_id)
        
        return jsonify({
            "success": True,
            "context": context
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/context/current', methods=['GET'])
def get_current_context():
    """è·å–å½“å‰åœºæ™¯"""
    try:
        system = get_context_awareness()
        context = system.get_current_context()
        
        return jsonify({
            "success": True,
            "context": context
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/context/history', methods=['GET'])
def get_context_history():
    """è·å–åœºæ™¯å†å²"""
    try:
        user_id = request.args.get('user_id', 'default')
        days = int(request.args.get('days', 7))
        
        system = get_context_awareness()
        history = system.get_context_history(user_id, days)
        
        return jsonify({
            "success": True,
            "history": history,
            "count": len(history)
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/context/statistics', methods=['GET'])
def get_context_statistics():
    """è·å–åœºæ™¯ç»Ÿè®¡"""
    try:
        user_id = request.args.get('user_id', 'default')
        days = int(request.args.get('days', 30))
        
        system = get_context_awareness()
        stats = system.get_context_statistics(user_id, days)
        
        return jsonify({
            "success": True,
            "statistics": stats
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/context/predict', methods=['GET'])
def predict_next_context():
    """é¢„æµ‹ä¸‹ä¸€ä¸ªåœºæ™¯"""
    try:
        user_id = request.args.get('user_id', 'default')
        
        system = get_context_awareness()
        prediction = system.predict_next_context(user_id)
        
        return jsonify({
            "success": True,
            "prediction": prediction
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ==================== è‡ªåŠ¨æ‰§è¡Œ API ====================

@app.route('/api/execution/authorize', methods=['POST'])
def authorize_task_execution():
    """æˆæƒä»»åŠ¡æ‰§è¡Œ"""
    try:
        data = request.json or {}
        user_id = data.get('user_id', 'default')
        task_type = data.get('task_type')
        auto_execute = data.get('auto_execute', False)
        max_executions_per_day = data.get('max_executions_per_day', 10)
        expires_days = data.get('expires_days', 30)
        
        if not task_type:
            return jsonify({"error": "ç¼ºå°‘task_type"}), 400
        
        engine = get_auto_execution()
        engine.authorize_task(
            user_id, task_type, auto_execute,
            max_executions_per_day, expires_days
        )
        
        return jsonify({
            "success": True,
            "message": f"å·²æˆæƒ{task_type}ä»»åŠ¡"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/execution/revoke', methods=['POST'])
def revoke_task_authorization():
    """æ’¤é”€ä»»åŠ¡æˆæƒ"""
    try:
        data = request.json or {}
        user_id = data.get('user_id', 'default')
        task_type = data.get('task_type')
        
        if not task_type:
            return jsonify({"error": "ç¼ºå°‘task_type"}), 400
        
        engine = get_auto_execution()
        engine.revoke_authorization(user_id, task_type)
        
        return jsonify({
            "success": True,
            "message": f"å·²æ’¤é”€{task_type}ä»»åŠ¡æˆæƒ"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/execution/execute', methods=['POST'])
def execute_task():
    """æ‰§è¡Œä»»åŠ¡"""
    try:
        data = request.json or {}
        user_id = data.get('user_id', 'default')
        task_type = data.get('task_type')
        params = data.get('params', {})
        force = data.get('force', False)
        
        if not task_type:
            return jsonify({"error": "ç¼ºå°‘task_type"}), 400
        
        engine = get_auto_execution()
        result = engine.execute_task(user_id, task_type, params, force)
        
        if result['success']:
            return jsonify(result)
        else:
            return jsonify(result), 400
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/execution/queue', methods=['POST'])
def queue_task():
    """ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—"""
    try:
        data = request.json or {}
        user_id = data.get('user_id', 'default')
        task_type = data.get('task_type')
        params = data.get('params', {})
        priority = data.get('priority', 5)
        
        if not task_type:
            return jsonify({"error": "ç¼ºå°‘task_type"}), 400
        
        engine = get_auto_execution()
        task_id = engine.queue_task(user_id, task_type, params, priority)
        
        return jsonify({
            "success": True,
            "task_id": task_id
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/execution/history', methods=['GET'])
def get_execution_history():
    """è·å–æ‰§è¡Œå†å²"""
    try:
        user_id = request.args.get('user_id', 'default')
        limit = int(request.args.get('limit', 50))
        
        engine = get_auto_execution()
        history = engine.get_execution_history(user_id, limit)
        
        return jsonify({
            "success": True,
            "history": history,
            "count": len(history)
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/execution/statistics', methods=['GET'])
def get_execution_statistics():
    """è·å–æ‰§è¡Œç»Ÿè®¡"""
    try:
        user_id = request.args.get('user_id', 'default')
        days = int(request.args.get('days', 30))
        
        engine = get_auto_execution()
        stats = engine.get_statistics(user_id, days)
        
        return jsonify({
            "success": True,
            "statistics": stats
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/execution/start-processor', methods=['POST'])
def start_execution_processor():
    """å¯åŠ¨è‡ªåŠ¨æ‰§è¡Œå¤„ç†å™¨"""
    try:
        data = request.json or {}
        interval = data.get('interval', 60)  # é»˜è®¤1åˆ†é’Ÿ
        
        engine = get_auto_execution()
        engine.start_queue_processor(interval)
        
        return jsonify({
            "success": True,
            "message": "è‡ªåŠ¨æ‰§è¡Œå¤„ç†å™¨å·²å¯åŠ¨"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/execution/stop-processor', methods=['POST'])
def stop_execution_processor():
    """åœæ­¢è‡ªåŠ¨æ‰§è¡Œå¤„ç†å™¨"""
    try:
        engine = get_auto_execution()
        engine.stop_queue_processor()
        
        return jsonify({
            "success": True,
            "message": "è‡ªåŠ¨æ‰§è¡Œå¤„ç†å™¨å·²åœæ­¢"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ==================== ä¸»åŠ¨äº¤äº’è§¦å‘ç³»ç»Ÿ API ====================

@app.route('/api/triggers/evaluate', methods=['POST'])
def triggers_evaluate():
    """è¯„ä¼°æ˜¯å¦éœ€è¦ä¸»åŠ¨äº¤äº’"""
    try:
        data = request.json or {}
        user_id = data.get('user_id', 'default')
        execute = data.get('execute', True)
        
        system = get_trigger_system()
        decision = system.evaluate_interaction_need(user_id)
        
        if decision and decision.should_interact and execute:
            system.execute_interaction(decision, user_id)
        
        decision_payload = None
        if decision:
            decision_payload = {
                "should_interact": decision.should_interact,
                "interaction_type": decision.interaction_type.value,
                "priority": decision.priority,
                "reason": decision.reason,
                "content": decision.content,
                "scores": {
                    "urgency": decision.urgency_score,
                    "importance": decision.importance_score,
                    "disturbance": decision.disturbance_cost,
                    "final": decision.final_score
                }
            }
        
        return jsonify({
            "success": True,
            "decision": decision_payload
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/triggers/start', methods=['POST'])
def triggers_start():
    """å¯åŠ¨ä¸»åŠ¨äº¤äº’ç›‘æ§"""
    try:
        data = request.json or {}
        user_id = data.get('user_id', 'default')
        interval = data.get('interval', 300)
        
        system = get_trigger_system()
        system.start_monitoring(check_interval=interval, user_id=user_id)
        
        return jsonify({
            "success": True,
            "message": "ä¸»åŠ¨äº¤äº’è§¦å‘ç³»ç»Ÿå·²å¯åŠ¨",
            "interval": interval
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/triggers/stop', methods=['POST'])
def triggers_stop():
    """åœæ­¢ä¸»åŠ¨äº¤äº’ç›‘æ§"""
    try:
        system = get_trigger_system()
        system.stop_monitoring()
        
        return jsonify({
            "success": True,
            "message": "ä¸»åŠ¨äº¤äº’è§¦å‘ç³»ç»Ÿå·²åœæ­¢"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/triggers/stats', methods=['GET'])
def triggers_stats():
    """è·å–è§¦å‘ç»Ÿè®¡"""
    try:
        days = int(request.args.get('days', 7))
        
        system = get_trigger_system()
        stats = system.get_trigger_statistics(days)
        
        return jsonify({
            "success": True,
            "stats": stats
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/triggers/list', methods=['GET'])
def triggers_list():
    """è·å–è§¦å‘å™¨åˆ—è¡¨"""
    try:
        system = get_trigger_system()
        triggers = system.list_triggers()
        
        return jsonify({
            "success": True,
            "triggers": triggers
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/triggers/update', methods=['POST'])
def triggers_update():
    """æ›´æ–°è§¦å‘å™¨é…ç½®"""
    try:
        data = request.json or {}
        trigger_id = data.get('trigger_id')
        
        if not trigger_id:
            return jsonify({"error": "ç¼ºå°‘trigger_id"}), 400
        
        enabled = data.get('enabled')
        priority = data.get('priority')
        cooldown_minutes = data.get('cooldown_minutes')
        threshold_value = data.get('threshold_value')
        parameters = data.get('parameters')
        
        system = get_trigger_system()
        ok = system.update_trigger_config(
            trigger_id,
            enabled=enabled,
            priority=priority,
            cooldown_minutes=cooldown_minutes,
            threshold_value=threshold_value
        )
        
        if not ok:
            return jsonify({"error": "è§¦å‘å™¨ä¸å­˜åœ¨"}), 404
        
        # å¦‚æœæä¾›äº†å‚æ•°ï¼Œæ›´æ–°å‚æ•°
        if parameters is not None:
            system.update_trigger_params(trigger_id, parameters)
        
        return jsonify({
            "success": True,
            "message": "è§¦å‘å™¨é…ç½®å·²æ›´æ–°"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/triggers/params/<trigger_id>', methods=['GET'])
def get_trigger_params(trigger_id):
    """è·å–è§¦å‘å™¨å‚æ•°"""
    try:
        system = get_trigger_system()
        params = system.get_trigger_params(trigger_id)
        
        return jsonify({
            "success": True,
            "trigger_id": trigger_id,
            "parameters": params
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/triggers/params/<trigger_id>', methods=['POST'])
def update_trigger_params_endpoint(trigger_id):
    """æ›´æ–°è§¦å‘å™¨å‚æ•°"""
    try:
        data = request.json or {}
        parameters = data.get('parameters', {})
        
        system = get_trigger_system()
        ok = system.update_trigger_params(trigger_id, parameters)
        
        if not ok:
            return jsonify({"error": "è§¦å‘å™¨ä¸å­˜åœ¨"}), 404
        
        return jsonify({
            "success": True,
            "message": "è§¦å‘å™¨å‚æ•°å·²æ›´æ–°",
            "parameters": system.get_trigger_params(trigger_id)
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/triggers/feedback', methods=['POST'])
def triggers_feedback():
    """æäº¤è§¦å‘åé¦ˆ"""
    try:
        data = request.json or {}
        trigger_id = data.get('trigger_id')
        feedback = data.get('feedback')
        response_time_seconds = data.get('response_time_seconds', 0)
        
        if not trigger_id or not feedback:
            return jsonify({"error": "ç¼ºå°‘trigger_idæˆ–feedback"}), 400
        
        system = get_trigger_system()
        system.record_user_feedback(trigger_id, feedback, response_time_seconds)
        
        return jsonify({
            "success": True,
            "message": "åé¦ˆå·²è®°å½•"
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â•â•â• æ³¨å†Œå¢å¼ºè®°å¿†ç³»ç»ŸAPIï¼ˆæ¨¡å—çº§åˆ«ï¼Œç¡®ä¿å§‹ç»ˆæ‰§è¡Œï¼‰ â•â•â•
try:
    from memory_api_routes import register_memory_routes
    register_memory_routes(app, get_memory_manager)
except ImportError:
    try:
        from web.memory_api_routes import register_memory_routes
        register_memory_routes(app, get_memory_manager)
    except ImportError:
        print("âš ï¸  å¢å¼ºè®°å¿†ç³»ç»ŸAPIæœªæ‰¾åˆ°ï¼Œä½¿ç”¨åŸºç¡€åŠŸèƒ½")


# â•â•â• è‡ªåŠ¨å½’çº³è°ƒåº¦å™¨ API â•â•â•

@app.route('/api/auto-catalog/status', methods=['GET'])
def auto_catalog_status():
    """è·å–è‡ªåŠ¨å½’çº³çŠ¶æ€"""
    try:
        from auto_catalog_scheduler import get_auto_catalog_scheduler
        scheduler = get_auto_catalog_scheduler()
        
        return jsonify({
            "success": True,
            "enabled": scheduler.is_auto_catalog_enabled(),
            "schedule_time": scheduler.get_catalog_schedule(),
            "source_directories": scheduler.get_source_directories(),
            "backup_directory": scheduler.get_backup_directory()
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/api/auto-catalog/enable', methods=['POST'])
def auto_catalog_enable():
    """å¯ç”¨è‡ªåŠ¨å½’çº³"""
    try:
        from auto_catalog_scheduler import get_auto_catalog_scheduler
        scheduler = get_auto_catalog_scheduler()
        
        data = request.json or {}
        schedule_time = data.get('schedule_time', '02:00')
        source_dirs = data.get('source_directories')
        
        scheduler.enable_auto_catalog(schedule_time, source_dirs)
        
        return jsonify({
            "success": True,
            "message": f"è‡ªåŠ¨å½’çº³å·²å¯ç”¨ï¼Œæ¯æ—¥ {schedule_time} æ‰§è¡Œ",
            "schedule_time": schedule_time,
            "source_directories": scheduler.get_source_directories()
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/api/auto-catalog/disable', methods=['POST'])
def auto_catalog_disable():
    """ç¦ç”¨è‡ªåŠ¨å½’çº³"""
    try:
        from auto_catalog_scheduler import get_auto_catalog_scheduler
        scheduler = get_auto_catalog_scheduler()
        
        scheduler.disable_auto_catalog()
        
        return jsonify({
            "success": True,
            "message": "è‡ªåŠ¨å½’çº³å·²ç¦ç”¨"
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/api/auto-catalog/run-now', methods=['POST'])
def auto_catalog_run_now():
    """ç«‹å³æ‰§è¡Œä¸€æ¬¡å½’çº³ï¼ˆæ‰‹åŠ¨è§¦å‘ï¼‰"""
    try:
        from auto_catalog_scheduler import get_auto_catalog_scheduler
        scheduler = get_auto_catalog_scheduler()
        
        result = scheduler.manual_catalog_now()
        
        return jsonify({
            "success": result.get('success', False),
            "total_files": result.get('total_files', 0),
            "organized_count": result.get('organized_count', 0),
            "backed_up_count": result.get('backed_up_count', 0),
            "errors": result.get('errors', []),
            "report_path": result.get('report_path', '')
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/api/auto-catalog/backup-manifest/<path:filename>', methods=['GET'])
def get_backup_manifest(filename):
    """ä¸‹è½½å¤‡ä»½æ¸…å•æ–‡ä»¶"""
    try:
        from auto_catalog_scheduler import get_auto_catalog_scheduler
        scheduler = get_auto_catalog_scheduler()
        
        backup_dir = scheduler.get_backup_directory()
        return send_from_directory(backup_dir, filename, as_attachment=False)
    except Exception as e:
        return jsonify({"error": str(e)}), 404


