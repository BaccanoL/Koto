"""
è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡å¼•æ“ - å…è®¸ç³»ç»Ÿè‡ªåŠ¨æ‰§è¡Œæˆæƒçš„æ“ä½œ

åŠŸèƒ½ï¼š
1. ä»»åŠ¡å®šä¹‰å’Œæ³¨å†Œ
2. ç”¨æˆ·æˆæƒç®¡ç†
3. å®‰å…¨æ£€æŸ¥å’Œé£é™©è¯„ä¼°
4. è‡ªåŠ¨ä»»åŠ¡æ‰§è¡Œ
5. æ‰§è¡Œå†å²å’Œå›æ»š
"""

import json
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Callable, Any
import os
import shutil
from pathlib import Path
import threading
import time


class AutoExecutionEngine:
    """è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡å¼•æ“"""
    
    # ä»»åŠ¡é£é™©ç­‰çº§
    RISK_LEVELS = {
        'safe': {
            'level': 1,
            'description': 'å®Œå…¨å®‰å…¨ï¼Œæ— æ•°æ®é£é™©',
            'require_approval': False,
            'allow_auto_execute': True
        },
        'low': {
            'level': 2,
            'description': 'ä½é£é™©ï¼Œå¯é€†æ“ä½œ',
            'require_approval': False,
            'allow_auto_execute': True
        },
        'medium': {
            'level': 3,
            'description': 'ä¸­ç­‰é£é™©ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤',
            'require_approval': True,
            'allow_auto_execute': False
        },
        'high': {
            'level': 4,
            'description': 'é«˜é£é™©ï¼Œæ¶‰åŠæ–‡ä»¶åˆ é™¤æˆ–ç§»åŠ¨',
            'require_approval': True,
            'allow_auto_execute': False
        },
        'critical': {
            'level': 5,
            'description': 'ä¸¥é‡é£é™©ï¼Œä¸å¯é€†æ“ä½œ',
            'require_approval': True,
            'allow_auto_execute': False
        }
    }
    
    def __init__(
        self,
        db_path: str = "config/auto_execution.db",
        workspace_root: str = "workspace",
        notification_manager=None
    ):
        """åˆå§‹åŒ–è‡ªåŠ¨æ‰§è¡Œå¼•æ“"""
        self.db_path = db_path
        self.workspace_root = workspace_root
        self.notification_manager = notification_manager
        
        # æ³¨å†Œçš„ä»»åŠ¡å¤„ç†å™¨
        self.task_handlers: Dict[str, Callable] = {}
        
        self._init_database()
        self._register_builtin_tasks()
        
        # å®šæœŸä»»åŠ¡æ£€æŸ¥çº¿ç¨‹
        self.running = False
        self.check_thread = None
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ä»»åŠ¡å®šä¹‰è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS task_definitions (
                task_type TEXT PRIMARY KEY,
                task_name TEXT NOT NULL,
                description TEXT,
                risk_level TEXT NOT NULL,
                handler TEXT NOT NULL,
                params_schema TEXT,
                enabled INTEGER DEFAULT 1
            )
        """)
        
        # ç”¨æˆ·æˆæƒè¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_authorizations (
                user_id TEXT NOT NULL,
                task_type TEXT NOT NULL,
                authorized INTEGER DEFAULT 0,
                auto_execute INTEGER DEFAULT 0,
                max_executions_per_day INTEGER DEFAULT 10,
                authorized_at TIMESTAMP,
                expires_at TIMESTAMP,
                PRIMARY KEY (user_id, task_type)
            )
        """)
        
        # æ‰§è¡Œå†å²è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS execution_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                task_type TEXT NOT NULL,
                task_params TEXT,
                status TEXT NOT NULL,
                result TEXT,
                error_message TEXT,
                rollback_data TEXT,
                executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                duration_ms INTEGER
            )
        """)
        
        # å¾…æ‰§è¡Œä»»åŠ¡é˜Ÿåˆ—
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS task_queue (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                task_type TEXT NOT NULL,
                task_params TEXT NOT NULL,
                priority INTEGER DEFAULT 5,
                status TEXT DEFAULT 'pending',
                scheduled_at TIMESTAMP,
                executed_at TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # å›æ»šæ“ä½œè¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS rollback_operations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                execution_id INTEGER NOT NULL,
                operation_type TEXT NOT NULL,
                operation_data TEXT NOT NULL,
                executed INTEGER DEFAULT 0,
                executed_at TIMESTAMP,
                FOREIGN KEY (execution_id) REFERENCES execution_history (id)
            )
        """)
        
        conn.commit()
        conn.close()
    
    def _register_builtin_tasks(self):
        """æ³¨å†Œå†…ç½®ä»»åŠ¡"""
        # æ–‡ä»¶æ•´ç†ä»»åŠ¡
        self.register_task(
            'organize_files',
            'æ•´ç†æ–‡ä»¶',
            'å°†æŒ‡å®šç›®å½•çš„æ–‡ä»¶æŒ‰ç±»å‹åˆ†ç±»åˆ°å­æ–‡ä»¶å¤¹',
            'low',
            self._handler_organize_files
        )
        
        # æ–‡ä»¶å½’æ¡£ä»»åŠ¡
        self.register_task(
            'archive_old_files',
            'å½’æ¡£æ—§æ–‡ä»¶',
            'å°†é•¿æœŸæœªä½¿ç”¨çš„æ–‡ä»¶ç§»åŠ¨åˆ°å½’æ¡£ç›®å½•',
            'medium',
            self._handler_archive_old_files
        )
        
        # å¤‡ä»½æ–‡ä»¶ä»»åŠ¡
        self.register_task(
            'backup_file',
            'å¤‡ä»½æ–‡ä»¶',
            'åˆ›å»ºé‡è¦æ–‡ä»¶çš„å¤‡ä»½å‰¯æœ¬',
            'safe',
            self._handler_backup_file
        )
        
        # æ¸…ç†é‡å¤æ–‡ä»¶
        self.register_task(
            'remove_duplicates',
            'æ¸…ç†é‡å¤æ–‡ä»¶',
            'åˆ é™¤å†…å®¹å®Œå…¨ç›¸åŒçš„é‡å¤æ–‡ä»¶',
            'high',
            self._handler_remove_duplicates
        )
        
        # åˆ›å»ºæ–‡ä»¶å¤¹
        self.register_task(
            'create_folder',
            'åˆ›å»ºæ–‡ä»¶å¤¹',
            'åœ¨æŒ‡å®šä½ç½®åˆ›å»ºæ–°æ–‡ä»¶å¤¹',
            'safe',
            self._handler_create_folder
        )
        
        # é‡å‘½åæ–‡ä»¶
        self.register_task(
            'rename_file',
            'é‡å‘½åæ–‡ä»¶',
            'é‡å‘½åæŒ‡å®šæ–‡ä»¶',
            'low',
            self._handler_rename_file
        )
        
        # ç”ŸæˆæŠ¥å‘Š
        self.register_task(
            'generate_report',
            'ç”ŸæˆæŠ¥å‘Š',
            'è‡ªåŠ¨ç”Ÿæˆå·¥ä½œæŠ¥å‘Š',
            'safe',
            self._handler_generate_report
        )
    
    def register_task(
        self,
        task_type: str,
        task_name: str,
        description: str,
        risk_level: str,
        handler: Callable
    ):
        """æ³¨å†Œä»»åŠ¡ç±»å‹"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT OR REPLACE INTO task_definitions
            (task_type, task_name, description, risk_level, handler)
            VALUES (?, ?, ?, ?, ?)
        """, (task_type, task_name, description, risk_level, handler.__name__))
        
        conn.commit()
        conn.close()
        
        # æ³¨å†Œå¤„ç†å™¨
        self.task_handlers[task_type] = handler
    
    def authorize_task(
        self,
        user_id: str,
        task_type: str,
        auto_execute: bool = False,
        max_executions_per_day: int = 10,
        expires_days: int = 30
    ):
        """æˆæƒç”¨æˆ·æ‰§è¡ŒæŸç±»å‹ä»»åŠ¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        expires_at = (datetime.now() + timedelta(days=expires_days)).isoformat()
        
        cursor.execute("""
            INSERT OR REPLACE INTO user_authorizations
            (user_id, task_type, authorized, auto_execute, max_executions_per_day, 
             authorized_at, expires_at)
            VALUES (?, ?, 1, ?, ?, CURRENT_TIMESTAMP, ?)
        """, (user_id, task_type, int(auto_execute), max_executions_per_day, expires_at))
        
        conn.commit()
        conn.close()
    
    def revoke_authorization(self, user_id: str, task_type: str):
        """æ’¤é”€æˆæƒ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            UPDATE user_authorizations
            SET authorized = 0, auto_execute = 0
            WHERE user_id = ? AND task_type = ?
        """, (user_id, task_type))
        
        conn.commit()
        conn.close()
    
    def can_execute(self, user_id: str, task_type: str) -> tuple[bool, str]:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰§è¡Œä»»åŠ¡"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ£€æŸ¥æˆæƒ
        cursor.execute("""
            SELECT * FROM user_authorizations
            WHERE user_id = ? AND task_type = ? AND authorized = 1
        """, (user_id, task_type))
        
        auth = cursor.fetchone()
        if not auth:
            return False, "æœªæˆæƒæ­¤ç±»å‹ä»»åŠ¡"
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if auth['expires_at']:
            expires_at = datetime.fromisoformat(auth['expires_at'])
            if datetime.now() > expires_at:
                return False, "æˆæƒå·²è¿‡æœŸ"
        
        # æ£€æŸ¥æ¯æ—¥æ‰§è¡Œæ¬¡æ•°é™åˆ¶
        today = datetime.now().date()
        cursor.execute("""
            SELECT COUNT(*) FROM execution_history
            WHERE user_id = ? AND task_type = ? AND DATE(executed_at) = ?
        """, (user_id, task_type, today))
        
        today_count = cursor.fetchone()[0]
        if today_count >= auth['max_executions_per_day']:
            return False, f"å·²è¾¾æ¯æ—¥æ‰§è¡Œä¸Šé™ ({auth['max_executions_per_day']}æ¬¡)"
        
        conn.close()
        return True, "OK"
    
    def execute_task(
        self,
        user_id: str,
        task_type: str,
        params: Dict,
        force: bool = False
    ) -> Dict:
        """
        æ‰§è¡Œä»»åŠ¡
        
        Returns:
            {
                'success': True/False,
                'execution_id': 123,
                'result': {...},
                'error': None
            }
        """
        start_time = time.time()
        
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        if task_type not in self.task_handlers:
            return {
                'success': False,
                'error': f'æœªçŸ¥çš„ä»»åŠ¡ç±»å‹: {task_type}'
            }
        
        # æ£€æŸ¥æˆæƒ
        if not force:
            can_exec, reason = self.can_execute(user_id, task_type)
            if not can_exec:
                return {
                    'success': False,
                    'error': f'æ— æ³•æ‰§è¡Œ: {reason}'
                }
        
        # æ‰§è¡Œä»»åŠ¡
        try:
            handler = self.task_handlers[task_type]
            result = handler(params)
            
            duration_ms = int((time.time() - start_time) * 1000)
            
            # è®°å½•æ‰§è¡Œå†å²
            execution_id = self._save_execution_history(
                user_id, task_type, params, 'success', result, None, duration_ms
            )
            
            return {
                'success': True,
                'execution_id': execution_id,
                'result': result,
                'error': None,
                'duration_ms': duration_ms
            }
        
        except Exception as e:
            duration_ms = int((time.time() - start_time) * 1000)
            
            # è®°å½•æ‰§è¡Œå¤±è´¥
            execution_id = self._save_execution_history(
                user_id, task_type, params, 'failed', None, str(e), duration_ms
            )
            
            return {
                'success': False,
                'execution_id': execution_id,
                'error': str(e),
                'duration_ms': duration_ms
            }
    
    def _save_execution_history(
        self,
        user_id: str,
        task_type: str,
        params: Dict,
        status: str,
        result: Optional[Dict],
        error: Optional[str],
        duration_ms: int
    ) -> int:
        """ä¿å­˜æ‰§è¡Œå†å²"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO execution_history
            (user_id, task_type, task_params, status, result, error_message, duration_ms)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            user_id, task_type,
            json.dumps(params),
            status,
            json.dumps(result) if result else None,
            error,
            duration_ms
        ))
        
        execution_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return execution_id
    
    def queue_task(
        self,
        user_id: str,
        task_type: str,
        params: Dict,
        priority: int = 5,
        scheduled_at: Optional[datetime] = None
    ) -> int:
        """å°†ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO task_queue
            (user_id, task_type, task_params, priority, scheduled_at)
            VALUES (?, ?, ?, ?, ?)
        """, (
            user_id, task_type,
            json.dumps(params),
            priority,
            scheduled_at.isoformat() if scheduled_at else None
        ))
        
        task_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return task_id
    
    def process_queue(self):
        """å¤„ç†ä»»åŠ¡é˜Ÿåˆ—"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # è·å–å¾…æ‰§è¡Œä»»åŠ¡
        cursor.execute("""
            SELECT * FROM task_queue
            WHERE status = 'pending'
                AND (scheduled_at IS NULL OR scheduled_at <= CURRENT_TIMESTAMP)
            ORDER BY priority DESC, created_at ASC
            LIMIT 10
        """)
        
        tasks = cursor.fetchall()
        conn.close()
        
        for task in tasks:
            # æ›´æ–°çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
            self._update_task_status(task['id'], 'processing')
            
            # æ‰§è¡Œä»»åŠ¡
            result = self.execute_task(
                task['user_id'],
                task['task_type'],
                json.loads(task['task_params']),
                force=False
            )
            
            # æ›´æ–°æœ€ç»ˆçŠ¶æ€
            if result['success']:
                self._update_task_status(task['id'], 'completed')
            else:
                self._update_task_status(task['id'], 'failed')
    
    def _update_task_status(self, task_id: int, status: str):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if status in ['completed', 'failed']:
            cursor.execute("""
                UPDATE task_queue
                SET status = ?, executed_at = CURRENT_TIMESTAMP
                WHERE id = ?
            """, (status, task_id))
        else:
            cursor.execute("""
                UPDATE task_queue
                SET status = ?
                WHERE id = ?
            """, (status, task_id))
        
        conn.commit()
        conn.close()
    
    def start_queue_processor(self, interval: int = 60):
        """å¯åŠ¨é˜Ÿåˆ—å¤„ç†å™¨ï¼ˆæ¯åˆ†é’Ÿæ£€æŸ¥ï¼‰"""
        if self.running:
            return
        
        self.running = True
        self.check_thread = threading.Thread(
            target=self._queue_processing_loop,
            args=(interval,),
            daemon=True
        )
        self.check_thread.start()
        print("âœ… è‡ªåŠ¨æ‰§è¡Œå¼•æ“å·²å¯åŠ¨")
    
    def stop_queue_processor(self):
        """åœæ­¢é˜Ÿåˆ—å¤„ç†å™¨"""
        self.running = False
        if self.check_thread:
            self.check_thread.join(timeout=5)
        print("ğŸ›‘ è‡ªåŠ¨æ‰§è¡Œå¼•æ“å·²åœæ­¢")
    
    def _queue_processing_loop(self, interval: int):
        """é˜Ÿåˆ—å¤„ç†å¾ªç¯"""
        while self.running:
            try:
                self.process_queue()
            except Exception as e:
                print(f"é˜Ÿåˆ—å¤„ç†å‡ºé”™: {e}")
            
            time.sleep(interval)
    
    # ==================== å†…ç½®ä»»åŠ¡å¤„ç†å™¨ ====================
    
    def _handler_organize_files(self, params: Dict) -> Dict:
        """æ•´ç†æ–‡ä»¶å¤„ç†å™¨"""
        directory = params.get('directory', 'workspace')
        target_dir = os.path.join(self.workspace_root, directory)
        
        if not os.path.exists(target_dir):
            raise ValueError(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
        
        # æŒ‰æ–‡ä»¶æ‰©å±•ååˆ†ç±»
        file_types = {}
        for filename in os.listdir(target_dir):
            file_path = os.path.join(target_dir, filename)
            if os.path.isfile(file_path):
                ext = os.path.splitext(filename)[1].lower() or 'no_extension'
                if ext not in file_types:
                    file_types[ext] = []
                file_types[ext].append(filename)
        
        # åˆ›å»ºåˆ†ç±»æ–‡ä»¶å¤¹å¹¶ç§»åŠ¨æ–‡ä»¶
        moved_files = []
        for ext, files in file_types.items():
            if len(files) < 3:  # å°‘äº3ä¸ªæ–‡ä»¶ä¸å•ç‹¬åˆ†ç±»
                continue
            
            category_name = ext[1:] if ext.startswith('.') else ext
            category_dir = os.path.join(target_dir, f"{category_name}_files")
            os.makedirs(category_dir, exist_ok=True)
            
            for filename in files:
                src = os.path.join(target_dir, filename)
                dst = os.path.join(category_dir, filename)
                shutil.move(src, dst)
                moved_files.append({
                    'file': filename,
                    'from': directory,
                    'to': f"{directory}/{category_name}_files"
                })
        
        return {
            'directory': directory,
            'categories_created': len(file_types),
            'files_moved': len(moved_files),
            'details': moved_files
        }
    
    def _handler_archive_old_files(self, params: Dict) -> Dict:
        """å½’æ¡£æ—§æ–‡ä»¶å¤„ç†å™¨"""
        directory = params.get('directory', 'workspace')
        days_threshold = params.get('days', 90)
        
        target_dir = os.path.join(self.workspace_root, directory)
        archive_dir = os.path.join(self.workspace_root, 'archive', datetime.now().strftime('%Y%m%d'))
        os.makedirs(archive_dir, exist_ok=True)
        
        archived_files = []
        threshold_date = datetime.now() - timedelta(days=days_threshold)
        
        for filename in os.listdir(target_dir):
            file_path = os.path.join(target_dir, filename)
            if os.path.isfile(file_path):
                mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                if mtime < threshold_date:
                    dst = os.path.join(archive_dir, filename)
                    shutil.move(file_path, dst)
                    archived_files.append({
                        'file': filename,
                        'last_modified': mtime.isoformat(),
                        'archived_to': archive_dir
                    })
        
        return {
            'directory': directory,
            'days_threshold': days_threshold,
            'files_archived': len(archived_files),
            'archive_location': archive_dir,
            'details': archived_files
        }
    
    def _handler_backup_file(self, params: Dict) -> Dict:
        """å¤‡ä»½æ–‡ä»¶å¤„ç†å™¨"""
        file_path = params.get('file_path')
        if not file_path:
            raise ValueError("ç¼ºå°‘file_pathå‚æ•°")
        
        full_path = os.path.join(self.workspace_root, file_path)
        if not os.path.exists(full_path):
            raise ValueError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        backup_dir = os.path.join(self.workspace_root, 'backups', datetime.now().strftime('%Y%m%d'))
        os.makedirs(backup_dir, exist_ok=True)
        
        # å¤‡ä»½æ–‡ä»¶
        filename = os.path.basename(file_path)
        timestamp = datetime.now().strftime('%H%M%S')
        backup_name = f"{os.path.splitext(filename)[0]}_{timestamp}{os.path.splitext(filename)[1]}"
        backup_path = os.path.join(backup_dir, backup_name)
        
        shutil.copy2(full_path, backup_path)
        
        return {
            'original_file': file_path,
            'backup_path': os.path.relpath(backup_path, self.workspace_root),
            'backup_size': os.path.getsize(backup_path),
            'timestamp': datetime.now().isoformat()
        }
    
    def _handler_remove_duplicates(self, params: Dict) -> Dict:
        """æ¸…ç†é‡å¤æ–‡ä»¶å¤„ç†å™¨"""
        # è¿™æ˜¯ä¸€ä¸ªé«˜é£é™©æ“ä½œï¼Œéœ€è¦è°¨æ…å®ç°
        return {
            'message': 'é‡å¤æ–‡ä»¶æ£€æµ‹åŠŸèƒ½å¾…å®ç°',
            'risk_level': 'high'
        }
    
    def _handler_create_folder(self, params: Dict) -> Dict:
        """åˆ›å»ºæ–‡ä»¶å¤¹å¤„ç†å™¨"""
        folder_path = params.get('folder_path')
        if not folder_path:
            raise ValueError("ç¼ºå°‘folder_pathå‚æ•°")
        
        full_path = os.path.join(self.workspace_root, folder_path)
        os.makedirs(full_path, exist_ok=True)
        
        return {
            'folder_path': folder_path,
            'full_path': full_path,
            'created': True
        }
    
    def _handler_rename_file(self, params: Dict) -> Dict:
        """é‡å‘½åæ–‡ä»¶å¤„ç†å™¨"""
        old_path = params.get('old_path')
        new_name = params.get('new_name')
        
        if not old_path or not new_name:
            raise ValueError("ç¼ºå°‘old_pathæˆ–new_nameå‚æ•°")
        
        full_old_path = os.path.join(self.workspace_root, old_path)
        if not os.path.exists(full_old_path):
            raise ValueError(f"æ–‡ä»¶ä¸å­˜åœ¨: {old_path}")
        
        directory = os.path.dirname(full_old_path)
        full_new_path = os.path.join(directory, new_name)
        
        os.rename(full_old_path, full_new_path)
        
        return {
            'old_path': old_path,
            'new_path': os.path.relpath(full_new_path, self.workspace_root),
            'renamed': True
        }
    
    def _handler_generate_report(self, params: Dict) -> Dict:
        """ç”ŸæˆæŠ¥å‘Šå¤„ç†å™¨"""
        report_type = params.get('type', 'weekly')
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨insight_reporter
        return {
            'report_type': report_type,
            'generated': True,
            'message': 'æŠ¥å‘Šç”ŸæˆåŠŸèƒ½éœ€è¦é›†æˆinsight_reporteræ¨¡å—'
        }
    
    def get_execution_history(
        self, user_id: str, limit: int = 50
    ) -> List[Dict]:
        """è·å–æ‰§è¡Œå†å²"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT * FROM execution_history
            WHERE user_id = ?
            ORDER BY executed_at DESC
            LIMIT ?
        """, (user_id, limit))
        
        rows = cursor.fetchall()
        conn.close()
        
        return [dict(row) for row in rows]
    
    def get_statistics(self, user_id: str, days: int = 30) -> Dict:
        """è·å–æ‰§è¡Œç»Ÿè®¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        start_date = (datetime.now() - timedelta(days=days)).date()
        
        # æ€»æ‰§è¡Œæ¬¡æ•°
        cursor.execute("""
            SELECT COUNT(*) FROM execution_history
            WHERE user_id = ? AND DATE(executed_at) >= ?
        """, (user_id, start_date))
        total_executions = cursor.fetchone()[0]
        
        # æˆåŠŸç‡
        cursor.execute("""
            SELECT COUNT(*) FROM execution_history
            WHERE user_id = ? AND DATE(executed_at) >= ? AND status = 'success'
        """, (user_id, start_date))
        successful = cursor.fetchone()[0]
        
        # æŒ‰ä»»åŠ¡ç±»å‹ç»Ÿè®¡
        cursor.execute("""
            SELECT task_type, COUNT(*) as count, 
                   SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END) as success_count
            FROM execution_history
            WHERE user_id = ? AND DATE(executed_at) >= ?
            GROUP BY task_type
        """, (user_id, start_date))
        
        by_type = {}
        for row in cursor.fetchall():
            by_type[row[0]] = {
                'total': row[1],
                'successful': row[2],
                'success_rate': (row[2] / row[1] * 100) if row[1] > 0 else 0
            }
        
        conn.close()
        
        return {
            'period_days': days,
            'total_executions': total_executions,
            'successful_executions': successful,
            'success_rate': (successful / total_executions * 100) if total_executions > 0 else 0,
            'by_task_type': by_type
        }


# å…¨å±€å®ä¾‹
_auto_execution_instance = None

def get_auto_execution_engine(
    db_path: str = "config/auto_execution.db",
    workspace_root: str = "workspace",
    notification_manager=None
) -> AutoExecutionEngine:
    """è·å–è‡ªåŠ¨æ‰§è¡Œå¼•æ“å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _auto_execution_instance
    if _auto_execution_instance is None:
        _auto_execution_instance = AutoExecutionEngine(
            db_path, workspace_root, notification_manager
        )
    return _auto_execution_instance
