#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†å›¾è°±æ¨¡å— - æ„å»ºæ–‡ä»¶å…³ç³»ç½‘ç»œ
å°†æ–‡ä»¶ã€æ¦‚å¿µå’Œå…³è”å…³ç³»ç»„ç»‡æˆå¯è§†åŒ–çš„çŸ¥è¯†å›¾è°±
"""

import sqlite3
import json
from typing import List, Dict, Set, Tuple
from collections import defaultdict
from datetime import datetime
from pathlib import Path
import math

from concept_extractor import ConceptExtractor


class KnowledgeGraph:
    """çŸ¥è¯†å›¾è°± - æ–‡ä»¶å…³ç³»ç½‘ç»œç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "config/knowledge_graph.db"):
        """
        åˆå§‹åŒ–çŸ¥è¯†å›¾è°±
        
        Args:
            db_path: å›¾æ•°æ®åº“è·¯å¾„
        """
        self.db_path = db_path
        self.concept_extractor = ConceptExtractor()
        self._ensure_db()
    
    def _ensure_db(self):
        """ç¡®ä¿æ•°æ®åº“å’Œè¡¨ç»“æ„å­˜åœ¨"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # èŠ‚ç‚¹è¡¨ - å­˜å‚¨æ–‡ä»¶å’Œæ¦‚å¿µèŠ‚ç‚¹
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS nodes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                node_id TEXT UNIQUE NOT NULL,
                node_type TEXT NOT NULL,  -- 'file' or 'concept'
                label TEXT NOT NULL,
                metadata TEXT,  -- JSONæ ¼å¼çš„é¢å¤–ä¿¡æ¯
                created_at TEXT NOT NULL,
                updated_at TEXT NOT NULL
            )
        """)
        
        # è¾¹è¡¨ - å­˜å‚¨èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS edges (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_id TEXT NOT NULL,
                target_id TEXT NOT NULL,
                edge_type TEXT NOT NULL,  -- 'contains', 'relates_to', 'shares_concept'
                weight REAL DEFAULT 1.0,
                metadata TEXT,
                created_at TEXT NOT NULL,
                UNIQUE(source_id, target_id, edge_type)
            )
        """)
        
        # å›¾å¿«ç…§è¡¨ - å­˜å‚¨å®Œæ•´å›¾çš„å¿«ç…§ç”¨äºå¿«é€ŸåŠ è½½
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS graph_snapshots (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                snapshot_data TEXT NOT NULL,  -- JSONæ ¼å¼çš„å®Œæ•´å›¾æ•°æ®
                node_count INTEGER,
                edge_count INTEGER,
                created_at TEXT NOT NULL
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_nodes_type ON nodes(node_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_edges_source ON edges(source_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_edges_target ON edges(target_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_edges_weight ON edges(weight DESC)")
        
        conn.commit()
        conn.close()
    
    def add_file_node(self, file_path: str, metadata: Dict = None) -> str:
        """
        æ·»åŠ æ–‡ä»¶èŠ‚ç‚¹åˆ°å›¾ä¸­
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            metadata: æ–‡ä»¶å…ƒæ•°æ®
            
        Returns:
            èŠ‚ç‚¹ID
        """
        node_id = f"file:{file_path}"
        label = Path(file_path).name
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        current_time = datetime.now().isoformat()
        metadata_json = json.dumps(metadata or {})
        
        cursor.execute("""
            INSERT OR REPLACE INTO nodes (node_id, node_type, label, metadata, created_at, updated_at)
            VALUES (?, 'file', ?, ?, ?, ?)
        """, (node_id, label, metadata_json, current_time, current_time))
        
        conn.commit()
        conn.close()
        
        return node_id
    
    def add_concept_node(self, concept: str, metadata: Dict = None) -> str:
        """
        æ·»åŠ æ¦‚å¿µèŠ‚ç‚¹åˆ°å›¾ä¸­
        
        Args:
            concept: æ¦‚å¿µåç§°
            metadata: æ¦‚å¿µå…ƒæ•°æ®
            
        Returns:
            èŠ‚ç‚¹ID
        """
        node_id = f"concept:{concept}"
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        current_time = datetime.now().isoformat()
        metadata_json = json.dumps(metadata or {})
        
        cursor.execute("""
            INSERT OR REPLACE INTO nodes (node_id, node_type, label, metadata, created_at, updated_at)
            VALUES (?, 'concept', ?, ?, ?, ?)
        """, (node_id, concept, metadata_json, current_time, current_time))
        
        conn.commit()
        conn.close()
        
        return node_id
    
    def add_edge(self, source_id: str, target_id: str, edge_type: str, 
                 weight: float = 1.0, metadata: Dict = None):
        """
        æ·»åŠ è¾¹åˆ°å›¾ä¸­
        
        Args:
            source_id: æºèŠ‚ç‚¹ID
            target_id: ç›®æ ‡èŠ‚ç‚¹ID
            edge_type: è¾¹ç±»å‹
            weight: è¾¹çš„æƒé‡
            metadata: è¾¹çš„å…ƒæ•°æ®
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        current_time = datetime.now().isoformat()
        metadata_json = json.dumps(metadata or {})
        
        cursor.execute("""
            INSERT OR REPLACE INTO edges (source_id, target_id, edge_type, weight, metadata, created_at)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (source_id, target_id, edge_type, weight, metadata_json, current_time))
        
        conn.commit()
        conn.close()
    
    def build_file_graph(self, file_paths: List[str], force_rebuild: bool = False):
        """
        ä¸ºæ–‡ä»¶åˆ—è¡¨æ„å»ºçŸ¥è¯†å›¾è°±
        
        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»ºå›¾
        """
        print(f"ğŸ”¨ å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±... ({len(file_paths)} ä¸ªæ–‡ä»¶)")
        
        for i, file_path in enumerate(file_paths, 1):
            try:
                # åˆ†ææ–‡ä»¶æå–æ¦‚å¿µ
                result = self.concept_extractor.analyze_file(file_path)
                
                if "error" in result:
                    continue
                
                # æ·»åŠ æ–‡ä»¶èŠ‚ç‚¹
                file_node_id = self.add_file_node(file_path, {
                    "analyzed_at": result.get("analyzed_at"),
                    "cached": result.get("cached", False)
                })
                
                # æ·»åŠ æ¦‚å¿µèŠ‚ç‚¹å’Œè¾¹
                for concept_data in result.get("concepts", []):
                    concept = concept_data["concept"]
                    score = concept_data["score"]
                    
                    # æ·»åŠ æ¦‚å¿µèŠ‚ç‚¹
                    concept_node_id = self.add_concept_node(concept, {
                        "score": score
                    })
                    
                    # æ·»åŠ  file -> concept è¾¹
                    self.add_edge(
                        file_node_id, 
                        concept_node_id,
                        "contains",
                        weight=score,
                        metadata={"tf_idf_score": score}
                    )
                
                if i % 10 == 0:
                    print(f"  âœ“ å·²å¤„ç† {i}/{len(file_paths)} ä¸ªæ–‡ä»¶")
                    
            except Exception as e:
                print(f"  âœ— å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
        
        # æ„å»ºæ–‡ä»¶é—´å…³è”
        self._build_file_relations()
        
        # åˆ›å»ºå¿«ç…§
        self._create_snapshot()
        
        print(f"âœ… çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ")
    
    def _build_file_relations(self):
        """æ„å»ºæ–‡ä»¶ä¹‹é—´çš„å…³è”è¾¹"""
        print("ğŸ”— æ„å»ºæ–‡ä»¶å…³è”...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰æ–‡ä»¶èŠ‚ç‚¹
        cursor.execute("SELECT node_id FROM nodes WHERE node_type = 'file'")
        file_nodes = [row[0] for row in cursor.fetchall()]
        
        relation_count = 0
        
        for file_node_id in file_nodes:
            file_path = file_node_id.replace("file:", "")
            
            # æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶
            related_files = self.concept_extractor.find_related_files(file_path, limit=5)
            
            for related in related_files:
                related_path = related["file_path"]
                similarity = related["similarity"]
                
                if similarity > 0.1:  # åªä¿ç•™ç›¸ä¼¼åº¦å¤§äº0.1çš„å…³è”
                    related_node_id = f"file:{related_path}"
                    
                    self.add_edge(
                        file_node_id,
                        related_node_id,
                        "relates_to",
                        weight=similarity,
                        metadata={
                            "similarity": similarity,
                            "shared_concepts": related["shared_concepts"]
                        }
                    )
                    
                    relation_count += 1
        
        conn.close()
        
        print(f"  âœ“ åˆ›å»ºäº† {relation_count} ä¸ªæ–‡ä»¶å…³è”")
    
    def get_graph_data(self, max_nodes: int = 100) -> Dict:
        """
        è·å–å›¾æ•°æ®ç”¨äºå¯è§†åŒ–
        
        Args:
            max_nodes: æœ€å¤šè¿”å›çš„èŠ‚ç‚¹æ•°
            
        Returns:
            D3.jsæ ¼å¼çš„å›¾æ•°æ®
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–èŠ‚ç‚¹
        cursor.execute("""
            SELECT node_id, node_type, label, metadata
            FROM nodes
            LIMIT ?
        """, (max_nodes,))
        
        nodes = []
        node_ids = set()
        
        for row in cursor.fetchall():
            node_id, node_type, label, metadata_str = row
            node_ids.add(node_id)
            
            try:
                metadata = json.loads(metadata_str)
            except:
                metadata = {}
            
            nodes.append({
                "id": node_id,
                "type": node_type,
                "label": label,
                "metadata": metadata
            })
        
        # è·å–è¾¹ï¼ˆåªåŒ…å«å·²åŠ è½½èŠ‚ç‚¹ä¹‹é—´çš„è¾¹ï¼‰
        if node_ids:
            placeholders = ','.join(['?' for _ in node_ids])
            cursor.execute(f"""
                SELECT source_id, target_id, edge_type, weight, metadata
                FROM edges
                WHERE source_id IN ({placeholders}) AND target_id IN ({placeholders})
            """, (*node_ids, *node_ids))
            
            edges = []
            for row in cursor.fetchall():
                source, target, edge_type, weight, metadata_str = row
                
                try:
                    metadata = json.loads(metadata_str)
                except:
                    metadata = {}
                
                edges.append({
                    "source": source,
                    "target": target,
                    "type": edge_type,
                    "weight": weight,
                    "metadata": metadata
                })
        else:
            edges = []
        
        conn.close()
        
        return {
            "nodes": nodes,
            "edges": edges,
            "metadata": {
                "total_nodes": len(nodes),
                "total_edges": len(edges),
                "generated_at": datetime.now().isoformat()
            }
        }
    
    def get_file_neighbors(self, file_path: str, depth: int = 1) -> Dict:
        """
        è·å–æ–‡ä»¶çš„é‚»å±…èŠ‚ç‚¹ï¼ˆç›¸å…³æ–‡ä»¶å’Œæ¦‚å¿µï¼‰
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            depth: æœç´¢æ·±åº¦
            
        Returns:
            é‚»å±…å›¾æ•°æ®
        """
        file_node_id = f"file:{file_path}"
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
        cursor.execute("SELECT 1 FROM nodes WHERE node_id = ?", (file_node_id,))
        if not cursor.fetchone():
            conn.close()
            return {"error": "æ–‡ä»¶èŠ‚ç‚¹ä¸å­˜åœ¨"}
        
        visited_nodes = set([file_node_id])
        nodes_to_visit = [file_node_id]
        all_nodes = []
        all_edges = []
        
        for _ in range(depth):
            if not nodes_to_visit:
                break
            
            current_batch = nodes_to_visit
            nodes_to_visit = []
            
            for current_node in current_batch:
                # è·å–èŠ‚ç‚¹ä¿¡æ¯
                cursor.execute("""
                    SELECT node_id, node_type, label, metadata
                    FROM nodes
                    WHERE node_id = ?
                """, (current_node,))
                
                node_data = cursor.fetchone()
                if node_data:
                    node_id, node_type, label, metadata_str = node_data
                    try:
                        metadata = json.loads(metadata_str)
                    except:
                        metadata = {}
                    
                    all_nodes.append({
                        "id": node_id,
                        "type": node_type,
                        "label": label,
                        "metadata": metadata
                    })
                
                # è·å–å‡ºè¾¹
                cursor.execute("""
                    SELECT target_id, edge_type, weight, metadata
                    FROM edges
                    WHERE source_id = ?
                    ORDER BY weight DESC
                    LIMIT 10
                """, (current_node,))
                
                for row in cursor.fetchall():
                    target, edge_type, weight, metadata_str = row
                    
                    try:
                        metadata = json.loads(metadata_str)
                    except:
                        metadata = {}
                    
                    all_edges.append({
                        "source": current_node,
                        "target": target,
                        "type": edge_type,
                        "weight": weight,
                        "metadata": metadata
                    })
                    
                    if target not in visited_nodes:
                        visited_nodes.add(target)
                        nodes_to_visit.append(target)
        
        conn.close()
        
        return {
            "nodes": all_nodes,
            "edges": all_edges,
            "center_node": file_node_id,
            "depth": depth
        }
    
    def get_concept_cluster(self, concept: str, limit: int = 20) -> Dict:
        """
        è·å–ä¸æ¦‚å¿µç›¸å…³çš„æ–‡ä»¶é›†ç¾¤
        
        Args:
            concept: æ¦‚å¿µåç§°
            limit: æœ€å¤šè¿”å›çš„æ–‡ä»¶æ•°
            
        Returns:
            æ–‡ä»¶é›†ç¾¤æ•°æ®
        """
        concept_node_id = f"concept:{concept}"
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æŸ¥æ‰¾åŒ…å«è¯¥æ¦‚å¿µçš„æ–‡ä»¶
        cursor.execute("""
            SELECT e.source_id, e.weight, n.label, n.metadata
            FROM edges e
            JOIN nodes n ON e.source_id = n.node_id
            WHERE e.target_id = ? AND e.edge_type = 'contains'
            ORDER BY e.weight DESC
            LIMIT ?
        """, (concept_node_id, limit))
        
        files = []
        for row in cursor.fetchall():
            file_id, weight, label, metadata_str = row
            
            try:
                metadata = json.loads(metadata_str)
            except:
                metadata = {}
            
            files.append({
                "file_id": file_id,
                "file_path": file_id.replace("file:", ""),
                "label": label,
                "relevance": weight,
                "metadata": metadata
            })
        
        conn.close()
        
        return {
            "concept": concept,
            "file_count": len(files),
            "files": files
        }
    
    def _create_snapshot(self):
        """åˆ›å»ºå›¾çš„å¿«ç…§"""
        graph_data = self.get_graph_data(max_nodes=1000)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO graph_snapshots (snapshot_data, node_count, edge_count, created_at)
            VALUES (?, ?, ?, ?)
        """, (
            json.dumps(graph_data),
            graph_data["metadata"]["total_nodes"],
            graph_data["metadata"]["total_edges"],
            datetime.now().isoformat()
        ))
        
        # åªä¿ç•™æœ€è¿‘3ä¸ªå¿«ç…§
        cursor.execute("""
            DELETE FROM graph_snapshots
            WHERE id NOT IN (
                SELECT id FROM graph_snapshots
                ORDER BY created_at DESC
                LIMIT 3
            )
        """)
        
        conn.commit()
        conn.close()
    
    def get_statistics(self) -> Dict:
        """è·å–å›¾ç»Ÿè®¡ä¿¡æ¯"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM nodes WHERE node_type = 'file'")
        file_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM nodes WHERE node_type = 'concept'")
        concept_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM edges WHERE edge_type = 'contains'")
        contains_edges = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM edges WHERE edge_type = 'relates_to'")
        relation_edges = cursor.fetchone()[0]
        
        cursor.execute("SELECT AVG(degree) FROM (SELECT COUNT(*) as degree FROM edges GROUP BY source_id)")
        avg_degree = cursor.fetchone()[0] or 0
        
        conn.close()
        
        return {
            "total_files": file_count,
            "total_concepts": concept_count,
            "file_concept_edges": contains_edges,
            "file_relation_edges": relation_edges,
            "average_degree": round(avg_degree, 2),
            "graph_density": round(relation_edges / max(file_count * (file_count - 1), 1), 4)
        }


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    kg = KnowledgeGraph()
    
    print("ğŸ“Š çŸ¥è¯†å›¾è°±æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•æ·»åŠ èŠ‚ç‚¹
    file_id = kg.add_file_node("test_doc.txt", {"size": 1024})
    concept_id = kg.add_concept_node("æœºå™¨å­¦ä¹ ", {"frequency": 10})
    
    # æµ‹è¯•æ·»åŠ è¾¹
    kg.add_edge(file_id, concept_id, "contains", weight=0.8)
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = kg.get_statistics()
    print("\nå›¾ç»Ÿè®¡ä¿¡æ¯ï¼š")
    for key, value in stats.items():
        print(f"  â€¢ {key}: {value}")
    
    print("\n" + "=" * 50)
    print("âœ… çŸ¥è¯†å›¾è°±æ¨¡å—å·²å°±ç»ª")
