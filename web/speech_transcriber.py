#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è¯­éŸ³è½¬å†™ä¸æ€»ç»“ç³»ç»Ÿ - å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ï¼Œå¹¶è‡ªåŠ¨æå–å…³é”®æ€»ç»“
"""

import os
import json
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path


class SpeechTranscriber:
    """è¯­éŸ³è½¬å†™ä¸æ€»ç»“ç³»ç»Ÿ"""
    
    def __init__(self, output_dir: str = "workspace/transcripts"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å¼•æ“
        self.recognizer = self._init_recognizer()
    
    def _init_recognizer(self):
        """åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å¼•æ“"""
        try:
            # ä¼˜å…ˆä½¿ç”¨ SpeechRecognition åº“ï¼ˆæ”¯æŒå¤šç§å¼•æ“ï¼‰
            import speech_recognition as sr
            return sr.Recognizer()
        except ImportError:
            print("âš ï¸ æœªå®‰è£… SpeechRecognition åº“")
            print("å®‰è£…æ–¹æ³•: pip install SpeechRecognition pydub")
            return None
    
    def transcribe_audio_file(self, audio_path: str, language: str = "zh-CN") -> Dict[str, Any]:
        """
        è½¬å†™éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ .mp3, .wav, .m4a ç­‰ï¼‰
            language: è¯­è¨€ä»£ç ï¼ˆzh-CN/en-US/etcï¼‰
        
        Returns:
            è½¬å†™ç»“æœ
        """
        if self.recognizer is None:
            return {
                "success": False,
                "error": "è¯­éŸ³è¯†åˆ«å¼•æ“æœªåˆå§‹åŒ–ï¼Œè¯·å®‰è£… SpeechRecognition"
            }
        
        if not os.path.exists(audio_path):
            return {
                "success": False,
                "error": f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}"
            }
        
        try:
            import speech_recognition as sr
            
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            with sr.AudioFile(audio_path) as source:
                audio = self.recognizer.record(source)
            
            # å°è¯•ä½¿ç”¨ Google Speech-to-Text APIï¼ˆéœ€è¦ç½‘ç»œï¼‰
            try:
                text = self.recognizer.recognize_google(audio, language=language)
                engine = "google"
            except sr.UnknownValueError:
                return {
                    "success": False,
                    "error": "æ— æ³•è¯†åˆ«éŸ³é¢‘å†…å®¹ï¼Œè¯·å°è¯•å…¶ä»–æ–‡ä»¶"
                }
            except sr.RequestError as e:
                return {
                    "success": False,
                    "error": f"è¯­éŸ³è¯†åˆ«æœåŠ¡è¿æ¥å¤±è´¥: {str(e)}"
                }
            
            return {
                "success": True,
                "text": text,
                "engine": engine,
                "audio_file": audio_path,
                "language": language,
                "timestamp": datetime.now().isoformat()
            }
        
        except Exception as e:
            return {
                "success": False,
                "error": f"è½¬å†™å¤±è´¥: {str(e)}"
            }
    
    def transcribe_microphone(self, duration: int = 30, language: str = "zh-CN") -> Dict[str, Any]:
        """
        ä»éº¦å…‹é£å½•éŸ³å¹¶è½¬å†™
        
        Args:
            duration: å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
            language: è¯­è¨€ä»£ç 
        
        Returns:
            è½¬å†™ç»“æœ
        """
        if self.recognizer is None:
            return {
                "success": False,
                "error": "è¯­éŸ³è¯†åˆ«å¼•æ“æœªåˆå§‹åŒ–"
            }
        
        try:
            import speech_recognition as sr
            
            print(f"ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆ{duration}ç§’ï¼‰...")
            
            with sr.Microphone() as source:
                # è°ƒæ•´éº¦å…‹é£çµæ•åº¦
                self.recognizer.adjust_for_ambient_noise(source, duration=1)
                
                # å¼€å§‹å½•éŸ³
                print("æ­£åœ¨å¬å–...")
                audio = self.recognizer.listen(source, timeout=duration)
            
            print("æ­£åœ¨è¯†åˆ«...")
            
            # è¯†åˆ«
            try:
                text = self.recognizer.recognize_google(audio, language=language)
                
                return {
                    "success": True,
                    "text": text,
                    "engine": "google",
                    "source": "microphone",
                    "duration": duration,
                    "language": language,
                    "timestamp": datetime.now().isoformat()
                }
            except sr.UnknownValueError:
                return {
                    "success": False,
                    "error": "æ— æ³•è¯†åˆ«éŸ³é¢‘å†…å®¹"
                }
        
        except Exception as e:
            return {
                "success": False,
                "error": f"å½•éŸ³è½¬å†™å¤±è´¥: {str(e)}"
            }
    
    def extract_keywords_and_summary(self, text: str, max_keywords: int = 10, 
                                    max_summary_lines: int = 3) -> Dict[str, Any]:
        """
        ä½¿ç”¨ AI æå–å…³é”®è¯å’Œæ€»ç»“
        
        Args:
            text: è½¬å†™æ–‡æœ¬
            max_keywords: æœ€å¤šæå–å…³é”®è¯æ•°
            max_summary_lines: æ‘˜è¦æœ€å¤šè¡Œæ•°
        
        Returns:
            å…³é”®è¯å’Œæ‘˜è¦
        """
        try:
            from google import genai
            from dotenv import load_dotenv
            
            # åŠ è½½ API å¯†é’¥
            load_dotenv()
            api_key = os.getenv("GEMINI_API_KEY")
            
            if not api_key:
                return {
                    "success": False,
                    "error": "æœªé…ç½® GEMINI_API_KEY"
                }
            
            client = genai.Client(api_key=api_key)
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""åˆ†æä»¥ä¸‹è½¬å†™æ–‡æœ¬ï¼Œå¹¶æ‰§è¡Œä¸¤ä¸ªä»»åŠ¡ï¼š

1. æå–æœ€å¤š {max_keywords} ä¸ªå…³é”®è¯æˆ–æ ¸å¿ƒæ¦‚å¿µï¼ˆç”¨é€—å·åˆ†éš”ï¼‰
2. ç”Ÿæˆæœ€å¤š {max_summary_lines} è¡Œçš„å…³é”®æ€»ç»“

è½¬å†™æ–‡æœ¬ï¼š
---
{text}
---

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

å…³é”®è¯ï¼š[å…³é”®è¯åˆ—è¡¨]

å…³é”®æ€»ç»“ï¼š
[æ‘˜è¦ç¬¬ä¸€è¡Œ]
[æ‘˜è¦ç¬¬äºŒè¡Œ]
[æ‘˜è¦ç¬¬ä¸‰è¡Œ]
"""
            
            # è°ƒç”¨ API
            response = client.models.generate_content(
                model="gemini-3-flash-preview",
                contents=prompt,
                config=genai.types.GenerateContentConfig(
                    temperature=0.7,
                    max_output_tokens=500
                )
            )
            
            result_text = response.text
            
            # è§£æç»“æœ
            keywords = []
            summary = []
            
            lines = result_text.split('\n')
            in_summary = False
            
            for line in lines:
                line = line.strip()
                if line.startswith('å…³é”®è¯ï¼š'):
                    keywords_str = line.replace('å…³é”®è¯ï¼š', '').strip()
                    keywords = [k.strip() for k in keywords_str.split('ï¼Œ')]
                elif line.startswith('å…³é”®æ€»ç»“ï¼š'):
                    in_summary = True
                elif in_summary and line and not line.startswith('---'):
                    summary.append(line)
            
            return {
                "success": True,
                "keywords": keywords,
                "summary": summary,
                "raw_response": result_text
            }
        
        except Exception as e:
            # æœ¬åœ°ç®€å•å¤„ç†ï¼ˆå¦‚æœ API ä¸å¯ç”¨ï¼‰
            return self._extract_keywords_simple(text, max_keywords, max_summary_lines)
    
    def _extract_keywords_simple(self, text: str, max_keywords: int = 10, 
                                 max_summary_lines: int = 3) -> Dict[str, Any]:
        """
        ç®€å•çš„æœ¬åœ°å…³é”®è¯æå–ï¼ˆä¸éœ€è¦ APIï¼‰
        """
        from collections import Counter
        import re
        
        # åˆ†è¯ï¼ˆç®€å•æ–¹å¼ï¼‰
        words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', text)
        
        # è¿‡æ»¤åœç”¨è¯
        stop_words = {
            'çš„', 'äº†', 'å’Œ', 'æ˜¯', 'åœ¨', 'ä¸­', 'åˆ°', 'äº†', 'ä¸', 'æˆ–', 'ç­‰',
            'a', 'the', 'is', 'are', 'and', 'or', 'of', 'in', 'to'
        }
        
        filtered_words = [w for w in words if w not in stop_words and len(w) > 1]
        
        # ç»Ÿè®¡è¯é¢‘
        word_freq = Counter(filtered_words)
        keywords = [w for w, _ in word_freq.most_common(max_keywords)]
        
        # ç®€å•æ‘˜è¦ï¼ˆæå–å‰å‡ ä¸ªå¥å­ï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿï¼Œï¼›]', text)
        summary = [s.strip() for s in sentences[:max_summary_lines] if s.strip()]
        
        return {
            "success": True,
            "keywords": keywords,
            "summary": summary,
            "method": "simple"
        }

    def _extract_action_items_simple(self, text: str) -> Dict[str, List[str]]:
        """
        æœ¬åœ°è¡ŒåŠ¨é¡¹ä¸å†³ç­–æå–ï¼ˆä¸éœ€è¦ APIï¼‰
        """
        import re

        sentences = [s.strip() for s in re.split(r'[ã€‚ï¼ï¼Ÿ!?\n\r]', text) if s.strip()]

        action_patterns = re.compile(
            r'(éœ€è¦|åº”è¯¥|è¯·|åŠ¡å¿…|å®‰æ’|è´Ÿè´£|è·Ÿè¿›|å®Œæˆ|æäº¤|ç¡®è®¤|å¯¹æ¥|å‡†å¤‡|è½å®|å¤„ç†|ä¿®å¤|æ”¹è¿›|åœ¨.+?å‰)'
        )
        decision_patterns = re.compile(r'(å†³å®š|ç¡®è®¤|è¾¾æˆ|åŒæ„|é€šè¿‡|å®šä¸º|ç¡®å®š|ç»“è®º|å…±è¯†)')

        action_items = [s for s in sentences if action_patterns.search(s)]
        decisions = [s for s in sentences if decision_patterns.search(s)]

        # å‚ä¼šäººæå–ï¼ˆç®€å•è§„åˆ™ï¼šå‚ä¼šäººå‘˜/å‚ä¼šäºº/å‚ä¼šï¼šåé¢çš„åå•ï¼‰
        participants = []
        for line in text.splitlines():
            line = line.strip()
            if not line:
                continue
            if line.startswith("å‚ä¼šäººå‘˜") or line.startswith("å‚ä¼šäºº") or line.startswith("å‚ä¼šï¼š"):
                parts = re.split(r'[:ï¼š]', line, maxsplit=1)
                if len(parts) == 2:
                    names = re.split(r'[ã€,ï¼Œ\s]+', parts[1].strip())
                    participants.extend([n for n in names if n])

        # å»é‡ä¿æŒé¡ºåº
        def _dedupe(items: List[str]) -> List[str]:
            seen = set()
            result = []
            for item in items:
                if item not in seen:
                    seen.add(item)
                    result.append(item)
            return result

        return {
            "action_items": _dedupe(action_items),
            "decisions": _dedupe(decisions),
            "participants": _dedupe(participants)
        }

    def _segment_speakers_simple(self, text: str) -> List[Dict[str, str]]:
        """
        ç®€å•å‘è¨€äººåˆ†æ®µï¼ˆä¸éœ€è¦ APIï¼‰
        æ”¯æŒæ ¼å¼ï¼š
        - å¼ ä¸‰ï¼šå†…å®¹...
        - å¼ ä¸‰: å†…å®¹...
        - [00:01] å¼ ä¸‰ï¼šå†…å®¹...
        """
        import re

        segments = []
        current_speaker = None
        current_text = []

        speaker_pattern = re.compile(r'^(\[\d{2}:\d{2}\]\s*)?([^:ï¼š]{1,20})[:ï¼š]\s*(.+)$')

        def flush():
            nonlocal current_speaker, current_text
            if current_speaker and current_text:
                segments.append({
                    "speaker": current_speaker,
                    "content": " ".join(current_text).strip()
                })
            current_speaker = None
            current_text = []

        for raw_line in text.splitlines():
            line = raw_line.strip()
            if not line:
                continue
            match = speaker_pattern.match(line)
            if match:
                flush()
                current_speaker = match.group(2).strip()
                current_text.append(match.group(3).strip())
            else:
                if current_speaker:
                    current_text.append(line)

        flush()
        return segments
    
    def generate_transcript_document(self, text: str, keywords: List[str] = None, 
                                    summary: List[str] = None, title: str = None,
                                    output_format: str = "txt",
                                    action_items: List[str] = None,
                                    decisions: List[str] = None,
                                    participants: List[str] = None,
                                    speaker_segments: List[Dict[str, str]] = None) -> str:
        """
        ç”Ÿæˆè½¬å†™æ–‡æ¡£
        
        Args:
            text: å®Œæ•´è½¬å†™æ–‡æœ¬
            keywords: å…³é”®è¯åˆ—è¡¨
            summary: æ‘˜è¦è¡Œ
            title: æ–‡æ¡£æ ‡é¢˜
            output_format: è¾“å‡ºæ ¼å¼ (txt/md/docx)
            action_items: è¡ŒåŠ¨é¡¹åˆ—è¡¨
            decisions: å†³ç­–è¦ç‚¹
            participants: å‚ä¼šäººå‘˜
            speaker_segments: å‘è¨€äººåˆ†æ®µ
        
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename_base = f"transcript_{timestamp}"
        
        if title:
            filename_base = f"{title}_{timestamp}"
        
        # ç”Ÿæˆå†…å®¹
        content_lines = []
        
        if title:
            content_lines.append(f"# {title}\n")
        
        # è½¬å†™æ—¶é—´
        content_lines.append(f"è½¬å†™æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # å…³é”®è¯
        if keywords:
            content_lines.append("## å…³é”®è¯\n")
            keywords_str = "ã€".join(keywords)
            content_lines.append(f"{keywords_str}\n")
        
        # å…³é”®æ€»ç»“
        if summary:
            content_lines.append("## å…³é”®æ€»ç»“\n")
            for line in summary:
                content_lines.append(f"{line}\n")

        # å‚ä¼šäººå‘˜
        if participants:
            content_lines.append("## å‚ä¼šäººå‘˜\n")
            content_lines.append("ã€".join(participants) + "\n")

        # è¡ŒåŠ¨é¡¹
        if action_items:
            content_lines.append("## è¡ŒåŠ¨é¡¹\n")
            for item in action_items:
                content_lines.append(f"- {item}\n")

        # å†³ç­–è¦ç‚¹
        if decisions:
            content_lines.append("## å†³ç­–è¦ç‚¹\n")
            for item in decisions:
                content_lines.append(f"- {item}\n")

        # å‘è¨€äººè®°å½•
        if speaker_segments:
            content_lines.append("## å‘è¨€äººè®°å½•\n")
            for seg in speaker_segments:
                speaker = seg.get("speaker", "")
                content = seg.get("content", "")
                if speaker and content:
                    content_lines.append(f"ã€{speaker}ã€‘{content}\n")
        
        # å®Œæ•´è½¬å†™
        content_lines.append("## å®Œæ•´è½¬å†™\n")
        content_lines.append(f"{text}\n")
        
        content = "\n".join(content_lines)
        
        # ä¿å­˜æ–‡ä»¶
        if output_format == "txt":
            filepath = os.path.join(self.output_dir, f"{filename_base}.txt")
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
        
        elif output_format == "md":
            filepath = os.path.join(self.output_dir, f"{filename_base}.md")
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
        
        elif output_format == "docx":
            from web.document_generator import save_docx
            filepath = save_docx(
                content,
                title=title or "è¯­éŸ³è½¬å†™",
                output_dir=self.output_dir,
                filename=filename_base
            )
        
        return filepath
    
    def process_audio_complete(self, audio_path: str, language: str = "zh-CN", 
                               output_format: str = "txt", title: str = None,
                               auto_summary: bool = True,
                               extract_meeting_items: bool = True) -> Dict[str, Any]:
        """
        å®Œæ•´å¤„ç†æµç¨‹ï¼šè½¬å†™ â†’ æ€»ç»“ â†’ ç”Ÿæˆæ–‡æ¡£
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç 
            output_format: è¾“å‡ºæ ¼å¼
            title: æ–‡æ¡£æ ‡é¢˜
            auto_summary: æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆæ€»ç»“
            extract_meeting_items: æ˜¯å¦æå–ä¼šè®®è¡ŒåŠ¨é¡¹/å†³ç­–/å‚ä¼šäºº
        
        Returns:
            å®Œæ•´å¤„ç†ç»“æœ
        """
        # ç¬¬ä¸€æ­¥ï¼šè½¬å†™
        print(f"ğŸ“ å¼€å§‹è½¬å†™ {audio_path}...")
        transcribe_result = self.transcribe_audio_file(audio_path, language)
        
        if not transcribe_result["success"]:
            return transcribe_result
        
        text = transcribe_result["text"]
        print(f"âœ… è½¬å†™å®Œæˆ: {len(text)} å­—ç¬¦")
        
        keywords = None
        summary = None
        action_items = None
        decisions = None
        participants = None
        speaker_segments = None
        
        # ç¬¬äºŒæ­¥ï¼šæå–å…³é”®è¯å’Œæ€»ç»“
        if auto_summary:
            print("ğŸ“Š æå–å…³é”®è¯å’Œæ€»ç»“...")
            summary_result = self.extract_keywords_and_summary(text)
            
            if summary_result["success"]:
                keywords = summary_result.get("keywords")
                summary = summary_result.get("summary")
                print(f"âœ… æå–å®Œæˆ: {len(keywords)} ä¸ªå…³é”®è¯, {len(summary)} è¡Œæ‘˜è¦")
            else:
                print(f"âš ï¸ æ€»ç»“å¤±è´¥: {summary_result.get('error')}")

        # ä¼šè®®è¦ç´ æå–
        if extract_meeting_items:
            meeting_items = self._extract_action_items_simple(text)
            action_items = meeting_items.get("action_items")
            decisions = meeting_items.get("decisions")
            participants = meeting_items.get("participants")
            speaker_segments = self._segment_speakers_simple(text)
        
        # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆæ–‡æ¡£
        print("ğŸ“„ ç”Ÿæˆæ–‡æ¡£...")
        output_file = self.generate_transcript_document(
            text,
            keywords=keywords,
            summary=summary,
            title=title,
            output_format=output_format,
            action_items=action_items,
            decisions=decisions,
            participants=participants,
            speaker_segments=speaker_segments
        )
        
        print(f"âœ… æ–‡æ¡£å·²ä¿å­˜: {output_file}")
        
        return {
            "success": True,
            "text": text,
            "keywords": keywords,
            "summary": summary,
            "action_items": action_items,
            "decisions": decisions,
            "participants": participants,
            "speaker_segments": speaker_segments,
            "output_file": output_file,
            "format": output_format,
            "char_count": len(text),
            "word_count": len(text.split())
        }


if __name__ == "__main__":
    transcriber = SpeechTranscriber()
    
    print("=" * 60)
    print("è¯­éŸ³è½¬å†™ä¸æ€»ç»“ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    test_audio = "test_audio.wav"
    
    if os.path.exists(test_audio):
        print(f"\n1. æµ‹è¯•æ–‡ä»¶è½¬å†™: {test_audio}")
        result = transcriber.process_audio_complete(
            test_audio,
            language="zh-CN",
            output_format="txt",
            title="æµ‹è¯•è½¬å†™",
            auto_summary=True
        )
        
        if result["success"]:
            print(f"\nâœ… è½¬å†™æˆåŠŸ")
            print(f"   å­—ç¬¦æ•°: {result['char_count']}")
            print(f"   å…³é”®è¯: {', '.join(result['keywords'] or [])}")
            print(f"   ä¿å­˜ä½ç½®: {result['output_file']}")
    else:
        print(f"\nâš ï¸ æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {test_audio}")
        print("   æ”¯æŒçš„æ ¼å¼: .wav, .mp3, .m4a, .flac")
    
    print("\nâœ… è¯­éŸ³è½¬å†™ç³»ç»Ÿå°±ç»ª")
