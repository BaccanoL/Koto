"""
Koto å¿«é€Ÿæœ¬åœ°è¯­éŸ³è¯†åˆ«æ¨¡å—
ä¼˜å…ˆä½¿ç”¨ Vosk ç¦»çº¿è¯†åˆ«ï¼ˆæ— éœ€ç½‘ç»œï¼‰ï¼Œé™çº§åˆ° Google Speech API
"""
import os
import sys
import json
import time
import re
import struct
import tempfile
import threading
import queue
from typing import Dict, Optional
from dataclasses import dataclass


@dataclass
class VoiceResult:
    """è¯­éŸ³è¯†åˆ«ç»“æœ"""
    success: bool
    text: str = ""
    engine: str = ""
    message: str = ""
    confidence: float = 0.0
    
    def to_dict(self) -> Dict:
        return {
            "success": self.success,
            "text": self.text,
            "engine": self.engine,
            "message": self.message,
            "confidence": self.confidence
        }


def _clean_chinese_text(text: str) -> str:
    """æ¸…ç†ä¸­æ–‡æ–‡æœ¬ï¼Œå»é™¤ä¸å¿…è¦çš„ç©ºæ ¼"""
    if not text:
        return text
    chinese_pattern = r'[\u4e00-\u9fff]'
    result = re.sub(f'({chinese_pattern})\\s+({chinese_pattern})', r'\1\2', text)
    while re.search(f'({chinese_pattern})\\s+({chinese_pattern})', result):
        result = re.sub(f'({chinese_pattern})\\s+({chinese_pattern})', r'\1\2', result)
    return result.strip()


class FastVoiceRecognizer:
    """å¿«é€Ÿæœ¬åœ°è¯­éŸ³è¯†åˆ«å™¨ - ä¼˜å…ˆVoskç¦»çº¿ï¼Œé™çº§Google"""
    
    def __init__(self):
        self.available_engines = []
        self.primary_engine = None
        self.vosk_model = None
        self.vosk_model_path = None
        
        # é¢„åˆå§‹åŒ–ç¼“å­˜
        self._pyaudio_instance = None
        self._sr_recognizer = None
        self._vosk_model_loading = False
        self._init_lock = threading.Lock()
        
        self._detect_engines()
        
        # åå°é¢„åˆå§‹åŒ–éº¦å…‹é£å’Œæ¨¡å‹ï¼ˆä¸é˜»å¡ï¼‰
        self._start_background_init()
    
    def _detect_engines(self):
        """æ£€æµ‹å¯ç”¨çš„è¯­éŸ³å¼•æ“ - Voskä¼˜å…ˆ"""
        print("\n[å¿«é€Ÿè¯­éŸ³] æ£€æµ‹å¯ç”¨å¼•æ“...")
        
        # 1. Vosk ç¦»çº¿è¯†åˆ«ï¼ˆæœ€ä¼˜å…ˆ - æ— éœ€ç½‘ç»œï¼Œé€Ÿåº¦å¿«ï¼‰
        if self._check_vosk():
            self.available_engines.append("vosk")
            self.primary_engine = "vosk"
            print("  âœ… Voskç¦»çº¿è¯†åˆ«å¯ç”¨ï¼ˆæ¨èï¼Œæ— éœ€ç½‘ç»œï¼‰")
        
        # 2. Windowsè¯­éŸ³è¯†åˆ« + speech_recognitionï¼ˆéœ€éº¦å…‹é£ï¼‰
        if self._check_windows_sapi():
            self.available_engines.append("windows_sapi")
            if not self.primary_engine:
                self.primary_engine = "windows_sapi"
            print("  âœ… Windowsè¯­éŸ³è¯†åˆ«å¯ç”¨ï¼ˆæœ¬åœ°ï¼‰")
        
        # 3. speech_recognitionåº“ï¼ˆGoogle APIï¼Œéœ€ç½‘ç»œï¼‰
        if self._check_speech_recognition():
            self.available_engines.append("speech_recognition")
            if not self.primary_engine:
                self.primary_engine = "speech_recognition"
            print("  âœ… Google Speech APIå¯ç”¨ï¼ˆéœ€ç½‘ç»œï¼‰")
        
        # 4. é™çº§ï¼šç›´æ¥ä½¿ç”¨Win32 COM
        if self._check_win32_sapi():
            self.available_engines.append("win32_sapi")
            if not self.primary_engine:
                self.primary_engine = "win32_sapi"
            print("  âœ… Win32 SAPIå¯ç”¨ï¼ˆæœ¬åœ°ï¼‰")
        
        if not self.available_engines:
            print("  âš ï¸  æ— å¯ç”¨å¼•æ“ï¼Œè¯­éŸ³åŠŸèƒ½å°†å—é™")
            self.available_engines.append("offline")
            self.primary_engine = "offline"
        
        print(f"  ä¸»å¼•æ“: {self.primary_engine}")
    
    def _check_vosk(self) -> bool:
        """æ£€æŸ¥Voskç¦»çº¿è¯†åˆ«æ˜¯å¦å¯ç”¨"""
        if getattr(sys, 'frozen', False):
            return False  # æ‰“åŒ…ç¯å¢ƒç¦ç”¨
        try:
            from vosk import Model, KaldiRecognizer
            import pyaudio
            
            base_dir = os.path.dirname(__file__)
            model_paths = [
                os.path.join(base_dir, "..", "models", "vosk-model-small-cn-0.22"),
                os.path.join(base_dir, "..", "models", "vosk-model-small-cn"),
                os.path.join(base_dir, "..", "models", "vosk-model-cn-0.22"),
                os.path.join(base_dir, "..", "models", "vosk-model-cn"),
            ]
            
            for path in model_paths:
                abs_path = os.path.abspath(path)
                if os.path.exists(abs_path) and os.path.isdir(abs_path):
                    self.vosk_model_path = abs_path
                    return True
            return False
        except ImportError:
            return False
        except Exception:
            return False
    
    def _start_background_init(self):
        """åå°é¢„åˆå§‹åŒ–éŸ³é¢‘ç¡¬ä»¶å’Œæ¨¡å‹"""
        def init_thread():
            try:
                # é¢„åŠ è½½Voskæ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.primary_engine == "vosk" and self.vosk_model_path:
                    self._load_vosk_model_async()
                
                # é¢„åˆå§‹åŒ–speech_recognition
                if "speech_recognition" in self.available_engines:
                    self._init_sr_recognizer()
            except Exception as e:
                print(f"[å¿«é€Ÿè¯­éŸ³] åå°åˆå§‹åŒ–å‡ºé”™ï¼ˆéä¸¥é‡ï¼‰: {e}")
        
        # åªåœ¨ä¸»å¼•æ“æ˜¯voskæˆ–æœ‰sræ—¶æ‰åå°åˆå§‹åŒ–
        if self.primary_engine == "vosk" or "speech_recognition" in self.available_engines:
            init_thread_obj = threading.Thread(target=init_thread, daemon=True)
            init_thread_obj.start()
    
    def _load_vosk_model_async(self):
        """å¼‚æ­¥åŠ è½½Voskæ¨¡å‹"""
        if self._vosk_model_loading or self.vosk_model:
            return
        
        with self._init_lock:
            if self.vosk_model or not self.vosk_model_path:
                return
            
            try:
                self._vosk_model_loading = True
                from vosk import Model, SetLogLevel
                SetLogLevel(-1)
                print(f"[å¿«é€Ÿè¯­éŸ³] åå°åŠ è½½Voskæ¨¡å‹: {self.vosk_model_path}")
                self.vosk_model = Model(self.vosk_model_path)
            except Exception as e:
                print(f"[å¿«é€Ÿè¯­éŸ³] Voskæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            finally:
                self._vosk_model_loading = False
    
    def _load_vosk_model(self):
        """åŠ è½½Voskæ¨¡å‹ï¼ˆå³æ—¶åŠ è½½ï¼Œå¦‚æœåå°æœªå®Œæˆï¼‰"""
        if self.vosk_model is None and self.vosk_model_path:
            with self._init_lock:
                if self.vosk_model is None:
                    from vosk import Model, SetLogLevel
                    SetLogLevel(-1)
                    print(f"[å¿«é€Ÿè¯­éŸ³] ç«‹å³åŠ è½½Voskæ¨¡å‹: {self.vosk_model_path}")
                    self.vosk_model = Model(self.vosk_model_path)
    
    def _init_sr_recognizer(self):
        """é¢„åˆå§‹åŒ–speech_recognitionè¯†åˆ«å™¨"""
        if self._sr_recognizer is None:
            try:
                import speech_recognition as sr
                self._sr_recognizer = sr.Recognizer()
                # é¢„è®¾å‚æ•°
                self._sr_recognizer.energy_threshold = 300  # æ›´æ•æ„Ÿ
                self._sr_recognizer.dynamic_energy_threshold = True
                self._sr_recognizer.dynamic_energy_adjustment_damping = 0.15
                self._sr_recognizer.pause_threshold = 0.3  # æ›´å¿«æ£€æµ‹
                self._sr_recognizer.non_speaking_duration = 0.2  # æ›´å¿«
            except Exception as e:
                print(f"[å¿«é€Ÿè¯­éŸ³] åˆå§‹åŒ–speech_recognitionå¤±è´¥: {e}")
    
    def get_sr_recognizer(self):
        """è·å–æˆ–åˆ›å»ºspeech_recognitionè¯†åˆ«å™¨"""
        if self._sr_recognizer is None:
            self._init_sr_recognizer()
        return self._sr_recognizer
    
    def _check_windows_sapi(self) -> bool:
        """æ£€æŸ¥Windows SAPIæ˜¯å¦å¯ç”¨"""
        try:
            import speech_recognition as sr
            recognizer = sr.Recognizer()
            with sr.Microphone() as source:
                pass
            return True
        except:
            return False
    
    def _check_speech_recognition(self) -> bool:
        """æ£€æŸ¥speech_recognitionåº“"""
        try:
            import speech_recognition as sr
            return True
        except ImportError:
            return False
    
    def _check_win32_sapi(self) -> bool:
        """æ£€æŸ¥Win32 SAPI COMæ¥å£"""
        if sys.platform != 'win32':
            return False
        try:
            import win32com.client
            return True
        except ImportError:
            return False
    
    def recognize(self, timeout: int = 5, language: str = 'zh-CN') -> VoiceResult:
        """å¿«é€Ÿè¯†åˆ«è¯­éŸ³ - ä¼˜å…ˆVoskç¦»çº¿"""
        # ä¼˜å…ˆVoskç¦»çº¿è¯†åˆ«
        if self.primary_engine == "vosk":
            result = self._recognize_with_vosk(timeout, language)
            if result.success:
                return result
            print("[å¿«é€Ÿè¯­éŸ³] Voskå¤±è´¥ï¼Œé™çº§åˆ°Google...")
        
        # é™çº§åˆ°Google
        if "windows_sapi" in self.available_engines or "speech_recognition" in self.available_engines:
            return self._recognize_with_sr_google(timeout, language)
        elif "win32_sapi" in self.available_engines:
            return self._recognize_with_win32(timeout, language)
        else:
            return VoiceResult(
                success=False,
                message="æ— å¯ç”¨è¯­éŸ³å¼•æ“",
                engine="none"
            )
    
    def _recognize_with_vosk(self, timeout: int = 5, language: str = 'zh-CN') -> VoiceResult:
        """ä½¿ç”¨Voskæœ¬åœ°ç¦»çº¿è¯†åˆ« - æ— éœ€ç½‘ç»œï¼ˆä¼˜åŒ–ç‰ˆï¼šç«‹å³å¼€å§‹ï¼Œçµæ•åº¦é«˜ï¼‰"""
        try:
            from vosk import KaldiRecognizer
            import pyaudio
            
            self._load_vosk_model()
            if not self.vosk_model:
                return VoiceResult(success=False, message="Voskæ¨¡å‹æœªåŠ è½½", engine="vosk")
            
            RATE = 16000
            CHUNK = 800  # 0.05ç§’ï¼Œæ›´é¢‘ç¹æ›´æ–°ï¼ˆä»1600æ”¹ä¸º800ï¼‰
            
            rec = KaldiRecognizer(self.vosk_model, RATE)
            rec.SetWords(True)
            
            p = pyaudio.PyAudio()
            stream = p.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK
            )
            
            print(f"[å¿«é€Ÿè¯­éŸ³] ğŸ¤ Voskç¦»çº¿è¯†åˆ«ä¸­ï¼ˆ{timeout}ç§’ï¼‰...")
            
            # ä¼˜åŒ–ï¼šæ›´å¿«çš„é™éŸ³æ£€æµ‹å’Œè¯†åˆ«åœæ­¢
            silence_count = 0
            max_silence = 10  # 1ç§’é™éŸ³åœæ­¢ï¼ˆä»15æ”¹ä¸º10ï¼‰
            has_speech = False
            start_time = time.time()
            final_text = ""
            last_partial = ""
            energy_history = []
            
            try:
                while True:
                    # æ”¹è¿›ï¼šåªåœ¨è¶…è¿‡å®é™…è¶…æ—¶+2ç§’ï¼ˆè€Œä¸æ˜¯+10ç§’ï¼‰æ‰åœæ­¢
                    if time.time() - start_time > timeout + 2:
                        break
                    
                    # 1. ç«‹å³è¯»å–éŸ³é¢‘ï¼ˆä¸ç­‰å¾…ï¼‰
                    data = stream.read(CHUNK, exception_on_overflow=False)
                    
                    # 2. ç«‹å³è®¡ç®—èƒ½é‡ï¼ˆæ£€æµ‹è¯­éŸ³ï¼‰
                    audio_data = struct.unpack(f'{len(data)//2}h', data)
                    energy = sum(abs(x) for x in audio_data) / len(audio_data)
                    
                    # 3. æ›´æ•æ„Ÿçš„èƒ½é‡å†å²è·Ÿè¸ª
                    energy_history.append(energy)
                    if len(energy_history) > 30:  # ä»50æ”¹ä¸º30ï¼Œæ›´å¿«ååº”
                        energy_history.pop(0)
                    
                    # 4. åŠ¨æ€é˜ˆå€¼ï¼ˆæ›´æ•æ„Ÿï¼‰
                    if len(energy_history) > 5:  # ä»10æ”¹ä¸º5ï¼Œæ›´å¿«é€‚åº”
                        avg_energy = sum(energy_history) / len(energy_history)
                        dynamic_threshold = max(200, avg_energy * 1.1)  # ä»300å’Œ1.2æ”¹ä¸º200å’Œ1.1ï¼Œæ›´æ•æ„Ÿ
                    else:
                        dynamic_threshold = 250  # ä»400æ”¹ä¸º250
                    
                    is_silent = energy < dynamic_threshold
                    
                    if rec.AcceptWaveform(data):
                        result = json.loads(rec.Result())
                        text = result.get("text", "").strip()
                        if text:
                            final_text = text
                            break
                    else:
                        partial = json.loads(rec.PartialResult())
                        partial_text = partial.get("partial", "").strip()
                        
                        if partial_text and partial_text != last_partial:
                            last_partial = partial_text
                            has_speech = True
                            silence_count = 0
                        elif has_speech:
                            if is_silent or not partial_text:
                                silence_count += 1
                                if silence_count >= max_silence:
                                    result = json.loads(rec.FinalResult())
                                    final_text = result.get("text", "").strip()
                                    if not final_text:
                                        final_text = last_partial
                                    break
                            else:
                                silence_count = 0
                    
                    if not has_speech and (time.time() - start_time) > timeout:
                        break
                        
            finally:
                stream.stop_stream()
                stream.close()
                p.terminate()
            
            final_text = _clean_chinese_text(final_text)
            
            if final_text:
                return VoiceResult(
                    success=True,
                    text=final_text,
                    engine="vosk",
                    message="ç¦»çº¿è¯†åˆ«æˆåŠŸ",
                    confidence=0.85
                )
            else:
                return VoiceResult(
                    success=False,
                    message="æœªæ£€æµ‹åˆ°è¯­éŸ³" if not has_speech else "æ— æ³•è¯†åˆ«",
                    engine="vosk"
                )
                
        except Exception as e:
            print(f"[å¿«é€Ÿè¯­éŸ³] Voskè¯†åˆ«é”™è¯¯: {e}")
            return VoiceResult(
                success=False,
                message=f"Voskè¯†åˆ«é”™è¯¯: {str(e)}",
                engine="vosk"
            )
    
    def _recognize_with_sr_google(self, timeout: int, language: str) -> VoiceResult:
        """ä½¿ç”¨speech_recognitionåº“ + Google APIï¼ˆé™çº§æ–¹æ¡ˆï¼Œéœ€ç½‘ç»œ - ä¼˜åŒ–ç‰ˆï¼‰"""
        try:
            import speech_recognition as sr
            
            # ä½¿ç”¨é¢„åˆå§‹åŒ–çš„è¯†åˆ«å™¨æˆ–åˆ›å»ºæ–°çš„
            recognizer = self.get_sr_recognizer()
            if recognizer is None:
                recognizer = sr.Recognizer()
            
            # ä¼˜åŒ–å‚æ•°ï¼šæ›´æ•æ„Ÿï¼Œæ›´å¿«å“åº”
            recognizer.energy_threshold = 300  # ä»400æ”¹ä¸º300ï¼Œæ›´æ•æ„Ÿ
            recognizer.dynamic_energy_threshold = True
            recognizer.dynamic_energy_adjustment_damping = 0.15
            recognizer.pause_threshold = 0.3  # ä»0.4æ”¹ä¸º0.3ï¼Œæ›´å¿«æ£€æµ‹ç»“æŸ
            recognizer.non_speaking_duration = 0.2  # ä»0.3æ”¹ä¸º0.2ï¼Œæ›´å¿«ååº”
            
            with sr.Microphone(sample_rate=16000) as source:
                print(f"[å¿«é€Ÿè¯­éŸ³] Google APIè¯†åˆ«ï¼ˆ{timeout}ç§’ï¼‰...")          
                # ä¼˜åŒ–ï¼šå¤§å¤§å‡å°‘å™ªéŸ³æ£€æµ‹æ—¶é—´ï¼ˆä»0.15ç§’æ”¹ä¸º0.05ç§’ï¼‰
                try:
                    recognizer.adjust_for_ambient_noise(source, duration=0.05)
                except:
                    # å¦‚æœè°ƒæ•´å¤±è´¥ï¼Œç»§ç»­ï¼ˆä¸å½±å“è¯†åˆ«ï¼‰
                    pass
                
                try:
                    # ç«‹å³ç›‘å¬ï¼ˆä¸å†ç­‰å¾…ï¼‰
                    audio = recognizer.listen(source, timeout=timeout, phrase_time_limit=min(8, timeout))
                    
                    try:
                        text = recognizer.recognize_google(audio, language=language)
                        return VoiceResult(
                            success=True,
                            text=_clean_chinese_text(text),
                            engine="google",
                            message="è¯†åˆ«æˆåŠŸ",
                            confidence=0.9
                        )
                    except sr.UnknownValueError:
                        return VoiceResult(
                            success=False,
                            message="æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é è¿‘éº¦å…‹é£è¯´è¯",
                            engine="google"
                        )
                    except sr.RequestError as e:
                        print(f"[å¿«é€Ÿè¯­éŸ³] Google APIä¸å¯ç”¨: {e}")
                        return VoiceResult(
                            success=False,
                            message="Google APIä¸å¯ç”¨ï¼ˆç½‘ç»œé—®é¢˜ï¼‰ï¼Œè¯·ä½¿ç”¨ç¦»çº¿è¯†åˆ«",
                            engine="google_error"
                        )
                
                except sr.WaitTimeoutError:
                    return VoiceResult(
                        success=False,
                        message=f"ç­‰å¾…è¶…æ—¶ï¼ˆ{timeout}ç§’å†…æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼‰",
                        engine="timeout"
                    )
        
        except Exception as e:
            print(f"[å¿«é€Ÿè¯­éŸ³] è¯†åˆ«é”™è¯¯: {e}")
            return VoiceResult(
                success=False,
                message=f"è¯†åˆ«å¤±è´¥: {str(e)}",
                engine="error"
            )
    
    def _recognize_with_win32(self, timeout: int, language: str) -> VoiceResult:
        """ä½¿ç”¨Win32 SAPI COMæ¥å£ï¼ˆçº¯æœ¬åœ°ï¼Œä½†å¯èƒ½ä¸æ”¯æŒä¸­æ–‡ï¼‰"""
        try:
            import win32com.client
            import pythoncom
            
            pythoncom.CoInitialize()
            
            # åˆ›å»ºSAPIè¯†åˆ«å™¨
            recognizer = win32com.client.Dispatch("SAPI.SpVoice")
            
            # æ³¨æ„ï¼šWin32 SAPIä¸»è¦ç”¨äºTTSï¼Œè¯†åˆ«åŠŸèƒ½æœ‰é™
            return VoiceResult(
                success=False,
                message="Win32 SAPIä»…æ”¯æŒè¯­éŸ³åˆæˆï¼Œå»ºè®®å®‰è£…speech_recognitionåº“",
                engine="win32_limited"
            )
        
        except Exception as e:
            return VoiceResult(
                success=False,
                message=f"Win32 SAPIé”™è¯¯: {str(e)}",
                engine="win32_error"
            )
    
    def get_available_engines(self) -> Dict:
        """è¿”å›å¯ç”¨å¼•æ“åˆ—è¡¨"""
        engines = []
        
        for engine in self.available_engines:
            if engine == "vosk":
                engines.append({
                    "type": "vosk",
                    "name": "Vosk ç¦»çº¿è¯†åˆ«",
                    "description": "å®Œå…¨ç¦»çº¿ï¼Œæ— éœ€ç½‘ç»œï¼ˆæ¨èï¼‰",
                    "is_primary": engine == self.primary_engine
                })
            elif engine == "windows_sapi" or engine == "speech_recognition":
                engines.append({
                    "type": "google",
                    "name": "Google Speech API",
                    "description": "åœ¨çº¿è¯†åˆ«ï¼Œæ•ˆæœå¥½ï¼ˆéœ€ç½‘ç»œï¼‰",
                    "is_primary": engine == self.primary_engine
                })
            elif engine == "win32_sapi":
                engines.append({
                    "type": "windows",
                    "name": "Windows SAPI",
                    "description": "æœ¬åœ°è¯†åˆ«ï¼ˆåŠŸèƒ½æœ‰é™ï¼‰",
                    "is_primary": engine == self.primary_engine
                })
            elif engine == "offline":
                engines.append({
                    "type": "offline",
                    "name": "ç¦»çº¿å½•éŸ³",
                    "description": "ä»…å½•éŸ³ï¼Œéœ€æ‰‹åŠ¨å¤„ç†",
                    "is_primary": engine == self.primary_engine
                })
        
        return {
            "success": True,
            "engines": engines,
            "primary": self.primary_engine
        }


# å…¨å±€å®ä¾‹
_recognizer_instance = None

def get_recognizer() -> FastVoiceRecognizer:
    """è·å–è¯†åˆ«å™¨å•ä¾‹"""
    global _recognizer_instance
    if _recognizer_instance is None:
        _recognizer_instance = FastVoiceRecognizer()
    return _recognizer_instance


# APIå‡½æ•°
def recognize_voice(timeout: int = 5, language: str = 'zh-CN') -> Dict:
    """è¯†åˆ«è¯­éŸ³ï¼ˆAPIæ¥å£ï¼‰"""
    recognizer = get_recognizer()
    result = recognizer.recognize(timeout, language)
    return result.to_dict()


def get_available_engines() -> Dict:
    """è·å–å¯ç”¨å¼•æ“åˆ—è¡¨"""
    recognizer = get_recognizer()
    return recognizer.get_available_engines()


# æµå¼è¯†åˆ«ï¼ˆä¼˜å…ˆVoskç¦»çº¿ï¼‰
def recognize_streaming(timeout: int = 10):
    """æµå¼è¯†åˆ« - ç”Ÿæˆå™¨ï¼Œä¼˜å…ˆä½¿ç”¨Voskç¦»çº¿è¯†åˆ«"""
    recognizer_obj = get_recognizer()
    
    yield {"type": "start", "message": "å¼€å§‹è¯†åˆ«..."}
    
    # ä¼˜å…ˆä½¿ç”¨Voskç¦»çº¿è¯†åˆ«ï¼ˆæ— éœ€ç½‘ç»œï¼‰
    if recognizer_obj.primary_engine == "vosk":
        yield from _streaming_vosk(recognizer_obj, timeout)
    else:
        yield from _streaming_google(timeout)


def _streaming_vosk(recognizer_obj, timeout: int):
    """Voskç¦»çº¿æµå¼è¯†åˆ«"""
    try:
        from vosk import KaldiRecognizer
        import pyaudio
        
        recognizer_obj._load_vosk_model()
        if not recognizer_obj.vosk_model:
            yield {"type": "error", "message": "Voskæ¨¡å‹æœªåŠ è½½", "engine": "vosk"}
            return
        
        RATE = 16000
        CHUNK = 1600  # 0.1ç§’
        
        rec = KaldiRecognizer(recognizer_obj.vosk_model, RATE)
        rec.SetWords(True)
        
        p = pyaudio.PyAudio()
        stream = p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK
        )
        
        print(f"[æµå¼è¯­éŸ³] Voskç¦»çº¿è¯†åˆ«ï¼ˆ{timeout}ç§’ï¼‰...")
        
        silence_count = 0
        max_silence = 12  # 1.2ç§’é™éŸ³åœæ­¢
        has_speech = False
        start_time = time.time()
        last_partial = ""
        energy_history = []
        
        try:
            while True:
                elapsed = time.time() - start_time
                if elapsed > timeout + 5:
                    break
                
                data = stream.read(CHUNK, exception_on_overflow=False)
                
                # è®¡ç®—éŸ³é¢‘èƒ½é‡
                audio_data = struct.unpack(f'{len(data)//2}h', data)
                energy = sum(abs(x) for x in audio_data) / len(audio_data)
                
                energy_history.append(energy)
                if len(energy_history) > 50:
                    energy_history.pop(0)
                
                if len(energy_history) > 10:
                    avg_energy = sum(energy_history) / len(energy_history)
                    dynamic_threshold = max(300, avg_energy * 1.2)
                else:
                    dynamic_threshold = 400
                
                is_silent = energy < dynamic_threshold
                
                if rec.AcceptWaveform(data):
                    result = json.loads(rec.Result())
                    text = _clean_chinese_text(result.get("text", ""))
                    if text:
                        yield {"type": "final", "text": text, "engine": "vosk"}
                        return
                else:
                    partial = json.loads(rec.PartialResult())
                    partial_text = _clean_chinese_text(partial.get("partial", ""))
                    
                    if partial_text and partial_text != last_partial:
                        last_partial = partial_text
                        has_speech = True
                        silence_count = 0
                        yield {
                            "type": "partial",
                            "text": partial_text,
                            "elapsed": round(elapsed, 1),
                            "is_final": False
                        }
                    elif has_speech:
                        if is_silent or not partial_text:
                            silence_count += 1
                            if silence_count >= max_silence:
                                result = json.loads(rec.FinalResult())
                                text = _clean_chinese_text(result.get("text", ""))
                                if not text:
                                    text = _clean_chinese_text(last_partial)
                                if text:
                                    yield {"type": "final", "text": text, "engine": "vosk"}
                                else:
                                    yield {"type": "error", "message": "æ— æ³•è¯†åˆ«", "engine": "vosk"}
                                return
                        else:
                            silence_count = 0
                
                # æœªè¯´è¯è¶…æ—¶
                if not has_speech and elapsed > timeout:
                    yield {"type": "error", "message": "æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•", "engine": "timeout"}
                    return
                
                # ç­‰å¾…æç¤º
                if not has_speech:
                    if elapsed < 2.0:
                        yield {
                            "type": "partial",
                            "text": "ğŸ¤ æ­£åœ¨è†å¬...",
                            "elapsed": round(elapsed, 1)
                        }
                    else:
                        yield {
                            "type": "partial",
                            "text": f"â±ï¸ è¯·è¯´è¯... {int(elapsed)}s",
                            "elapsed": round(elapsed, 1)
                        }
        
        finally:
            stream.stop_stream()
            stream.close()
            p.terminate()
        
        # è¶…æ—¶
        if has_speech and last_partial:
            yield {"type": "final", "text": _clean_chinese_text(last_partial), "engine": "vosk"}
        else:
            yield {"type": "error", "message": "è¯†åˆ«è¶…æ—¶", "engine": "vosk"}
            
    except Exception as e:
        print(f"[æµå¼è¯­éŸ³] Voské”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        yield {"type": "error", "message": f"è¯†åˆ«å¤±è´¥: {str(e)}", "engine": "vosk"}


def _streaming_google(timeout: int):
    """Google APIæµå¼è¯†åˆ«ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
    try:
        import speech_recognition as sr
        import queue
        
        recognizer = sr.Recognizer()
        recognizer.energy_threshold = 400
        recognizer.dynamic_energy_threshold = True
        recognizer.dynamic_energy_adjustment_damping = 0.15
        recognizer.pause_threshold = 0.4
        recognizer.non_speaking_duration = 0.3
        
        result_queue = queue.Queue()
        is_speaking = False
        last_text = ""
        
        with sr.Microphone(sample_rate=16000) as source:
            print(f"[æµå¼è¯­éŸ³] Google APIè¯†åˆ«ï¼ˆ{timeout}ç§’ï¼‰...")
            recognizer.adjust_for_ambient_noise(source, duration=0.15)
            
            start_time = time.time()
            accumulated_audio = []
            last_recognition_time = start_time
            final_text = ""
            silence_start = None
            
            stop_listening = recognizer.listen_in_background(
                source,
                lambda recognizer, audio: result_queue.put(audio),
                phrase_time_limit=2
            )
            
            try:
                while time.time() - start_time < timeout:
                    elapsed = time.time() - start_time
                    
                    try:
                        audio_chunk = result_queue.get(timeout=0.3)
                        accumulated_audio.append(audio_chunk)
                        is_speaking = True
                        silence_start = None
                        
                        if time.time() - last_recognition_time >= 0.8:
                            if accumulated_audio:
                                try:
                                    latest_audio = accumulated_audio[-1]
                                    text = recognizer.recognize_google(latest_audio, language='zh-CN')
                                    
                                    if text and text != last_text:
                                        final_text = text
                                        last_text = text
                                        yield {
                                            "type": "partial",
                                            "text": _clean_chinese_text(text),
                                            "elapsed": round(elapsed, 1),
                                            "is_final": False
                                        }
                                except sr.UnknownValueError:
                                    pass
                                except sr.RequestError as e:
                                    print(f"[æµå¼] Google APIé”™è¯¯: {e}")
                                    
                                last_recognition_time = time.time()
                        
                    except queue.Empty:
                        if is_speaking:
                            if silence_start is None:
                                silence_start = time.time()
                            elif time.time() - silence_start > 1.5:
                                break
                        
                        if elapsed < 2.0:
                            yield {
                                "type": "partial",
                                "text": "ğŸ¤ æ­£åœ¨è†å¬...",
                                "elapsed": round(elapsed, 1)
                            }
                        elif not is_speaking:
                            yield {
                                "type": "partial",
                                "text": f"â±ï¸ è¯·è¯´è¯... {int(elapsed)}s",
                                "elapsed": round(elapsed, 1)
                            }
                
            finally:
                stop_listening(wait_for_stop=False)
            
            if accumulated_audio and final_text:
                yield {"type": "final", "text": _clean_chinese_text(final_text), "engine": "google_streaming"}
            elif not is_speaking:
                yield {"type": "error", "message": "æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•", "engine": "timeout"}
            else:
                yield {"type": "error", "message": "è¯†åˆ«å¤±è´¥", "engine": "error"}
                    
    except Exception as e:
        print(f"[æµå¼è¯­éŸ³] Googleé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        yield {"type": "error", "message": f"è¯†åˆ«å¤±è´¥: {str(e)}", "engine": "error"}


if __name__ == "__main__":
    # æµ‹è¯•
    print("ğŸ¤ å¿«é€Ÿè¯­éŸ³è¯†åˆ«æµ‹è¯•")
    print("="*50)
    
    recognizer = get_recognizer()
    print(f"\nä¸»å¼•æ“: {recognizer.primary_engine}")
    print(f"å¯ç”¨å¼•æ“: {recognizer.available_engines}")
    
    print("\nè¯·åœ¨5ç§’å†…è¯´è¯...")
    result = recognizer.recognize(timeout=5)
    
    print(f"\nç»“æœ: {result.to_dict()}")
