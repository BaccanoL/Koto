#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ´å¯ŸæŠ¥å‘Šç”Ÿæˆå™¨ - å‘¨æœŸæ€§ç”¨æˆ·æ´»åŠ¨åˆ†ææŠ¥å‘Š
ç”Ÿæˆç¾è§‚çš„å‘¨æŠ¥ã€æœˆæŠ¥ï¼Œå±•ç¤ºç”¨æˆ·å·¥ä½œæ¨¡å¼å’Œç”Ÿäº§åŠ›æ´å¯Ÿ
"""

import sqlite3
import json
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from pathlib import Path
from collections import Counter, defaultdict

from behavior_monitor import BehaviorMonitor
from knowledge_graph import KnowledgeGraph
from suggestion_engine import SuggestionEngine


class InsightReporter:
    """æ´å¯ŸæŠ¥å‘Šç”Ÿæˆå™¨ - ç”Ÿæˆå‘¨æœŸæ€§åˆ†ææŠ¥å‘Š"""
    
    # æŠ¥å‘Šç±»å‹
    REPORT_DAILY = "daily"
    REPORT_WEEKLY = "weekly"
    REPORT_MONTHLY = "monthly"
    
    def __init__(self, behavior_monitor: BehaviorMonitor = None,
                 knowledge_graph: KnowledgeGraph = None,
                 suggestion_engine: SuggestionEngine = None,
                 db_path: str = "config/insights.db"):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            behavior_monitor: è¡Œä¸ºç›‘æ§å™¨
            knowledge_graph: çŸ¥è¯†å›¾è°±
            suggestion_engine: å»ºè®®å¼•æ“
            db_path: æ•°æ®åº“è·¯å¾„
        """
        self.behavior_monitor = behavior_monitor or BehaviorMonitor()
        self.knowledge_graph = knowledge_graph or KnowledgeGraph()
        self.suggestion_engine = suggestion_engine or SuggestionEngine()
        self.db_path = db_path
        self._ensure_db()
    
    def _ensure_db(self):
        """ç¡®ä¿æ•°æ®åº“å’Œè¡¨ç»“æ„å­˜åœ¨"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æŠ¥å‘Šè¡¨ - å­˜å‚¨ç”Ÿæˆçš„æŠ¥å‘Š
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS reports (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                report_type TEXT NOT NULL,
                period_start TEXT NOT NULL,
                period_end TEXT NOT NULL,
                report_data TEXT NOT NULL,  -- JSONæ ¼å¼çš„å®Œæ•´æŠ¥å‘Šæ•°æ®
                summary TEXT,  -- Markdownæ ¼å¼çš„æ‘˜è¦
                created_at TEXT NOT NULL
            )
        """)
        
        # è¶‹åŠ¿æ•°æ®è¡¨ - å­˜å‚¨æ—¶é—´åºåˆ—æ•°æ®ç”¨äºè¶‹åŠ¿åˆ†æ
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS trend_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                metric_name TEXT NOT NULL,
                metric_value REAL NOT NULL,
                recorded_at TEXT NOT NULL
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_reports_type ON reports(report_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_reports_period ON reports(period_start, period_end)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_trend_metric ON trend_data(metric_name)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_trend_time ON trend_data(recorded_at DESC)")
        
        conn.commit()
        conn.close()
    
    def generate_weekly_report(self) -> Dict:
        """ç”Ÿæˆå‘¨æŠ¥"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=7)
        
        return self._generate_report(
            self.REPORT_WEEKLY,
            start_date,
            end_date
        )
    
    def generate_monthly_report(self) -> Dict:
        """ç”ŸæˆæœˆæŠ¥"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=30)
        
        return self._generate_report(
            self.REPORT_MONTHLY,
            start_date,
            end_date
        )
    
    def _generate_report(self, report_type: str, start_date: datetime, 
                        end_date: datetime) -> Dict:
        """
        ç”ŸæˆæŠ¥å‘Š
        
        Args:
            report_type: æŠ¥å‘Šç±»å‹
            start_date: èµ·å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            æŠ¥å‘Šå­—å…¸
        """
        report = {
            "type": report_type,
            "period": {
                "start": start_date.isoformat(),
                "end": end_date.isoformat(),
                "days": (end_date - start_date).days
            },
            "generated_at": datetime.now().isoformat(),
            "sections": {}
        }
        
        # 1. æ´»åŠ¨æ¦‚è§ˆ
        report["sections"]["activity_overview"] = self._get_activity_overview(start_date, end_date)
        
        # 2. æ–‡ä»¶æ“ä½œç»Ÿè®¡
        report["sections"]["file_operations"] = self._get_file_operations_stats(start_date, end_date)
        
        # 3. ç”Ÿäº§åŠ›åˆ†æ
        report["sections"]["productivity"] = self._get_productivity_analysis(start_date, end_date)
        
        # 4. çŸ¥è¯†å›¾è°±æ´å¯Ÿ
        report["sections"]["knowledge_insights"] = self._get_knowledge_insights()
        
        # 5. å·¥ä½œæ¨¡å¼åˆ†æ
        report["sections"]["work_patterns"] = self._get_work_patterns_analysis()
        
        # 6. çƒ­é—¨æ–‡ä»¶
        report["sections"]["top_files"] = self._get_top_files()
        
        # 7. æœç´¢åˆ†æ
        report["sections"]["search_analysis"] = self._get_search_analysis()
        
        # 8. å»ºè®®æ€»ç»“
        report["sections"]["suggestions_summary"] = self._get_suggestions_summary()
        
        # 9. è¶‹åŠ¿å¯¹æ¯”
        report["sections"]["trends"] = self._get_trends_comparison(report_type)
        
        # 10. ç”ŸæˆMarkdownæ‘˜è¦
        report["summary_markdown"] = self._generate_markdown_summary(report)
        
        # ä¿å­˜æŠ¥å‘Š
        self._save_report(report)
        
        # è®°å½•è¶‹åŠ¿æ•°æ®
        self._record_trend_data(report)
        
        return report
    
    def _get_activity_overview(self, start_date: datetime, end_date: datetime) -> Dict:
        """è·å–æ´»åŠ¨æ¦‚è§ˆ"""
        # è·å–æ¯æ—¥æ´»åŠ¨
        daily_activity = self.behavior_monitor.get_daily_activity(days=(end_date - start_date).days)
        
        total_events = sum(day["event_count"] for day in daily_activity)
        avg_daily_events = total_events / max(len(daily_activity), 1)
        
        # æœ€æ´»è·ƒçš„ä¸€å¤©
        most_active_day = max(daily_activity, key=lambda x: x["event_count"]) if daily_activity else None
        
        return {
            "total_events": total_events,
            "daily_average": round(avg_daily_events, 1),
            "most_active_day": most_active_day,
            "active_days": len([d for d in daily_activity if d["event_count"] > 0])
        }
    
    def _get_file_operations_stats(self, start_date: datetime, end_date: datetime) -> Dict:
        """è·å–æ–‡ä»¶æ“ä½œç»Ÿè®¡"""
        stats = self.behavior_monitor.get_statistics()
        
        # è·å–æ“ä½œç±»å‹åˆ†å¸ƒ
        recent_events = self.behavior_monitor.get_recent_events(limit=1000)
        
        operation_counts = Counter()
        for event in recent_events:
            event_time = datetime.fromisoformat(event["timestamp"])
            if start_date <= event_time <= end_date:
                operation_counts[event["event_type"]] += 1
        
        return {
            "total_operations": sum(operation_counts.values()),
            "operations_by_type": dict(operation_counts),
            "most_common_operation": operation_counts.most_common(1)[0] if operation_counts else None
        }
    
    def _get_productivity_analysis(self, start_date: datetime, end_date: datetime) -> Dict:
        """ç”Ÿäº§åŠ›åˆ†æ"""
        # è·å–æ–‡ä»¶ç¼–è¾‘æ¬¡æ•°
        frequent_files = self.behavior_monitor.get_frequently_used_files(limit=50)
        
        total_edits = sum(f.get("edit_count", 0) for f in frequent_files)
        total_opens = sum(f.get("open_count", 0) for f in frequent_files)
        
        # è®¡ç®—ç”Ÿäº§åŠ›è¯„åˆ†ï¼ˆç¼–è¾‘vsæ‰“å¼€æ¯”ä¾‹ï¼‰
        productivity_score = (total_edits / max(total_opens, 1)) * 100
        
        return {
            "total_files_edited": len([f for f in frequent_files if f.get("edit_count", 0) > 0]),
            "total_edits": total_edits,
            "total_file_opens": total_opens,
            "productivity_score": round(productivity_score, 1),
            "interpretation": self._interpret_productivity_score(productivity_score)
        }
    
    def _interpret_productivity_score(self, score: float) -> str:
        """è§£é‡Šç”Ÿäº§åŠ›è¯„åˆ†"""
        if score >= 50:
            return "é«˜æ•ˆ - ä½ ä¸“æ³¨äºåˆ›é€ å†…å®¹"
        elif score >= 30:
            return "è‰¯å¥½ - ä¿æŒäº†ä¸é”™çš„ç¼–è¾‘ä¹ æƒ¯"
        elif score >= 15:
            return "ä¸­ç­‰ - æ›´å¤šæ—¶é—´åœ¨æµè§ˆæ–‡ä»¶"
        else:
            return "è¾ƒä½ - å¯èƒ½åœ¨å¯»æ‰¾èµ„æ–™æˆ–è§„åˆ’ä¸­"
    
    def _get_knowledge_insights(self) -> Dict:
        """çŸ¥è¯†å›¾è°±æ´å¯Ÿ"""
        try:
            kg_stats = self.knowledge_graph.get_statistics()
            
            # è·å–çƒ­é—¨æ¦‚å¿µ
            top_concepts = self.knowledge_graph.concept_extractor.get_top_concepts(limit=10)
            
            return {
                "total_concepts": kg_stats.get("total_concepts", 0),
                "total_file_connections": kg_stats.get("file_relation_edges", 0),
                "average_connections_per_file": kg_stats.get("average_degree", 0),
                "graph_density": kg_stats.get("graph_density", 0),
                "top_concepts": [c["concept"] for c in top_concepts[:5]],
                "insight": self._interpret_graph_density(kg_stats.get("graph_density", 0))
            }
        except Exception as e:
            return {"error": str(e)}
    
    def _interpret_graph_density(self, density: float) -> str:
        """è§£é‡Šå›¾å¯†åº¦"""
        if density >= 0.3:
            return "æ–‡ä»¶å…³è”åº¦å¾ˆé«˜ï¼ŒçŸ¥è¯†ä½“ç³»è¿è´¯"
        elif density >= 0.1:
            return "æ–‡ä»¶æœ‰ä¸€å®šå…³è”ï¼Œå½¢æˆäº†çŸ¥è¯†ç½‘ç»œ"
        elif density >= 0.05:
            return "æ–‡ä»¶å…³è”åº¦ä¸­ç­‰ï¼Œå¯ä»¥åŠ å¼ºæ•´ç†"
        else:
            return "æ–‡ä»¶è¾ƒä¸ºåˆ†æ•£ï¼Œå»ºè®®å»ºç«‹æ›´å¤šå…³è”"
    
    def _get_work_patterns_analysis(self) -> Dict:
        """å·¥ä½œæ¨¡å¼åˆ†æ"""
        patterns = self.behavior_monitor.get_work_patterns()
        
        # æ‰¾å‡ºæœ€æ´»è·ƒçš„æ—¶é—´æ®µ
        time_patterns = patterns.get("time_of_day", [])
        most_active_period = time_patterns[0] if time_patterns else None
        
        # æ‰¾å‡ºæœ€å¸¸ç”¨çš„æ“ä½œ
        operation_patterns = patterns.get("operation_types", [])
        top_operations = operation_patterns[:3]
        
        return {
            "most_active_period": most_active_period,
            "top_operations": top_operations,
            "work_style": self._determine_work_style(patterns)
        }
    
    def _determine_work_style(self, patterns: Dict) -> str:
        """åˆ¤æ–­å·¥ä½œé£æ ¼"""
        operations = patterns.get("operation_types", [])
        if not operations:
            return "æ¢ç´¢è€… - æ­£åœ¨ç†Ÿæ‚‰ç³»ç»Ÿ"
        
        op_dict = {op["operation"]: op["frequency"] for op in operations}
        
        edit_count = op_dict.get(BehaviorMonitor.EVENT_FILE_EDIT, 0)
        search_count = op_dict.get(BehaviorMonitor.EVENT_FILE_SEARCH, 0)
        organize_count = op_dict.get(BehaviorMonitor.EVENT_FILE_ORGANIZE, 0)
        
        if edit_count > search_count and edit_count > organize_count:
            return "åˆ›ä½œè€… - ä¸“æ³¨äºå†…å®¹åˆ›ä½œ"
        elif search_count > edit_count:
            return "ç ”ç©¶è€… - æ“…é•¿æŸ¥æ‰¾å’Œæ•´ç†ä¿¡æ¯"
        elif organize_count > edit_count * 0.5:
            return "ç®¡ç†è€… - æ³¨é‡æ–‡ä»¶ç»„ç»‡å’Œç®¡ç†"
        else:
            return "å¹³è¡¡è€… - åœ¨åˆ›ä½œå’Œç®¡ç†é—´ä¿æŒå¹³è¡¡"
    
    def _get_top_files(self) -> List[Dict]:
        """è·å–çƒ­é—¨æ–‡ä»¶"""
        files = self.behavior_monitor.get_frequently_used_files(limit=10)
        
        return [
            {
                "path": f["file_path"],
                "name": Path(f["file_path"]).name,
                "opens": f["open_count"],
                "edits": f["edit_count"],
                "last_used": f.get("last_opened", f.get("last_edited"))
            }
            for f in files
        ]
    
    def _get_search_analysis(self) -> Dict:
        """æœç´¢åˆ†æ"""
        search_history = self.behavior_monitor.get_search_history(limit=100)
        
        if not search_history:
            return {"total_searches": 0}
        
        # ç»Ÿè®¡æœç´¢é¢‘ç‡
        query_counts = Counter(s["query"] for s in search_history)
        
        # ç‚¹å‡»ç‡åˆ†æ
        total_searches = len(search_history)
        searches_with_click = len([s for s in search_history if s.get("clicked_result")])
        click_through_rate = (searches_with_click / total_searches) * 100
        
        return {
            "total_searches": total_searches,
            "unique_queries": len(query_counts),
            "most_searched": query_counts.most_common(5),
            "click_through_rate": round(click_through_rate, 1),
            "search_effectiveness": self._interpret_ctr(click_through_rate)
        }
    
    def _interpret_ctr(self, ctr: float) -> str:
        """è§£é‡Šç‚¹å‡»ç‡"""
        if ctr >= 70:
            return "ä¼˜ç§€ - æœç´¢å¾ˆå‡†ç¡®"
        elif ctr >= 50:
            return "è‰¯å¥½ - é€šå¸¸èƒ½æ‰¾åˆ°éœ€è¦çš„"
        elif ctr >= 30:
            return "ä¸­ç­‰ - æœ‰æ”¹è¿›ç©ºé—´"
        else:
            return "è¾ƒä½ - å¯èƒ½éœ€è¦ä¼˜åŒ–æœç´¢ç­–ç•¥"
    
    def _get_suggestions_summary(self) -> Dict:
        """å»ºè®®æ€»ç»“"""
        stats = self.suggestion_engine.get_statistics()
        
        pending_suggestions = self.suggestion_engine.get_pending_suggestions(limit=5)
        
        return {
            "total_suggestions": stats.get("total_suggestions", 0),
            "applied": stats.get("applied_suggestions", 0),
            "dismissed": stats.get("dismissed_suggestions", 0),
            "pending": stats.get("pending_suggestions", 0),
            "acceptance_rate": stats.get("acceptance_rate", 0),
            "top_pending": [
                {"title": s["title"], "priority": s["priority"]}
                for s in pending_suggestions[:3]
            ]
        }
    
    def _get_trends_comparison(self, report_type: str) -> Dict:
        """è¶‹åŠ¿å¯¹æ¯”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–å†å²æŠ¥å‘Šè¿›è¡Œå¯¹æ¯”
        cursor.execute("""
            SELECT report_data, created_at
            FROM reports
            WHERE report_type = ?
            ORDER BY created_at DESC
            LIMIT 2
        """, (report_type,))
        
        results = cursor.fetchall()
        conn.close()
        
        if len(results) < 2:
            return {"trend_available": False}
        
        try:
            current_report = json.loads(results[0][0])
            previous_report = json.loads(results[1][0])
            
            # å¯¹æ¯”å…³é”®æŒ‡æ ‡
            current_events = current_report["sections"]["activity_overview"]["total_events"]
            previous_events = previous_report["sections"]["activity_overview"]["total_events"]
            
            change_percent = ((current_events - previous_events) / max(previous_events, 1)) * 100
            
            return {
                "trend_available": True,
                "activity_change": round(change_percent, 1),
                "trend_direction": "up" if change_percent > 0 else "down" if change_percent < 0 else "stable",
                "interpretation": self._interpret_trend(change_percent)
            }
        except Exception as e:
            return {"trend_available": False, "error": str(e)}
    
    def _interpret_trend(self, change: float) -> str:
        """è§£é‡Šè¶‹åŠ¿"""
        if change > 20:
            return "æ´»è·ƒåº¦å¤§å¹…æå‡ ğŸ“ˆ"
        elif change > 5:
            return "æ´»è·ƒåº¦ç¨³æ­¥å¢é•¿ ğŸ“Š"
        elif change > -5:
            return "æ´»è·ƒåº¦ä¿æŒç¨³å®š â¡ï¸"
        elif change > -20:
            return "æ´»è·ƒåº¦æœ‰æ‰€ä¸‹é™ ğŸ“‰"
        else:
            return "æ´»è·ƒåº¦æ˜¾è‘—ä¸‹é™ âš ï¸"
    
    def _generate_markdown_summary(self, report: Dict) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„æ‘˜è¦"""
        sections = report["sections"]
        period = report["period"]
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        start = datetime.fromisoformat(period["start"])
        end = datetime.fromisoformat(period["end"])
        
        md = f"""# ğŸ“Š Koto å·¥ä½œæŠ¥å‘Š

**æŠ¥å‘Šå‘¨æœŸ**: {start.strftime('%Y-%m-%d')} è‡³ {end.strftime('%Y-%m-%d')} ({period['days']}å¤©)
**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}

---

## ğŸ¯ æ´»åŠ¨æ¦‚è§ˆ

- **æ€»æ“ä½œæ•°**: {sections['activity_overview']['total_events']} æ¬¡
- **æ—¥å‡æ´»è·ƒ**: {sections['activity_overview']['daily_average']} æ¬¡
- **æ´»è·ƒå¤©æ•°**: {sections['activity_overview']['active_days']}/{period['days']} å¤©

"""
        
        # ç”Ÿäº§åŠ›åˆ†æ
        productivity = sections.get("productivity", {})
        md += f"""## ğŸ“ˆ ç”Ÿäº§åŠ›åˆ†æ

- **ç¼–è¾‘æ–‡ä»¶æ•°**: {productivity.get('total_files_edited', 0)} ä¸ª
- **æ€»ç¼–è¾‘æ¬¡æ•°**: {productivity.get('total_edits', 0)} æ¬¡
- **ç”Ÿäº§åŠ›è¯„åˆ†**: {productivity.get('productivity_score', 0)}% - {productivity.get('interpretation', 'æš‚æ— æ•°æ®')}

"""
        
        # çƒ­é—¨æ–‡ä»¶
        top_files = sections.get("top_files", [])[:5]
        if top_files:
            md += "## ğŸ”¥ æœ€å¸¸ç”¨æ–‡ä»¶\n\n"
            for i, file in enumerate(top_files, 1):
                md += f"{i}. **{file['name']}** - æ‰“å¼€{file['opens']}æ¬¡ï¼Œç¼–è¾‘{file['edits']}æ¬¡\n"
            md += "\n"
        
        # çŸ¥è¯†æ´å¯Ÿ
        knowledge = sections.get("knowledge_insights", {})
        if not knowledge.get("error"):
            md += f"""## ğŸ§  çŸ¥è¯†å›¾è°±æ´å¯Ÿ

- **æ¦‚å¿µæ€»æ•°**: {knowledge.get('total_concepts', 0)} ä¸ª
- **æ–‡ä»¶å…³è”**: {knowledge.get('total_file_connections', 0)} ä¸ª
- **å›¾è°±è¯„ä»·**: {knowledge.get('insight', 'æš‚æ— è¯„ä»·')}

"""
            
            if knowledge.get("top_concepts"):
                md += "**çƒ­é—¨æ¦‚å¿µ**: " + ", ".join(knowledge["top_concepts"]) + "\n\n"
        
        # å·¥ä½œæ¨¡å¼
        patterns = sections.get("work_patterns", {})
        if patterns.get("most_active_period"):
            period_name = patterns["most_active_period"]["period"]
            period_freq = patterns["most_active_period"]["frequency"]
            md += f"""## â° å·¥ä½œæ¨¡å¼

- **æœ€æ´»è·ƒæ—¶æ®µ**: {period_name} ({period_freq}æ¬¡æ“ä½œ)
- **å·¥ä½œé£æ ¼**: {patterns.get('work_style', 'æœªçŸ¥')}

"""
        
        # æœç´¢åˆ†æ
        search = sections.get("search_analysis", {})
        if search.get("total_searches", 0) > 0:
            md += f"""## ğŸ” æœç´¢åˆ†æ

- **æœç´¢æ¬¡æ•°**: {search['total_searches']} æ¬¡
- **ç‹¬ç‰¹æŸ¥è¯¢**: {search['unique_queries']} ä¸ª
- **ç‚¹å‡»ç‡**: {search['click_through_rate']}% - {search['search_effectiveness']}

"""
        
        # æ™ºèƒ½å»ºè®®
        suggestions = sections.get("suggestions_summary", {})
        if suggestions.get("pending", 0) > 0:
            md += f"""## ğŸ’¡ æ™ºèƒ½å»ºè®®

- **å¾…å¤„ç†å»ºè®®**: {suggestions['pending']} æ¡
- **é‡‡çº³ç‡**: {suggestions['acceptance_rate']}%

"""
            if suggestions.get("top_pending"):
                md += "**æ¨èå»ºè®®**:\n"
                for sug in suggestions["top_pending"]:
                    priority_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(sug["priority"], "âšª")
                    md += f"- {priority_emoji} {sug['title']}\n"
                md += "\n"
        
        # è¶‹åŠ¿
        trends = sections.get("trends", {})
        if trends.get("trend_available"):
            md += f"""## ğŸ“Š è¶‹åŠ¿å¯¹æ¯”

- **æ´»è·ƒåº¦å˜åŒ–**: {trends['activity_change']:+.1f}%
- **è¶‹åŠ¿**: {trends['interpretation']}

"""
        
        md += """---

*ç”± Koto æ™ºèƒ½æ–‡ä»¶å¤§è„‘è‡ªåŠ¨ç”Ÿæˆ*
"""
        
        return md
    
    def _save_report(self, report: Dict):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO reports (report_type, period_start, period_end, report_data, summary, created_at)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (
            report["type"],
            report["period"]["start"],
            report["period"]["end"],
            json.dumps(report),
            report.get("summary_markdown", ""),
            datetime.now().isoformat()
        ))
        
        conn.commit()
        conn.close()
    
    def _record_trend_data(self, report: Dict):
        """è®°å½•è¶‹åŠ¿æ•°æ®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        timestamp = datetime.now().isoformat()
        sections = report["sections"]
        
        # è®°å½•å…³é”®æŒ‡æ ‡
        metrics = {
            "total_events": sections["activity_overview"]["total_events"],
            "daily_average": sections["activity_overview"]["daily_average"],
            "productivity_score": sections["productivity"]["productivity_score"],
            "total_edits": sections["productivity"]["total_edits"]
        }
        
        for metric_name, metric_value in metrics.items():
            cursor.execute("""
                INSERT INTO trend_data (metric_name, metric_value, recorded_at)
                VALUES (?, ?, ?)
            """, (metric_name, metric_value, timestamp))
        
        conn.commit()
        conn.close()
    
    def get_latest_report(self, report_type: str = REPORT_WEEKLY) -> Optional[Dict]:
        """è·å–æœ€æ–°æŠ¥å‘Š"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT report_data, summary, created_at
            FROM reports
            WHERE report_type = ?
            ORDER BY created_at DESC
            LIMIT 1
        """, (report_type,))
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            report_data = json.loads(result[0])
            report_data["summary_markdown"] = result[1]
            return report_data
        
        return None
    
    def export_report_markdown(self, report: Dict, output_path: str):
        """å¯¼å‡ºæŠ¥å‘Šä¸ºMarkdownæ–‡ä»¶"""
        md_content = report.get("summary_markdown", "")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        return output_path


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    reporter = InsightReporter()
    
    print("ğŸ“Š æ´å¯ŸæŠ¥å‘Šç”Ÿæˆå™¨æµ‹è¯•")
    print("=" * 50)
    
    # ç”Ÿæˆå‘¨æŠ¥
    print("\nç”Ÿæˆå‘¨æŠ¥...")
    report = reporter.generate_weekly_report()
    
    print(f"\næŠ¥å‘Šç±»å‹: {report['type']}")
    print(f"æŠ¥å‘Šå‘¨æœŸ: {report['period']['days']}å¤©")
    print(f"\nç”Ÿæˆçš„Markdownæ‘˜è¦:\n")
    print(report.get("summary_markdown", "æš‚æ— æ‘˜è¦")[:500] + "...\n")
    
    print("=" * 50)
    print("âœ… æ´å¯ŸæŠ¥å‘Šç”Ÿæˆå™¨å·²å°±ç»ª")
