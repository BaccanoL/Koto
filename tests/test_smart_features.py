#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½åŠŸèƒ½ç»¼åˆæµ‹è¯•è„šæœ¬
æµ‹è¯•æ¦‚å¿µæå–ã€çŸ¥è¯†å›¾è°±ã€è¡Œä¸ºç›‘æ§ã€æ™ºèƒ½å»ºè®®å’Œæ´å¯ŸæŠ¥å‘Š
"""

import os
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, PROJECT_ROOT)

from web.concept_extractor import ConceptExtractor
from web.knowledge_graph import KnowledgeGraph
from web.behavior_monitor import BehaviorMonitor
from web.suggestion_engine import SuggestionEngine
from web.insight_reporter import InsightReporter


def print_section(title):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print("\n" + "=" * 60)
    print(f"  {title}")
    print("=" * 60 + "\n")


def test_concept_extraction():
    """æµ‹è¯•æ¦‚å¿µæå–"""
    print_section("ğŸ“ 1. æ¦‚å¿µæå–æµ‹è¯•")
    
    extractor = ConceptExtractor()
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    test_files = {
        'test_ai.txt': """
        äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ æ­£åœ¨æ”¹å˜ä¸–ç•Œã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹å¯ä»¥è¯†åˆ«å›¾åƒã€ç†è§£è¯­è¨€ã€‚
        ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ çš„åŸºç¡€ã€‚TensorFlowå’ŒPyTorchæ˜¯æµè¡Œçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚
        è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯è®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£äººç±»è¯­è¨€ã€‚
        """,
        'test_python.txt': """
        Pythonæ˜¯ä¸€ç§å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ã€‚å®ƒå¹¿æ³›åº”ç”¨äºæ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ é¢†åŸŸã€‚
        NumPyå’ŒPandasæ˜¯Pythonæ•°æ®åˆ†æçš„æ ¸å¿ƒåº“ã€‚
        Flaskå’ŒDjangoæ˜¯æµè¡Œçš„Python Webæ¡†æ¶ã€‚
        """,
        'test_web.txt': """
        å‰ç«¯å¼€å‘ä½¿ç”¨HTMLã€CSSå’ŒJavaScriptã€‚
        Reactã€Vueå’ŒAngularæ˜¯æµè¡Œçš„å‰ç«¯æ¡†æ¶ã€‚
        Node.jsè®©JavaScriptå¯ä»¥è¿è¡Œåœ¨æœåŠ¡å™¨ç«¯ã€‚
        RESTful APIæ˜¯WebæœåŠ¡çš„å¸¸ç”¨è®¾è®¡æ¨¡å¼ã€‚
        """
    }
    
    print("åˆ›å»ºæµ‹è¯•æ–‡ä»¶...")
    workspace_dir = Path("workspace")
    workspace_dir.mkdir(exist_ok=True)
    
    file_paths = []
    for filename, content in test_files.items():
        filepath = workspace_dir / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        file_paths.append(str(filepath))
        print(f"  âœ“ {filename}")
    
    print("\næå–æ¦‚å¿µ...")
    for filepath in file_paths:
        print(f"\nğŸ“„ {Path(filepath).name}:")
        result = extractor.analyze_file(filepath)
        
        if "error" not in result:
            for concept_data in result["concepts"][:5]:
                print(f"  â€¢ {concept_data['concept']}: {concept_data['score']:.4f}")
    
    # æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶
    print("\n\næŸ¥æ‰¾ç›¸å…³æ–‡ä»¶...")
    related = extractor.find_related_files(file_paths[0], limit=2)
    if related:
        print(f"ä¸ {Path(file_paths[0]).name} ç›¸å…³çš„æ–‡ä»¶:")
        for item in related:
            print(f"  â€¢ {Path(item['file_path']).name}")
            print(f"    ç›¸ä¼¼åº¦: {item['similarity']:.2%}")
            print(f"    å…±äº«æ¦‚å¿µ: {', '.join(item['shared_concepts'][:3])}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = extractor.get_statistics()
    print("\nğŸ“Š æ¦‚å¿µæå–ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  â€¢ {key}: {value}")
    
    return file_paths


def test_knowledge_graph(file_paths):
    """æµ‹è¯•çŸ¥è¯†å›¾è°±"""
    print_section("ğŸ•¸ï¸ 2. çŸ¥è¯†å›¾è°±æµ‹è¯•")
    
    kg = KnowledgeGraph()
    
    print("æ„å»ºçŸ¥è¯†å›¾è°±...")
    kg.build_file_graph(file_paths, force_rebuild=True)
    
    # è·å–å›¾æ•°æ®
    print("\nè·å–å›¾è°±æ•°æ®...")
    graph_data = kg.get_graph_data(max_nodes=50)
    print(f"  â€¢ èŠ‚ç‚¹æ•°: {len(graph_data['nodes'])}")
    print(f"  â€¢ è¾¹æ•°: {len(graph_data['edges'])}")
    
    # è·å–æ–‡ä»¶é‚»å±…
    print(f"\nè·å– {Path(file_paths[0]).name} çš„é‚»å±…èŠ‚ç‚¹...")
    neighbors = kg.get_file_neighbors(file_paths[0], depth=1)
    if "error" not in neighbors:
        print(f"  â€¢ é‚»å±…èŠ‚ç‚¹: {len(neighbors['nodes'])}")
        print(f"  â€¢ è¿æ¥è¾¹: {len(neighbors['edges'])}")
    
    # æ¦‚å¿µèšç±»
    print("\næµ‹è¯•æ¦‚å¿µèšç±»...")
    concepts = kg.concept_extractor.get_top_concepts(limit=1)
    if concepts:
        concept = concepts[0]['concept']
        cluster = kg.get_concept_cluster(concept, limit=5)
        print(f"æ¦‚å¿µ '{concept}' ç›¸å…³çš„æ–‡ä»¶:")
        for file_data in cluster['files']:
            print(f"  â€¢ {Path(file_data['file_path']).name}")
            print(f"    ç›¸å…³åº¦: {file_data['relevance']:.4f}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = kg.get_statistics()
    print("\nğŸ“Š çŸ¥è¯†å›¾è°±ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  â€¢ {key}: {value}")


def test_behavior_monitoring():
    """æµ‹è¯•è¡Œä¸ºç›‘æ§"""
    print_section("ğŸ‘ï¸ 3. è¡Œä¸ºç›‘æ§æµ‹è¯•")
    
    monitor = BehaviorMonitor()
    
    print("æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸º...")
    
    # æ¨¡æ‹Ÿä¸€äº›æ“ä½œ
    events = [
        (BehaviorMonitor.EVENT_FILE_OPEN, "workspace/test_ai.txt", 5000),
        (BehaviorMonitor.EVENT_FILE_EDIT, "workspace/test_ai.txt", 120000),
        (BehaviorMonitor.EVENT_FILE_OPEN, "workspace/test_python.txt", 3000),
        (BehaviorMonitor.EVENT_FILE_EDIT, "workspace/test_python.txt", 60000),
        (BehaviorMonitor.EVENT_FILE_SEARCH, None, 1000),
        (BehaviorMonitor.EVENT_FILE_OPEN, "workspace/test_ai.txt", 2000),
    ]
    
    for event_type, file_path, duration in events:
        monitor.log_event(
            event_type=event_type,
            file_path=file_path,
            duration_ms=duration
        )
        print(f"  âœ“ {event_type}")
        time.sleep(0.1)  # æ¨¡æ‹Ÿæ—¶é—´é—´éš”
    
    # è®°å½•æœç´¢
    monitor.log_search("æœºå™¨å­¦ä¹ ", result_count=5, clicked_result="test_ai.txt")
    monitor.log_search("Python", result_count=3, clicked_result="test_python.txt")
    print("  âœ“ è®°å½•æœç´¢å†å²")
    
    # è·å–æœ€å¸¸ç”¨æ–‡ä»¶
    print("\nğŸ“Š æœ€å¸¸ç”¨æ–‡ä»¶:")
    frequent_files = monitor.get_frequently_used_files(limit=3)
    for file_data in frequent_files:
        print(f"  â€¢ {Path(file_data['file_path']).name}")
        print(f"    æ‰“å¼€: {file_data['open_count']}æ¬¡, ç¼–è¾‘: {file_data['edit_count']}æ¬¡")
        print(f"    ä½¿ç”¨è¯„åˆ†: {file_data['usage_score']}")
    
    # å·¥ä½œæ¨¡å¼
    print("\nâ° å·¥ä½œæ¨¡å¼:")
    patterns = monitor.get_work_patterns()
    if patterns.get('time_of_day'):
        for pattern in patterns['time_of_day']:
            print(f"  â€¢ {pattern['period']}: {pattern['frequency']}æ¬¡")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = monitor.get_statistics()
    print("\nğŸ“Š è¡Œä¸ºç›‘æ§ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  â€¢ {key}: {value}")


def test_suggestions():
    """æµ‹è¯•æ™ºèƒ½å»ºè®®"""
    print_section("ğŸ’¡ 4. æ™ºèƒ½å»ºè®®æµ‹è¯•")
    
    engine = SuggestionEngine()
    
    print("ç”Ÿæˆæ™ºèƒ½å»ºè®®...")
    suggestions = engine.generate_suggestions(force_regenerate=True)
    
    if suggestions:
        print(f"\nç”Ÿæˆäº† {len(suggestions)} æ¡å»ºè®®:\n")
        for i, suggestion in enumerate(suggestions[:5], 1):
            priority_emoji = {
                "high": "ğŸ”´",
                "medium": "ğŸŸ¡",
                "low": "ğŸŸ¢"
            }.get(suggestion['priority'], "âšª")
            
            print(f"{i}. {priority_emoji} [{suggestion['type']}] {suggestion['title']}")
            print(f"   {suggestion['description']}")
            print()
    else:
        print("æš‚æ— å»ºè®®")
    
    # è·å–å¾…å¤„ç†å»ºè®®
    pending = engine.get_pending_suggestions(limit=3)
    print(f"å¾…å¤„ç†å»ºè®®: {len(pending)} æ¡")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = engine.get_statistics()
    print("\nğŸ“Š å»ºè®®å¼•æ“ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  â€¢ {key}: {value}")


def test_insights():
    """æµ‹è¯•æ´å¯ŸæŠ¥å‘Š"""
    print_section("ğŸ“ˆ 5. æ´å¯ŸæŠ¥å‘Šæµ‹è¯•")
    
    reporter = InsightReporter()
    
    print("ç”Ÿæˆå‘¨æŠ¥...")
    report = reporter.generate_weekly_report()
    
    print("\nğŸ“Š æŠ¥å‘Šæ‘˜è¦:")
    print(f"  æŠ¥å‘Šç±»å‹: {report['type']}")
    print(f"  å‘¨æœŸ: {report['period']['days']}å¤©")
    
    # æ˜¾ç¤ºéƒ¨åˆ†æŠ¥å‘Šå†…å®¹
    sections = report['sections']
    
    if 'activity_overview' in sections:
        activity = sections['activity_overview']
        print(f"\næ´»åŠ¨æ¦‚è§ˆ:")
        print(f"  â€¢ æ€»æ“ä½œæ•°: {activity['total_events']}")
        print(f"  â€¢ æ—¥å‡æ´»è·ƒ: {activity['daily_average']}æ¬¡")
        print(f"  â€¢ æ´»è·ƒå¤©æ•°: {activity['active_days']}")
    
    if 'productivity' in sections:
        prod = sections['productivity']
        print(f"\nç”Ÿäº§åŠ›åˆ†æ:")
        print(f"  â€¢ ç¼–è¾‘æ–‡ä»¶: {prod['total_files_edited']}ä¸ª")
        print(f"  â€¢ æ€»ç¼–è¾‘æ¬¡æ•°: {prod['total_edits']}")
        print(f"  â€¢ ç”Ÿäº§åŠ›è¯„åˆ†: {prod['productivity_score']}%")
        print(f"  â€¢ è¯„ä»·: {prod['interpretation']}")
    
    # æ˜¾ç¤ºMarkdownæ‘˜è¦çš„å‰500å­—ç¬¦
    print("\nğŸ“ MarkdownæŠ¥å‘Šæ‘˜è¦:")
    print(report.get('summary_markdown', '')[:500] + "...\n")
    
    # å¯¼å‡ºæŠ¥å‘Š
    output_path = "workspace/weekly_report.md"
    reporter.export_report_markdown(report, output_path)
    print(f"âœ… æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_path}")


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "ğŸ§ " * 30)
    print("    Koto æ™ºèƒ½æ–‡ä»¶å¤§è„‘ - ç»¼åˆåŠŸèƒ½æµ‹è¯•")
    print("ğŸ§ " * 30)
    
    try:
        # 1. æ¦‚å¿µæå–
        file_paths = test_concept_extraction()
        
        # 2. çŸ¥è¯†å›¾è°±
        test_knowledge_graph(file_paths)
        
        # 3. è¡Œä¸ºç›‘æ§
        test_behavior_monitoring()
        
        # 4. æ™ºèƒ½å»ºè®®
        test_suggestions()
        
        # 5. æ´å¯ŸæŠ¥å‘Š
        test_insights()
        
        print_section("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        
        print("\nğŸ‰ åŠŸèƒ½æ¼”ç¤º:")
        print("  1. æ¦‚å¿µæå–: è‡ªåŠ¨è¯†åˆ«æ–‡ä»¶ä¸­çš„å…³é”®è¯å’Œä¸»é¢˜")
        print("  2. çŸ¥è¯†å›¾è°±: æ„å»ºæ–‡ä»¶å…³ç³»ç½‘ç»œï¼Œå‘ç°å…³è”")
        print("  3. è¡Œä¸ºç›‘æ§: è¿½è¸ªç”¨æˆ·æ“ä½œï¼Œåˆ†æä½¿ç”¨æ¨¡å¼")
        print("  4. æ™ºèƒ½å»ºè®®: åŸºäºè¡Œä¸ºä¸»åŠ¨æä¾›å»ºè®®")
        print("  5. æ´å¯ŸæŠ¥å‘Š: ç”Ÿæˆå‘¨æŠ¥/æœˆæŠ¥ï¼Œå±•ç¤ºå·¥ä½œæ´å¯Ÿ")
        
        print("\nğŸŒ å¯åŠ¨Webç•Œé¢:")
        print("  1. è¿è¡Œ: python web/app.py")
        print("  2. è®¿é—®: http://localhost:5000/knowledge-graph")
        print("  3. ä½“éªŒå¯è§†åŒ–çŸ¥è¯†å›¾è°±å’Œæ™ºèƒ½å»ºè®®\n")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
