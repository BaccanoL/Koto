from typing import Dict, Any, Tuple, List, Optional
import time
import re

# å»¶è¿Ÿå¯¼å…¥ - è¿™äº›æ¨¡å—ä»…åœ¨è¿è¡Œæ—¶æ–¹æ³•è°ƒç”¨æ—¶åŠ è½½ï¼Œé¿å…å¯åŠ¨æ—¶åŠ è½½ google.genai (~4.7s) å’Œ requests (~0.5s)
# from app.core.routing.local_model_router import LocalModelRouter
# from app.core.routing.ai_router import AIRouter
# from app.core.routing.task_decomposer import TaskDecomposer
# from app.core.routing.local_planner import LocalPlanner

def _get_local_model_router():
    from app.core.routing.local_model_router import LocalModelRouter
    return LocalModelRouter

def _get_ai_router():
    from app.core.routing.ai_router import AIRouter
    return AIRouter

def _get_task_decomposer():
    from app.core.routing.task_decomposer import TaskDecomposer
    return TaskDecomposer

def _get_local_planner():
    from app.core.routing.local_planner import LocalPlanner
    return LocalPlanner

class SmartDispatcher:
    """
    æ··åˆæ™ºèƒ½è·¯ç”±ç®—æ³•
    1. é¦–å…ˆå°è¯• AI è·¯ç”±å™¨ï¼ˆå¿«é€Ÿã€æ™ºèƒ½ï¼‰
    2. å¦‚æœ AI è¶…æ—¶æˆ–å¤±è´¥ï¼Œå›é€€åˆ°æœ¬åœ°ç®—æ³•
    """
    
    # æ˜¯å¦å¯ç”¨ AI è·¯ç”±
    USE_AI_ROUTER = True
    
    # ä¾èµ–æ³¨å…¥å®¹å™¨
    _dependencies = {
        "LocalExecutor": None,
        "ContextAnalyzer": None,
        "WebSearcher": None,
        "MODEL_MAP": {},
        "client": None
    }
    
    @classmethod
    def configure(cls, local_executor, context_analyzer, web_searcher, model_map, client):
        """é…ç½®å¤–éƒ¨ä¾èµ–"""
        cls._dependencies["LocalExecutor"] = local_executor
        cls._dependencies["ContextAnalyzer"] = context_analyzer
        cls._dependencies["WebSearcher"] = web_searcher
        cls._dependencies["MODEL_MAP"] = model_map
        cls._dependencies["client"] = client

    # ä»»åŠ¡è¯­æ–™åº“ - æ¯ä¸ªä»»åŠ¡çš„å…¸å‹è¡¨è¾¾æ–¹å¼ (Simplified for brevity, but should be full list)
    TASK_CORPUS = {
        "PAINTER": [
            "ç”»ä¸€å¼ å›¾", "å¸®æˆ‘ç”»", "ç”Ÿæˆå›¾ç‰‡", "ç”»ä¸ªå›¾", "æ¥å¼ å›¾", "è¦å¼ å›¾ç‰‡",
            "åšä¸€å¼ å›¾", "åšå¼ å›¾", "åšä¸ªå›¾", "åšå›¾", "å‡ºä¸€å¼ å›¾", "å‡ºå¼ å›¾",
            "ç”»å£çº¸", "ç”»å¤´åƒ", "ç”»æ’ç”»", "ç”»æµ·æŠ¥", "ç”»logo", "ç”»é£æ™¯",
            "ç»˜åˆ¶", "ä½œç”»", "åˆ›ä½œå›¾åƒ", "è®¾è®¡å›¾ç‰‡", "å›¾ç‰‡ç”Ÿæˆ",
            "ç”»ä¸€ä¸ª", "ç”»åª", "ç”»æœµ", "ç”»åº§", "ç”»ä¸ªäººç‰©",
            "ç”Ÿæˆä¸€å¼ ", "ç”Ÿæˆä¸€å¹…", "åˆ›ä½œä¸€å¼ ", "åˆ¶ä½œä¸€å¼ å›¾",
            "å¯çˆ±å›¾", "å¸…æ°”å›¾", "ç¾å›¾", "èŒå›¾", "å›¾ç‰‡",
            "èµ›åšæœ‹å…‹é£æ ¼", "äºŒæ¬¡å…ƒé£æ ¼", "å†™å®é£æ ¼", "æ°´å½©ç”»", "æ²¹ç”»é£æ ¼",
            "åŠ¨æ¼«é£æ ¼", "å¡é€šé£æ ¼", "åƒç´ é£æ ¼", "æ‰‹ç»˜é£æ ¼",
            "ç”»ä¸ªè§’è‰²", "äººç‰©å›¾", "è§’è‰²å›¾", "ç«‹ç»˜", "å¤´åƒå›¾",
            "ç”Ÿæˆç…§ç‰‡", "ä¸€å¼ ç…§ç‰‡", "ç…§ç‰‡", "æ¥å¼ ç…§ç‰‡", "è¦å¼ ç…§ç‰‡",
            "æ˜æ—¥é¦™", "ç»‘èœ", "åˆéŸ³", "é›·å§†", "è•¾å§†", "è•¾ç±³", "çªäºšå¨œ",
            "ç”Ÿæˆä¸€å¼ xxxçš„ç…§ç‰‡", "xxxçš„å›¾ç‰‡", "xxxçš„ç…§ç‰‡",
            "ä¿®æ”¹å›¾ç‰‡", "ç¼–è¾‘ç…§ç‰‡", "ä¿®æ”¹ç…§ç‰‡", "æ¢èƒŒæ™¯", "æ¢åº•è‰²",
            "æŠŠèƒŒæ™¯", "æŠŠåº•è‰²", "èƒŒæ™¯æ”¹æˆ", "åº•è‰²æ”¹æˆ", "æ¢æˆè“è‰²",
            "æ¢æˆç™½è‰²", "æ¢æˆçº¢è‰²", "è¯ä»¶ç…§", "æŠ å›¾", "å»èƒŒæ™¯",
            "ä¿®å›¾", "På›¾", "ç¾åŒ–", "æ»¤é•œ", "è°ƒè‰²",
            "draw me", "generate image", "create picture", "make artwork",
            "paint a", "illustration of", "wallpaper of", "portrait of",
            "make an image", "create an image", "generate a picture",
            "edit image", "change background", "modify photo",
            "generate a photo", "photo of", "picture of",
        ],
        "CODER": [
            "å†™ä»£ç ", "ç¼–å†™ç¨‹åº", "å†™ä¸ªè„šæœ¬", "ä»£ç å®ç°", "ç¼–ç¨‹å®ç°",
            "å¸®æˆ‘å†™ä¸ªå‡½æ•°", "ä»£ç æ€ä¹ˆå†™", "è¿™æ®µä»£ç ", "ä¿®å¤bug", "è°ƒè¯•",
            "pythonå®ç°", "javascriptä»£ç ", "ç”¨javaå†™", "ç®—æ³•å®ç°",
            "æ•°æ®ç»“æ„", "æ’åºç®—æ³•", "ç½‘é¡µå¼€å‘", "åç«¯å¼€å‘", "APIæ¥å£",
            "æ•°æ®åº“æŸ¥è¯¢", "sqlè¯­å¥", "æ­£åˆ™è¡¨è¾¾å¼", "çˆ¬è™«",
            "write code", "implement function", "debug this", "fix bug",
            "python script", "javascript code", "coding", "programming",
        ],
        "FILE_GEN": [
            "ç”Ÿæˆpdf", "åˆ›å»ºword", "ç”Ÿæˆword", "å¯¼å‡ºword", "åšä¸ªwordæ–‡æ¡£", 
            "å†™ä»½wordæŠ¥å‘Š", "å¯¼å‡ºexcel", "ç”Ÿæˆexcelè¡¨æ ¼",
            "åˆ¶ä½œç®€å†", "å†™ä»½åˆåŒ", "ç”Ÿæˆè¡¨æ ¼", "åšppt", "åˆ¶ä½œppt", "ç”Ÿæˆå¹»ç¯ç‰‡",
            "æ–‡æ¡£æ¨¡æ¿", "æŠ¥å‘Šæ¨¡æ¿", "ç”Ÿæˆæ–‡ä»¶", "è¾“å‡ºæ–‡æ¡£", "ä¿å­˜ä¸ºæ–‡æ¡£",
            ".docx", ".pdf", ".xlsx", ".pptx",
            "æ–‡æ¡£æ ‡æ³¨", "æ‰¹æ³¨ä¿®æ”¹", "å…¨æ–‡æ¶¦è‰²", "docxæ¶¦è‰²", "wordæ–‡æ¡£æ”¹å†™",
            "æ”¹å†™æˆæ›´é€šé¡º", "è¯­åºä¸é€šé¡º", "ç¿»è¯‘è…”ä¿®æ”¹", "ç”¨ä¸­æ–‡è¯­åºæ”¹", 
            "æ ¡å¯¹æ–‡ç¨¿", "å®¡æ ¡æ–‡æ¡£", "çº é”™", "æ–‡æ¡£æ‰¹æ³¨", "æ–‡æ¡£ä¿®æ”¹",
            "create pdf", "generate word", "make document", "export excel",
            "create resume", "generate file", "save as document",
        ],
        "RESEARCH": [
            "æ·±å…¥åˆ†æ", "è¯¦ç»†ç ”ç©¶", "å…¨é¢è°ƒç ”", "ç³»ç»Ÿåˆ†æ", "æ·±åº¦è§£è¯»",
            "è®ºæ–‡åˆ†æ", "å­¦æœ¯ç ”ç©¶", "æŠ€æœ¯åŸç†", "åº•å±‚æœºåˆ¶", "æ¶æ„è®¾è®¡",
            "å¯¹æ¯”åˆ†æ", "ä¼˜ç¼ºç‚¹åˆ†æ", "å†å²æ¼”å˜", "å‘å±•è¶‹åŠ¿",
            "ä¸ºä»€ä¹ˆ", "åŸç†æ˜¯ä»€ä¹ˆ", "å¦‚ä½•å·¥ä½œ", "æ·±å…¥ç†è§£",
            "deep analysis", "research on", "in-depth study", "comprehensive review",
            "technical principle", "architecture design", "compare and contrast",
        ],
        "WEB_SEARCH": [
            "å¤©æ°”", "æ°”æ¸©", "ä¸‹é›¨å—", "ä¸‹é›ªå—", "æ¸©åº¦å¤šå°‘", "å¤©æ°”æ€ä¹ˆæ ·",
            "ä»Šå¤©å¤©æ°”", "æ˜å¤©å¤©æ°”", "è¿™å‘¨å¤©æ°”", "å¤©æ°”é¢„æŠ¥", "ä¼šä¸‹é›¨",
            "åŒ—äº¬å¤©æ°”", "ä¸Šæµ·å¤©æ°”", "æ·±åœ³å¤©æ°”", "æ­å·å¤©æ°”",
            "æœ€æ–°æ¶ˆæ¯", "ä»Šå¤©æ–°é—»", "ç°åœ¨", "å®æ—¶", "æœ€è¿‘å‘ç”Ÿ",
            "æœ€æ–°", "ä»Šæ—¥", "å½“å‰", "æ­¤åˆ»",
            "è‚¡ä»·å¤šå°‘", "ç°åœ¨æ±‡ç‡", "æ¯”ç‰¹å¸ä»·æ ¼", "é»„é‡‘ä»·æ ¼",
            "æ¯”åˆ†", "æ¯”èµ›ç»“æœ", "è°èµ¢äº†",
            "weather", "temperature", "forecast", "latest news", "current price",
        ],
        "FILE_OP": [
            "è¯»å–æ–‡ä»¶", "æ‰“å¼€æ–‡ä»¶", "æŸ¥çœ‹æ–‡ä»¶", "è¯»æ–‡ä»¶", "çœ‹çœ‹æ–‡ä»¶å†…å®¹",
            "æ–‡ä»¶åˆ—è¡¨", "åˆ—å‡ºæ–‡ä»¶", "ç›®å½•ä¸‹æœ‰ä»€ä¹ˆ", "æ–‡ä»¶å¤¹é‡Œæœ‰",
            "workspaceé‡Œ", "å·¥ä½œåŒºæ–‡ä»¶",
            "è‡ªåŠ¨å½’çº³æ–‡ä»¶å¤¹", "è‡ªåŠ¨æ•´ç†æ–‡ä»¶å¤¹", "å½’çº³è¿™ä¸ªè·¯å¾„", "æ•´ç†è¿™ä¸ªç›®å½•", "å¾®ä¿¡æ–‡ä»¶å½’çº³",
            "æ‰¹é‡", "æ‰¹é‡è½¬æ¢", "æ‰¹é‡é‡å‘½å", "æ‰¹é‡å½’æ¡£", "æ‰¹é‡å‹ç¼©", "æŠ½å–æ–‡æœ¬", "æå–æ–‡æœ¬", "æ ¼å¼è½¬æ¢",
            "read file", "open file", "list files", "show directory",
        ],
        "FILE_EDIT": [
            "ä¿®æ”¹æ–‡ä»¶", "ç¼–è¾‘æ–‡ä»¶", "æ”¹æ–‡ä»¶", "æ”¹ä¸€ä¸‹", "ä¿®æ”¹ä¸€ä¸‹",
            "æ›¿æ¢", "æŠŠxxxæ”¹æˆ", "å°†xxxæ”¹ä¸º", "æŠŠxxxæ¢æˆ", "æ”¹æˆxxx",
            "åˆ é™¤ç¬¬", "åˆ é™¤è¡Œ", "å»æ‰ç¬¬", "æ’å…¥", "æ·»åŠ ä¸€è¡Œ", "åŠ ä¸€è¡Œ",
            "åœ¨ç¬¬å‡ è¡Œ", "ç¬¬å‡ è¡Œæ”¹æˆ", "ç¬¬å‡ è¡Œæ’å…¥", "ç¬¬å‡ è¡Œä¹‹å",
            "æ–‡ä»¶é‡Œçš„", "ä»£ç ä¸­çš„", "è„šæœ¬é‡Œçš„", "é…ç½®æ–‡ä»¶",
            "ä¿®å¤æ–‡ä»¶", "æ›´æ–°æ–‡ä»¶", "è¿½åŠ å†…å®¹", "æœ«å°¾æ·»åŠ ",
            "edit file", "modify file", "change file", "replace in file",
            "delete line", "insert line", "append to file", "update file",
        ],
        "FILE_SEARCH": [
            "æ‰¾æ–‡ä»¶", "æŸ¥æ‰¾æ–‡ä»¶", "æœç´¢æ–‡ä»¶", "æ‰¾ä¸€ä¸‹", "æŸ¥ä¸€ä¸‹", "æœä¸€ä¸‹",
            "å“ªä¸ªæ–‡ä»¶", "å“ªäº›æ–‡ä»¶", "æ–‡ä»¶åœ¨å“ª", "æœ‰ä»€ä¹ˆæ–‡ä»¶",
            "åŒ…å«xxxçš„æ–‡ä»¶", "å†…å®¹æ˜¯xxx", "æ–‡ä»¶å†…å®¹", "æœç´¢å†…å®¹",
            "æ‰¾åˆ°", "æŸ¥åˆ°", "ä¹‹å‰", "ä»¥å‰", "å¤„ç†è¿‡", "ç”Ÿæˆè¿‡",
            "é‚£ä¸ªæ–‡ä»¶", "é‚£ä»½æ–‡ä»¶", "å“ªä»½æ–‡ä»¶", "å“ªä¸ªæ–‡æ¡£",
            "å…³äºxxxçš„æ–‡ä»¶", "xxxç›¸å…³çš„æ–‡ä»¶",
            "find file", "search file", "locate file", "which file",
            "file contains", "file with", "search for", "look for file",
        ],
        "CHAT": [
            "ä½ å¥½", "åœ¨å—", "èŠèŠ", "è¯´è¯´", "è®²ä¸ªç¬‘è¯", "æœ‰ç©ºå—",
            "æ€ä¹ˆæ ·", "æ˜¯ä»€ä¹ˆ", "ä»€ä¹ˆæ˜¯", "ä»‹ç»ä¸€ä¸‹", "ä»‹ç»ä¸‹",
            "æ¨èä¸€ä¸‹", "å»ºè®®", "å¸®å¿™", "èƒ½ä¸èƒ½", "å¯ä»¥å—",
            "è°¢è°¢", "æ„Ÿè°¢", "å†è§", "æ™šå®‰",
            "äº†è§£", "æƒ³äº†è§£", "æˆ‘æƒ³çŸ¥é“", "å‘Šè¯‰æˆ‘", "è®²è®²", "è¯´ä¸€ä¸‹", "è¯´è¯´çœ‹",
            "è§£é‡Šä¸€ä¸‹", "æ˜¯å•¥", "æœ‰ä»€ä¹ˆ", "æ€ä¹ˆå›äº‹", "ä¸ºå•¥",
            "èƒ½ä»‹ç»", "å¸®æˆ‘ä»‹ç»", "ç»™æˆ‘è®²è®²", "è°ˆè°ˆ",
            "å†™ä¸€æ®µ", "å†™ç‚¹", "å†™ä¸ªä»‹ç»", "ç®€å•ä»‹ç»", "ç®€çŸ­ä»‹ç»",
            "äº§å“ä»‹ç»", "å…¬å¸ä»‹ç»", "é¡¹ç›®ä»‹ç»", "åŠŸèƒ½ä»‹ç»",
            "å†™ä¸€ç¯‡", "å†™å‡ å¥", "å†™ç‚¹å†…å®¹", "æ–‡å­—è¯´æ˜", "æ–‡æ¡ˆ",
            "å£å·", "æ ‡è¯­", "å¹¿å‘Šè¯", "å®£ä¼ è¯­",
            "hello", "hi there", "how are you", "what is", "tell me about",
            "can you", "please help", "thanks", "recommend", "suggest",
            "explain", "describe", "I want to know", "I'd like to learn",
            "write a brief", "write some text", "short description", "introduction of",
        ],
        "SYSTEM": [
            "ç³»ç»Ÿæ—¶é—´", "å½“å‰æ—¶é—´", "å‡ ç‚¹äº†", "ä»Šå¤©å‡ å·", "æ—¥æœŸ", "æ˜ŸæœŸå‡ ",
            "å…³æœº", "é‡å¯", "ä¼‘çœ ", "ç¡çœ ", "æˆªå›¾", "æœç´¢",
            "æ‰“å¼€", "å¯åŠ¨", "è¿è¡Œ", "å…³é—­", "é€€å‡º", "æ€æ­»",
            "ç³»ç»ŸçŠ¶æ€", "ç”µè„‘çŠ¶æ€", "ç³»ç»Ÿä¿¡æ¯", "ç”µè„‘ä¿¡æ¯", "é…ç½®", "å†…å­˜", "cpu", "ç¡¬ç›˜",
            "what time is it", "current time", "date today", "shutdown", "restart",
        ],
    }

    # é¢„è®¡ç®—ç‰¹å¾ (å­—ç¬¦çº§ n-gram)
    _features = None
    _task_vectors = None
    
    @classmethod
    def _init_features(cls):
        """åˆå§‹åŒ–ç‰¹å¾å‘é‡ (æ‡’åŠ è½½)"""
        if cls._features is not None:
            return
        
        all_ngrams = set()
        for corpus in cls.TASK_CORPUS.values():
            for text in corpus:
                ngrams = cls._extract_ngrams(text)
                all_ngrams.update(ngrams)
        
        cls._features = list(all_ngrams)
        
        cls._task_vectors = {}
        for task, corpus in cls.TASK_CORPUS.items():
            vectors = [cls._text_to_vector(text) for text in corpus]
            avg_vector = [sum(v[i] for v in vectors) / len(vectors) for i in range(len(cls._features))]
            cls._task_vectors[task] = avg_vector

    @classmethod
    def _compute_similarity_scores(cls, user_input: str) -> dict:
        """è®¡ç®—å„ä»»åŠ¡çš„ç›¸ä¼¼åº¦åˆ†æ•°"""
        if cls._features is None or cls._task_vectors is None:
            cls._init_features()
        user_vector = cls._text_to_vector(user_input)
        return {
            task: cls._cosine_similarity(user_vector, task_vector)
            for task, task_vector in cls._task_vectors.items()
        }

    @classmethod
    def _build_routing_list(cls, scores: dict, boosts: dict = None, reasons: dict = None, top_k: int = 6) -> list:
        """æ„å»ºè·¯ç”±åˆ†é…åˆ—è¡¨ï¼ˆç”¨äºå¯è§†åŒ–å±•ç¤ºï¼‰"""
        boosts = boosts or {}
        reasons = reasons or {}
        routing = []
        for task, score in scores.items():
            final_score = max(score, boosts.get(task, 0))
            reason_list = reasons.get(task, [])
            if not reason_list:
                reason_list = ["similarity"]
            routing.append({
                "task": task,
                "score": float(final_score),
                "reason": " + ".join(reason_list)
            })
        routing.sort(key=lambda x: x["score"], reverse=True)
        return routing[:top_k]
    
    @staticmethod
    def _extract_ngrams(text, n=2):
        """æå–å­—ç¬¦çº§ n-gram"""
        text = text.lower().strip()
        ngrams = set()
        for char in text:
            if char.strip():
                ngrams.add(char)
        for i in range(len(text) - 1):
            if text[i:i+2].strip():
                ngrams.add(text[i:i+2])
        return ngrams
    
    @classmethod
    def _quick_task_hint(cls, user_input: str) -> str:
        text_lower = user_input.lower()
        if any(k in text_lower for k in ["ç”»", "å›¾", "ç…§ç‰‡", "ç”Ÿæˆå›¾", "ç»˜åˆ¶"]):
            return "PAINTER"
        if any(k in text_lower for k in ["ä»£ç ", "ç¼–ç¨‹", "python", "javascript", "å‡½æ•°"]):
            return "CODER"
        if any(k in text_lower for k in ["æŸ¥", "æœç´¢", "ä»·æ ¼", "å¤©æ°”", "æ–°é—»"]):
            return "WEB_SEARCH"
        if any(k in text_lower for k in ["word", "pdf", "docx", "è¡¨æ ¼", "æ–‡æ¡£", "æŠ¥å‘Š", "ç”Ÿæˆ", "åšæˆ", "æ ‡æ³¨", "æ‰¹æ³¨", "æ¶¦è‰²", "æ”¹å†™", "æ ¡å¯¹", "å®¡æ ¡", "ä¿®è®¢", "çº é”™"]):
            return "FILE_GEN"
        if any(k in text_lower for k in ["ç ”ç©¶", "åˆ†æ", "æ·±å…¥", "ä»‹ç»"]):
            return "RESEARCH"
        return "CHAT"
    
    @classmethod
    def _text_to_vector(cls, text):
        if cls._features is None:
            cls._init_features()
        ngrams = cls._extract_ngrams(text)
        vector = [1 if f in ngrams else 0 for f in cls._features]
        return vector
    
    @staticmethod
    def _cosine_similarity(v1, v2):
        dot_product = sum(a * b for a, b in zip(v1, v2))
        norm1 = sum(a * a for a in v1) ** 0.5
        norm2 = sum(b * b for b in v2) ** 0.5
        if norm1 == 0 or norm2 == 0:
            return 0
        return dot_product / (norm1 * norm2)
    
    @classmethod
    def _get_dep(cls, name):
        """Helper to get dependency safely"""
        return cls._dependencies.get(name)

    @staticmethod
    def _should_use_annotation_system(user_input, has_file=False):
        """Simplistic check if annotation system should be used"""
        # This logic was previously inline or imported, implementing basic check here
        keywords = ["æ ‡æ³¨", "æ‰¹æ³¨", "æ¶¦è‰²", "æ”¹å†™", "æ ¡å¯¹", "å®¡æ ¡", "ä¿®è®¢", "çº é”™", "æ”¹å–„", "ä¼˜åŒ–", "ä¿®æ”¹"]
        quality_words = ["ä¸åˆé€‚", "ç”Ÿç¡¬", "ç¿»è¯‘è…”", "è¯­åº", "ç”¨è¯", "é€»è¾‘", "é—®é¢˜"]
        target_words = ["ç¿»è¯‘", "æ–‡ç« ", "æ–‡æ¡£", "å†…å®¹", "æ–‡æœ¬", "æ®µè½", "å¥å­", "å­—è¯"]
        
        if not has_file:
            return False
            
        has_kw = any(k in user_input for k in keywords)
        has_qw = any(q in user_input for q in quality_words)
        has_target = any(t in user_input for t in target_words)
        
        return has_kw or (has_qw and has_target)

    @classmethod
    def analyze(cls, user_input: str, history=None, file_context=None):
        """
        æ™ºèƒ½åˆ†æç”¨æˆ·è¾“å…¥ï¼Œè¿”å›æœ€åŒ¹é…çš„ä»»åŠ¡ç±»å‹
        ä¼˜å…ˆçº§ï¼šè§„åˆ™æ£€æµ‹ > æœ¬åœ°å¿«é€Ÿæ¨¡å‹ > RAG > è¿œç¨‹AI > æœ¬åœ°è¯­æ–™
        
        è¿”å›: (task_type, confidence_info, context_info)
        """
        start_time = time.time()
        
        # Get dependencies
        LocalExecutor = cls._get_dep("LocalExecutor")
        ContextAnalyzer = cls._get_dep("ContextAnalyzer")
        WebSearcher = cls._get_dep("WebSearcher")
        client = cls._get_dep("client")
        
        # åˆå§‹åŒ–ç‰¹å¾ (é¦–æ¬¡è°ƒç”¨)
        cls._init_features()
        
        user_lower = user_input.lower().strip()
        context_info = None
        similarity_scores = cls._compute_similarity_scores(user_input)
        base_routing_list = cls._build_routing_list(similarity_scores)
        
        # === 0. Force Plan Mode (New Feature) ===
        if user_input.strip().startswith("/plan ") or "è¯·åˆ¶å®šè®¡åˆ’" in user_input or "æ‹†è§£ä»»åŠ¡" in user_input:
            context_info = {"complexity": "complex", "is_multi_step_task": True}
            context_info["multi_step_info"] = {
                "pattern": "forced_plan",
                "description": "User forced planning mode"
            }
            context_info["routing_list"] = cls._build_routing_list(
                similarity_scores, 
                boosts={"MULTI_STEP": 1.0},
                reasons={"MULTI_STEP": ["user_forced"]}
            )
            return "MULTI_STEP", "ğŸ› ï¸ Forced-Plan", context_info
        
        # === ä¼˜å…ˆï¼šæ–‡ä»¶é™„ä»¶å¤„ç† logic ===
        if file_context and file_context.get("has_file"):
            file_ext = file_context.get("file_type", "")
            edit_keywords = ["ä¿®æ”¹", "æ›´æ”¹", "æ ‡æ³¨", "æ‰¹æ³¨", "æ¶¦è‰²", "æ”¹å†™", "æ ¡å¯¹", "å®¡æ ¡", "ä¿®è®¢", "çº é”™", "æ”¹å–„", "ä¼˜åŒ–", "è°ƒæ•´"]
            has_edit_intent = any(kw in user_lower for kw in edit_keywords)
            
            if has_edit_intent and file_ext in [".docx", ".doc"]:
                context_info = {"complexity": "complex"}
                context_info["routing_list"] = cls._build_routing_list(
                    similarity_scores, 
                    boosts={"DOC_ANNOTATE": 1.0},
                    reasons={"DOC_ANNOTATE": ["rule:doc_annotate"]}
                )
                print(f"[SmartDispatcher] ğŸ“„ æ£€æµ‹åˆ° Word æ–‡æ¡£æ ‡æ³¨è¯·æ±‚: {file_ext}")
                return "DOC_ANNOTATE", "ğŸ“„ Doc-Annotate", context_info
            elif has_edit_intent and file_ext in [".md", ".txt"]:
                context_info = {"complexity": "complex", "is_multi_step_task": True}
                context_info["multi_step_info"] = {
                    "pattern": "document_workflow",
                    "description": "æ–‡æ¡£æ™ºèƒ½ç¼–è¾‘å·¥ä½œæµ"
                }
                context_info["routing_list"] = cls._build_routing_list(
                    similarity_scores, 
                    boosts={"MULTI_STEP": 1.0},
                    reasons={"MULTI_STEP": ["rule:doc_workflow"]}
                )
                print(f"[SmartDispatcher] ğŸ“„ æ£€æµ‹åˆ°æ–‡ä»¶ç¼–è¾‘è¯·æ±‚: {file_ext}")
                return "MULTI_STEP", "ğŸ“„ Doc-Workflow", context_info

        # === å¿«é€Ÿé€šé“: è¶…çŸ­è¾“å…¥ ===
        if len(user_input) <= 3:
            if LocalExecutor and LocalExecutor.is_system_command(user_input):
                context_info = context_info or {}
                context_info["routing_list"] = cls._build_routing_list(
                    similarity_scores,
                    boosts={"SYSTEM": 1.0},
                    reasons={"SYSTEM": ["rule:standalone_command"]}
                )
                return "SYSTEM", "ğŸ–¥ï¸ Rule-Detected", context_info
            return "CHAT", "âš¡ Quick", None

        # === æœ¬åœ° Ollama è·¯ç”±ï¼ˆå‚è€ƒä¿¡å·ï¼Œä¸ç‹¬è£ï¼‰ ===
        local_task, local_confidence, local_source = _get_local_model_router().classify(user_input, timeout=4.0)
        if local_task:
            if local_task == "CHAT" and WebSearcher and WebSearcher.needs_web_search(user_input):
                context_info = context_info or {}
                context_info["routing_list"] = cls._build_routing_list(
                    similarity_scores,
                    boosts={"WEB_SEARCH": 0.95},
                    reasons={"WEB_SEARCH": ["override:chat_to_web_search"]}
                )
                return "WEB_SEARCH", "ğŸŒ Override-Detected", context_info

            if LocalExecutor and LocalExecutor.is_system_command(user_input) and local_task != "SYSTEM":
                context_info = context_info or {}
                context_info["routing_list"] = cls._build_routing_list(
                    similarity_scores,
                    boosts={"SYSTEM": 0.95},
                    reasons={"SYSTEM": ["local_override:system"]}
                )
                return "SYSTEM", "ğŸ–¥ï¸ Local-Override", context_info

            agent_overrides = [
                r"å‘å¾®ä¿¡", r"å›å¾®ä¿¡", r"å¾®ä¿¡å‘", r"å¾®ä¿¡å›",
                r"ç»™.{1,6}å‘æ¶ˆæ¯", r"ç»™.{1,6}å‘å¾®ä¿¡",
                r"æµè§ˆå™¨æ‰“å¼€", r"ç‚¹å‡».{1,6}æŒ‰é’®",
            ]
            if any(re.search(p, user_lower) for p in agent_overrides):
                context_info = context_info or {}
                context_info["routing_list"] = cls._build_routing_list(
                    similarity_scores,
                    boosts={"AGENT": 0.95},
                    reasons={"AGENT": ["local_override:agent"]}
                )
                return "AGENT", "ğŸ¤– Local-Override", context_info

            ticket_keywords = ["12306", "ç«è½¦ç¥¨", "é«˜é“ç¥¨", "åŠ¨è½¦ç¥¨"]
            if any(k in user_lower for k in ticket_keywords):
                context_info = context_info or {}
                context_info["routing_list"] = cls._build_routing_list(
                    similarity_scores,
                    boosts={"AGENT": 0.95},
                    reasons={"AGENT": ["local_override:ticket"]}
                )
                return "AGENT", "ğŸ¤– Local-Override", context_info

            _easily_confused = {"DOC_ANNOTATE", "FILE_GEN"}
            if local_task in _easily_confused:
                has_file = file_context and file_context.get("has_file")
                if not has_file:
                    print(f"[SmartDispatcher] âš ï¸ æœ¬åœ°æ¨¡å‹è¿”å› {local_task} ä½†æ— æ–‡ä»¶ä¸Šä¸‹æ–‡ï¼Œè·³è¿‡")
                    pass 
                else:
                    context_info = context_info or {}
                    context_info["routing_list"] = cls._build_routing_list(
                        similarity_scores,
                        boosts={local_task: 0.9},
                        reasons={local_task: ["local_model_with_file"]}
                    )
                    return local_task, f"{local_confidence}", context_info
            else:
                context_info = context_info or {}
                context_info["routing_list"] = cls._build_routing_list(
                    similarity_scores,
                    boosts={local_task: 0.9},
                    reasons={local_task: ["local_model"]}
                )
                return local_task, f"{local_confidence}", context_info

        # === æ·±åº¦æ–‡æ¡£è¯·æ±‚ç›´é€š FILE_GEN ===
        deep_doc_keywords = ["æ·±åº¦", "è¯¦ç»†", "ç ”ç©¶", "å…¨é¢", "æŠ€æœ¯", "æŠ¥å‘Š", "ç»¼è¿°", "whitepaper", "word", "docx", "è®ºæ–‡", "åˆ†æ"]
        _file_format_kw = ["word", "doc", "docx", "pdf", "æŠ¥å‘Š", "æ–‡æ¡£", "whitepaper", "è®ºæ–‡", "ç»¼è¿°"]
        if any(k in user_lower for k in deep_doc_keywords) and any(k in user_lower for k in _file_format_kw):
            context_info = {"complexity": "complex"}
            context_info["routing_list"] = cls._build_routing_list(
                similarity_scores,
                boosts={"FILE_GEN": 1.0},
                reasons={"FILE_GEN": ["rule:deep-doc"]}
            )
            return "FILE_GEN", "ğŸ“„ Rule-Detected", context_info
        
        # === è§„åˆ™æ£€æµ‹ ===
        
        if file_context and file_context.get("has_file"):
            _fc_ext = file_context.get("file_type", "")
            if _fc_ext in [".doc", ".docx"]:
                try:
                    if cls._should_use_annotation_system(user_input, has_file=True):
                        context_info = {"complexity": "complex"}
                        context_info["routing_list"] = cls._build_routing_list(
                            similarity_scores,
                            boosts={"DOC_ANNOTATE": 1.0},
                            reasons={"DOC_ANNOTATE": ["rule:annotation_with_file"]}
                        )
                        return "DOC_ANNOTATE", "ğŸ“„ Annotation-Strict", context_info
                except Exception:
                    pass

        _ppt_direct_keywords = ["ppt", "å¹»ç¯ç‰‡", "æ¼”ç¤ºæ–‡ç¨¿", "presentation", "slide", "slides", ".pptx"]
        _ppt_action_words = ["åš", "ç”Ÿæˆ", "åˆ›å»º", "åˆ¶ä½œ", "åšä¸€ä¸ª", "åšä¸ª", "å¸®æˆ‘åš", "å¸®æˆ‘ç”Ÿæˆ"]
        if any(k in user_lower for k in _ppt_direct_keywords) and any(a in user_lower for a in _ppt_action_words):
            context_info = {"complexity": "complex"}
            context_info["routing_list"] = cls._build_routing_list(
                similarity_scores,
                boosts={"FILE_GEN": 1.0},
                reasons={"FILE_GEN": ["rule:ppt_direct"]}
            )
            print(f"[SmartDispatcher] ğŸ¯ PPT è¯·æ±‚ç›´é€š FILE_GEN ä¸“ç”¨ç®¡çº¿")
            return "FILE_GEN", "ğŸ“„ PPT-Direct", context_info

        if LocalExecutor and LocalExecutor.is_system_command(user_input):
            context_info = context_info or {}
            context_info["routing_list"] = cls._build_routing_list(
                similarity_scores,
                boosts={"SYSTEM": 0.9},
                reasons={"SYSTEM": ["rule:system"]}
            )
            return "SYSTEM", "ğŸ–¥ï¸ Rule-Detected", context_info

        _agent_keywords = [
            "å‘å¾®ä¿¡", "å›å¾®ä¿¡", "å¾®ä¿¡å‘", "å¾®ä¿¡å›", "ç»™.*å‘æ¶ˆæ¯", "ç»™.*å‘å¾®ä¿¡",
            "è®¾æ—¥ç¨‹", "æ·»åŠ æ—¥ç¨‹", "æ—¥å†", "å®‰æ’ä¼šè®®", "çº¦.*æ—¶é—´",
            "åˆ é™¤æ—¥ç¨‹", "å–æ¶ˆæ—¥ç¨‹", "åˆ—å‡ºæ—¥ç¨‹", "æŸ¥çœ‹æ—¥ç¨‹",
            "æé†’æˆ‘", "è®©æˆ‘", "é€šçŸ¥æˆ‘",
            "åˆ—å‡ºæé†’", "å–æ¶ˆæé†’", "åˆ é™¤æé†’", "æœ‰.*æé†’", "æŸ¥çœ‹æé†’",
            "è¯»å–æ–‡ä»¶", "è¯»æ–‡ä»¶", "çœ‹æ–‡ä»¶", "è¯»å–.*æ–‡ä»¶", "æ–‡ä»¶å†…å®¹",
            "åˆ—å‡º.*æ–‡ä»¶", "ç›®å½•ä¸‹.*æ–‡ä»¶", "æœ‰ä»€ä¹ˆæ–‡ä»¶", "æœ‰å“ªäº›æ–‡ä»¶",
            "æœæœ¬åœ°", "æ‰¾æ–‡ä»¶", "æŸ¥æ‰¾.*æ–‡ä»¶",
            "å†™æ–‡ä»¶", "å†™å…¥æ–‡ä»¶", "ä¿å­˜.*æ–‡ä»¶", "ä¿å­˜åˆ°.*æ–‡ä»¶",
            "workspace", "å·¥ä½œåŒº",
            "å‰ªè´´æ¿", "ç²˜è´´æ¿", "å‰ªåˆ‡æ¿", "å¤åˆ¶äº†ä»€ä¹ˆ", "æœ€è¿‘å¤åˆ¶",
            "å¤åˆ¶å†å²", "å¤åˆ¶è®°å½•",
            "è¯»å–æ–‡æ¡£", "è¯»æ–‡æ¡£", "æ‰“å¼€æ–‡æ¡£",
            "æ‰“å¼€ç½‘é¡µ", "æµè§ˆå™¨æ‰“å¼€", "è®¿é—®.*ç½‘ç«™",
            "æµè§ˆå™¨æˆªå›¾", "ç½‘é¡µæˆªå›¾", "æˆªä¸ªå›¾",
            "ç‚¹å‡».*å…ƒç´ ", "ç‚¹å‡».*æŒ‰é’®", "è¾“å…¥.*æ–‡æœ¬",
            "è·å–.*æ–‡æœ¬", "è·å–ç½‘é¡µ.*å†…å®¹",
        ]
        _agent_patterns = [
            "ç„¶å", "æ¥ç€", "é¡ºä¾¿", "å†", "ä¹‹å", "å®Œæˆå",
            "å¸®æˆ‘.*æ‰¾.*ç„¶å", "å…ˆ.*å†.*", ".*å®Œäº†.*",
            "ä¿å­˜åˆ°.*txt", "ä¿å­˜åˆ°.*æ–‡ä»¶", "å†™åˆ°.*æ–‡ä»¶",
        ]
        
        has_agent_keyword = any(re.search(k, user_lower) for k in _agent_keywords)
        has_agent_pattern = any(re.search(p, user_lower) for p in _agent_patterns)
        
        _question_words = ["æ€ä¹ˆ", "å¦‚ä½•", "ä»€ä¹ˆåŠæ³•", "ä»€ä¹ˆæ–¹æ³•", "æ˜¯ä»€ä¹ˆ", "ä»€ä¹ˆæ˜¯",
                          "ä¸ºä»€ä¹ˆ", "èƒ½ä¸èƒ½", "å¯ä»¥å—", "æ€æ ·", "ä¸€èˆ¬ç”¨", "å“ªäº›",
                          "ç”¨ä»€ä¹ˆ", "è®²è®²", "è¯´è¯´", "ä»‹ç»", "æ•™ç¨‹", "åŸç†",
                          "how to", "what is", "why", "which"]
        is_question = any(qw in user_lower for qw in _question_words)
        
        if (has_agent_keyword or (has_agent_pattern and len(user_input) > 15)) and not is_question:
            context_info = context_info or {}
            context_info["routing_list"] = cls._build_routing_list(
                similarity_scores,
                boosts={"AGENT": 1.0},
                reasons={"AGENT": ["rule:agent_tools"]}
            )
            print(f"[SmartDispatcher] ğŸ¤– æ£€æµ‹åˆ° Agent ä»»åŠ¡ï¼Œä½¿ç”¨å·¥å…·è°ƒç”¨")
            return "AGENT", "ğŸ¤– Agent-Tools", context_info

        _LocalPlanner = _get_local_planner()
        if _LocalPlanner.can_plan(user_input):
            plan = _LocalPlanner.plan(user_input)
            if plan and plan.get("use_planner") and plan.get("steps"):
                context_info = context_info or {}
                context_info["is_multi_step_task"] = True
                context_info["multi_step_info"] = {
                    "pattern": "local_plan",
                    "subtasks": plan.get("steps", [])
                }
                context_info["routing_list"] = cls._build_routing_list(
                    similarity_scores,
                    boosts={"MULTI_STEP": 0.95},
                    reasons={"MULTI_STEP": ["local_planner"]}
                )
                return "MULTI_STEP", "ğŸ§­ Local-Plan", context_info

        initial_task_hint = cls._quick_task_hint(user_input)
        compound_info = _get_task_decomposer().detect_compound_task(user_input, initial_task_hint)
        
        if compound_info["is_compound"]:
            context_info = {
                "is_multi_step_task": True,
                "multi_step_info": compound_info
            }
            context_info["routing_list"] = base_routing_list
            return "MULTI_STEP", "ğŸ”„ Multi-Step", context_info

        if history and len(history) >= 2 and ContextAnalyzer:
            context_info = ContextAnalyzer.analyze_context(user_input, history)
            if context_info.get("is_continuation") and context_info.get("related_task") == "WEB_SEARCH":
                search_verbs = ["æŸ¥", "æœ", "æœç´¢", "æŸ¥è¯¢", "æ‰¾", "å†æ‰¾", "å†æŸ¥", "å†æœ", "å†çœ‹çœ‹"]
                if any(v in user_lower for v in search_verbs):
                    context_info["routing_list"] = cls._build_routing_list(
                        similarity_scores,
                        boosts={"WEB_SEARCH": 0.9},
                        reasons={"WEB_SEARCH": ["rag:search_followup"]}
                    )
                    return "WEB_SEARCH", "ğŸŒ RAG-Followup", context_info
        
        file_extensions = [".pdf", ".docx", ".doc", ".xlsx", ".xls", ".pptx", ".ppt"]
        file_type_words = ["pdf", "word", "excel", "ppt", "docx", "æ–‡æ¡£", "æŠ¥å‘Š", "ç®€å†", "åˆåŒ", "è¡¨æ ¼", "å¹»ç¯ç‰‡", "è®¡åˆ’", "æ–¹æ¡ˆ", "ææ¡ˆ", "å»ºè®®ä¹¦", "ä¼šè®®è®°å½•"]
        file_action_words = [
            "ç”Ÿæˆ", "åˆ›å»º", "å¯¼å‡º", "å†™ä»½", "å†™ä¸ª", "å†™ä¸€ä¸ª", "åšä¸ª", "åšä¸€ä¸ª", "åˆ¶ä½œ", "è¾“å‡º", "ç¼–å†™", "æ’°å†™", "ç»„ç»‡"
        ]
        
        has_extension = any(ext in user_lower for ext in file_extensions)
        has_file_type = any(ft in user_lower for ft in file_type_words)
        has_action = any(act in user_lower for act in file_action_words)
        has_write_file = ("å†™" in user_lower or "å¸®æˆ‘å†™" in user_lower or "å¸®æˆ‘" in user_lower) and (has_file_type or any(w in user_lower for w in ["è®¡åˆ’", "æ–¹æ¡ˆ", "æŠ¥å‘Š"]))
        
        short_text_patterns = ["å†™ä¸€æ®µ", "å†™ç‚¹", "ä»‹ç»ä¸€ä¸‹", "ä»‹ç»ä¸‹", "è¯´è¯´", "è®²è®²", "èŠèŠ", "è°ˆè°ˆ"]
        is_short_text_request = any(p in user_lower for p in short_text_patterns)
        
        convert_patterns = [
            "æŠŠè¿™ä¸ªåšæˆ", "æŠŠå®ƒåšæˆ", "æŠŠè¿™ä»½åšæˆ",
            "åšæˆword", "åšæˆpdf", "åšæˆæ–‡æ¡£",
            "è½¬æˆword", "è½¬æˆpdf", "å¯¼å‡ºword", "å¯¼å‡ºpdf"
        ]
        is_convert_request = any(p in user_lower for p in convert_patterns)
        
        edit_markers = ["æ ‡æ³¨", "æ‰¹æ³¨", "æ¶¦è‰²", "æ”¹å†™", "æ ¡å¯¹", "å®¡æ ¡", "ä¿®è®¢", "çº é”™"]
        has_edit_marker = any(m in user_lower for m in edit_markers) and has_file_type
        
        is_file_gen = False
        if not is_short_text_request:
            is_file_gen = (has_extension and has_action) or \
                          (has_file_type and (has_action or has_write_file)) or \
                          is_convert_request or \
                          has_edit_marker
        
        if is_file_gen:
            complex_markers = ["åˆ†æ", "æ•´ç†", "è½¬æ¢", "æ ‡æ³¨", "æ‰¹æ³¨", "æ¶¦è‰²", "æ”¹å†™", "æ ¡å¯¹", "å®¡æ ¡", "ä¿®è®¢", "çº é”™", "ç¿»è¯‘è…”", "è¯­åº", "ç”Ÿç¡¬"]
            context_info = {"complexity": "complex" if any(kw in user_lower for kw in complex_markers) else "normal"}
            if is_convert_request and history and len(history) >= 2 and ContextAnalyzer:
                context_info.update(ContextAnalyzer.analyze_context(user_input, history))
                context_info["continuation_type"] = "convert"
                context_info["related_task"] = "FILE_GEN"
            context_info["routing_list"] = cls._build_routing_list(
                similarity_scores,
                boosts={"FILE_GEN": 0.95},
                reasons={"FILE_GEN": ["rule:file_gen"]}
            )
            
            return "FILE_GEN", "ğŸ“„ Rule-Detected", context_info
        
        research_markers = [
            "è¯¦ç»†ç ”ç©¶", "æ·±å…¥ç ”ç©¶", "æ·±å…¥åˆ†æ", "è¯¦ç»†åˆ†æ", "å…¨é¢åˆ†æ", "ç³»ç»Ÿåˆ†æ",
            "æ·±åº¦è§£è¯»", "è¯¦ç»†ä»‹ç»", "å……åˆ†ä»‹ç»", "æŠ€æœ¯åŸç†", "åº•å±‚æœºåˆ¶",
            "å¯¹æ¯”åˆ†æ", "ä¼˜ç¼ºç‚¹åˆ†æ", "research", "in-depth"
        ]
        if any(m in user_lower for m in research_markers):
            context_info = context_info or {}
            context_info["routing_list"] = cls._build_routing_list(
                similarity_scores,
                boosts={"RESEARCH": 0.9},
                reasons={"RESEARCH": ["rule:research"]}
            )
            return "RESEARCH", "ğŸ“š Rule-Detected", context_info
        
        paint_chars = set("ç”»ç»˜")
        paint_words = ["å›¾ç‰‡", "å›¾åƒ", "å£çº¸", "å¤´åƒ", "æ’ç”»", "æµ·æŠ¥", "ç…§ç‰‡", "draw", "paint", "image", "picture", "photo"]
        paint_actions = ["åšä¸€å¼ å›¾", "åšå¼ å›¾", "åšä¸ªå›¾", "æ¥å¼ å›¾", "ç”Ÿæˆå›¾", "å‡ºå¼ å›¾", "ä¸€å¼ å›¾", "ä¸€å¹…å›¾", "ä¸€å¼ ç…§ç‰‡", "æ¥å¼ ç…§ç‰‡", "ç”Ÿæˆç…§ç‰‡", "ç”Ÿæˆä¸€å¼ "]
        paint_modify = ["æ–°çš„å›¾", "æ–°å›¾ç‰‡", "é‡æ–°ç”Ÿæˆ", "å†ç”Ÿæˆ", "å†ç”»", "æ¢ä¸€å¼ ", "å†æ¥ä¸€å¼ "]
        paint_verbs = ["åš", "ç”Ÿæˆ", "åˆ›ä½œ", "åˆ¶ä½œ", "æ¥"]
        
        if any(c in user_lower for c in paint_chars) or any(w in user_lower for w in paint_words) or \
           any(a in user_lower for a in paint_actions) or any(m in user_lower for m in paint_modify) or \
           ("å›¾" in user_lower and any(v in user_lower for v in paint_verbs)):
            context_info = context_info or {}
            context_info["routing_list"] = cls._build_routing_list(
                similarity_scores,
                boosts={"PAINTER": 0.9},
                reasons={"PAINTER": ["rule:paint"]}
            )
            return "PAINTER", "ğŸ¨ Rule-Detected", context_info
        
        code_markers = ["```", "def ", "function ", "class ", "import ", "from ",
                       "ä»£ç ", "ç¼–ç¨‹", "è„šæœ¬", "å‡½æ•°", "ç®—æ³•", "bug", "debug", "è°ƒè¯•", "æŠ¥é”™"]
        if any(m in user_lower for m in code_markers):
            context_info = context_info or {}
            context_info["routing_list"] = cls._build_routing_list(
                similarity_scores,
                boosts={"CODER": 0.9},
                reasons={"CODER": ["rule:code"]}
            )
            return "CODER", "ğŸ’» Rule-Detected", context_info
        
        ticket_keywords = ["12306", "ç«è½¦ç¥¨", "é«˜é“ç¥¨", "åŠ¨è½¦ç¥¨", "è½¦ç¥¨", "ä¹°ç¥¨", "è´­ç¥¨", "ä½™ç¥¨", "è½¦æ¬¡"]
        if any(k in user_lower for k in ticket_keywords):
            context_info = context_info or {}
            context_info["routing_list"] = cls._build_routing_list(
                similarity_scores,
                boosts={"AGENT": 1.0},
                reasons={"AGENT": ["rule:ticket_tool"]}
            )
            return "AGENT", "ğŸ¤– Agent-Tools", context_info

        if WebSearcher and WebSearcher.needs_web_search(user_input):
            context_info = context_info or {}
            context_info["routing_list"] = cls._build_routing_list(
                similarity_scores,
                boosts={"WEB_SEARCH": 0.9},
                reasons={"WEB_SEARCH": ["rule:web_search"]}
            )
            return "WEB_SEARCH", "ğŸŒ Rule-Detected", context_info
        
        if history and len(history) >= 2 and ContextAnalyzer:
            context_info = ContextAnalyzer.analyze_context(user_input, history)
            
            if context_info["is_continuation"] and context_info["confidence"] > 0.7:
                related_task = context_info["related_task"]
                continuation_type = context_info.get("continuation_type", "unknown")
                
                if continuation_type == "convert" or related_task == "FILE_GEN":
                    context_info["routing_list"] = cls._build_routing_list(
                        similarity_scores,
                        boosts={"FILE_GEN": 0.88},
                        reasons={"FILE_GEN": [f"rag:{continuation_type}"]}
                    )
                    return "FILE_GEN", f"ğŸ“„ RAG-{continuation_type}", context_info
                
                if related_task == "PAINTER":
                    context_info["routing_list"] = cls._build_routing_list(
                        similarity_scores,
                        boosts={"PAINTER": 0.88},
                        reasons={"PAINTER": [f"rag:{continuation_type}"]}
                    )
                    return "PAINTER", f"ğŸ¨ RAG-{continuation_type}", context_info
                
                if related_task == "RESEARCH":
                    context_info["routing_list"] = cls._build_routing_list(
                        similarity_scores,
                        boosts={"RESEARCH": 0.88},
                        reasons={"RESEARCH": [f"rag:{continuation_type}"]}
                    )
                    return "RESEARCH", f"ğŸ“š RAG-{continuation_type}", context_info
                
                if related_task:
                    context_info["routing_list"] = cls._build_routing_list(
                        similarity_scores,
                        boosts={related_task: 0.88},
                        reasons={related_task: [f"rag:{continuation_type}"]}
                    )
                    return related_task, f"ğŸ”— RAG-{continuation_type}", context_info
        
        if client:
            ai_task, ai_confidence, ai_source = _get_ai_router().classify(client, user_input, timeout=2.0)
            if ai_task:
                latency = (time.time() - start_time) * 1000
                context_info = context_info or {}
                context_info["routing_list"] = cls._build_routing_list(
                    similarity_scores,
                    boosts={ai_task: 0.8},
                    reasons={ai_task: ["ai_router"]}
                )
                return ai_task, f"{ai_confidence} ({latency:.0f}ms)", context_info
        
        scores = similarity_scores
        best_task = max(scores, key=scores.get)
        best_score = scores[best_task]
        latency = (time.time() - start_time) * 1000
        
        if best_score > 0.3:
            _q_words = ["æ€ä¹ˆ", "å¦‚ä½•", "ä»€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "èƒ½ä¸èƒ½", "å¯ä»¥å—",
                        "æ€æ ·", "å’‹", "å•¥", "how", "what", "why", "which"]
            is_q = any(qw in user_lower for qw in _q_words)
            if is_q and best_score < 0.5 and best_task != "CHAT":
                pass 
            else:
                confidence = f"ğŸ§  ML ({best_score:.0%}, {latency:.1f}ms)"
                context_info = context_info or {}
                context_info["routing_list"] = cls._build_routing_list(
                    similarity_scores,
                    boosts={best_task: best_score},
                    reasons={best_task: ["similarity_best"]}
                )
                return best_task, confidence, context_info
        
        context_info = context_info or {}
        context_info["routing_list"] = base_routing_list
        return "CHAT", f"ğŸ’¬ Default ({latency:.1f}ms)", context_info
    
    @classmethod
    def get_model_for_task(cls, task_type, has_image=False, complexity="normal"):
        """æ ¹æ®ä»»åŠ¡ç±»å‹è·å–æœ€ä¼˜æ¨¡å‹"""
        MODEL_MAP = cls._get_dep("MODEL_MAP")
        if not MODEL_MAP:
             # Default fallback if MODEL_MAP is not configured
             MODEL_MAP = {"CHAT": "gemini-model"}

        if task_type == "FILE_GEN":
            if complexity == "complex":
                return "gemini-3-pro-preview"
            return "gemini-3-flash-preview"
        
        if task_type == "DOC_ANNOTATE":
            return "gemini-3-pro-preview"
            
        if task_type == "RESEARCH":
            return "gemini-3-pro-preview"
        
        if task_type == "CODER":
            return "gemini-3-pro-preview"

        if has_image and task_type != "PAINTER":
            return MODEL_MAP.get("VISION", MODEL_MAP.get("CHAT"))
        
        return MODEL_MAP.get(task_type, MODEL_MAP.get("CHAT"))
