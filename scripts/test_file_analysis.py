"""æµ‹è¯• AI å¢å¼ºåˆ†æå™¨å¯¹å¾®ä¿¡æ–‡ä»¶çš„åˆ†ç±»æ•ˆæœ vs æ—§è§„åˆ™å¼•æ“"""
import sys, os, time
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'web'))

from file_analyzer import FileAnalyzer
from pathlib import Path

analyzer = FileAnalyzer()
src = Path(r'C:\Users\12524\Documents\WeChat Files\wxid_vfk3vjs6qgtn22\FileStorage\File\2026-02')
files = sorted([f for f in src.rglob('*') if f.is_file()], key=lambda x: x.name)

# å»é‡ï¼šåŒä¸€æ–‡ä»¶åçš„ _revised ç‰ˆæœ¬åªåˆ†æåŸå§‹ç‰ˆ
seen_stems = {}
unique_files = []
for f in files:
    stem = analyzer._clean_filename_stem(f.stem)
    if stem not in seen_stems:
        seen_stems[stem] = f
        unique_files.append(f)

print(f"\nå…± {len(files)} ä¸ªæ–‡ä»¶ï¼Œ{len(unique_files)} ä¸ªä¸é‡å¤ä¸»é¢˜\n")
print(f"{'æ–‡ä»¶å':<48} | {'AI?':<3} | {'è¡Œä¸š':<15} | {'ç±»åˆ«':<15} | {'ç½®ä¿¡åº¦':<6} | {'å®ä½“':<22} | å»ºè®®è·¯å¾„")
print("-" * 170)

start = time.time()
for f in unique_files:
    r = analyzer.analyze_file(str(f))
    if r.get('success'):
        name = f.name[:46]
        ai_flag = "âœ¦" if r.get('ai_enhanced') else " "
        industry = r['industry']
        category = r['category']
        confidence = f"{r['confidence']:.2f}"
        entity = (r.get('entity') or '')[:20]
        folder = r['suggested_folder']
        print(f"{name:<48} | {ai_flag:<3} | {industry:<15} | {category:<15} | {confidence:<6} | {entity:<22} | {folder}")

elapsed = time.time() - start
print(f"\nåˆ†æè€—æ—¶: {elapsed:.1f}s (å¹³å‡ {elapsed/len(unique_files):.1f}s/æ–‡ä»¶)")

# ä¹Ÿæ˜¾ç¤ºé‡å¤æ–‡ä»¶çš„åˆå¹¶æƒ…å†µ
dupes = len(files) - len(unique_files)
if dupes > 0:
    print(f"\nğŸ“‹ {dupes} ä¸ªä¿®è®¢/å‰¯æœ¬ç‰ˆæœ¬å°†åˆå¹¶åˆ°åŒä¸»é¢˜æ–‡ä»¶å¤¹ä¸­")
    for stem, f in seen_stems.items():
        versions = [x for x in files if analyzer._clean_filename_stem(x.stem) == stem]
        if len(versions) > 1:
            print(f"  {stem}: {len(versions)} ä¸ªç‰ˆæœ¬")
